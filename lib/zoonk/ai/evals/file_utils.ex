defmodule Zoonk.AI.Evals.FileUtils do
  @moduledoc false
  require Logger

  @doc """
  Stores results generated by an AI model.

  We use these results to evaluate the model's performance
  and to compare it against other models.

  ## Examples

      iex> store_model("openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json", %{})
      :ok

      iex> store_model("openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json", %{})
      :ok

  """
  def store_model(model, prompt, results_dir, filename, data) do
    Logger.info("Storing model results for #{model} in #{filename}")

    model_name = String.replace(model, "/", "_")
    prompt = prompt_name(prompt)

    dir = Path.join(["priv", "evals", "models", model_name, prompt, results_dir])
    File.mkdir_p!(dir)

    file_path = Path.join(dir, filename)
    file_content = Jason.encode!(data, pretty: true)

    File.write!(file_path, file_content)

    Logger.info("Stored model results in #{file_path}")
  end

  @doc """
  Stores the results generated by a prompt.

  We use these results to evaluate the prompt's performance
  and to compare it against other prompts.

  ## Examples

      iex> store_prompt(:recommend_courses, "outputs", "test_1.json", %{})
      :ok

      iex> store_prompt(:recommend_courses, "scores", "test_1.json", %{})
      :ok
  """
  def store_prompt(prompt, results_dir, filename, data) do
    Logger.info("Storing prompt results for #{prompt} in #{filename}")

    prompt = prompt_name(prompt)

    dir = Path.join(["priv", "evals", "prompts", prompt, results_dir])
    File.mkdir_p!(dir)

    file_path = Path.join(dir, filename)
    file_content = Jason.encode!(data, pretty: true)

    File.write!(file_path, file_content)

    Logger.info("Stored prompt results in #{file_path}")
  end

  defp prompt_name(prompt) when is_atom(prompt), do: Atom.to_string(prompt)
  defp prompt_name(prompt) when is_binary(prompt), do: prompt
end
