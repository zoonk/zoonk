defmodule Zoonk.AI.Evals.FileUtils do
  @moduledoc """
  Utility functions to store and retrieve evaluation
  results for AI models and prompts.

  This module helps persist outputs and scores from
  LLM evaluations, avoiding duplicate processing and
  enabling comparison between models and prompts.

  It organizes the results in a structured directory
  format under `priv/evals`.
  """
  require Logger

  @doc """
  Stores results generated by an AI model.

  We use these results to evaluate the model's performance
  and to compare it against other models.

  ## Examples

      iex> store_model("openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json", %{})
      :ok

      iex> store_model("openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json", %{})
      :ok

  """
  def store_model(model, prompt, results_dir, filename, data) do
    Logger.info("Storing model results for #{model} in #{filename}")

    model
    |> model_dir!(prompt, results_dir)
    |> write_file!(filename, data)
  end

  @doc """
  Stores the results generated by a prompt.

  We use these results to evaluate the prompt's performance
  and to compare it against other prompts.

  ## Examples

      iex> store_prompt(:recommend_courses, "outputs", "test_1.json", %{})
      :ok

      iex> store_prompt(:recommend_courses, "scores", "test_1.json", %{})
      :ok
  """
  def store_prompt(prompt, results_dir, filename, data) do
    Logger.info("Storing prompt results for #{prompt} in #{filename}")

    prompt
    |> prompt_dir!(results_dir)
    |> write_file!(filename, data)
  end

  @doc """
  Checks if a model file exists.

  This is useful to avoid sending duplicated requests
  to LLMs when we've already stored the results.

  ## Examples

      iex> model_file_exists?("openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json")
      true

      iex> model_file_exists?("openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json")
      false
  """
  def model_file_exists?(model, prompt, results_dir, filename) do
    model
    |> model_dir!(prompt, results_dir)
    |> Path.join(filename)
    |> File.exists?()
  end

  @doc """
  Checks if a prompt file exists.

  This is useful to avoid sending duplicated requests
  to LLMs when we've already stored the results.

  ## Examples

      iex> prompt_file_exists?(:recommend_courses, "outputs", "test_1.json")
      true

      iex> prompt_file_exists?(:recommend_courses, "scores", "test_1.json")
      false
  """
  def prompt_file_exists?(prompt, results_dir, filename) do
    prompt
    |> prompt_dir!(results_dir)
    |> Path.join(filename)
    |> File.exists?()
  end

  defp model_dir!(model, prompt, results_dir) do
    model_name = String.replace(model, "/", "_")
    prompt = prompt_name(prompt)

    Path.join(["priv", "evals", "models", model_name, prompt, results_dir])
  end

  defp prompt_dir!(prompt, results_dir) do
    prompt = prompt_name(prompt)

    Path.join(["priv", "evals", "prompts", prompt, results_dir])
  end

  defp write_file!(dir, filename, data) do
    File.mkdir_p!(dir)

    file_path = Path.join(dir, filename)
    file_content = Jason.encode!(data, pretty: true)

    File.write!(file_path, file_content)

    Logger.info("Stored results in #{file_path}")
  end

  defp prompt_name(prompt) when is_atom(prompt), do: Atom.to_string(prompt)
  defp prompt_name(prompt) when is_binary(prompt), do: prompt
end
