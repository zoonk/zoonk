defmodule Zoonk.AI.Evals.EvalFiles do
  @moduledoc """
  Utility functions to store and retrieve evaluation
  results for AI models and prompts.

  This module helps persist outputs and scores from
  LLM evaluations, avoiding duplicate processing and
  enabling comparison between models and prompts.

  It organizes the results in a structured directory
  format under `priv/evals`.
  """
  require Logger

  @type eval_type :: :model | :prompt

  @doc """
  Stores results generated by an AI model.

  We use these results to evaluate the model's performance
  and to compare it against other models.

  ## Examples

      iex> store_results(:model, "openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json", %{})
      :ok

      iex> store_results(:prompt, "openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json", %{})
      :ok

  """
  @spec store_results(eval_type(), String.t(), atom(), String.t(), String.t(), map()) :: :ok
  def store_results(eval_type, model, prompt, results_dir, filename, data) do
    Logger.info("Storing #{eval_type} results for #{model} in #{filename}")

    eval_type
    |> results_dir!(model, prompt, results_dir)
    |> write_file!(filename, data)
  end

  @doc """
  Checks if a model file exists.

  This is useful to avoid sending duplicated requests
  to LLMs when we've already stored the results.

  ## Examples

      iex> file_exists?(:model, "openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json")
      true

      iex> file_exists?(:prompt, "openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json")
      false
  """
  @spec file_exists?(eval_type(), String.t(), atom(), String.t(), String.t()) :: boolean()
  def file_exists?(eval_type, model, prompt, results_dir, filename) do
    eval_type
    |> results_dir!(model, prompt, results_dir)
    |> Path.join(filename)
    |> File.exists?()
  end

  defp results_dir!(:model, model, prompt, results_dir) do
    model_name = model_name(model)
    prompt = prompt_name(prompt)

    Path.join(["priv", "evals", "models", model_name, prompt, results_dir])
  end

  defp results_dir!(:prompt, _model, prompt, results_dir) do
    prompt = prompt_name(prompt)

    Path.join(["priv", "evals", "prompts", prompt, results_dir])
  end

  defp write_file!(dir, filename, data) do
    File.mkdir_p!(dir)

    file_path = Path.join(dir, filename)
    file_content = Jason.encode!(data, pretty: true)

    File.write!(file_path, file_content)

    Logger.info("Stored results in #{file_path}")
  end

  defp prompt_name(prompt) when is_atom(prompt), do: Atom.to_string(prompt)
  defp prompt_name(prompt) when is_binary(prompt), do: prompt

  defp model_name(model) do
    model
    |> String.split("/", parts: 2)
    |> List.last()
    |> String.replace("/", "_")
    |> String.replace_suffix(":free", "")
  end
end
