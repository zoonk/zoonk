defmodule Zoonk.AI.Evals.EvalFiles do
  @moduledoc """
  Utility functions to store and retrieve evaluation
  results for AI models and prompts.

  This module helps persist outputs and scores from
  LLM evaluations, avoiding duplicate processing and
  enabling comparison between models and prompts.

  It organizes the results in a structured directory
  format under `priv/evals`.
  """
  require Logger

  @type eval_type :: :model | :prompt

  @doc """
  Stores results generated by an AI model.

  We use these results to evaluate the model's performance
  and to compare it against other models.

  ## Examples

      iex> store_output(:model, "openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json", %{})
      :ok

      iex> store_output(:prompt, "openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json", %{})
      :ok

  """
  def store_output(eval_type, model, prompt, results_dir, filename, data) do
    Logger.info("Storing #{eval_type} results for #{model} in #{filename}")

    eval_type
    |> output_dir!(model, prompt, results_dir)
    |> write_file!(filename, data)
  end

  @doc """
  Loads results from a file.

  This is useful to retrieve previously stored results
  for evaluation without needing to re-run the model.

  It parses the JSON file and returns the data as a map with string keys.

  ## Examples

      iex> load_results(:model, "openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json")
      %{...}

      iex> load_results(:prompt, "openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json")
      %{...}
  """
  def load_results(eval_type, model, prompt, results_dir, filename) do
    eval_type
    |> output_dir!(model, prompt, results_dir)
    |> Path.join(filename)
    |> File.read!()
    |> Jason.decode!()
  end

  @doc """
  Checks if a model file exists.

  This is useful to avoid sending duplicated requests
  to LLMs when we've already stored the results.

  ## Examples

      iex> file_exists?(:model, "openai/gpt-4.1-mini", :recommend_courses, "outputs", "test_1.json")
      true

      iex> file_exists?(:prompt, "openai/gpt-4.1-mini", :recommend_courses, "scores", "test_1.json")
      false
  """
  def file_exists?(eval_type, model, prompt, results_dir, filename) do
    eval_type
    |> output_dir!(model, prompt, results_dir)
    |> Path.join(filename)
    |> File.exists?()
  end

  defp output_dir!(:model, model, prompt, results_dir) do
    model_name = model_name(model)
    prompt = prompt_name(prompt)

    Path.join(["priv", "evals", "models", model_name, prompt, results_dir])
  end

  defp output_dir!(:prompt, _model, prompt, results_dir) do
    prompt = prompt_name(prompt)

    Path.join(["priv", "evals", "prompts", prompt, results_dir])
  end

  defp write_file!(dir, filename, data) do
    File.mkdir_p!(dir)

    file_path = Path.join(dir, filename)
    file_content = Jason.encode!(data, pretty: true)

    File.write!(file_path, file_content)

    Logger.info("Stored results in #{file_path}")
  end

  defp prompt_name(prompt) when is_atom(prompt), do: Atom.to_string(prompt)
  defp prompt_name(prompt) when is_binary(prompt), do: prompt

  defp model_name(model) do
    model
    |> String.split("/", parts: 2)
    |> List.last()
    |> String.replace("/", "_")
    |> String.replace_suffix(":free", "")
  end
end
