{
  "generatedAt": "2026-01-17T15:46:57.440Z",
  "modelId": "anthropic/claude-sonnet-4.5",
  "outputs": [
    {
      "duration": 142252.51504199998,
      "inputTokens": 4218,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we've got a production bug. Users are getting random crashes when they try to view their order history. I traced it to the OrderSummary component — someone's passing undefined to it sometimes, and it's calling .formatDate() on that undefined value. Classic runtime error.\",\n      \"options\": [\n        {\n          \"feedback\": \"That's a runtime fix, but TypeScript should have caught this before deployment. The real issue is we're not using the type system to prevent undefined from being passed in the first place.\",\n          \"isCorrect\": false,\n          \"text\": \"The component should check for undefined\"\n        },\n        {\n          \"feedback\": \"Exactly. If we properly typed the component props, TypeScript would've flagged any code trying to pass undefined. Type safety catches these bugs before they reach production.\",\n          \"isCorrect\": true,\n          \"text\": \"Type safety wasn't enforced at compile time\"\n        },\n        {\n          \"feedback\": \"Adding error handling treats the symptom. With proper types, TypeScript prevents you from calling formatDate on undefined in the first place — the bug never exists.\",\n          \"isCorrect\": false,\n          \"text\": \"The formatDate function needs error handling\"\n        },\n        {\n          \"feedback\": \"Logging helps debug issues, but doesn't prevent them. Type safety stops this entire class of bugs at compile time, before any code runs.\",\n          \"isCorrect\": false,\n          \"text\": \"We need better runtime logging\"\n        }\n      ],\n      \"question\": \"What's the root issue here?\"\n    },\n    {\n      \"context\": \"Right. Let me pull up the component definition. Oh... I see it. The props interface says 'order: Order', but half our API endpoints return 'order: Order | null' when there's no order history yet. So we're literally passing null into something that expects a non-null Order.\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. This accurately represents reality — orders can be null. Now TypeScript will force us to handle that null case inside the component, which is exactly what we need.\",\n          \"isCorrect\": true,\n          \"text\": \"Change the prop type to Order | null\"\n        },\n        {\n          \"feedback\": \"Type casting (as Order) silences TypeScript but doesn't solve the problem. You're lying to the compiler, and the runtime crash will still happen when null arrives.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep it as Order and cast the API response\"\n        },\n        {\n          \"feedback\": \"That's overly broad. We don't need all props optional — just the order field needs to reflect that it can be null. Too much optionality makes the type less useful.\",\n          \"isCorrect\": false,\n          \"text\": \"Make the entire props object optional\"\n        },\n        {\n          \"feedback\": \"Using 'any' disables all type checking for that prop. You've just thrown away all the safety TypeScript provides. That's worse than having no types at all.\",\n          \"isCorrect\": false,\n          \"text\": \"Use 'any' for the order prop\"\n        }\n      ],\n      \"question\": \"How should we fix the type mismatch?\"\n    },\n    {\n      \"context\": \"Good call. I updated it to 'order: Order | null'. Now TypeScript is yelling at me everywhere we try to access order properties — 'Object is possibly null'. Which... is exactly what we want, honestly. Better to fix it now than in production.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. Type narrowing in action — inside an if-block that checks 'if (order !== null)', TypeScript knows order is definitely an Order, not null. Safe access guaranteed.\",\n          \"isCorrect\": true,\n          \"text\": \"Add null checks before accessing properties\"\n        },\n        {\n          \"feedback\": \"Writing 'order!.formatDate()' tells TypeScript 'trust me, it's not null' — but you're just guessing. If you're wrong, hello runtime crash. Defeats the purpose of the type system.\",\n          \"isCorrect\": false,\n          \"text\": \"Use the non-null assertion operator (!)\"\n        },\n        {\n          \"feedback\": \"Try-catch is for runtime errors you can't prevent. Here, TypeScript is offering to prevent the error at compile time with proper null checking. Use the type system, not runtime handlers.\",\n          \"isCorrect\": false,\n          \"text\": \"Wrap everything in try-catch blocks\"\n        },\n        {\n          \"feedback\": \"Turning off strictNullChecks is like unplugging a smoke detector because it's beeping. Null reference bugs are exactly what we're trying to prevent — don't disable the protection.\",\n          \"isCorrect\": false,\n          \"text\": \"Disable strict null checks in tsconfig\"\n        }\n      ],\n      \"question\": \"How do we safely access order properties now?\"\n    },\n    {\n      \"context\": \"Okay, I've added null checks throughout the component. Much cleaner. Now I'm looking at the API layer... {{NAME}}, we have five different endpoint functions that all return order data, and they each define their own interface. OrderResponse, ApiOrder, OrderData, FetchedOrder... they're all structurally identical but TypeScript treats them as separate.\",\n      \"options\": [\n        {\n          \"feedback\": \"TypeScript isn't confused — it's working exactly as designed. Understanding why requires knowing how TypeScript's type system actually works.\",\n          \"isCorrect\": false,\n          \"text\": \"TypeScript is broken and confused\"\n        },\n        {\n          \"feedback\": \"Exactly. TypeScript cares about shape, not names. If OrderResponse and ApiOrder have identical properties, they're compatible. This is structural typing — the structure matters, not what you called it.\",\n          \"isCorrect\": true,\n          \"text\": \"It uses structural typing, not nominal\"\n        },\n        {\n          \"feedback\": \"No, these are properly defined interfaces. If they were 'any', you wouldn't get any type checking at all. This is about how TypeScript compares types.\",\n          \"isCorrect\": false,\n          \"text\": \"They're all implicitly 'any' types\"\n        },\n        {\n          \"feedback\": \"Type assertions would force compatibility, but that's not what's happening here. TypeScript is naturally accepting them because of how it determines type compatibility.\",\n          \"isCorrect\": false,\n          \"text\": \"Someone used type assertions everywhere\"\n        }\n      ],\n      \"question\": \"Why is TypeScript accepting these different types interchangeably?\"\n    },\n    {\n      \"context\": \"Right, structural typing. So we could consolidate these into a single Order interface, and everything would still work because the structure matches. That'll clean up this mess. Speaking of cleanup... there's this utility function, processOrderItems, that's supposed to work with different item types — CartItem, WishlistItem, SavedItem. They all have 'id' and 'quantity' but other different fields.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. Something like <T extends {id: string, quantity: number}> lets you write reusable code that works with any type having those fields, while preserving specific type info. This is what generics are for.\",\n          \"isCorrect\": true,\n          \"text\": \"Use a generic type with constraints\"\n        },\n        {\n          \"feedback\": \"Using 'any' gives flexibility but destroys all type safety. You lose autocomplete, refactoring support, and error detection. Generics give you flexibility AND safety — always prefer that.\",\n          \"isCorrect\": false,\n          \"text\": \"Type it as 'any[]' for flexibility\"\n        },\n        {\n          \"feedback\": \"CartItem | WishlistItem | SavedItem works, but now you can ONLY use these three types. Generics would let it work with ANY type that has the required fields — more flexible and reusable.\",\n          \"isCorrect\": false,\n          \"text\": \"Create a union type of all three\"\n        },\n        {\n          \"feedback\": \"You'd be copy-pasting the same logic three times. Generics exist specifically to avoid this — write once, work with multiple types while keeping type safety intact.\",\n          \"isCorrect\": false,\n          \"text\": \"Make separate functions for each type\"\n        }\n      ],\n      \"question\": \"How do we type processOrderItems to work with all three?\"\n    },\n    {\n      \"context\": \"Nice, I made it generic. Now it works with all three item types and we're getting full autocomplete. This is way better. Okay, moving on... {{NAME}}, I'm looking at our webhook handler. It receives data from external services, and the previous dev typed the payload parameter as 'any' because 'we don't know what format different webhooks will send.' Thoughts?\",\n      \"options\": [\n        {\n          \"feedback\": \"'Any' disables all type checking. You can accidentally call methods that don't exist, access wrong properties, and TypeScript won't help. There's a better option for truly unknown types.\",\n          \"isCorrect\": false,\n          \"text\": \"It's fine — we truly don't know the type\"\n        },\n        {\n          \"feedback\": \"Exactly. 'Unknown' says 'I don't know the type yet' but forces you to check before using it. You must narrow the type (with validation) before accessing properties. 'Any' is a free-for-all; 'unknown' is safe uncertainty.\",\n          \"isCorrect\": true,\n          \"text\": \"Should use 'unknown' instead\"\n        },\n        {\n          \"feedback\": \"A union of all possible webhook types could work, but you can't predict every external service. 'Unknown' handles truly unpredictable data while forcing you to validate before use.\",\n          \"isCorrect\": false,\n          \"text\": \"Should create a mega-interface with all fields\"\n        },\n        {\n          \"feedback\": \"TypeScript absolutely helps with external data — that's what 'unknown' is for. It forces you to validate and narrow the type before use, catching bugs where you assume the wrong structure.\",\n          \"isCorrect\": false,\n          \"text\": \"TypeScript can't help with external data\"\n        }\n      ],\n      \"question\": \"What's wrong with using 'any' for unknown webhook payloads?\"\n    },\n    {\n      \"context\": \"Good point. I'll switch it to 'unknown' and add proper validation. That way we're forced to check what we actually received before trying to use it. Much safer. Alright, I'm writing a validation function now — isStripeWebhook — that checks if the payload has the right structure. If it returns true, I want TypeScript to know the payload is a StripeWebhook type.\",\n      \"options\": [\n        {\n          \"feedback\": \"Type assertions don't create runtime guarantees. You're just telling TypeScript to trust you. A type guard actually checks the structure AND tells TypeScript about it.\",\n          \"isCorrect\": false,\n          \"text\": \"Cast the result with 'as StripeWebhook'\"\n        },\n        {\n          \"feedback\": \"Exactly. Define it as 'function isStripeWebhook(payload: unknown): payload is StripeWebhook'. The 'is' keyword is a type predicate — it tells TypeScript that if the function returns true, the payload is definitely that type.\",\n          \"isCorrect\": true,\n          \"text\": \"Use a type predicate in the return type\"\n        },\n        {\n          \"feedback\": \"A plain boolean return doesn't narrow types. TypeScript sees 'true' but doesn't know what that means about the payload's type. You need an explicit type predicate with 'is'.\",\n          \"isCorrect\": false,\n          \"text\": \"Just return boolean; TypeScript will infer it\"\n        },\n        {\n          \"feedback\": \"That defeats the purpose. The whole point is checking if an unknown payload IS a StripeWebhook. You can't check if something matches a type if you've already claimed it is that type.\",\n          \"isCorrect\": false,\n          \"text\": \"Change the parameter type to StripeWebhook\"\n        }\n      ],\n      \"question\": \"How do we make TypeScript understand the type after validation?\"\n    },\n    {\n      \"context\": \"Perfect. I added the type predicate and now TypeScript knows the type after the check passes. The webhook handler is way safer now. {{NAME}}, while I was refactoring, I found something weird. There's a function called 'getUser' that returns User | undefined, and then immediately there's code that does 'const name = getUser().name' without any checks. But... TypeScript isn't complaining. At all.\",\n      \"options\": [\n        {\n          \"feedback\": \"Bingo. Without strict mode (or at least strictNullChecks), TypeScript doesn't enforce checking for undefined/null. Someone turned off the safety features. Time to enable strict mode in tsconfig.json.\",\n          \"isCorrect\": true,\n          \"text\": \"Strict mode must be disabled\"\n        },\n        {\n          \"feedback\": \"TypeScript absolutely checks return types. If strict mode is enabled and getUser returns User | undefined, it will force you to handle the undefined case before accessing properties.\",\n          \"isCorrect\": false,\n          \"text\": \"TypeScript doesn't check function returns\"\n        },\n        {\n          \"feedback\": \"The code is 'getUser().name', not 'getUser()?.name'. There's no optional chaining here — this is a direct property access that would crash if getUser returns undefined.\",\n          \"isCorrect\": false,\n          \"text\": \"The code is using optional chaining\"\n        },\n        {\n          \"feedback\": \"Try-catch doesn't affect TypeScript's type checking. It catches runtime errors, but TypeScript should prevent this error at compile time if strict mode is enabled.\",\n          \"isCorrect\": false,\n          \"text\": \"It's in a try-catch block\"\n        }\n      ],\n      \"question\": \"Why isn't TypeScript catching this unsafe access?\"\n    },\n    {\n      \"context\": \"Let me check tsconfig... yep, 'strict: false'. Fantastic. I'm enabling strict mode now. And... wow, {{NAME}}, TypeScript just lit up like a Christmas tree. 847 errors. Everything from implicit 'any' types to null checks we're missing to unsafe type assertions. This is going to take a while to fix.\",\n      \"options\": [\n        {\n          \"feedback\": \"Fixing 847 errors in one PR is a nightmare for review and debugging. If something breaks, you won't know which change caused it. Incremental migration is safer and more manageable.\",\n          \"isCorrect\": false,\n          \"text\": \"Fix them all at once before merging\"\n        },\n        {\n          \"feedback\": \"These errors represent real bugs waiting to happen. Turning strict mode off means staying vulnerable to null crashes, type mismatches, and runtime errors. The risk is in NOT fixing them.\",\n          \"isCorrect\": false,\n          \"text\": \"Turn strict mode back off — too risky\"\n        },\n        {\n          \"feedback\": \"Smart. Enable strict mode, but use @ts-expect-error comments to suppress errors in unfixed files. Then migrate file by file, removing suppressions as you go. Gradual, reviewable, testable.\",\n          \"isCorrect\": true,\n          \"text\": \"Migrate incrementally, file by file\"\n        },\n        {\n          \"feedback\": \"Casting everything to 'any' defeats the entire purpose of strict mode. You're just hiding errors, not fixing them. The bugs remain, you've just made TypeScript stop warning you about them.\",\n          \"isCorrect\": false,\n          \"text\": \"Add 'as any' everywhere to silence errors\"\n        }\n      ],\n      \"question\": \"What's the best approach to fixing 847 strict mode errors?\"\n    },\n    {\n      \"context\": \"Incremental migration it is. I'll tackle the critical paths first — the payment flow, authentication, user data handling. Those are where null reference bugs would hurt the most. Actually, {{NAME}}... wait. Remember that production crash we started with? The one in OrderSummary?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! When we changed the prop to Order | null and added null checks, we fixed the crash. Type safety doesn't just catch future bugs — it forces you to handle edge cases properly right now.\",\n          \"isCorrect\": true,\n          \"text\": \"It's already fixed by our type changes\"\n        },\n        {\n          \"feedback\": \"The runtime checks are the null guards we added after changing the type. Those changes happened together — TypeScript forced us to add the checks when we made the type accurate.\",\n          \"isCorrect\": false,\n          \"text\": \"We still need to deploy the runtime checks\"\n        },\n        {\n          \"feedback\": \"Monitoring is good practice, but the crash is already fixed. Once we deploy the type-safe version with proper null checks, the error can't happen anymore.\",\n          \"isCorrect\": false,\n          \"text\": \"We should add error monitoring first\"\n        },\n        {\n          \"feedback\": \"The API returning null for missing orders is correct behavior — not all users have order history. The bug was the component not handling that valid null case. The types now enforce handling it.\",\n          \"isCorrect\": false,\n          \"text\": \"We need to find the root API issue\"\n        }\n      ],\n      \"question\": \"What are you thinking?\"\n    },\n    {\n      \"context\": \"Right! I just tested it locally — OrderSummary now shows a nice 'No orders yet' message when order is null, instead of crashing. The type system forced us to handle that case. {{NAME}}, I'm running the type checker on the whole codebase now with our changes... and oh. Oh wow. It just caught three other null reference bugs in different components that we didn't even know about.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Once you properly type your code, TypeScript catches not just the bug you're fixing, but every similar bug throughout the codebase. Type safety compounds — the more you add, the more bugs you prevent.\",\n          \"isCorrect\": true,\n          \"text\": \"It prevents entire categories of bugs\"\n        },\n        {\n          \"feedback\": \"Actually the opposite. Type checking is exhaustive — it analyzes every single type interaction in the codebase. It catches bugs you didn't know existed in places you weren't even looking.\",\n          \"isCorrect\": false,\n          \"text\": \"It only catches the bugs you look for\"\n        },\n        {\n          \"feedback\": \"Type checking happens in seconds at compile time. Finding these three bugs with runtime testing would require writing tests, running them, waiting for crashes, debugging — hours of work. The type system found them instantly.\",\n          \"isCorrect\": false,\n          \"text\": \"It's slower than runtime testing\"\n        },\n        {\n          \"feedback\": \"Type errors aren't new bugs — they're existing bugs that TypeScript is exposing. The bugs were always there in the code, the type system just makes them visible before they crash in production.\",\n          \"isCorrect\": false,\n          \"text\": \"It creates more bugs than it fixes\"\n        }\n      ],\n      \"question\": \"What does this reveal about type safety?\"\n    },\n    {\n      \"context\": \"I'm fixing those three bugs now. Each one was the same pattern — functions returning nullable values, components not checking before accessing properties. This would've been three production incidents. {{NAME}}, I think I'm finally understanding why people say TypeScript pays for itself. The upfront effort of adding types is way less than the cost of debugging runtime crashes.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. A type error at compile time takes seconds to fix. A runtime crash in production costs hours of debugging, incident response, user frustration, and potentially lost revenue. Type safety shifts bugs left — catch them early when they're cheap.\",\n          \"isCorrect\": true,\n          \"text\": \"Type errors are cheaper than runtime bugs\"\n        },\n        {\n          \"feedback\": \"TypeScript catches type-related bugs, but you still need tests for business logic, edge cases, and integration. Type safety and testing complement each other — both are essential.\",\n          \"isCorrect\": false,\n          \"text\": \"TypeScript eliminates the need for testing\"\n        },\n        {\n          \"feedback\": \"Even with great tests, you can miss null reference bugs in untested code paths. Strict mode catches them automatically across the entire codebase. Why make testing do what the type system does better?\",\n          \"isCorrect\": false,\n          \"text\": \"Strict mode is optional if you test well\"\n        },\n        {\n          \"feedback\": \"Type safety helps at any scale. Even small projects benefit from catching null errors, type mismatches, and refactoring mistakes. The benefits scale up, but they start immediately.\",\n          \"isCorrect\": false,\n          \"text\": \"Types only help in large codebases\"\n        }\n      ],\n      \"question\": \"What's the key insight here?\"\n    },\n    {\n      \"context\": \"Alright, I've fixed all the critical path files — payments, auth, user profiles. All properly typed, all null-safe, all using type guards where we validate external data. The test suite is passing. {{NAME}}, I'm going to create a PR with these changes and the strict mode config update. Wait... actually, there's one more thing. The original webhook handler with 'unknown' types — I want to show the team why 'unknown' is better than 'any' with a concrete example. Help me write a good commit message explaining it.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. That's the critical distinction. 'Unknown' is safe uncertainty — you must validate before use. 'Any' is unsafe trust — you can do anything and TypeScript won't stop you. Unknown forces good practices; any enables bad ones.\",\n          \"isCorrect\": true,\n          \"text\": \"'Unknown' requires validation; 'any' doesn't\"\n        },\n        {\n          \"feedback\": \"Both 'unknown' and 'any' compile to the same JavaScript — there's no runtime difference. The difference is compile-time safety. Unknown forces you to add validation code; any lets you skip it dangerously.\",\n          \"isCorrect\": false,\n          \"text\": \"'Unknown' is faster at runtime\"\n        },\n        {\n          \"feedback\": \"It's not about what works better with APIs — both technically work. It's about safety. Unknown forces you to validate API responses before trusting them; any lets you blindly assume the structure is correct.\",\n          \"isCorrect\": false,\n          \"text\": \"'Unknown' works with external APIs better\"\n        },\n        {\n          \"feedback\": \"There are rare legitimate uses for 'any' — like interfacing with truly dynamic JavaScript libraries. But for most cases where you 'don't know the type yet,' unknown is the safer choice. Any is an escape hatch, not a default.\",\n          \"isCorrect\": false,\n          \"text\": \"'Any' should never be used in TypeScript\"\n        }\n      ],\n      \"question\": \"What's the core difference to emphasize?\"\n    },\n    {\n      \"context\": \"Great explanation. I'll use that in the commit message. PR is ready. {{NAME}}, before I push this... I just realized something. When we started this morning, we had one production crash. Now we've fixed that crash, prevented three more we didn't know about, made our API layer type-safe, and set up the codebase to catch these bugs automatically going forward. Not bad for a Tuesday.\",\n      \"options\": [\n        {\n          \"feedback\": \"Strict mode is great, but the deeper lesson is about mindset. Type safety isn't a configuration option — it's a way of thinking. Design with types first, and bugs become structurally impossible rather than caught after the fact.\",\n          \"isCorrect\": false,\n          \"text\": \"Always enable strict mode from the start\"\n        },\n        {\n          \"feedback\": \"Exactly. This is the power of type safety — it doesn't just catch bugs, it makes entire categories of bugs impossible to write. When you encode constraints in types, the compiler enforces them everywhere, automatically, forever.\",\n          \"isCorrect\": true,\n          \"text\": \"Type systems prevent bugs before they exist\"\n        },\n        {\n          \"feedback\": \"It's not about better or worse — TypeScript IS JavaScript, just with a type layer. The lesson is that catching bugs at compile time beats finding them in production, regardless of language.\",\n          \"isCorrect\": false,\n          \"text\": \"TypeScript is better than JavaScript\"\n        },\n        {\n          \"feedback\": \"Testing remains critical for business logic and integration. The lesson is that type safety and testing work together — types catch structure errors automatically, freeing tests to focus on behavior and edge cases.\",\n          \"isCorrect\": false,\n          \"text\": \"Testing is less important with TypeScript\"\n        }\n      ],\n      \"question\": \"What's the lasting takeaway from this experience?\"\n    },\n    {\n      \"context\": \"Exactly. And you know the best part? Once these types are in place, they keep working. Every future change gets type-checked automatically. If someone tries to pass undefined to OrderSummary six months from now, TypeScript will stop them immediately. We're not just fixing bugs — we're building guardrails that prevent them permanently. Alright, pushing the PR now. {{NAME}}, thanks for talking through this with me. I think I finally get why type safety isn't just a nice-to-have.\",\n      \"options\": [\n        {\n          \"feedback\": \"That's it. Without types, every change is risky — you might break something anywhere. With types, the compiler verifies correctness across the entire codebase. You can refactor fearlessly. Type safety makes large, complex systems maintainable.\",\n          \"isCorrect\": true,\n          \"text\": \"It scales developer confidence with codebase size\"\n        },\n        {\n          \"feedback\": \"TypeScript compiles to JavaScript — there's no runtime performance difference. The value is development speed, bug prevention, and maintainability, not execution speed.\",\n          \"isCorrect\": false,\n          \"text\": \"It makes code run faster in production\"\n        },\n        {\n          \"feedback\": \"Most frameworks work fine with plain JavaScript. TypeScript is optional tooling. What makes it fundamental is the engineering value — safer refactoring, better tooling, fewer bugs — not framework requirements.\",\n          \"isCorrect\": false,\n          \"text\": \"It's required by modern frameworks\"\n        },\n        {\n          \"feedback\": \"Types ARE documentation, but they don't replace explanatory comments or architecture docs. The fundamental value is bug prevention and refactoring safety, not just communication (though that's a nice bonus).\",\n          \"isCorrect\": false,\n          \"text\": \"It replaces code documentation\"\n        }\n      ],\n      \"question\": \"Why is type safety a fundamental practice, not optional?\"\n    }\n  ]\n}",
      "outputTokens": 6401,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-cs-typescript-type-safety-1",
      "userPrompt": "LESSON_TITLE: Type Safety in Practice\nLESSON_DESCRIPTION: Applying TypeScript's type system to catch bugs early and write more maintainable code\nCHAPTER_TITLE: Type Systems\nCOURSE_TITLE: Advanced TypeScript\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Compile-Time Safety: Type safety catches errors at compile time instead of runtime. When TypeScript knows a variable's type, it can prevent operations that would fail — like calling .length on undefined.\n2. Structural Typing: TypeScript uses structural typing — it cares about shape, not names. Two types are compatible if they have the same structure, even if defined separately.\n3. Type Narrowing: Type narrowing lets TypeScript understand more specific types after checks. Inside an if-block that checks for null, TypeScript knows the value isn't null.\n4. Generics: Generic types let you write reusable code that works with multiple types while preserving type information. Array<T> knows what's inside, unlike just 'Array'.\n5. Any vs Unknown: The 'any' type disables type checking entirely. It's an escape hatch but defeats the purpose of TypeScript. Use 'unknown' when the type truly isn't known.\n6. Type Guards: Type guards are functions that narrow types. They return a type predicate that tells TypeScript what the type is after the check passes."
    },
    {
      "duration": 86341.67424999998,
      "inputTokens": 4176,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we have a problem. Our competitor just slashed their prices by 30%. Marketing is freaking out and wants us to match immediately. But if we both stay at low prices, we'll both lose money on every sale.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. This is a strategic interaction — what we should do depends entirely on what they'll do next, and vice versa. We need to think through their incentives, not just react.\",\n          \"isCorrect\": true,\n          \"text\": \"Whether this is strategic interdependence\"\n        },\n        {\n          \"feedback\": \"Costs matter, but this is strategic interdependence — our best move depends on predicting their response. If we only look at our costs, we'll miss the competitive dynamics.\",\n          \"isCorrect\": false,\n          \"text\": \"Our production costs only\"\n        },\n        {\n          \"feedback\": \"Customer preferences are important, but this is a competitive situation. What we should do depends on what our competitor will do in response — that's strategic interdependence.\",\n          \"isCorrect\": false,\n          \"text\": \"What our customers want\"\n        },\n        {\n          \"feedback\": \"Goals are important, but we need to analyze the strategic interaction first. Our outcome depends on both our choice AND their response — that's the game theory element here.\",\n          \"isCorrect\": false,\n          \"text\": \"Our market share goals\"\n        }\n      ],\n      \"question\": \"What should we consider before reacting?\"\n    },\n    {\n      \"context\": \"Right. So I mapped out the scenarios. If we both keep prices high, we each make $500k profit. If we both go low, we each make only $200k. But here's the kicker — if one of us goes low while the other stays high, the low-price company makes $700k and the high-price one makes just $50k.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly right. Individually, each of us has incentive to go low regardless of what the other does. But if we both follow that logic, we both end up worse off than if we'd both stayed high.\",\n          \"isCorrect\": true,\n          \"text\": \"This looks like a prisoner's dilemma\"\n        },\n        {\n          \"feedback\": \"Actually the opposite — going low is the dominant strategy for both companies. If they're high, we make $700k low vs $500k high. If they're low, we make $200k low vs $50k high. Low is always better individually.\",\n          \"isCorrect\": false,\n          \"text\": \"We have a dominant strategy to stay high\"\n        },\n        {\n          \"feedback\": \"That might be the individually rational move, but you're missing the prisoner's dilemma structure. If both companies follow that logic, both end up with $200k instead of the $500k you'd both get staying high.\",\n          \"isCorrect\": false,\n          \"text\": \"We should definitely match their price cut\"\n        },\n        {\n          \"feedback\": \"Not quite. The Nash equilibrium is both going low — neither can improve by unilaterally changing. It's stable but inefficient. Both high would be better, but it's not an equilibrium because each has incentive to defect.\",\n          \"isCorrect\": false,\n          \"text\": \"The Nash equilibrium is both staying high\"\n        }\n      ],\n      \"question\": \"What does this payoff structure tell us?\"\n    },\n    {\n      \"context\": \"Okay, so if we're both rational, we'll both cut prices and both make less money. Fantastic. But {{NAME}}, I just remembered something — we're not in a one-time game. We compete with them in this market every quarter, year after year.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! In repeated games, the threat of future retaliation makes defection costly. If we can signal we'll punish price cuts, both companies might maintain higher prices. The shadow of the future changes incentives.\",\n          \"isCorrect\": true,\n          \"text\": \"It makes cooperation potentially rational\"\n        },\n        {\n          \"feedback\": \"Actually, repetition transforms the game completely. When you'll interact again, future punishment makes defection costly. Cooperation becomes rational because the long-term gains outweigh short-term advantages from undercutting.\",\n          \"isCorrect\": false,\n          \"text\": \"It doesn't change anything fundamental\"\n        },\n        {\n          \"feedback\": \"That's backwards. Repeated interaction makes cooperation MORE attractive, not less. The threat of ongoing price wars in future quarters makes undercutting less appealing. The shadow of the future changes the calculus.\",\n          \"isCorrect\": false,\n          \"text\": \"It means we should cut prices faster\"\n        },\n        {\n          \"feedback\": \"There's no dominant strategy that changes with repetition. What changes is the payoff structure — future interactions mean today's defection triggers tomorrow's punishment, making cooperation potentially sustainable.\",\n          \"isCorrect\": false,\n          \"text\": \"We need to find a dominant strategy\"\n        }\n      ],\n      \"question\": \"How does repeated interaction change the situation?\"\n    },\n    {\n      \"context\": \"That makes sense. So maybe we don't match their price cut. Instead, we could signal that if they raise prices back, we'll stay high too. But if they keep prices low, we'll match and both suffer. What do you think?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. We're trying to establish the mutually beneficial outcome (both high prices) by making credible the threat of mutual punishment if they defect. That's how repeated games can sustain cooperation.\",\n          \"isCorrect\": true,\n          \"text\": \"A way to reach the cooperative equilibrium\"\n        },\n        {\n          \"feedback\": \"We're not finding a dominant strategy — cutting prices is still individually better in any single round. We're trying to use repetition to make cooperation sustainable despite both having incentive to defect.\",\n          \"isCorrect\": false,\n          \"text\": \"Our dominant strategy\"\n        },\n        {\n          \"feedback\": \"Close, but not quite. In the single-period game, both high isn't a Nash equilibrium. We're trying to use repeated interaction and credible threats to make cooperation sustainable over time.\",\n          \"isCorrect\": false,\n          \"text\": \"A Nash equilibrium where we go high\"\n        },\n        {\n          \"feedback\": \"This isn't about information advantages. We're trying to use the repeated nature of the game to make cooperation rational through credible punishment threats. That works even with symmetric information.\",\n          \"isCorrect\": false,\n          \"text\": \"Proof we have better information\"\n        }\n      ],\n      \"question\": \"What are we trying to establish?\"\n    },\n    {\n      \"context\": \"Perfect. I'll draft a statement for our next earnings call signaling we prefer stable pricing and will respond to competitive moves. But {{NAME}}... I just got an email. They're launching this price cut in a market they're about to exit next quarter. They announced they're closing that regional division.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. If they're exiting, there's no future punishment to deter them. The repeated game logic collapses back to one-shot game incentives. They'll likely play their dominant strategy: stay low. We need to rethink our approach.\",\n          \"isCorrect\": true,\n          \"text\": \"The game is no longer repeated for them\"\n        },\n        {\n          \"feedback\": \"Cooperation requires the shadow of the future. If they're exiting the market, they have no incentive to maintain high prices — there's no future retaliation to fear. We're back to one-shot prisoner's dilemma logic.\",\n          \"isCorrect\": false,\n          \"text\": \"We should still try to cooperate\"\n        },\n        {\n          \"feedback\": \"Actually the opposite — exiting removes their repeated game incentives. Without future rounds, they'll play the one-shot dominant strategy: stay low. They have nothing to lose from defection.\",\n          \"isCorrect\": false,\n          \"text\": \"They now have a dominant strategy to go high\"\n        },\n        {\n          \"feedback\": \"The equilibrium has shifted dramatically. Without repeated interaction, the cooperative outcome isn't sustainable. They have no reason to return to high prices, so we're facing the one-shot Nash equilibrium: both low.\",\n          \"isCorrect\": false,\n          \"text\": \"Our Nash equilibrium hasn't changed\"\n        }\n      ],\n      \"question\": \"How does this change our analysis?\"\n    },\n    {\n      \"context\": \"Right, they have nothing to lose. So we're probably stuck matching their price cut in that region. But wait... {{NAME}}, that's only one regional market. We compete with them in five other regions where they're definitely staying long-term.\",\n      \"options\": [\n        {\n          \"feedback\": \"Brilliant insight. Even though this market isn't repeated for them, the OTHER markets are watching. If we don't match here, we look weak everywhere. Our reputation for responding affects all future interactions.\",\n          \"isCorrect\": true,\n          \"text\": \"Our response here signals future behavior\"\n        },\n        {\n          \"feedback\": \"That misses the signaling aspect. Other markets are watching how we respond. Our reputation for credible retaliation affects competitor behavior everywhere. We can't treat markets in isolation strategically.\",\n          \"isCorrect\": false,\n          \"text\": \"We should ignore this market completely\"\n        },\n        {\n          \"feedback\": \"In theory yes, but reputation links them. How we respond in one market signals how we'll respond in others. Failing to match here could invite price cuts everywhere because we'd look unwilling to retaliate.\",\n          \"isCorrect\": false,\n          \"text\": \"Each market is an independent game\"\n        },\n        {\n          \"feedback\": \"There's no dominant strategy that emerges from multiple markets. What changes is the reputational stakes — our response here affects credibility elsewhere. That's a strategic consideration, not a dominant strategy.\",\n          \"isCorrect\": false,\n          \"text\": \"We've found a dominant strategy now\"\n        }\n      ],\n      \"question\": \"What's the strategic consideration across multiple markets?\"\n    },\n    {\n      \"context\": \"Okay, so we match their price cut in that region to protect our reputation, but we simultaneously announce stable pricing everywhere else and our commitment to respond to any market disruptions. Sound right?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly right. We're using the repeated game structure in ongoing markets to sustain cooperation while showing we'll punish defection. That combination — credible retaliation plus repeated interaction — can maintain the better equilibrium.\",\n          \"isCorrect\": true,\n          \"text\": \"Credible threats in repeated interactions\"\n        },\n        {\n          \"feedback\": \"We don't have a dominant strategy. We're leveraging repeated game dynamics — the threat of future punishment makes cooperation sustainable. That's different from having a strategy that's always best regardless of opponent moves.\",\n          \"isCorrect\": false,\n          \"text\": \"Our dominant strategy across markets\"\n        },\n        {\n          \"feedback\": \"We're fully embracing strategic interdependence! Our announcement recognizes that outcomes depend on their choices and ours. We're just using repetition and credible threats to try reaching the cooperative outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"Lack of strategic interdependence\"\n        },\n        {\n          \"feedback\": \"This isn't about information advantages. We're using the repeated nature of the game and credible retaliation threats to sustain cooperation. That works even when both players have the same information.\",\n          \"isCorrect\": false,\n          \"text\": \"Information asymmetry advantages\"\n        }\n      ],\n      \"question\": \"What are we leveraging?\"\n    },\n    {\n      \"context\": \"Perfect strategy, {{NAME}}. I'll get this to the executive team. Oh, one more thing just came in — their CEO was quoted saying 'We believe in competitive but rational pricing.' That's... basically exactly what we're signaling.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! They're signaling the same thing. Both companies understand the prisoner's dilemma and want to avoid the mutually destructive equilibrium. When both players recognize the repeated game structure, cooperation becomes possible.\",\n          \"isCorrect\": true,\n          \"text\": \"They're also trying to sustain cooperation\"\n        },\n        {\n          \"feedback\": \"That's overly cynical. Their statement mirrors ours — both companies likely recognize that price wars hurt everyone in a repeated game. When players signal mutual understanding of the cooperative equilibrium, it's often genuine.\",\n          \"isCorrect\": false,\n          \"text\": \"They're trying to trick us into high prices\"\n        },\n        {\n          \"feedback\": \"In the one-shot game, both high still isn't a Nash equilibrium. But in the repeated game with credible threats, both companies can sustain cooperation. They're signaling they understand this — that's different from changing the equilibrium concept.\",\n          \"isCorrect\": false,\n          \"text\": \"We've found the Nash equilibrium is high prices\"\n        },\n        {\n          \"feedback\": \"Strategic interdependence is stronger than ever — both companies recognize outcomes depend on mutual choices. What's changed is both are signaling understanding of how to reach the cooperative outcome through repeated interaction.\",\n          \"isCorrect\": false,\n          \"text\": \"Strategic interdependence has disappeared\"\n        }\n      ],\n      \"question\": \"What does this suggest?\"\n    },\n    {\n      \"context\": \"Makes sense. So we both recognize the repeated game structure and we're both signaling we'll cooperate if they cooperate. I think we just turned a potential price war into... mutually beneficial stability. Who knew game theory could save us money?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect! The one-shot game had a destructive equilibrium, but repeated interaction with credible punishment threats made cooperation sustainable. That's the power of the shadow of the future in strategic situations.\",\n          \"isCorrect\": true,\n          \"text\": \"Repetition transforms prisoner's dilemmas\"\n        },\n        {\n          \"feedback\": \"Cooperation isn't a dominant strategy — in any single round, cutting prices is still individually better. Repetition and credible threats make cooperation sustainable despite individual incentives to defect.\",\n          \"isCorrect\": false,\n          \"text\": \"We found our dominant strategy was cooperation\"\n        },\n        {\n          \"feedback\": \"We didn't eliminate interdependence — we managed it! The outcome still depends on both companies' choices. We just used repeated game logic to coordinate on the mutually beneficial outcome instead of the destructive one.\",\n          \"isCorrect\": false,\n          \"text\": \"We eliminated strategic interdependence\"\n        },\n        {\n          \"feedback\": \"The one-shot Nash equilibrium (both low) didn't change. What changed is that repeated interaction and punishment threats can sustain cooperation even though it's not a Nash equilibrium in the single-period game.\",\n          \"isCorrect\": false,\n          \"text\": \"Nash equilibrium changed to both going high\"\n        }\n      ],\n      \"question\": \"What was the key insight that solved this?\"\n    },\n    {\n      \"context\": \"Absolutely. I'm sending the final recommendation now. Oh, and {{NAME}}? Finance just told me that if we'd matched their price cut everywhere without thinking it through, we'd have lost about $3 million this quarter. Turns out game theory pays pretty well.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Instead of instinctively matching, you recognized the prisoner's dilemma, saw how repetition changes incentives, understood signaling, and found the path to cooperation. That's strategic thinking with game theory.\",\n          \"isCorrect\": true,\n          \"text\": \"Analyzing strategic structure, not just reacting\"\n        },\n        {\n          \"feedback\": \"The situation was deeply interdependent throughout — that's what made it a game theory problem. What made the difference was analyzing that interdependence strategically rather than just reacting emotionally.\",\n          \"isCorrect\": false,\n          \"text\": \"Finding a situation without interdependence\"\n        },\n        {\n          \"feedback\": \"No dominant strategy emerged. What made the difference was understanding how repeated games and credible threats can sustain cooperation even when each player has individual incentive to defect in any single round.\",\n          \"isCorrect\": false,\n          \"text\": \"Waiting for a dominant strategy to emerge\"\n        },\n        {\n          \"feedback\": \"Actually the opposite — we assumed they'd act rationally, which meant understanding their incentives. Recognizing mutual rationality in a repeated game is what opened the path to cooperation rather than destructive competition.\",\n          \"isCorrect\": false,\n          \"text\": \"Assuming competitors act irrationally\"\n        }\n      ],\n      \"question\": \"What made the difference?\"\n    }\n  ]\n}",
      "outputTokens": 4023,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-economics-game-theory-strategy-1",
      "userPrompt": "LESSON_TITLE: Strategic Thinking with Game Theory\nLESSON_DESCRIPTION: Using game theory to analyze competitive situations and make better strategic decisions\nCHAPTER_TITLE: Strategic Decision Making\nCOURSE_TITLE: Microeconomics\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Strategic Interdependence: Game theory studies strategic interactions where your outcome depends on others' choices too. It's not about games — it's about any situation where what you should do depends on what others do.\n2. Nash Equilibrium: A Nash equilibrium is a stable state where no player can improve by changing only their own strategy. Everyone is doing their best given what everyone else is doing.\n3. Dominant Strategies: A dominant strategy is best regardless of what others do. If you have one, use it. But most real situations don't have dominant strategies — you must anticipate others.\n4. The Prisoner's Dilemma: The prisoner's dilemma shows how individual rationality can lead to collective irrationality. Both players choosing their dominant strategy leaves both worse off.\n5. Repeated Interactions: Repeated games change the calculus. When you'll interact again, cooperation becomes rational because future punishment makes defection costly."
    },
    {
      "duration": 139219.50974999997,
      "inputTokens": 4222,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we got approval for the sickle cell trial! But the ethics board is asking us to explain our guide RNA design before we start editing patient cells. They want to know why we chose this specific 20-nucleotide sequence.\",\n      \"options\": [\n        {\n          \"feedback\": \"Matching the target is necessary but not sufficient. You also need to minimize similarity to other genome locations to prevent off-target cuts, which could cause serious harm in patients.\",\n          \"isCorrect\": false,\n          \"text\": \"It matches our target gene perfectly\"\n        },\n        {\n          \"feedback\": \"Exactly right! For therapeutic applications, your guide RNA must be highly specific to avoid cutting unintended locations. This requires computational analysis to ensure minimal similarity to other genome regions.\",\n          \"isCorrect\": true,\n          \"text\": \"It's unique with minimal off-target matches\"\n        },\n        {\n          \"feedback\": \"Guide RNAs are typically 20 nucleotides — longer isn't better. What matters is specificity to your target and minimal matches elsewhere in the genome to prevent off-target effects.\",\n          \"isCorrect\": false,\n          \"text\": \"It's the longest sequence possible\"\n        },\n        {\n          \"feedback\": \"That would be the opposite of what you want! Targeting multiple genes simultaneously creates massive off-target risk. Each guide RNA should be specific to one target location.\",\n          \"isCorrect\": false,\n          \"text\": \"It targets multiple similar genes\"\n        }\n      ],\n      \"question\": \"What's the most critical factor in your guide RNA design choice?\"\n    },\n    {\n      \"context\": \"Perfect. Now they're asking about our editing strategy. We need to knock out the mutant beta-globin gene. The patient's cells have the sickle mutation — a single nucleotide change. Should we try to correct that one nucleotide or just disrupt the gene?\",\n      \"options\": [\n        {\n          \"feedback\": \"Smart choice for this application. NHEJ is more efficient and doesn't require a template. Knocking out the mutant gene while preserving the other copy can be more reliable than trying precise correction.\",\n          \"isCorrect\": true,\n          \"text\": \"NHEJ to knock out the gene\"\n        },\n        {\n          \"feedback\": \"While HDR can make precise changes, it's much less efficient than NHEJ and requires providing a DNA template. For therapeutic applications, the simpler knockout approach is often more practical and reliable.\",\n          \"isCorrect\": false,\n          \"text\": \"HDR to correct the single nucleotide\"\n        },\n        {\n          \"feedback\": \"These pathways compete with each other. The cell uses NHEJ or HDR, not both at once. Using both would create unpredictable outcomes and reduce efficiency of your intended edit.\",\n          \"isCorrect\": false,\n          \"text\": \"Use both pathways simultaneously\"\n        },\n        {\n          \"feedback\": \"The cell will naturally prefer NHEJ (faster, no template needed), but you need a controlled strategy. For patient safety, you must design for a specific, predictable repair outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"Let the cell choose randomly\"\n        }\n      ],\n      \"question\": \"What repair pathway strategy should you use?\"\n    },\n    {\n      \"context\": \"Great. Here's where it gets tricky, {{NAME}}. We're extracting the patient's blood stem cells to edit them in the lab. But the review board wants to know our delivery method for getting CRISPR into those cells. I'm thinking electroporation versus lentiviral vector.\",\n      \"options\": [\n        {\n          \"feedback\": \"Actually, electroporation delivers CRISPR transiently — it doesn't integrate. That's an advantage! You want temporary CRISPR activity to make the edit, then it degrades, reducing off-target effects over time.\",\n          \"isCorrect\": false,\n          \"text\": \"It integrates CRISPR into the genome\"\n        },\n        {\n          \"feedback\": \"Electroporation is temporary, not permanent. CRISPR components degrade after editing. This is actually safer — persistent CRISPR expression increases off-target cutting risk.\",\n          \"isCorrect\": false,\n          \"text\": \"It's permanent in the cell\"\n        },\n        {\n          \"feedback\": \"Exactly! Electroporation delivers CRISPR components that work briefly then degrade. This 'hit and run' approach minimizes the time window for off-target cuts, making it safer than permanent viral integration.\",\n          \"isCorrect\": true,\n          \"text\": \"Transient delivery reduces off-targets\"\n        },\n        {\n          \"feedback\": \"Electroporation works on cells in a dish (ex vivo), not in living organisms. For in vivo delivery, you'd need viral vectors or nanoparticles that can reach target tissues systemically.\",\n          \"isCorrect\": false,\n          \"text\": \"It works better in living patients\"\n        }\n      ],\n      \"question\": \"What's the key advantage of electroporation for this ex vivo application?\"\n    },\n    {\n      \"context\": \"Okay, we're ready to edit the cells. We've done three test runs. Run A shows 40% editing efficiency with 2% off-target effects. Run B shows 65% efficiency with 8% off-target effects. Run C shows 55% efficiency with 3% off-target effects. Which batch should we scale up?\",\n      \"options\": [\n        {\n          \"feedback\": \"While low off-target is good, 40% efficiency might be too low for therapeutic benefit. Run C offers better editing efficiency with only slightly higher off-target rate — a better overall balance.\",\n          \"isCorrect\": false,\n          \"text\": \"Run A - lowest off-target rate\"\n        },\n        {\n          \"feedback\": \"8% off-target effects is dangerously high for patient safety. Those unintended edits could cause mutations or cancer. Efficiency matters, but not at the cost of safety.\",\n          \"isCorrect\": false,\n          \"text\": \"Run B - highest editing efficiency\"\n        },\n        {\n          \"feedback\": \"Correct! Run C offers strong editing efficiency (55%) with acceptable off-target rates (3%). In therapeutic applications, you need to balance efficacy with safety — not just maximize one metric.\",\n          \"isCorrect\": true,\n          \"text\": \"Run C - balanced efficiency and safety\"\n        },\n        {\n          \"feedback\": \"Mixing batches with different performance profiles would create unpredictable results and dilute your quality control. You need consistent, reproducible editing outcomes for patient safety.\",\n          \"isCorrect\": false,\n          \"text\": \"Combine all three batches\"\n        }\n      ],\n      \"question\": \"Which test run demonstrates the best risk-benefit profile for patients?\"\n    },\n    {\n      \"context\": \"We've edited 10 million cells and confirmed the edits are working. Now we need to expand these cells before transplanting them back into the patient. But I'm seeing something weird, {{NAME}}. About 30% of the edited cells are showing a second mutation we didn't intend. It's always at the same location — chromosome 7.\",\n      \"options\": [\n        {\n          \"feedback\": \"Random mutations wouldn't appear at the same location in 30% of cells. This specific, recurring pattern points to CRISPR off-target activity at a site with partial sequence similarity to your guide RNA.\",\n          \"isCorrect\": false,\n          \"text\": \"Random mutations from cell culture\"\n        },\n        {\n          \"feedback\": \"Exactly. A consistent mutation at the same chromosome location across many cells indicates CRISPR is cutting an unintended site. You'll need to redesign your guide RNA to eliminate this off-target match.\",\n          \"isCorrect\": true,\n          \"text\": \"Off-target cutting by your guide RNA\"\n        },\n        {\n          \"feedback\": \"Contamination wouldn't cause a specific genomic mutation at chromosome 7. This pattern indicates CRISPR activity at an unintended target site that shares sequence similarity with your guide RNA.\",\n          \"isCorrect\": false,\n          \"text\": \"Contamination in the cell culture\"\n        },\n        {\n          \"feedback\": \"30% of cells with the identical mutation at the same location isn't normal variation. This is a specific, reproducible pattern indicating CRISPR off-target activity that must be addressed.\",\n          \"isCorrect\": false,\n          \"text\": \"Normal variation in stem cells\"\n        }\n      ],\n      \"question\": \"What does this pattern most likely indicate?\"\n    },\n    {\n      \"context\": \"Okay, we've redesigned the guide RNA. I ran it through three different off-target prediction algorithms. Two show zero predicted off-targets. But one algorithm flags a possible site in an intron of a tumor suppressor gene. The sequence match is only 17 out of 20 nucleotides. Should we be worried?\",\n      \"options\": [\n        {\n          \"feedback\": \"Never ignore a flagged tumor suppressor site, even if other algorithms miss it. Different algorithms use different criteria. You need experimental validation, especially for sites in cancer-related genes.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore it - two algorithms say it's fine\"\n        },\n        {\n          \"feedback\": \"Correct! Computational predictions aren't perfect. Given the tumor suppressor location, you must experimentally verify whether cutting occurs at this site. Sequence the region in edited cells to check for mutations.\",\n          \"isCorrect\": true,\n          \"text\": \"Test it experimentally in the cells\"\n        },\n        {\n          \"feedback\": \"That might be premature. First, experimentally verify if this off-target actually occurs. If sequencing shows no cutting at that site, the guide RNA may be fine. Test before redesigning.\",\n          \"isCorrect\": false,\n          \"text\": \"Redesign the guide RNA completely\"\n        },\n        {\n          \"feedback\": \"CRISPR can tolerate mismatches, especially depending on their position. A 17/20 match in a tumor suppressor gene warrants experimental validation — you can't assume it won't cut based on sequence alone.\",\n          \"isCorrect\": false,\n          \"text\": \"17/20 match is too different to cut\"\n        }\n      ],\n      \"question\": \"How should you evaluate this potential off-target site?\"\n    },\n    {\n      \"context\": \"Good call, {{NAME}}. We sequenced that region in 200 edited cells. Zero mutations detected at the tumor suppressor site. The guide RNA is clean. We're cleared for the patient transplant. The cells are ready, editing is verified, off-targets are minimal. But I just got a call from the manufacturing team. They can produce the CRISPR components as either Cas9 mRNA plus guide RNA, or as purified Cas9 protein plus guide RNA. Same cost, same delivery method.\",\n      \"options\": [\n        {\n          \"feedback\": \"Production ease isn't the safety consideration here. Cas9 protein is actually safer because it acts immediately then degrades. mRNA must be translated first, extending the window for potential off-target activity.\",\n          \"isCorrect\": false,\n          \"text\": \"Cas9 mRNA - easier to produce\"\n        },\n        {\n          \"feedback\": \"They're not equivalent for safety. Cas9 protein has a shorter activity window because it acts directly and degrades. mRNA requires translation, extending CRISPR's active period and increasing off-target risk.\",\n          \"isCorrect\": false,\n          \"text\": \"Either - they're equivalent\"\n        },\n        {\n          \"feedback\": \"Exactly! Protein degrades faster than mRNA, giving you a brief editing window that reduces off-target accumulation. For therapeutic applications, this 'hit and run' approach minimizes unintended cuts while still making your desired edit.\",\n          \"isCorrect\": true,\n          \"text\": \"Cas9 protein - shorter activity window\"\n        },\n        {\n          \"feedback\": \"More stability actually increases risk here. You want CRISPR to act briefly and disappear. The longer Cas9 remains active (from stable mRNA), the more opportunity for off-target cutting.\",\n          \"isCorrect\": false,\n          \"text\": \"Cas9 mRNA - more stable in cells\"\n        }\n      ],\n      \"question\": \"Which format offers a safety advantage for this one-time therapeutic edit?\"\n    },\n    {\n      \"context\": \"We're using the protein format. Everything's on track. But {{NAME}}, I just realized something. We've been so focused on the beta-globin edit that we haven't discussed what happens if the patient needs another CRISPR treatment in the future. I'm reading this new paper about immune responses to Cas9. Apparently a lot of people have pre-existing antibodies to it because it comes from bacteria they've been exposed to.\",\n      \"options\": [\n        {\n          \"feedback\": \"For ex vivo editing (cells edited outside the body), immune response to Cas9 isn't an immediate issue — the protein doesn't enter the patient. But if they ever need in vivo CRISPR therapy, antibodies could neutralize it.\",\n          \"isCorrect\": false,\n          \"text\": \"It could reject the current treatment\"\n        },\n        {\n          \"feedback\": \"Correct! This treatment is ex vivo, so immune response isn't an issue now. But exposure to Cas9 protein could generate antibodies, potentially preventing future in vivo CRISPR therapies from working. Worth monitoring long-term.\",\n          \"isCorrect\": true,\n          \"text\": \"It limits future in vivo treatments\"\n        },\n        {\n          \"feedback\": \"You can still use Cas9 for ex vivo editing since edited cells don't contain Cas9 when transplanted. The concern is about future in vivo applications where immune responses could neutralize CRISPR before it works.\",\n          \"isCorrect\": false,\n          \"text\": \"It means we can't use Cas9 at all\"\n        },\n        {\n          \"feedback\": \"The edited cells won't contain Cas9 protein when transplanted — they just carry the genomic edit. Immune responses target the Cas9 protein itself, which would only matter for future in vivo deliveries.\",\n          \"isCorrect\": false,\n          \"text\": \"It will attack the edited cells\"\n        }\n      ],\n      \"question\": \"Why is this immune response concern important for your patient?\"\n    },\n    {\n      \"context\": \"That's a good point for the long-term follow-up plan. Okay, {{NAME}}, final check before we proceed. We've edited the cells, validated the edits, confirmed minimal off-targets, and they're ready for transplant. But the patient just asked me a question I wasn't expecting: 'Will this edit be passed on to my children?' How do we answer that?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not true. Only edits to germline cells (eggs/sperm) or embryos are heritable. This patient received edited blood stem cells (somatic cells), which won't affect reproductive cells or be passed to children.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes - all CRISPR edits are heritable\"\n        },\n        {\n          \"feedback\": \"Correct! You edited somatic cells (blood stem cells), not germline cells (eggs or sperm). The edit will be in the patient's blood but won't be in reproductive cells, so it won't be inherited by offspring.\",\n          \"isCorrect\": true,\n          \"text\": \"No - blood stem cells aren't germline\"\n        },\n        {\n          \"feedback\": \"Sex doesn't matter here. The key is cell type: somatic vs. germline. Since you edited blood stem cells (somatic), the edit won't reach eggs or sperm in either sex and won't be inherited.\",\n          \"isCorrect\": false,\n          \"text\": \"Only if the patient is female\"\n        },\n        {\n          \"feedback\": \"Blood stem cells don't migrate to become reproductive cells. These lineages are separate. Edited somatic cells remain somatic — they can't become germline cells, so the edit cannot be inherited.\",\n          \"isCorrect\": false,\n          \"text\": \"Possibly - it depends on migration\"\n        }\n      ],\n      \"question\": \"Will the CRISPR edit be inherited by the patient's offspring?\"\n    },\n    {\n      \"context\": \"Perfect explanation. The patient feels good about that. Alright, {{NAME}}, we're at the moment of truth. Cells are prepared for infusion. But I just got a text from the lab. They found one vial from the edited batch that shows 15% of cells with a large deletion near our cut site — way bigger than expected. The other nine vials look perfect with clean, small indels. This outlier vial is only 10% of the total dose, but still.\",\n      \"options\": [\n        {\n          \"feedback\": \"Never compromise on quality control for patient safety. Large unexpected deletions could disrupt neighboring genes or cause genomic instability. Exclude the outlier vial and use only the nine clean batches.\",\n          \"isCorrect\": false,\n          \"text\": \"Include it - it's only 10% of total\"\n        },\n        {\n          \"feedback\": \"Absolutely right! Large deletions weren't part of your designed edit and could have unpredictable consequences. Patient safety trumps dose concerns. Use only vials with expected editing outcomes.\",\n          \"isCorrect\": true,\n          \"text\": \"Exclude it - unexpected edits are a risk\"\n        },\n        {\n          \"feedback\": \"Dilution doesn't eliminate the risk — you'd still be transplanting cells with large, unexpected deletions. Quality control means excluding aberrant results, not diluting them into acceptable batches.\",\n          \"isCorrect\": false,\n          \"text\": \"Dilute it with the other vials\"\n        },\n        {\n          \"feedback\": \"You have nine perfect vials — enough for treatment. Further testing the outlier delays care without benefit. The right move is to exclude the questionable vial and proceed with the validated batches.\",\n          \"isCorrect\": false,\n          \"text\": \"Test it further while delaying treatment\"\n        }\n      ],\n      \"question\": \"What should you do with the outlier vial?\"\n    },\n    {\n      \"context\": \"Good decision. We're moving forward with the nine clean vials. The infusion went smoothly, {{NAME}}. Now we're three weeks post-transplant. The edited cells are engrafting nicely — we're seeing them in the blood counts. But here's something interesting. I'm tracking the percentage of cells carrying our edit over time. Week 1: 62%. Week 2: 58%. Week 3: 53%. It's dropping. Should we be concerned, or is this expected?\",\n      \"options\": [\n        {\n          \"feedback\": \"DNA edits don't revert — they're permanent changes to the genome. The declining percentage more likely reflects competition between edited and unedited stem cells, or selective pressure if the edit affects cell fitness.\",\n          \"isCorrect\": false,\n          \"text\": \"The edit is unstable and reverting\"\n        },\n        {\n          \"feedback\": \"Immune rejection would cause rapid decline and clinical symptoms. This gradual decrease over weeks more likely reflects normal stem cell dynamics — edited cells competing with any remaining unedited cells.\",\n          \"isCorrect\": false,\n          \"text\": \"Immune system is rejecting edited cells\"\n        },\n        {\n          \"feedback\": \"Exactly! Some edited and unedited cells likely coexist, competing for the stem cell niche. Slight differences in fitness or proliferation rates cause shifts over time. Monitor the trend — therapeutic levels may stabilize.\",\n          \"isCorrect\": true,\n          \"text\": \"Normal competition between cell populations\"\n        },\n        {\n          \"feedback\": \"CRISPR components degraded weeks ago — they don't persist for three weeks. This trend reflects stem cell population dynamics, not ongoing CRISPR activity. The edits themselves are permanent.\",\n          \"isCorrect\": false,\n          \"text\": \"The CRISPR components are still active\"\n        }\n      ],\n      \"question\": \"What does this declining percentage most likely indicate?\"\n    },\n    {\n      \"context\": \"Makes sense. We'll keep monitoring. It actually stabilized at 48% by week five, and the patient's symptoms are improving. Success, {{NAME}}! The hospital wants us to write this up as a case study. But I just got an email from a research group in Singapore. They tried replicating our protocol for a different mutation using our exact guide RNA design strategy. Worked great in their lab dishes, but when they transplanted into patients, they got severe off-target effects we never saw. Same guide RNA approach, different target gene. What do you think happened?\",\n      \"options\": [\n        {\n          \"feedback\": \"While possible, the more likely issue is that guide RNA specificity is context-dependent. The genome location they targeted may have more similar sequences elsewhere, creating off-target vulnerability their design didn't account for.\",\n          \"isCorrect\": false,\n          \"text\": \"They made technical errors\"\n        },\n        {\n          \"feedback\": \"Exactly! Each target site sits in unique genomic context with different potential off-target matches. Your guide design strategy worked for your sequence but may not transfer to their gene. Every target requires custom analysis.\",\n          \"isCorrect\": true,\n          \"text\": \"Different gene = different genomic context\"\n        },\n        {\n          \"feedback\": \"While individual variation exists, severe off-target effects across multiple patients points to a design issue, not patient genetics. The target gene's genomic context likely has more off-target matches than yours did.\",\n          \"isCorrect\": false,\n          \"text\": \"Their patients have different DNA\"\n        },\n        {\n          \"feedback\": \"Delivery affects efficiency but doesn't fundamentally change off-target profiles determined by guide RNA sequence. The issue is more likely that their target gene's genomic context creates off-target vulnerability.\",\n          \"isCorrect\": false,\n          \"text\": \"They used the wrong delivery method\"\n        }\n      ],\n      \"question\": \"What's the most likely explanation for their off-target problems?\"\n    },\n    {\n      \"context\": \"That makes sense. Every CRISPR application needs custom optimization. We've been corresponding with them about guide RNA redesign strategies. Actually, {{NAME}}, plot twist — they just sent me their off-target sequencing data. The 'off-target effects' they detected? They're not from CRISPR at all. They're natural polymorphisms that exist in their patient population. They weren't comparing to the right baseline. Their CRISPR edits were actually clean the whole time.\",\n      \"options\": [\n        {\n          \"feedback\": \"Sequencing is reliable — the issue was experimental design. They needed proper controls: unedited cells from the same patients to distinguish pre-existing variants from CRISPR-induced mutations. The method was fine; the comparison wasn't.\",\n          \"isCorrect\": false,\n          \"text\": \"Sequencing is unreliable for validation\"\n        },\n        {\n          \"feedback\": \"Exactly! You can't distinguish CRISPR edits from natural variation without proper controls. They needed baseline sequences from each patient's unedited cells to separate polymorphisms from actual off-target cuts. Essential for accurate validation.\",\n          \"isCorrect\": true,\n          \"text\": \"Controls must match patient backgrounds\"\n        },\n        {\n          \"feedback\": \"The predictions weren't the problem — interpreting experimental results was. They mistook natural genetic variation for CRISPR effects. This shows why you need appropriate controls, not that predictions are unreliable.\",\n          \"isCorrect\": false,\n          \"text\": \"Off-target predictions are always wrong\"\n        },\n        {\n          \"feedback\": \"Population variation absolutely matters! It can confound off-target analysis if you don't control for it. That's exactly what happened here — they found natural variants but thought they were CRISPR-induced mutations.\",\n          \"isCorrect\": false,\n          \"text\": \"Population variation doesn't affect CRISPR\"\n        }\n      ],\n      \"question\": \"What does this reveal about validating CRISPR experiments?\"\n    },\n    {\n      \"context\": \"What a relief for them! Six months have passed, {{NAME}}. Our patient is doing incredibly well — near-normal hemoglobin, no pain crises. The Singapore team fixed their analysis and their patients are thriving too. We're both publishing next month. But here's the final twist: I just got a call from a biotech startup. They want to license our protocol to develop an in vivo CRISPR therapy — direct injection instead of extracting cells. Same edit, but delivered with lipid nanoparticles straight into bone marrow. They're asking if our ex vivo data supports moving to in vivo trials. What do you think?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not at all! In vivo delivery faces completely different challenges: targeting the right cells systemically, immune responses, delivery efficiency, and exposure of many more cells to CRISPR. Ex vivo success is encouraging but doesn't validate in vivo safety.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes - same edit means same results\"\n        },\n        {\n          \"feedback\": \"Exactly right! In vivo delivery creates new variables: systemic distribution, immune responses, off-target exposure in unintended tissues, and delivery efficiency. They need entirely new preclinical studies before human trials. Different approach = different validation.\",\n          \"isCorrect\": true,\n          \"text\": \"No - delivery context completely changes risks\"\n        },\n        {\n          \"feedback\": \"They can't skip safety validation. While the edit is proven, in vivo delivery exposes many more cells and tissues to CRISPR, creates immune response risks, and has different efficiency. Full preclinical testing is essential.\",\n          \"isCorrect\": false,\n          \"text\": \"Partially - they can skip some safety tests\"\n        },\n        {\n          \"feedback\": \"Even for the same patients, in vivo delivery is fundamentally different. Systemic delivery can reach unintended tissues, trigger immune responses, and has different efficiency than controlled ex vivo editing. New validation is required.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes - but only for the same patients\"\n        }\n      ],\n      \"question\": \"Does your ex vivo success predict in vivo safety and efficacy?\"\n    }\n  ]\n}",
      "outputTokens": 6263,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-biology-crispr-applications-1",
      "userPrompt": "LESSON_TITLE: CRISPR Gene Editing in Practice\nLESSON_DESCRIPTION: Understanding how to apply CRISPR gene editing technology effectively and responsibly\nCHAPTER_TITLE: Genetic Engineering\nCOURSE_TITLE: Modern Biotechnology\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. The Molecular Scissors: CRISPR-Cas9 is a molecular scissors that cuts DNA at specific locations. The Cas9 protein does the cutting; a guide RNA tells it exactly where to cut.\n2. Guide RNA Targeting: Guide RNA is a short sequence that matches the target DNA. It base-pairs with the DNA sequence you want to edit, bringing Cas9 to the exact spot.\n3. Cellular Repair Pathways: After CRISPR cuts, the cell's repair machinery fixes the break. Non-homologous end joining often introduces errors (knockouts). Homology-directed repair can insert new sequences (knock-ins).\n4. Off-Target Effects: Off-target effects occur when CRISPR cuts unintended locations. Guide RNA design and delivery methods affect specificity. This is a major safety concern for therapeutic applications.\n5. Delivery Challenges: Delivery is a key challenge. Getting CRISPR components into the right cells in a living organism is harder than in a lab dish. Viral vectors and lipid nanoparticles are common approaches."
    },
    {
      "duration": 136395.47012500005,
      "inputTokens": 4282,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, preciso da sua ajuda. O curso de programação que lancei semana passada está com taxa de abandono de 68%. Os alunos dizem que está 'confuso' e 'cansativo', mas o conteúdo é bom. Acho que tem algo errado com o design.\",\n      \"options\": [\n        {\n          \"feedback\": \"A dificuldade (carga intrínseca) existe, mas os alunos disseram 'confuso' e 'cansativo', não 'difícil demais'. Isso sugere problema de design, não de complexidade do tópico.\",\n          \"isCorrect\": false,\n          \"text\": \"A dificuldade do conteúdo em si\"\n        },\n        {\n          \"feedback\": \"Exato! 'Confuso' e 'cansativo' indicam carga extrínseca — problemas de design que sobrecarregam sem contribuir para aprendizagem. É aqui que começamos.\",\n          \"isCorrect\": true,\n          \"text\": \"Como o material está sendo apresentado\"\n        },\n        {\n          \"feedback\": \"Pré-requisitos são importantes, mas 68% de abandono com feedback sobre 'confusão' aponta para problema no design do material, não no perfil dos alunos.\",\n          \"isCorrect\": false,\n          \"text\": \"Se os alunos têm base suficiente\"\n        },\n        {\n          \"feedback\": \"Prática é crucial, mas primeiro precisamos identificar por que o material está 'confuso'. Pode ser que eles nem cheguem aos exercícios devido a problemas anteriores.\",\n          \"isCorrect\": false,\n          \"text\": \"O tempo dedicado aos exercícios\"\n        }\n      ],\n      \"question\": \"O que você sugere investigar primeiro?\"\n    },\n    {\n      \"context\": \"Boa sacada. Vou te mostrar uma tela típica do curso. Tem o vídeo da aula no centro, uma barra lateral com 15 links de recursos relacionados, um chat ao vivo no canto, notificações pop-up de novos comentários, e uma transcrição sincronizada embaixo do vídeo rolando automaticamente.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfeito! A interface está criando carga extrínseca massiva. A memória de trabalho só aguenta ~4 itens, mas há vídeo, links, chat, notificações, transcrição... O cérebro não consegue processar o conteúdo em si.\",\n          \"isCorrect\": true,\n          \"text\": \"Muitos elementos competindo por atenção\"\n        },\n        {\n          \"feedback\": \"Muito pelo contrário — há recursos DEMAIS simultaneamente. O problema não é falta de conteúdo, é excesso de estímulos competindo pela atenção limitada do aluno.\",\n          \"isCorrect\": false,\n          \"text\": \"Falta de recursos de apoio\"\n        },\n        {\n          \"feedback\": \"A localização da transcrição não é o cerne do problema. A questão é a quantidade de elementos simultâneos sobrecarregando a memória de trabalho do aluno.\",\n          \"isCorrect\": false,\n          \"text\": \"A transcrição deveria estar acima\"\n        },\n        {\n          \"feedback\": \"Adicionar mais interatividade nesse contexto só aumentaria a sobrecarga. O problema é que já há elementos demais disputando a capacidade limitada de processamento.\",\n          \"isCorrect\": false,\n          \"text\": \"O vídeo não é interativo\"\n        }\n      ],\n      \"question\": \"Qual o problema principal dessa interface?\"\n    },\n    {\n      \"context\": \"Exato. Os alunos não conseguem nem absorver o conteúdo do vídeo porque estão sendo bombardeados. Então pensei: vou simplificar. Removo o chat, as notificações, metade dos links. Mas ainda preciso que eles tenham acesso aos recursos e à transcrição. Como organizo isso sem sobrecarregar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Mesmo minimizados, os elementos ainda dividem atenção. A presença visual de múltiplas opções já consome recursos cognitivos, impedindo foco total no conteúdo principal.\",\n          \"isCorrect\": false,\n          \"text\": \"Deixar tudo disponível mas minimizado\"\n        },\n        {\n          \"feedback\": \"Sim! Apresente o vídeo primeiro. Depois ofereça transcrição (se solicitada) e recursos em momentos específicos. Isso respeita a capacidade limitada da memória de trabalho (~4 itens).\",\n          \"isCorrect\": true,\n          \"text\": \"Revelar recursos conforme necessário\"\n        },\n        {\n          \"feedback\": \"Abas múltiplas forçam o aluno a alternar contextos, sobrecarregando a memória de trabalho. Eles perdem o fio da meada a cada troca, aumentando carga sem benefício.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar abas separadas para cada recurso\"\n        },\n        {\n          \"feedback\": \"Uma lista ainda apresenta todos os elementos simultaneamente. O problema não é a organização visual, mas a quantidade de informação competindo por processamento ao mesmo tempo.\",\n          \"isCorrect\": false,\n          \"text\": \"Colocar tudo numa lista numerada\"\n        }\n      ],\n      \"question\": \"Qual estratégia reduz melhor a carga extrínseca?\"\n    },\n    {\n      \"context\": \"Faz sentido. Então reorganizei: vídeo limpo, transcrição opcional no rodapé, recursos aparecem ao final de cada seção. Agora outro problema: a primeira aula ensina loops, variáveis, funções e arrays — tudo de uma vez. São conceitos fundamentais, mas os alunos estão travando mesmo com a interface limpa.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exatamente! Loops, variáveis, funções e arrays são conceitos complexos. Ensinar todos juntos excede a capacidade da memória de trabalho. A carga intrínseca precisa ser sequenciada melhor.\",\n          \"isCorrect\": true,\n          \"text\": \"A carga intrínseca está alta demais\"\n        },\n        {\n          \"feedback\": \"Carga germânica é esforço produtivo (criar conexões, elaborar). Mas primeiro, os alunos precisam conseguir processar o básico. Estão sobrecarregados antes de poder elaborar.\",\n          \"isCorrect\": false,\n          \"text\": \"Falta carga germânica na abordagem\"\n        },\n        {\n          \"feedback\": \"Você mencionou que limpou a interface. O problema agora não é design, é a quantidade de conceitos novos sendo apresentados simultaneamente — isso é carga intrínseca.\",\n          \"isCorrect\": false,\n          \"text\": \"A interface ainda tem problemas\"\n        },\n        {\n          \"feedback\": \"Exemplos ruins criam carga extrínseca, mas o problema descrito é ensinar 4 conceitos fundamentais de uma vez — isso é sobrecarga da complexidade inerente (intrínseca).\",\n          \"isCorrect\": false,\n          \"text\": \"Os exemplos não são práticos\"\n        }\n      ],\n      \"question\": \"Qual é o problema agora?\"\n    },\n    {\n      \"context\": \"Então não dá pra eliminar essa carga, né? São conceitos essenciais. Mas dá pra gerenciar. Estou pensando em dividir: aula 1 só variáveis, aula 2 loops simples, aula 3 funções, aula 4 arrays. Mas aí o curso fica com 20 aulas em vez de 8. Será que não fica arrastado demais?\",\n      \"options\": [\n        {\n          \"feedback\": \"Duração não é o problema — sobrecarga é. 8 aulas densas que ninguém completa são piores que 20 aulas digeríveis com alta conclusão. Respeite a memória de trabalho.\",\n          \"isCorrect\": false,\n          \"text\": \"Está certa, vai ficar longo demais\"\n        },\n        {\n          \"feedback\": \"Perfeito! Apresentar conceitos gradualmente não 'arrasta', permite processamento. A memória de trabalho processa ~4 itens. Gerenciar carga intrínseca assim aumenta aprendizagem real, não tempo percebido.\",\n          \"isCorrect\": true,\n          \"text\": \"Sequenciar é crucial, não alonga\"\n        },\n        {\n          \"feedback\": \"Mais exemplos ajudam, mas não resolvem sobrecarga de múltiplos conceitos novos simultaneamente. Antes de exemplificar 4 conceitos juntos, é melhor apresentá-los sequencialmente.\",\n          \"isCorrect\": false,\n          \"text\": \"Melhor usar mais exemplos por aula\"\n        },\n        {\n          \"feedback\": \"Ainda seria sobrecarga. Dois conceitos novos e complexos simultaneamente já excedem a capacidade de processamento ideal. Melhor construir base sólida com um de cada vez.\",\n          \"isCorrect\": false,\n          \"text\": \"Combine em duplas de conceitos\"\n        }\n      ],\n      \"question\": \"Como você avalia essa preocupação?\"\n    },\n    {\n      \"context\": \"Ok, vou sequenciar melhor. Agora olha isso — na aula sobre funções, criei um diagrama super completo: mostra sintaxe, fluxo de execução, escopo, passagem de parâmetros e retorno de valores. Tudo num visual só. Levei horas fazendo, ficou lindo. Mas os alunos dizem que 'não entra na cabeça'.\",\n      \"options\": [\n        {\n          \"feedback\": \"Formato não resolve sobrecarga de informação. Um vídeo animado com 5 conceitos simultâneos ainda excederia a memória de trabalho (~4 itens). O problema é quantidade, não mídia.\",\n          \"isCorrect\": false,\n          \"text\": \"Deveria ser um vídeo animado\"\n        },\n        {\n          \"feedback\": \"Sim! Sintaxe + fluxo + escopo + parâmetros + retorno = sobrecarga massiva. A memória de trabalho não aguenta. Melhor seria diagramas separados ou progressivos, apresentando um elemento por vez.\",\n          \"isCorrect\": true,\n          \"text\": \"Apresenta muitos elementos de uma vez\"\n        },\n        {\n          \"feedback\": \"Adicionar mais texto criaria ainda mais carga extrínseca. O problema é excesso de informação simultânea, não falta de explicação. Simplicidade é a chave aqui.\",\n          \"isCorrect\": false,\n          \"text\": \"Falta texto explicativo detalhado\"\n        },\n        {\n          \"feedback\": \"Diagramas são excelentes para funções — quando bem feitos. O problema não é o formato, mas tentar mostrar 5 aspectos complexos simultaneamente, excedendo capacidade de processamento.\",\n          \"isCorrect\": false,\n          \"text\": \"Diagrama não é bom para funções\"\n        }\n      ],\n      \"question\": \"Por que o diagrama completo não está funcionando?\"\n    },\n    {\n      \"context\": \"Entendi. Vou quebrar o diagrama em etapas progressivas. Primeiro sintaxe básica, depois adiciono parâmetros, depois retorno, etc. Agora uma coisa: os números de telefone nos exemplos de código. Uso 11987654321 ou 11-98765-4321? Parece besteira, mas...\",\n      \"options\": [\n        {\n          \"feedback\": \"Tecnicamente correto, mas cognitivamente ruim. Uma sequência longa de dígitos sobrecarrega a memória de trabalho. O código é exemplo, não teste de memorização.\",\n          \"isCorrect\": false,\n          \"text\": \"11987654321 — é tecnicamente correto\"\n        },\n        {\n          \"feedback\": \"Exato! Chunking agrupa informação em unidades significativas. 11-98765-4321 é mais fácil de processar que 11 dígitos soltos. Reduz carga extrínseca em exemplos, liberando memória para o conceito real.\",\n          \"isCorrect\": true,\n          \"text\": \"11-98765-4321 — usa chunking\"\n        },\n        {\n          \"feedback\": \"Cada pequeno esforço extra de processamento soma. Dados mal formatados criam carga extrínseca desnecessária. Chunking permite que alunos foquem no conceito, não em decifrar números.\",\n          \"isCorrect\": false,\n          \"text\": \"Tanto faz, foca no código\"\n        },\n        {\n          \"feedback\": \"Parênteses adicionam elemento visual extra sem benefício cognitivo claro aqui. O formato com hífens (11-98765-4321) já faz o chunking necessário sem complexidade adicional.\",\n          \"isCorrect\": false,\n          \"text\": \"(11) 98765-4321 — mais completo\"\n        }\n      ],\n      \"question\": \"Qual formato você recomenda e por quê?\"\n    },\n    {\n      \"context\": \"Detalhes importam, entendi. {{NAME}}, estou refazendo tudo com esses princípios. Mas me preocupa uma coisa: se eu simplificar demais, facilitar demais, os alunos não vão aprender de verdade. Aprendizagem precisa ser desafiadora, não?\",\n      \"options\": [\n        {\n          \"feedback\": \"Verdade, mas QUAL esforço? Esforço para entender interface confusa (extrínseca) não ensina. Esforço para integrar conceitos e criar conexões (germânica) sim. Confundir os dois é perigoso.\",\n          \"isCorrect\": false,\n          \"text\": \"Aprendizagem eficaz precisa de esforço\"\n        },\n        {\n          \"feedback\": \"Perfeito! Reduza carga extrínseca (design ruim), gerencie intrínseca (sequenciamento), para MAXIMIZAR germânica (conexões, elaboração, integração). O desafio deve ser no pensar, não no navegar.\",\n          \"isCorrect\": true,\n          \"text\": \"Maximize desafio cognitivo produtivo\"\n        },\n        {\n          \"feedback\": \"Simplicidade no design não significa facilitar o pensamento. Interface limpa e sequenciamento claro liberam capacidade mental para o trabalho cognitivo REAL — elaborar, conectar, integrar.\",\n          \"isCorrect\": false,\n          \"text\": \"Simplicidade sempre facilita demais\"\n        },\n        {\n          \"feedback\": \"Esforço sim, mas direcionado. Lutar contra design confuso ou sobrecarga de informação não desenvolve expertise — só frustra e esgota. Queremos esforço na construção de entendimento profundo.\",\n          \"isCorrect\": false,\n          \"text\": \"Alunos devem se esforçar sozinhos\"\n        }\n      ],\n      \"question\": \"Como você responderia essa preocupação?\"\n    },\n    {\n      \"context\": \"Isso mudou minha perspectiva. Então refiz o curso: interface limpa, conceitos sequenciados, diagramas progressivos, dados formatados com chunking. Lancei a versão 2.0 ontem. Hoje de manhã, a primeira turma já completou 40% do curso. Taxa de abandono caiu pra 12%. Melhor ainda...\",\n      \"options\": [\n        {\n          \"feedback\": \"Notas podem melhorar, mas não é o indicador mais importante. O valor está em COMO aprendem — capacidade de aplicar, conectar conceitos, resolver problemas novos. Isso é carga germânica em ação.\",\n          \"isCorrect\": false,\n          \"text\": \"Notas nas avaliações finais\"\n        },\n        {\n          \"feedback\": \"Velocidade não é o objetivo. Alguns podem até levar mais tempo porque estão realmente processando e elaborando (carga germânica) ao invés de apenas sobrevivendo ao material confuso.\",\n          \"isCorrect\": false,\n          \"text\": \"Tempo de conclusão do curso\"\n        },\n        {\n          \"feedback\": \"Sim! Com menos carga extrínseca e intrínseca gerenciada, sobra capacidade mental para carga germânica — fazer conexões, elaborar, integrar. ISSO é aprendizagem real que transfere para problemas novos.\",\n          \"isCorrect\": true,\n          \"text\": \"Capacidade de aplicar conhecimento\"\n        },\n        {\n          \"feedback\": \"Satisfação é bom sinal, mas não garante aprendizagem profunda. O verdadeiro sucesso está na capacidade de aplicar conceitos em contextos novos — resultado de maximizar carga germânica.\",\n          \"isCorrect\": false,\n          \"text\": \"Satisfação nas pesquisas de feedback\"\n        }\n      ],\n      \"question\": \"O que você espera que tenha melhorado além da conclusão?\"\n    },\n    {\n      \"context\": \"...os alunos estão criando projetos próprios sem eu pedir. Uma aluna refatorou o código do trabalho dela usando os padrões do curso. Outro postou no fórum ajudando colegas com variações que EU nem tinha ensinado. {{NAME}}, eles não estão só completando — estão elaborando, conectando, criando.\",\n      \"options\": [\n        {\n          \"feedback\": \"Muito pelo contrário. Aplicar a contextos novos e elaborar além do ensinado mostra aprendizagem PROFUNDA. Isso só acontece quando há capacidade mental livre para processamento de alto nível.\",\n          \"isCorrect\": false,\n          \"text\": \"O curso ficou fácil demais\"\n        },\n        {\n          \"feedback\": \"Exatamente! Elaboração espontânea, transferência, criação — isso é carga germânica em ação. Ao eliminar extrínseca e gerenciar intrínseca, você liberou recursos mentais para o trabalho cognitivo que REALMENTE constrói expertise.\",\n          \"isCorrect\": true,\n          \"text\": \"Carga germânica está maximizada\"\n        },\n        {\n          \"feedback\": \"Motivação ajuda, mas não explica tudo. A diferença está em PODER processar profundamente. Alunos motivados também abandonavam a v1.0 porque estavam sobrecarregados. Agora têm capacidade de elaborar.\",\n          \"isCorrect\": false,\n          \"text\": \"Os alunos são mais motivados agora\"\n        },\n        {\n          \"feedback\": \"Não houve menção a gamificação. O engajamento profundo vem de conseguir realmente APRENDER — processar, conectar, criar. Isso é resultado direto de gerenciar carga cognitiva adequadamente.\",\n          \"isCorrect\": false,\n          \"text\": \"A gamificação está funcionando\"\n        }\n      ],\n      \"question\": \"O que isso demonstra sobre a abordagem?\"\n    },\n    {\n      \"context\": \"Incrível como teoria vira prática assim. Mas plot twist, {{NAME}}: o CEO viu os resultados e quer que eu aplique isso no curso avançado de arquitetura de software. Só que lá os alunos JÁ sabem programar. Será que ainda preciso me preocupar com carga cognitiva? Eles são experientes...\",\n      \"options\": [\n        {\n          \"feedback\": \"Memória de trabalho tem ~4 itens para TODOS. Expertise muda o que conta como 'item' (chunking automático de padrões), mas não elimina limites. Experts também sofrem com design ruim.\",\n          \"isCorrect\": false,\n          \"text\": \"Avançados não têm limite de memória\"\n        },\n        {\n          \"feedback\": \"Sim! Experts têm chunks maiores (padrões integrados), mas AINDA têm ~4 slots. Carga extrínseca ainda atrapalha. Intrínseca ainda existe (conceitos novos complexos). Germânica ainda é onde acontece aprendizagem real.\",\n          \"isCorrect\": true,\n          \"text\": \"Princípios se aplicam em todo nível\"\n        },\n        {\n          \"feedback\": \"Experts apreciam desafio INTELECTUAL (germânico), não design confuso (extrínseco). Interface limpa e sequenciamento claro beneficiam todos — liberam capacidade para pensamento de alto nível.\",\n          \"isCorrect\": false,\n          \"text\": \"Avançados preferem complexidade\"\n        },\n        {\n          \"feedback\": \"Mesmo experts sofrem com carga extrínseca (design ruim) e intrínseca mal gerenciada (conceitos novos complexos apresentados de uma vez). Gerenciar todas continua essencial.\",\n          \"isCorrect\": false,\n          \"text\": \"Só se preocupe com carga germânica\"\n        }\n      ],\n      \"question\": \"O que você diria sobre aplicar isso em nível avançado?\"\n    },\n    {\n      \"context\": \"Verdade. No fundo, estou sempre trabalhando com memória de trabalho humana, seja iniciante ou expert. A diferença é que experts têm chunks maiores, mas os princípios são os mesmos. Aliás, {{NAME}}, tenho uma confissão: antes dessa conversa, eu achava que 'carga cognitiva' era só jargão acadêmico. Coisa que fica bonita em artigo mas não muda nada na prática. Que ironia...\",\n      \"options\": [\n        {\n          \"feedback\": \"Números são consequência, não causa. O que mudou foi entender que cada decisão de design — da interface ao sequenciamento aos exemplos — impacta DIRETAMENTE como o cérebro processa. Isso não é teoria, é mecânica.\",\n          \"isCorrect\": false,\n          \"text\": \"Ver os números de abandono caírem\"\n        },\n        {\n          \"feedback\": \"Exato! ~4 itens na memória de trabalho não é 'teoria', é limite biológico. Carga extrínseca vs germânica não é jargão, é diferença entre esforço inútil e aprendizagem real. Entender isso transforma cada escolha de design.\",\n          \"isCorrect\": true,\n          \"text\": \"Entender a mecânica cerebral real\"\n        },\n        {\n          \"feedback\": \"Não foi seguir checklist, foi entender o PORQUÊ. Saber que interface confusa não é 'ruim' abstratamente, mas SOBRECARREGA slots limitados de processamento — isso muda como você pensa design desde a base.\",\n          \"isCorrect\": false,\n          \"text\": \"Aplicar checklist de boas práticas\"\n        },\n        {\n          \"feedback\": \"Feedback é valioso, mas a mudança veio de entender mecanismos. Saber que seu cérebro processa ~4 itens, que chunking reduz carga, que design ruim esgota recursos — isso torna cada princípio acionável e claro.\",\n          \"isCorrect\": false,\n          \"text\": \"Receber validação dos alunos\"\n        }\n      ],\n      \"question\": \"O que mudou sua perspectiva?\"\n    },\n    {\n      \"context\": \"...porque agora quando olho qualquer material de aprendizagem — meu ou de outros — vejo carga cognitiva em ação. Aquela apresentação poluída? Carga extrínseca. Aquele tutorial que explica 5 conceitos juntos? Intrínseca mal gerenciada. Aquele curso que só faz você assistir passivamente? Zero carga germânica. É tipo ter raio-X do design. {{NAME}}, obrigado por me ajudar a ver isso. Literalmente mudou como trabalho.\",\n      \"options\": [\n        {\n          \"feedback\": \"Não é simplificar tudo, é INTENCIONALIDADE. Elimine extrínseca (design ruim). Gerencie intrínseca (sequenciamento). Maximize germânica (elaboração). Cada carga tem papel — saber qual é qual muda tudo.\",\n          \"isCorrect\": false,\n          \"text\": \"Sempre simplificar ao máximo\"\n        },\n        {\n          \"feedback\": \"Perfeito! Você tem ~4 slots de memória de trabalho nos seus alunos. Cada decisão de design decide o que preenche esses slots. Interface confusa? Desperdício. Conceitos fundamentais bem sequenciados? Investimento. Essa consciência é transformadora.\",\n          \"isCorrect\": true,\n          \"text\": \"Gerenciar onde gastar atenção limitada\"\n        },\n        {\n          \"feedback\": \"Melhores práticas ajudam, mas o insight real é ENTENDER os mecanismos. Quando você sabe POR QUE carga extrínseca desperdiça capacidade limitada, pode tomar decisões informadas mesmo em situações sem 'prática estabelecida'.\",\n          \"isCorrect\": false,\n          \"text\": \"Seguir as melhores práticas da área\"\n        },\n        {\n          \"feedback\": \"Testes são valiosos, mas entender carga cognitiva permite ANTECIPAR problemas no design. Você não precisa testar para saber que 15 links simultâneos sobrecarregam — você entende os limites da memória de trabalho.\",\n          \"isCorrect\": false,\n          \"text\": \"Testar tudo com usuários primeiro\"\n        }\n      ],\n      \"question\": \"Qual o principal insight que você aplicará daqui pra frente?\"\n    }\n  ]\n}",
      "outputTokens": 6594,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-psychology-cognitive-load-1",
      "userPrompt": "LESSON_TITLE: Carga Cognitiva na Pratica\nLESSON_DESCRIPTION: Aplicando a teoria da carga cognitiva para criar materiais de aprendizagem mais eficazes\nCHAPTER_TITLE: Psicologia da Aprendizagem\nCOURSE_TITLE: Design Instrucional\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Limites da Memoria: A memoria de trabalho tem capacidade limitada — cerca de 4 itens simultaneamente. Quando sobrecarregada, a aprendizagem para. O cerebro nao consegue processar mais.\n2. Carga Intrinseca: Carga intrinseca vem da complexidade inerente do conteudo. Algumas coisas sao simplesmente dificeis. Nao da para eliminar, mas da para gerenciar.\n3. Carga Extrinseca: Carga extrinseca vem do design ruim — instrucoes confusas, distracao visual, navegacao complicada. Essa carga pode e deve ser eliminada.\n4. Carga Germanica: Carga germanica e o esforco produtivo de aprender — criar conexoes, elaborar, integrar. Queremos maximizar essa carga enquanto minimizamos a extrinseca.\n5. Chunking: Chunking agrupa informacoes em unidades significativas. Um numero de telefone e mais facil de lembrar como blocos (99-8765-4321) do que como 10 digitos soltos."
    },
    {
      "duration": 91996.85887499998,
      "inputTokens": 4273,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, tenemos un problema serio. El cliente quiere instalar un motor térmico en su planta que promete 95% de eficiencia. El vendedor dice que es tecnología revolucionaria. Suena demasiado bueno para ser cierto, ¿no?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. El límite de Carnot depende de las temperaturas. Si conocemos las fuentes caliente y fría, podemos calcular la eficiencia máxima teórica y ver si el 95% es físicamente posible.\",\n          \"isCorrect\": true,\n          \"text\": \"Las temperaturas de operación del motor\"\n        },\n        {\n          \"feedback\": \"El precio no nos dice si la eficiencia es posible. Primero necesitamos verificar si esa eficiencia viola las leyes termodinámicas antes de considerar aspectos económicos.\",\n          \"isCorrect\": false,\n          \"text\": \"El costo del motor comparado con otros\"\n        },\n        {\n          \"feedback\": \"La reputación importa, pero ningún fabricante puede superar los límites físicos. Necesitamos verificar las temperaturas para calcular la eficiencia máxima teórica de Carnot.\",\n          \"isCorrect\": false,\n          \"text\": \"La marca y reputación del fabricante\"\n        },\n        {\n          \"feedback\": \"El consumo energético no determina si la eficiencia declarada es posible. El límite de Carnot depende de las temperaturas de las fuentes caliente y fría.\",\n          \"isCorrect\": false,\n          \"text\": \"Cuánta energía consume por hora\"\n        }\n      ],\n      \"question\": \"¿Qué debemos verificar primero?\"\n    },\n    {\n      \"context\": \"Buen punto. Conseguí los datos: la fuente caliente opera a 600 K y la fría a 300 K. El vendedor insiste que su motor alcanza 95% de eficiencia a esas temperaturas. ¿Qué opinas?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Eficiencia de Carnot = 1 - (Tfría/Tcaliente) = 1 - (300/600) = 0.5 o 50%. Ningún motor real puede superar esto. El vendedor está mintiendo o equivocado.\",\n          \"isCorrect\": true,\n          \"text\": \"No, la eficiencia de Carnot es solo 50%\"\n        },\n        {\n          \"feedback\": \"No. Ninguna tecnología puede superar el límite de Carnot. Con 600 K y 300 K, la eficiencia máxima es 50%. El 95% viola la segunda ley de la termodinámica.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, con tecnología avanzada es posible\"\n        },\n        {\n          \"feedback\": \"La cantidad de calor no cambia el límite de eficiencia. Con estas temperaturas (600 K y 300 K), la eficiencia máxima de Carnot es 50%, independiente del flujo de calor.\",\n          \"isCorrect\": false,\n          \"text\": \"Depende de cuánto calor entre al sistema\"\n        },\n        {\n          \"feedback\": \"Incluso un motor ideal sin fricción no puede superar Carnot. Con Tcaliente=600 K y Tfría=300 K, el máximo teórico es 50%. El 95% es imposible.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, si minimizamos las pérdidas por fricción\"\n        }\n      ],\n      \"question\": \"¿Es físicamente posible esta eficiencia?\"\n    },\n    {\n      \"context\": \"Tienes razón, {{NAME}}. Le mostré los cálculos al cliente y rechazó esa compra. Ahora me pide ayuda con otro problema: quiere diseñar un sistema de refrigeración para su almacén. Dice que necesita mover 5000 J de calor desde el interior frío hacia el exterior caliente.\",\n      \"options\": [\n        {\n          \"feedback\": \"No es imposible. Los refrigeradores mueven calor de frío a caliente, pero requieren trabajo externo. Esto NO viola la segunda ley porque el trabajo compensa el flujo 'antinatural'.\",\n          \"isCorrect\": false,\n          \"text\": \"Es imposible, viola la segunda ley\"\n        },\n        {\n          \"feedback\": \"Exacto. El calor no fluye espontáneamente de frío a caliente. Un refrigerador necesita trabajo externo para mover calor en esa dirección. Mientras haya trabajo, no se viola la segunda ley.\",\n          \"isCorrect\": true,\n          \"text\": \"Necesitará suministrar trabajo al sistema\"\n        },\n        {\n          \"feedback\": \"Al revés. El calor fluye espontáneamente de caliente a frío. Para moverlo de frío (interior) a caliente (exterior), necesita un refrigerador que consuma trabajo.\",\n          \"isCorrect\": false,\n          \"text\": \"El calor fluirá naturalmente afuera\"\n        },\n        {\n          \"feedback\": \"Esperar no ayuda. Necesita un sistema de refrigeración activo que use trabajo para mover calor de frío a caliente. Sin trabajo externo, el calor fluiría en la dirección opuesta.\",\n          \"isCorrect\": false,\n          \"text\": \"Debe esperar hasta que las temperaturas se igualen\"\n        }\n      ],\n      \"question\": \"¿Qué debe entender sobre este proceso?\"\n    },\n    {\n      \"context\": \"Claro, le expliqué eso. Pero ahora pregunta: si necesita mover 5000 J de calor del almacén frío, ¿puede usar exactamente 5000 J de trabajo eléctrico? Dice que así la energía 'se equilibra'. ¿Qué le respondo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Por conservación de energía, el calor expulsado afuera = calor removido + trabajo consumido. Si remueve 5000 J, necesita trabajo adicional. Los refrigeradores reales siempre requieren más trabajo que calor removido.\",\n          \"isCorrect\": true,\n          \"text\": \"No, necesitará MÁS de 5000 J de trabajo\"\n        },\n        {\n          \"feedback\": \"No. Por la primera ley, el calor total expulsado = Qfrío + W. Si quita 5000 J del interior, el trabajo debe ser adicional. En realidad necesitará más de 5000 J de trabajo.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, 5000 J de trabajo moverán 5000 J de calor\"\n        },\n        {\n          \"feedback\": \"Al revés. Un refrigerador eficiente podría tener un coeficiente de desempeño >1, pero en casos reales típicos, para mover 5000 J necesitará más trabajo, especialmente con grandes diferencias de temperatura.\",\n          \"isCorrect\": false,\n          \"text\": \"No, necesitará MENOS de 5000 J de trabajo\"\n        },\n        {\n          \"feedback\": \"La conservación de energía es más directa aquí. El calor expulsado afuera = calor removido + trabajo. Para remover 5000 J, necesitará trabajo adicional, típicamente más de 5000 J en condiciones reales.\",\n          \"isCorrect\": false,\n          \"text\": \"Depende de la entropía del sistema\"\n        }\n      ],\n      \"question\": \"¿Es correcto su razonamiento energético?\"\n    },\n    {\n      \"context\": \"Perfecto, {{NAME}}. Le aclaré eso también. Ahora está diseñando dos opciones: Opción A opera entre 280 K y 320 K. Opción B opera entre 260 K y 340 K. Ambas removerían la misma cantidad de calor. ¿Cuál recomendamos?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Menor diferencia de temperatura significa menos trabajo requerido. Es más fácil mover calor cuando las temperaturas están más cerca. La opción A (40 K de diferencia) es más eficiente que la B (80 K).\",\n          \"isCorrect\": true,\n          \"text\": \"Opción A (menor diferencia de temperatura)\"\n        },\n        {\n          \"feedback\": \"No. Mayor diferencia de temperatura requiere MÁS trabajo para mover calor. La opción B tiene 80 K de diferencia vs 40 K en la opción A. A es más eficiente.\",\n          \"isCorrect\": false,\n          \"text\": \"Opción B (mayor diferencia de temperatura)\"\n        },\n        {\n          \"feedback\": \"No. El trabajo requerido depende de la diferencia de temperatura. La opción A (40 K) requiere menos trabajo que la opción B (80 K) para mover la misma cantidad de calor.\",\n          \"isCorrect\": false,\n          \"text\": \"Ambas requieren el mismo trabajo\"\n        },\n        {\n          \"feedback\": \"La humedad afecta otros factores, pero termodinámicamente, la opción A necesita menos trabajo porque tiene menor diferencia de temperatura (40 K vs 80 K en la opción B).\",\n          \"isCorrect\": false,\n          \"text\": \"Depende de la humedad del almacén\"\n        }\n      ],\n      \"question\": \"¿Qué opción requerirá menos trabajo?\"\n    },\n    {\n      \"context\": \"Excelente análisis, {{NAME}}. El cliente eligió la opción A. Pero ahora surge algo extraño: su ingeniero en sitio reporta que el refrigerador está funcionando, el almacén se enfría correctamente, pero el área alrededor del condensador exterior está mucho más caliente de lo esperado.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Por conservación de energía: Qexpulsado = Qremovido + Trabajo. El condensador libera TODO ese calor al ambiente. Por eso el exterior se calienta más de lo que el interior se enfría.\",\n          \"isCorrect\": true,\n          \"text\": \"Expulsa el calor removido MÁS el calor del trabajo\"\n        },\n        {\n          \"feedback\": \"No necesariamente. Es normal que el exterior esté muy caliente. El condensador expulsa el calor removido del interior MÁS el calor equivalente al trabajo del compresor.\",\n          \"isCorrect\": false,\n          \"text\": \"Hay una fuga en el sistema de refrigeración\"\n        },\n        {\n          \"feedback\": \"Eso no explica por qué está TAN caliente. La razón es que el condensador expulsa el calor removido del interior MÁS el trabajo consumido. Es más energía que la simplemente removida.\",\n          \"isCorrect\": false,\n          \"text\": \"El calor fluye naturalmente hacia afuera\"\n        },\n        {\n          \"feedback\": \"La entropía no es calor acumulado. La razón real es conservación de energía: el condensador expulsa Qremovido + Trabajo, por eso libera más calor del que se extrajo del almacén.\",\n          \"isCorrect\": false,\n          \"text\": \"La entropía se está acumulando allí\"\n        }\n      ],\n      \"question\": \"¿Por qué el exterior se calienta tanto?\"\n    },\n    {\n      \"context\": \"Perfecto, {{NAME}}. Les expliqué que es completamente normal. El sistema lleva tres semanas funcionando bien. Pero hoy el cliente me llama preocupado: 'El refrigerador sigue funcionando, pero noto que con el tiempo, mi factura eléctrica sube. ¿El sistema se está volviendo menos eficiente?'\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Los refrigeradores reales pierden eficiencia con el tiempo por fricción, suciedad en intercambiadores, fugas menores de refrigerante, etc. El límite teórico no cambia, pero las condiciones reales sí.\",\n          \"isCorrect\": true,\n          \"text\": \"Acumulación de suciedad o problemas mecánicos\"\n        },\n        {\n          \"feedback\": \"El límite de Carnot es teórico y solo depende de las temperaturas. Si las temperaturas no cambian, el límite tampoco. La pérdida de eficiencia viene de factores prácticos como suciedad o desgaste.\",\n          \"isCorrect\": false,\n          \"text\": \"La eficiencia de Carnot está disminuyendo\"\n        },\n        {\n          \"feedback\": \"La segunda ley siempre se aplica, no 'empieza a afectar' con el tiempo. La pérdida de eficiencia se debe a factores prácticos: suciedad, desgaste, fricción incrementada, no a cambios en las leyes físicas.\",\n          \"isCorrect\": false,\n          \"text\": \"La segunda ley está afectando el sistema\"\n        },\n        {\n          \"feedback\": \"Si el refrigerador funciona, el calor sigue moviéndose correctamente. La pérdida de eficiencia se debe a problemas mecánicos como suciedad en intercambiadores, fricción, o fugas menores de refrigerante.\",\n          \"isCorrect\": false,\n          \"text\": \"El calor ya no fluye de frío a caliente\"\n        }\n      ],\n      \"question\": \"¿Qué puede estar causando la pérdida de eficiencia?\"\n    },\n    {\n      \"context\": \"Bien pensado, {{NAME}}. Recomendé mantenimiento preventivo. Pero ahora me hace una pregunta interesante: '¿Y si invierto en el sistema más caro que opera entre 270 K y 310 K? Tiene menor diferencia de temperatura. ¿Valdrá la pena el costo extra?'\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Menor diferencia de temperatura (40 K vs original) mejora eficiencia y reduce costos de operación. Pero hay que calcular cuánto ahorra en electricidad a largo plazo vs el costo inicial extra.\",\n          \"isCorrect\": true,\n          \"text\": \"Comparar ahorro energético vs costo adicional\"\n        },\n        {\n          \"feedback\": \"No automáticamente. Aunque menor diferencia es más eficiente, el costo inicial puede no justificarse. Hay que analizar el retorno de inversión: ahorro energético anual vs costo adicional del equipo.\",\n          \"isCorrect\": false,\n          \"text\": \"Siempre elegir la menor diferencia de temperatura\"\n        },\n        {\n          \"feedback\": \"La entropía total del universo siempre aumenta en ambos casos. La decisión práctica depende de economía: ¿el ahorro energético por mayor eficiencia justifica el costo adicional del equipo?\",\n          \"isCorrect\": false,\n          \"text\": \"La entropía será menor en el sistema nuevo\"\n        },\n        {\n          \"feedback\": \"Cualquier sistema real está bajo el límite de Carnot, eso no es la preocupación aquí. La decisión real es económica: ¿el ahorro en electricidad compensa el costo extra del equipo más eficiente?\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar si viola el límite de Carnot\"\n        }\n      ],\n      \"question\": \"¿Qué factor es clave para esta decisión?\"\n    },\n    {\n      \"context\": \"Muy bien, {{NAME}}. Hicimos los números y recomendamos el sistema original — el payback del más caro era de 15 años. El cliente quedó satisfecho con la decisión. Pero espera... acabo de recibir un email extraño de él.\",\n      \"options\": [\n        {\n          \"feedback\": \"El email dice: '{{NAME}} y equipo: Gracias por salvarme de una mala inversión y enseñarme termodinámica aplicada. PD: ¿Pueden explicarle estos conceptos a mi vendedor de motores milagrosos? Sigue insistiendo.' 😄\",\n          \"isCorrect\": true,\n          \"text\": \"Ver el contenido del mensaje\"\n        },\n        {\n          \"feedback\": \"No necesitas revisar. El email en realidad dice: 'Gracias por salvarme de una mala inversión y enseñarme termodinámica aplicada. PD: ¿Pueden explicarle esto a mi vendedor de motores milagrosos?' Caso cerrado con humor.\",\n          \"isCorrect\": false,\n          \"text\": \"Revisar los cálculos una vez más\"\n        },\n        {\n          \"feedback\": \"Siempre lee los mensajes del cliente. Este dice: 'Gracias por salvarme de una mala inversión y enseñarme termodinámica aplicada. PD: ¿Pueden explicarle esto a mi vendedor de motores milagrosos?' Una conclusión satisfactoria.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorarlo y continuar con otros proyectos\"\n        },\n        {\n          \"feedback\": \"El email es simple: 'Gracias por salvarme de una mala inversión y enseñarme termodinámica aplicada. PD: ¿Pueden explicarle esto a mi vendedor de motores milagrosos?' No necesita seguimiento, es gratitud y humor.\",\n          \"isCorrect\": false,\n          \"text\": \"Programar una llamada de seguimiento\"\n        }\n      ],\n      \"question\": \"¿Qué dice el email?\"\n    },\n    {\n      \"context\": \"Jajaja, {{NAME}}, me encanta. Pero hablando en serio, este proyecto fue un caso perfecto de termodinámica aplicada. Evaluamos eficiencias imposibles, diseñamos refrigeración, analizamos conservación de energía, y tomamos decisiones económicas basadas en principios físicos. ¿Qué diríamos que es la lección más importante?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Ninguna tecnología supera Carnot. La segunda ley establece direcciones. La primera ley conserva energía. Entender estos límites nos permite evaluar afirmaciones, diseñar sistemas realistas y tomar decisiones informadas.\",\n          \"isCorrect\": true,\n          \"text\": \"Las leyes termodinámicas son límites reales\"\n        },\n        {\n          \"feedback\": \"No siempre. La eficiencia importa, pero vimos que el sistema más eficiente puede no justificar su costo. El takeaway real: las leyes termodinámicas establecen límites físicos que ninguna tecnología puede violar.\",\n          \"isCorrect\": false,\n          \"text\": \"Siempre elegir el sistema más eficiente\"\n        },\n        {\n          \"feedback\": \"Aunque algunos lo hacen, la lección más profunda es termodinámica: hay límites físicos reales (Carnot, segunda ley, conservación) que nos permiten evaluar afirmaciones y diseñar sistemas realistas.\",\n          \"isCorrect\": false,\n          \"text\": \"Los vendedores siempre exageran sus productos\"\n        },\n        {\n          \"feedback\": \"La entropía es importante, pero el takeaway clave es más amplio: las leyes termodinámicas (Carnot, segunda ley, conservación de energía) establecen límites reales que guían el diseño y evaluación de sistemas energéticos.\",\n          \"isCorrect\": false,\n          \"text\": \"La entropía controla todos los sistemas\"\n        }\n      ],\n      \"question\": \"¿Cuál es el takeaway clave de este proyecto?\"\n    }\n  ]\n}",
      "outputTokens": 5104,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-physics-thermodynamics-applications-1",
      "userPrompt": "LESSON_TITLE: Termodinamica Aplicada\nLESSON_DESCRIPTION: Aplicando las leyes de la termodinamica para entender y disenar sistemas energeticos\nCHAPTER_TITLE: Termodinamica\nCOURSE_TITLE: Fisica para Ingenieros\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Conservacion de Energia: La primera ley dice que la energia se conserva — no se crea ni destruye, solo se transforma. El calor que entra menos el trabajo que sale iguala el cambio de energia interna.\n2. Direccion del Calor: La segunda ley establece una direccion: el calor fluye espontaneamente de caliente a frio, nunca al reves. Esto limita la eficiencia de cualquier motor termico.\n3. Entropia: La entropia mide la dispersion de energia. Cuando la energia se dispersa (calor fluyendo a lo frio), la entropia aumenta. Concentrar energia requiere trabajo externo.\n4. Limite de Carnot: El ciclo de Carnot define la eficiencia maxima teorica. Ningun motor real puede ser mas eficiente. La eficiencia depende de las temperaturas de las fuentes caliente y fria.\n5. Refrigeracion: Los refrigeradores y bombas de calor mueven calor de frio a caliente usando trabajo. No violan la segunda ley — el trabajo compensa el flujo 'antinatural' de calor."
    },
    {
      "duration": 159334.983083,
      "inputTokens": 4226,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we've got a situation. Our global e-commerce platform just started showing inconsistent inventory counts. A user in Tokyo sees 5 items in stock, but someone in New York is seeing 12 for the same product. Both checked at the exact same time.\",\n      \"options\": [\n        {\n          \"feedback\": \"Unlikely. If the database were corrupted, we'd see random errors, not systematic regional differences. This looks like a distributed system consistency issue.\",\n          \"isCorrect\": false,\n          \"text\": \"The database is corrupted\"\n        },\n        {\n          \"feedback\": \"Exactly. Different regional replicas haven't synchronized yet. Eventual consistency lets each region serve requests quickly but means replicas can temporarily show different data.\",\n          \"isCorrect\": true,\n          \"text\": \"We're using eventual consistency\"\n        },\n        {\n          \"feedback\": \"That's a big leap. Security breaches usually show unusual patterns or data loss, not simple regional differences. This is a consistency model issue, not a security one.\",\n          \"isCorrect\": false,\n          \"text\": \"Someone hacked our inventory system\"\n        },\n        {\n          \"feedback\": \"Cache staleness could cause one user to see old data, but both users are querying live systems. This is about how our distributed replicas are staying in sync.\",\n          \"isCorrect\": false,\n          \"text\": \"The cache needs to be cleared\"\n        }\n      ],\n      \"question\": \"What's the most likely explanation for what's happening?\"\n    },\n    {\n      \"context\": \"Right. We're running eventual consistency to keep the site fast globally. But here's the problem — someone just bought what they thought was the last item in Tokyo, but New York's replica still shows 11 in stock. If we keep accepting orders, we might oversell.\",\n      \"options\": [\n        {\n          \"feedback\": \"Not quite. This isn't about security — it's about the fundamental CAP theorem trade-off: consistency versus availability. We can't have both during network delays.\",\n          \"isCorrect\": false,\n          \"text\": \"Speed vs security\"\n        },\n        {\n          \"feedback\": \"Exactly. We chose availability (letting all regions accept orders quickly) over consistency (ensuring all regions see identical inventory). That's the CAP theorem in action.\",\n          \"isCorrect\": true,\n          \"text\": \"Availability vs consistency\"\n        },\n        {\n          \"feedback\": \"While distributed systems do involve cost considerations, this specific problem is about the CAP theorem — choosing between serving requests quickly everywhere or guaranteeing all nodes show the same data.\",\n          \"isCorrect\": false,\n          \"text\": \"Cost vs performance\"\n        },\n        {\n          \"feedback\": \"The system is both scalable and reliable. The issue is consistency — whether all replicas show the same data at the same time. That's a different dimension from reliability.\",\n          \"isCorrect\": false,\n          \"text\": \"Scalability vs reliability\"\n        }\n      ],\n      \"question\": \"What trade-off are we facing here?\"\n    },\n    {\n      \"context\": \"The product team is freaking out. They want to switch to strong consistency immediately so we never oversell again. They're saying 'just make all the databases show the same number at the same time, how hard can it be?'\",\n      \"options\": [\n        {\n          \"feedback\": \"Strong consistency doesn't cause crashes. It requires coordination between regions, which adds latency and could reduce availability during network issues, but the site would still function.\",\n          \"isCorrect\": false,\n          \"text\": \"The site would crash\"\n        },\n        {\n          \"feedback\": \"Correct. Strong consistency requires coordinating across regions before confirming writes. That adds latency, and if a network partition occurs, we'd have to reject requests to maintain consistency.\",\n          \"isCorrect\": true,\n          \"text\": \"Increased latency and potential unavailability\"\n        },\n        {\n          \"feedback\": \"Strong consistency doesn't inherently require more storage — it's about coordination timing. We'd still have the same replicas, just synchronized differently.\",\n          \"isCorrect\": false,\n          \"text\": \"Higher storage costs\"\n        },\n        {\n          \"feedback\": \"Consistency models don't affect security. Strong consistency actually ensures all nodes agree on data state, but the trade-off is performance and availability, not security.\",\n          \"isCorrect\": false,\n          \"text\": \"Data would be less secure\"\n        }\n      ],\n      \"question\": \"What would be the consequence of switching to strong consistency?\"\n    },\n    {\n      \"context\": \"I just pulled up our metrics. During peak holiday traffic, we're seeing 200ms network latency between Tokyo and New York. If we enforce strong consistency, every inventory update would need to wait for cross-region confirmation. {{NAME}}, that could push our response times from 50ms to over 300ms.\",\n      \"options\": [\n        {\n          \"feedback\": \"Smart thinking! Critical data like inventory counts could use strong consistency or quorums, while less critical data like recommendations stays eventually consistent. Not all data needs the same guarantees.\",\n          \"isCorrect\": true,\n          \"text\": \"Different consistency per data type\"\n        },\n        {\n          \"feedback\": \"That's too rigid. Strong consistency everywhere would make the site unacceptably slow and less available. The CAP theorem forces trade-offs — we need to be strategic about which data needs which guarantees.\",\n          \"isCorrect\": false,\n          \"text\": \"Always choose strong consistency\"\n        },\n        {\n          \"feedback\": \"We just saw the problem with this approach — overselling inventory. Some data types need stronger guarantees. The right solution is matching consistency models to business requirements.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep eventual consistency everywhere\"\n        },\n        {\n          \"feedback\": \"That defeats the purpose of global distribution. A single database would add massive latency for distant users and create a single point of failure. Distributed systems exist for good reasons.\",\n          \"isCorrect\": false,\n          \"text\": \"Build a single central database\"\n        }\n      ],\n      \"question\": \"How should we approach this problem?\"\n    },\n    {\n      \"context\": \"Good call. I'm thinking we use a quorum system for inventory. But I need to explain this to the product team, and honestly, I'm not 100% sure I understand how quorums work. Something about voting, right?\",\n      \"options\": [\n        {\n          \"feedback\": \"That would be too slow and wouldn't handle failures well. Quorums use majority voting — write and read quorums overlap, ensuring you always read at least one up-to-date replica without needing unanimous agreement.\",\n          \"isCorrect\": false,\n          \"text\": \"All nodes must agree on every write\"\n        },\n        {\n          \"feedback\": \"Exactly! If we have 5 replicas and require 3 for writes and 3 for reads, the quorums overlap — guaranteeing any read includes at least one node with the latest write. It's consistency through math.\",\n          \"isCorrect\": true,\n          \"text\": \"Read + write quorum > total nodes\"\n        },\n        {\n          \"feedback\": \"Speed has nothing to do with quorums. Quorum systems use voting thresholds to ensure overlapping sets of nodes, guaranteeing reads see recent writes. It's about mathematical guarantees, not performance.\",\n          \"isCorrect\": false,\n          \"text\": \"The fastest node always wins\"\n        },\n        {\n          \"feedback\": \"You're thinking of leader election, which is different. Quorum systems use overlapping read and write thresholds to guarantee consistency. No leader is needed — the math ensures correctness.\",\n          \"isCorrect\": false,\n          \"text\": \"Nodes vote to elect a leader\"\n        }\n      ],\n      \"question\": \"How do quorum systems ensure consistency?\"\n    },\n    {\n      \"context\": \"Okay, so if we have 5 regional replicas and set write quorum to 3 and read quorum to 3, we're guaranteed to read fresh data. I'm setting this up now for inventory counts. {{NAME}}, we should also think about what happens during a network partition. What if Tokyo gets cut off from the other regions?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not with quorums. If Tokyo can't reach enough replicas to form a quorum (3 out of 5), it must reject requests to maintain consistency guarantees. Availability decreases but consistency is preserved.\",\n          \"isCorrect\": false,\n          \"text\": \"Tokyo continues normally, might serve stale data\"\n        },\n        {\n          \"feedback\": \"Correct. Without access to a quorum of replicas, Tokyo can't guarantee consistency, so it must reject inventory updates. This is the CAP theorem in practice — partition happens, we chose consistency over availability.\",\n          \"isCorrect\": true,\n          \"text\": \"Tokyo rejects requests until partition heals\"\n        },\n        {\n          \"feedback\": \"Quorum systems don't have leaders. If Tokyo is partitioned and can't reach enough replicas for a quorum, it must reject requests. Leadership doesn't solve the fundamental CAP theorem constraint.\",\n          \"isCorrect\": false,\n          \"text\": \"Tokyo automatically becomes the leader\"\n        },\n        {\n          \"feedback\": \"That would be catastrophic! Partitions are temporary network issues, not reasons to delete data. The system would reject requests until the partition heals, then resume normal operation.\",\n          \"isCorrect\": false,\n          \"text\": \"All replicas reset to zero\"\n        }\n      ],\n      \"question\": \"What would happen to Tokyo during a network partition with quorum-based inventory?\"\n    },\n    {\n      \"context\": \"This is tricky. So with quorums on inventory, Tokyo users might see errors during network issues. But wait — I just realized something. What about shopping carts? If two users in different regions add the last item to their cart at the same time before the replicas sync, we've got conflicting writes.\",\n      \"options\": [\n        {\n          \"feedback\": \"Close, but in distributed systems we call this a write conflict. Two replicas accepted concurrent updates that can't both be true. We need a conflict resolution strategy to handle this.\",\n          \"isCorrect\": false,\n          \"text\": \"A race condition\"\n        },\n        {\n          \"feedback\": \"Exactly. Two regions accepted concurrent writes that conflict. Now we need a strategy: last-write-wins, vector clocks, or application logic. The right choice depends on whether losing one update is acceptable.\",\n          \"isCorrect\": true,\n          \"text\": \"A write conflict needing resolution\"\n        },\n        {\n          \"feedback\": \"Deadlocks occur when processes wait for each other circularly. This is a write conflict — two replicas accepted updates that contradict each other. Different problem requiring conflict resolution.\",\n          \"isCorrect\": false,\n          \"text\": \"A deadlock\"\n        },\n        {\n          \"feedback\": \"Byzantine failures involve malicious or arbitrary behavior from nodes. This is just normal concurrent writes being accepted by different replicas — a conflict that needs resolution, not a Byzantine fault.\",\n          \"isCorrect\": false,\n          \"text\": \"A Byzantine failure\"\n        }\n      ],\n      \"question\": \"What problem is this describing?\"\n    },\n    {\n      \"context\": \"Right, we need conflict resolution. I'm looking at our options. Last-write-wins seems simple — just timestamp everything and keep the newest write. For shopping carts, that should work fine, right?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! Distributed clocks aren't perfectly synchronized. If Tokyo's clock is slightly ahead, it always \\\"wins\\\" even if its write was actually older. For carts, losing user additions is frustrating — maybe we want merge logic instead.\",\n          \"isCorrect\": true,\n          \"text\": \"Clock skew could pick the wrong winner\"\n        },\n        {\n          \"feedback\": \"Last-write-wins is actually very fast — just compare timestamps. The issue is correctness: clock skew can make the 'last' write ambiguous, and discarding user actions (like cart additions) might hurt the experience.\",\n          \"isCorrect\": false,\n          \"text\": \"It's too slow for production use\"\n        },\n        {\n          \"feedback\": \"Last-write-wins doesn't require extra storage — you keep one version and discard others. The problem is semantic: blindly discarding cart additions based on timestamps might lose user actions due to clock skew.\",\n          \"isCorrect\": false,\n          \"text\": \"It requires too much storage\"\n        },\n        {\n          \"feedback\": \"Last-write-wins works fine during partitions — that's why eventual consistency systems use it. The issue is that it discards one write, which for shopping carts might mean losing items a user added.\",\n          \"isCorrect\": false,\n          \"text\": \"It can't handle network partitions\"\n        }\n      ],\n      \"question\": \"What's the risk with last-write-wins for shopping carts?\"\n    },\n    {\n      \"context\": \"Good point. Clock skew is real, and users would be furious if items disappeared from their carts. Maybe for shopping carts we should merge conflicts — combine items from both carts instead of picking a winner. {{NAME}}, what would be the downside of always merging?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! If a user removes an item in one region and adds a different item in another during a partition, merging brings back the removed item. Sometimes application logic needs to be smarter than simple merging.\",\n          \"isCorrect\": true,\n          \"text\": \"Users could see items they removed\"\n        },\n        {\n          \"feedback\": \"Merging is totally implementable — systems like Dynamo do it. The challenge is semantic: naive merging can resurrect items users deleted. You might need vector clocks or CRDTs to handle deletes properly.\",\n          \"isCorrect\": false,\n          \"text\": \"Merging is impossible to implement\"\n        },\n        {\n          \"feedback\": \"Merging is a conflict resolution strategy for eventually consistent systems. It doesn't violate anything — it defines how conflicts are resolved. The question is whether the merge semantics match user expectations.\",\n          \"isCorrect\": false,\n          \"text\": \"It violates strong consistency\"\n        },\n        {\n          \"feedback\": \"Merging doesn't require any specific quorum. It's what happens after a conflict is detected. You can use merging with eventual consistency, quorums, or any consistency model.\",\n          \"isCorrect\": false,\n          \"text\": \"It requires unanimous quorum\"\n        }\n      ],\n      \"question\": \"What's a problem with always merging shopping cart conflicts?\"\n    },\n    {\n      \"context\": \"Ugh, you're right. A user removes an item, we merge, and suddenly it's back. That's terrible UX. Maybe we need vector clocks to track causality? I've heard they can tell if one write happened after another or if they're truly concurrent.\",\n      \"options\": [\n        {\n          \"feedback\": \"Vector clocks don't affect write speed. They track causality — which updates have 'seen' which other updates. This helps distinguish 'user removed then added' from 'two concurrent additions', enabling smarter conflict resolution.\",\n          \"isCorrect\": false,\n          \"text\": \"They make writes faster\"\n        },\n        {\n          \"feedback\": \"Correct! Vector clocks track which events have 'seen' which others. If one write's vector clock dominates another's, they're causally related. If neither dominates, they're concurrent. This enables application logic to resolve conflicts intelligently.\",\n          \"isCorrect\": true,\n          \"text\": \"They detect true concurrency vs causality\"\n        },\n        {\n          \"feedback\": \"Vector clocks detect concurrency but don't resolve conflicts automatically. They give you information to make smart decisions: merge concurrent adds, but respect causal deletes. The application still chooses the resolution strategy.\",\n          \"isCorrect\": false,\n          \"text\": \"They automatically resolve all conflicts\"\n        },\n        {\n          \"feedback\": \"Vector clocks do replace timestamps for causality tracking, but that's not the main benefit. They help distinguish 'A happened before B' from 'A and B were concurrent', enabling context-aware conflict resolution.\",\n          \"isCorrect\": false,\n          \"text\": \"They eliminate the need for timestamps\"\n        }\n      ],\n      \"question\": \"How do vector clocks help with this problem?\"\n    },\n    {\n      \"context\": \"Okay, so vector clocks give us causality information, then our application logic decides what to do. This is getting complex though. {{NAME}}, I'm starting to wonder if we're overengineering this. What if we just went back to strong consistency for everything and called it a day?\",\n      \"options\": [\n        {\n          \"feedback\": \"Cost isn't the main issue. Strong consistency is implementable but kills the performance and availability that made us go distributed in the first place. We'd have slow responses globally and downtime during network partitions.\",\n          \"isCorrect\": false,\n          \"text\": \"It's too expensive to implement\"\n        },\n        {\n          \"feedback\": \"Exactly. We went distributed for low latency and high availability globally. Strong consistency everywhere means waiting for cross-region coordination on every operation — slow responses and unavailability during partitions. The CAP theorem doesn't go away.\",\n          \"isCorrect\": true,\n          \"text\": \"It negates the benefits of distribution\"\n        },\n        {\n          \"feedback\": \"Many databases support strong consistency (like Spanner). The issue isn't technical support — it's that strong consistency everywhere sacrifices the availability and low latency that global distribution provides. Wrong tool for a global e-commerce platform.\",\n          \"isCorrect\": false,\n          \"text\": \"It's not supported by modern databases\"\n        },\n        {\n          \"feedback\": \"Strong consistency actually does prevent conflicts by coordinating all writes. But it achieves this by adding latency and reducing availability during partitions — trading the benefits of distribution for consistency guarantees.\",\n          \"isCorrect\": false,\n          \"text\": \"It can't prevent all conflicts\"\n        }\n      ],\n      \"question\": \"Why wouldn't strong consistency everywhere be a good solution?\"\n    },\n    {\n      \"context\": \"You're right, we'd be throwing away everything good about going distributed. Okay, new approach: inventory gets quorum-based consistency because overselling is bad for business. Shopping carts get eventual consistency with vector-clock-based merging because users care more about speed than perfect conflict resolution on carts.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! Not all data is equal. Critical data like inventory needs stronger consistency. User-facing, non-critical data like carts can tolerate eventual consistency. Matching consistency models to business requirements is key to distributed system design.\",\n          \"isCorrect\": true,\n          \"text\": \"Different data needs different guarantees\"\n        },\n        {\n          \"feedback\": \"No! We're being selective. Inventory gets stronger consistency (correctness over speed) because overselling is costly. Carts get eventual consistency (speed over perfect consistency) because the trade-off makes sense there. It's context-dependent.\",\n          \"isCorrect\": false,\n          \"text\": \"Always prioritize performance over correctness\"\n        },\n        {\n          \"feedback\": \"We're literally using quorums for inventory, which provides stronger guarantees than eventual consistency. The principle is matching consistency models to requirements — not picking one approach for everything.\",\n          \"isCorrect\": false,\n          \"text\": \"Eventual consistency is always better\"\n        },\n        {\n          \"feedback\": \"Quorums are great for some use cases but aren't universal. We're using them for inventory but eventual consistency with merging for carts. The principle is choosing the right consistency model for each data type.\",\n          \"isCorrect\": false,\n          \"text\": \"Quorums solve all distributed problems\"\n        }\n      ],\n      \"question\": \"What principle are we applying here?\"\n    },\n    {\n      \"context\": \"I'm configuring this now. Inventory: 5 replicas, write quorum 3, read quorum 3. Shopping carts: eventual consistency with vector clock merging that respects causality. {{NAME}}, wait... I just thought of something. What happens during checkout? That's when cart becomes an actual inventory deduction.\",\n      \"options\": [\n        {\n          \"feedback\": \"No — at checkout, we're decrementing real inventory. That needs the stronger guarantees of the quorum system. The checkout process must validate against and update inventory using its consistency model.\",\n          \"isCorrect\": false,\n          \"text\": \"Use the cart's consistency model\"\n        },\n        {\n          \"feedback\": \"Correct! At checkout, we switch from eventual cart consistency to quorum-based inventory consistency. We validate stock levels and deduct using the quorum system, potentially failing if inventory is gone. Different stages, different guarantees.\",\n          \"isCorrect\": true,\n          \"text\": \"Validate and deduct using inventory's model\"\n        },\n        {\n          \"feedback\": \"That's overcomplicating it. Checkout is just moving from 'considering buying' (carts) to 'actually buying' (inventory). Use the eventual model for carts, then validate and commit using inventory's quorum system.\",\n          \"isCorrect\": false,\n          \"text\": \"Create a new consistency model for checkout\"\n        },\n        {\n          \"feedback\": \"Carts and inventory have different requirements — carts need speed, inventory needs accuracy. At checkout, we transition from one to the other: validate cart items against quorum-based inventory and commit if available.\",\n          \"isCorrect\": false,\n          \"text\": \"Merge the two systems into one\"\n        }\n      ],\n      \"question\": \"How should we handle the cart-to-inventory transition?\"\n    },\n    {\n      \"context\": \"Perfect. So carts can have items that are eventually unavailable, but checkout validates against real inventory using quorums. Worst case, users get an 'out of stock' error at checkout, but at least they had a fast shopping experience. I'm deploying this config now...\",\n      \"options\": [\n        {\n          \"feedback\": \"Error rates matter, but you need more. Monitor quorum success rates (are regions reachable?), replication lag (how eventual is eventual?), conflict frequency, and checkout failures. These show if your consistency trade-offs are working.\",\n          \"isCorrect\": false,\n          \"text\": \"Only error rates\"\n        },\n        {\n          \"feedback\": \"Exactly! Quorum success rates show partition impact, replication lag shows convergence speed, conflict frequency reveals concurrent write patterns, and checkout failures indicate inventory consistency issues. These metrics validate your consistency model choices.\",\n          \"isCorrect\": true,\n          \"text\": \"Quorum health, lag, conflicts, checkout failures\"\n        },\n        {\n          \"feedback\": \"Infrastructure metrics are important but don't show if your consistency models are working. You need to monitor quorum health, replication lag, conflict rates, and business metrics like checkout failures to see if your trade-offs make sense.\",\n          \"isCorrect\": false,\n          \"text\": \"CPU and memory usage only\"\n        },\n        {\n          \"feedback\": \"Distributed systems are complex! Monitor quorum availability, replication lag, conflict rates, and checkout failure patterns. These show whether your consistency trade-offs match reality and where you might need to adjust.\",\n          \"isCorrect\": false,\n          \"text\": \"Nothing, trust the system\"\n        }\n      ],\n      \"question\": \"What should we monitor after deployment?\"\n    },\n    {\n      \"context\": \"Great point. I'm setting up dashboards for all of that. {{NAME}}, deployment's done! Initial metrics look good — inventory quorum writes averaging 180ms, cart writes at 45ms. Replication lag is under 100ms globally. Wait... I'm seeing something weird. Tokyo is showing 15% checkout failures, but other regions are under 2%. What's going on?\",\n      \"options\": [\n        {\n          \"feedback\": \"If Tokyo's database were broken, we'd see errors across the board. Checkout failures specifically suggest Tokyo's eventual cart replicas are more stale than other regions — users are adding unavailable items to carts that haven't synced yet.\",\n          \"isCorrect\": false,\n          \"text\": \"Tokyo's database is broken\"\n        },\n        {\n          \"feedback\": \"Most likely! If Tokyo's replication lag is higher, cart replicas are more stale. Users add items that are already sold out elsewhere, then hit inventory's quorum check at checkout and fail. This is eventual consistency in action — lag matters.\",\n          \"isCorrect\": true,\n          \"text\": \"Higher replication lag in Tokyo\"\n        },\n        {\n          \"feedback\": \"Possible but unlikely to cause a 15% vs 2% difference. The more probable explanation is that Tokyo's cart replicas have higher lag, showing inventory as available when it's already sold out in other regions.\",\n          \"isCorrect\": false,\n          \"text\": \"Tokyo users are more aggressive shoppers\"\n        },\n        {\n          \"feedback\": \"Quorum configuration is global. If Tokyo had quorum issues, we'd see problems with inventory reads/writes, not specifically checkout failures. This points to replication lag making cart data stale.\",\n          \"isCorrect\": false,\n          \"text\": \"The quorum size is wrong for Tokyo\"\n        }\n      ],\n      \"question\": \"What could explain Tokyo's higher checkout failure rate?\"\n    },\n    {\n      \"context\": \"I just checked — you're right! Tokyo's replication lag spiked to 800ms during the last hour. Network issues with the undersea cable to the US. So Tokyo users were seeing inventory availability from 800ms ago, adding items to carts, then failing at checkout when the quorum check happened against current inventory.\",\n      \"options\": [\n        {\n          \"feedback\": \"That would make Tokyo's response times terrible during network issues and potentially unavailable during partitions. Better to show lag-aware warnings or check inventory before adding to cart in high-lag scenarios.\",\n          \"isCorrect\": false,\n          \"text\": \"Switch Tokyo to strong consistency\"\n        },\n        {\n          \"feedback\": \"Smart! Monitor replication lag and surface warnings like 'inventory numbers may be delayed' when lag exceeds thresholds. Or do soft inventory checks before cart adds during high lag. Transparency helps manage user expectations around eventual consistency.\",\n          \"isCorrect\": true,\n          \"text\": \"Show warnings when lag is high\"\n        },\n        {\n          \"feedback\": \"That's too drastic. Some checkouts will succeed! Better to warn users about potential delays or do soft inventory checks during high lag periods. Complete shutdowns sacrifice too much availability.\",\n          \"isCorrect\": false,\n          \"text\": \"Disable checkouts in Tokyo during lag\"\n        },\n        {\n          \"feedback\": \"That defeats the whole point of global distribution. Tokyo users need low-latency access. Better to monitor lag and adjust the UX (warnings, soft checks) when lag is high rather than eliminate the replica.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove Tokyo's replica entirely\"\n        }\n      ],\n      \"question\": \"How could we reduce this user impact?\"\n    },\n    {\n      \"context\": \"I like that. I'm adding lag monitoring to the UI — if replication lag exceeds 500ms, we show a banner: 'High demand, inventory numbers updating.' Also adding a lightweight inventory check before cart adds when lag is high. It won't be perfect, but it sets expectations. {{NAME}}, this has been quite the journey.\",\n      \"options\": [\n        {\n          \"feedback\": \"No! We explicitly used different models for different data. Inventory got quorum consistency, carts got eventual. The lesson is matching consistency guarantees to business requirements, not one-size-fits-all.\",\n          \"isCorrect\": false,\n          \"text\": \"Always use the same consistency everywhere\"\n        },\n        {\n          \"feedback\": \"Exactly! The CAP theorem forces trade-offs. Critical data (inventory) gets stronger guarantees. User-facing data (carts) prioritizes availability. Monitor lag, adapt UX, and choose consistency models that match business needs. That's distributed systems design.\",\n          \"isCorrect\": true,\n          \"text\": \"Consistency models should match requirements\"\n        },\n        {\n          \"feedback\": \"They are complex, but the complexity brings global low latency and high availability. The lesson isn't to avoid distribution — it's to thoughtfully choose consistency models per data type and monitor the trade-offs you've made.\",\n          \"isCorrect\": false,\n          \"text\": \"Distributed systems are too complex\"\n        },\n        {\n          \"feedback\": \"We used eventual consistency successfully for shopping carts! It works great when temporary staleness is acceptable. The lesson is matching models to requirements — eventual consistency for some data, stronger guarantees for others.\",\n          \"isCorrect\": false,\n          \"text\": \"Eventual consistency never works\"\n        }\n      ],\n      \"question\": \"What's the key takeaway from what we just built?\"\n    },\n    {\n      \"context\": \"Absolutely. Oh, and {{NAME}}? The cable issues just cleared up. Tokyo's lag dropped back to 100ms and checkout failures are down to 2%. I guess there's one more lesson here: sometimes the 'bug' is just physics and networking doing their thing. Our job is building systems that handle it gracefully.\",\n      \"options\": [\n        {\n          \"feedback\": \"We just experienced one! Network issues are common in distributed systems. The CAP theorem says partitions happen, so you must choose between consistency and availability. Building for this reality is core distributed system design.\",\n          \"isCorrect\": false,\n          \"text\": \"Network partitions are rare edge cases\"\n        },\n        {\n          \"feedback\": \"Perfect! The CAP theorem's 'P' is non-negotiable — networks partition. We can't prevent it, so we design systems that handle it gracefully: choose appropriate consistency models, monitor lag, adapt UX. That's the distributed systems mindset.\",\n          \"isCorrect\": true,\n          \"text\": \"Partitions are inevitable, design for them\"\n        },\n        {\n          \"feedback\": \"No! Distributed systems give us global reach and resilience. The lesson is that partitions are inevitable, so we design for them: appropriate consistency models, monitoring, graceful degradation. Embrace distribution, handle the challenges.\",\n          \"isCorrect\": false,\n          \"text\": \"We should avoid distributed systems\"\n        },\n        {\n          \"feedback\": \"Strong consistency can't prevent network partitions — they're a physical reality. It just changes the failure mode: reject requests instead of serve potentially stale data. You still must design for partition scenarios.\",\n          \"isCorrect\": false,\n          \"text\": \"Strong consistency prevents all problems\"\n        }\n      ],\n      \"question\": \"What does this final observation illustrate?\"\n    }\n  ]\n}",
      "outputTokens": 7326,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-cs-distributed-systems-consistency-1",
      "userPrompt": "LESSON_TITLE: Consistency in Distributed Systems\nLESSON_DESCRIPTION: Navigating consistency and availability trade-offs in distributed systems\nCHAPTER_TITLE: Distributed Data\nCOURSE_TITLE: System Design\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. CAP Theorem: The CAP theorem states you can only have two of three: Consistency, Availability, and Partition tolerance. Since network partitions happen, you're really choosing between C and A.\n2. Strong Consistency: Strong consistency means all nodes see the same data at the same time. Every read returns the most recent write. This requires coordination that can slow things down.\n3. Eventual Consistency: Eventual consistency means replicas will converge given enough time without new writes. Reads might return stale data temporarily, but the system stays available.\n4. Partition Handling: Network partitions occur when nodes can't communicate. The system must decide: reject requests (maintain consistency) or accept requests that might conflict (maintain availability).\n5. Quorum Systems: Quorum-based systems use voting. A write succeeds if enough replicas acknowledge it. Read quorum + write quorum > total nodes ensures reading at least one up-to-date copy.\n6. Conflict Resolution: Conflict resolution strategies handle divergent writes: last-write-wins, vector clocks, or application-specific merge logic. The right choice depends on your data semantics."
    },
    {
      "duration": 147224.13612500002,
      "inputTokens": 4182,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we have a problem. Our new savings app launched three weeks ago with all the features users said they wanted — goal tracking, custom amounts, flexible schedules. Adoption is great, but only 12% of users are actually saving money. The rest signed up and... nothing.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. People intend to save but present bias makes today's money feel more valuable than future security. We need to understand this before designing interventions.\",\n          \"isCorrect\": true,\n          \"text\": \"Present bias — future rewards feel distant\"\n        },\n        {\n          \"feedback\": \"Social proof could help later, but the core issue is that users have the app and aren't using it. They already adopted it — now we need to address why they're not taking action.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — maybe they need testimonials\"\n        },\n        {\n          \"feedback\": \"Framing matters for persuasion, but users already signed up. The problem isn't how we present the value — it's that taking action feels harder than not taking action.\",\n          \"isCorrect\": false,\n          \"text\": \"Framing effects — reword our messaging\"\n        },\n        {\n          \"feedback\": \"Loss aversion is powerful, but jumping to messaging tactics skips diagnosis. First understand why the behavior isn't happening, then choose the right intervention.\",\n          \"isCorrect\": false,\n          \"text\": \"Loss aversion — highlight what they're losing\"\n        }\n      ],\n      \"question\": \"What behavioral principle should we examine first?\"\n    },\n    {\n      \"context\": \"Right, present bias is killing us. Users want to save 'someday' but every day, spending feels better. I'm looking at the onboarding flow — we ask users to choose an amount and set up a schedule. Totally flexible, totally in their control.\",\n      \"options\": [\n        {\n          \"feedback\": \"Decision fatigue is real, but that's not the main issue here. The bigger problem is that flexibility leaves users in their comfort zone of inaction.\",\n          \"isCorrect\": false,\n          \"text\": \"Too many decisions create friction\"\n        },\n        {\n          \"feedback\": \"Bingo. When everything is optional, nothing happens. Default effects show that pre-selecting an option dramatically increases follow-through. Right now, the default is 'do nothing.'\",\n          \"isCorrect\": true,\n          \"text\": \"No default means no anchor for action\"\n        },\n        {\n          \"feedback\": \"The interface is clear — users complete onboarding. The problem isn't comprehension, it's that choosing requires effort and commitment. Defaults remove that friction.\",\n          \"isCorrect\": false,\n          \"text\": \"Users don't understand the interface\"\n        },\n        {\n          \"feedback\": \"We're not suggesting amounts — that's the problem. Users face a blank slate. Even if amounts were too high, having a default would still outperform having none.\",\n          \"isCorrect\": false,\n          \"text\": \"The amounts we suggest are too high\"\n        }\n      ],\n      \"question\": \"What's the behavioral problem with this approach?\"\n    },\n    {\n      \"context\": \"Okay, so we need a default. I'm thinking we auto-select $50 per week, starting next Monday. Users can change it, but at least there's something there. Sound good?\",\n      \"options\": [\n        {\n          \"feedback\": \"Too high and users will change it to zero. Defaults work best when they're easy to accept. Start with an amount most people can comfortably commit to.\",\n          \"isCorrect\": false,\n          \"text\": \"Make it higher to maximize savings\"\n        },\n        {\n          \"feedback\": \"Yes. 'Next Monday' feeds present bias — it's still the future. Immediate action, even with a small amount, creates momentum. Make the first transfer happen today.\",\n          \"isCorrect\": true,\n          \"text\": \"Start immediately, not next Monday\"\n        },\n        {\n          \"feedback\": \"That's better than total flexibility, but it's still asking users to decide. A true default is already selected — they keep it or change it, but inertia favors keeping it.\",\n          \"isCorrect\": false,\n          \"text\": \"Let users pick from preset tiers\"\n        },\n        {\n          \"feedback\": \"Defaults are powerful because they preserve choice. Forcing behavior isn't a default — it's a requirement, and it will trigger resistance and abandonment.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove the ability to change it\"\n        }\n      ],\n      \"question\": \"What would make this default more effective?\"\n    },\n    {\n      \"context\": \"Good call. First transfer happens today. I'm updating the flow now. Actually, {{NAME}}, while we're at it — should we frame this as 'save $25 per week' or 'set aside less than $4 per day'? Same amount, different framing.\",\n      \"options\": [\n        {\n          \"feedback\": \"Both are honest. But '$4 per day' makes the sacrifice feel smaller and more immediate. Framing effects mean how you present numbers changes how they feel, even when logically identical.\",\n          \"isCorrect\": false,\n          \"text\": \"$25 per week — clear and honest\"\n        },\n        {\n          \"feedback\": \"Exactly. Smaller daily amounts feel less painful than larger weekly chunks. This framing reduces the perceived cost right now, making it easier to accept the default.\",\n          \"isCorrect\": true,\n          \"text\": \"Less than $4 per day — feels manageable\"\n        },\n        {\n          \"feedback\": \"Hiding information breaks trust. Behavioral design works with psychology, not against awareness. Users need to know what they're committing to.\",\n          \"isCorrect\": false,\n          \"text\": \"Don't show the amount at all\"\n        },\n        {\n          \"feedback\": \"Showing both creates cognitive load and invites comparison. Pick the framing that supports the behavior you want. Clarity matters more than exhaustive information.\",\n          \"isCorrect\": false,\n          \"text\": \"Show both framings for transparency\"\n        }\n      ],\n      \"question\": \"Which framing better addresses present bias?\"\n    },\n    {\n      \"context\": \"Okay, we're rolling out the new flow tomorrow — default $25/week, framed as under $4/day, first transfer today. I'm feeling optimistic. But {{NAME}}, I just remembered — our competitor app shows this big stat: '87% of our users save successfully.' Should we add something like that?\",\n      \"options\": [\n        {\n          \"feedback\": \"After the new default launches, that number will change. More importantly, you can use social proof about related behaviors: 'Most users start with our recommended amount.'\",\n          \"isCorrect\": false,\n          \"text\": \"Don't — we only have 12% success rate\"\n        },\n        {\n          \"feedback\": \"Volume implies popularity but not behavior. Better to show what people actually do: 'Most people save weekly' guides the specific action you want.\",\n          \"isCorrect\": false,\n          \"text\": \"Show 'Join 10,000+ savers' if we have volume\"\n        },\n        {\n          \"feedback\": \"Perfect. This combines social proof with the default, reinforcing that keeping the default is normal behavior. It makes the recommended action feel safe and appropriate.\",\n          \"isCorrect\": true,\n          \"text\": \"Add 'Most people start with $25/week'\"\n        },\n        {\n          \"feedback\": \"You can use social proof about the default itself right away. 'Most people keep the recommended amount' is likely true once you implement the default.\",\n          \"isCorrect\": false,\n          \"text\": \"Wait until our stats improve first\"\n        }\n      ],\n      \"question\": \"How should we use social proof here?\"\n    },\n    {\n      \"context\": \"Love it. I'm adding that copy. This is coming together. Oh — one more thing. We send users a weekly email showing their progress. Should we say 'You've saved $100!' or 'You're $100 closer to your $1,000 goal'? Or does it not matter?\",\n      \"options\": [\n        {\n          \"feedback\": \"Gains feel good but aren't as motivating as you'd think. The second framing emphasizes the remaining gap — which loss aversion makes more compelling. People work harder to close gaps.\",\n          \"isCorrect\": false,\n          \"text\": \"First option — celebrate the gain\"\n        },\n        {\n          \"feedback\": \"Yes. Loss aversion means the '$900 still to go' feels more urgent than '$100 saved.' Framing progress as closing a gap leverages our psychological aversion to incomplete goals.\",\n          \"isCorrect\": true,\n          \"text\": \"Second option — highlight the gap\"\n        },\n        {\n          \"feedback\": \"Inconsistent framing creates confusion. Pick the frame that drives behavior. Loss aversion research shows gap-framing motivates continued action better than gain-framing.\",\n          \"isCorrect\": false,\n          \"text\": \"Alternate between both each week\"\n        },\n        {\n          \"feedback\": \"Raw numbers require users to interpret them. Behavioral design means deliberately framing information to support the psychology that drives action. Don't leave motivation to chance.\",\n          \"isCorrect\": false,\n          \"text\": \"Neither — just show the numbers\"\n        }\n      ],\n      \"question\": \"What does behavioral design suggest?\"\n    },\n    {\n      \"context\": \"Gap-framing it is. {{NAME}}, I'm deploying all these changes now. Defaults, immediate action, social proof, loss-framed progress. Let's check back in two weeks and see if... wait. Hold on. I'm looking at the data again.\",\n      \"options\": [\n        {\n          \"feedback\": \"Engagement matters, but the real test is behavior change. Are more users actually saving money? That's the outcome we designed for.\",\n          \"isCorrect\": false,\n          \"text\": \"Whether users are opening the app\"\n        },\n        {\n          \"feedback\": \"Interesting metric, but secondary. Some will change it — that's fine. The question is whether the default increased overall saving rates. Focus on the primary outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"How many users change the default\"\n        },\n        {\n          \"feedback\": \"Satisfaction doesn't equal behavior change. Users might love features that don't help them save. Behavioral design measures actual actions, not just sentiment.\",\n          \"isCorrect\": false,\n          \"text\": \"User satisfaction scores\"\n        },\n        {\n          \"feedback\": \"Smart. You need a clear before-and-after comparison. Document current behavior now so you can measure the impact of your interventions. Good behavioral design is evidence-based.\",\n          \"isCorrect\": true,\n          \"text\": \"Baseline metrics before the changes\"\n        }\n      ],\n      \"question\": \"What are you checking?\"\n    },\n    {\n      \"context\": \"Yeah, documenting everything. Current state: 12% save anything, average first deposit $18, 4% still saving after 30 days. If our interventions work, all three numbers should jump. I'll set a calendar reminder to... {{NAME}}, why are you smiling?\",\n      \"options\": [\n        {\n          \"feedback\": \"Confidence is good, but behavioral design requires humility. We're testing hypotheses, not guaranteeing outcomes. The smile is probably about something else.\",\n          \"isCorrect\": false,\n          \"text\": \"This is going to work perfectly\"\n        },\n        {\n          \"feedback\": \"In a lab, yes. In product, bundling synergistic changes makes sense. Defaults + social proof + better framing work together. The smile isn't about methodology concerns.\",\n          \"isCorrect\": false,\n          \"text\": \"We should test one change at a time\"\n        },\n        {\n          \"feedback\": \"Exactly! Defaults for action, framing for pain reduction, present bias diagnosis, social proof for norms, loss aversion for motivation. Real behavioral design combines principles strategically.\",\n          \"isCorrect\": true,\n          \"text\": \"We just used all five principles together\"\n        },\n        {\n          \"feedback\": \"Competition isn't the point right now. The smile is about something more immediate — the realization of how all these concepts just came together in one solution.\",\n          \"isCorrect\": false,\n          \"text\": \"The competitor will copy our features\"\n        }\n      ],\n      \"question\": \"What might you be thinking?\"\n    },\n    {\n      \"context\": \"Ha, yes! We just applied the entire framework without even meaning to. It all fit together naturally. Okay, deploying now. Two weeks until we... wait. {{NAME}}. I just realized something. We're setting a default amount. What about a default goal?\",\n      \"options\": [\n        {\n          \"feedback\": \"Goals can have defaults too. 'Emergency fund: $1,000' is a widely recommended starter goal. Defaults work when they're reasonable for most people, and this one is.\",\n          \"isCorrect\": false,\n          \"text\": \"No — goals are too personal\"\n        },\n        {\n          \"feedback\": \"Perfect. This gives immediate purpose to saving, creates a progress bar to leverage loss aversion, and solves the 'I don't know what to save for' problem. Another smart default.\",\n          \"isCorrect\": true,\n          \"text\": \"Yes — 'Emergency fund: $1,000'\"\n        },\n        {\n          \"feedback\": \"That's better than nothing, but still requires a decision. A default goal kickstarts action. Users who want something different will change it — most will keep it.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes — but let them choose from a list\"\n        },\n        {\n          \"feedback\": \"That's just a fallback, not a true default. A default is presented first. Users who have strong preferences will override it. The goal is to help everyone else start.\",\n          \"isCorrect\": false,\n          \"text\": \"Only for users who don't set their own\"\n        }\n      ],\n      \"question\": \"Should we add a default savings goal?\"\n    },\n    {\n      \"context\": \"Adding the $1,000 emergency fund default now. This is good, {{NAME}}. Really good. Okay, everything's staged. I'm going to hit deploy and... actually, one last thing. Should we A/B test this, or just roll it out to everyone?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Keep a control group with the old flow. This lets you measure exactly how much these interventions improve behavior. Good behavioral design is always evidence-based.\",\n          \"isCorrect\": true,\n          \"text\": \"A/B test to measure impact\"\n        },\n        {\n          \"feedback\": \"Impatience can backfire. Without a control group, you won't know what caused changes. Maybe seasonality, maybe external factors. A/B testing gives you real learning.\",\n          \"isCorrect\": false,\n          \"text\": \"Full rollout — we need the impact now\"\n        },\n        {\n          \"feedback\": \"These principles work synergistically. Testing one at a time would take months. Better to test the bundle versus control, then iterate based on what you learn.\",\n          \"isCorrect\": false,\n          \"text\": \"Test defaults only, add other changes later\"\n        },\n        {\n          \"feedback\": \"User preference doesn't predict behavior. People might prefer flexibility but behave better with defaults. Behavioral design measures actual outcomes, not stated preferences.\",\n          \"isCorrect\": false,\n          \"text\": \"Ask users which version they prefer\"\n        }\n      ],\n      \"question\": \"What's the best approach?\"\n    },\n    {\n      \"context\": \"A/B test launching... now. 50% get the new flow with all the behavioral interventions, 50% get the current experience. Two weeks and we'll know if behavioral design actually... {{NAME}}, I'm getting a Slack from the CEO.\",\n      \"options\": [\n        {\n          \"feedback\": \"Unlikely — you just launched it. The message is probably about something else. Stay focused on your test. Good behavioral design takes patience to see results.\",\n          \"isCorrect\": false,\n          \"text\": \"She saw the experiment and has concerns\"\n        },\n        {\n          \"feedback\": \"Possible, but you just started the test. More likely this is about something unrelated. The real learning will come in two weeks when you have data.\",\n          \"isCorrect\": false,\n          \"text\": \"She wants an update on the 12% problem\"\n        },\n        {\n          \"feedback\": \"Could be, but there's a more interesting possibility given the context of what you've been working on and when the message arrived.\",\n          \"isCorrect\": false,\n          \"text\": \"Unrelated — bad timing coincidence\"\n        },\n        {\n          \"feedback\": \"Plot twist! She just went through the new onboarding and experienced the defaults firsthand. This is about to get interesting — your CEO is now a test subject.\",\n          \"isCorrect\": true,\n          \"text\": \"She's in the treatment group and noticed\"\n        }\n      ],\n      \"question\": \"What's it probably about?\"\n    },\n    {\n      \"context\": \"'Hey, I just opened the app to check something and it started a $25/week savings plan for me? I didn't choose that. I changed it to zero. What's going on?' Oh no. {{NAME}}, how do I respond to this?\",\n      \"options\": [\n        {\n          \"feedback\": \"Don't panic. She used the product exactly as designed — she changed the default. That's allowed. Explain the behavioral design rationale calmly. This is a learning moment.\",\n          \"isCorrect\": false,\n          \"text\": \"Apologize and remove her from the test\"\n        },\n        {\n          \"feedback\": \"Too vague. Be specific about the behavioral problem and the intervention. She's the CEO — give her the strategic context, not just 'we're testing something.'\",\n          \"isCorrect\": false,\n          \"text\": \"Explain it's an A/B test for engagement\"\n        },\n        {\n          \"feedback\": \"Exactly. 'We're testing defaults to improve our 12% action rate. You experienced the intervention and exercised choice — exactly as designed. Early data will tell us if this works.'\",\n          \"isCorrect\": true,\n          \"text\": \"Explain the behavioral design strategy\"\n        },\n        {\n          \"feedback\": \"Never lie about your design decisions. This isn't a bug — it's an intentional intervention based on behavioral economics. Own it and explain the reasoning.\",\n          \"isCorrect\": false,\n          \"text\": \"Say it's a bug and you'll fix it\"\n        }\n      ],\n      \"question\": \"What's the right move here?\"\n    },\n    {\n      \"context\": \"I sent her the explanation — the 12% problem, the behavioral principles, why defaults work, that choice is preserved. She's typing... 'Interesting. Okay, I get it. But I'm a power user. I know exactly what I want. Defaults are for people who don't.'\",\n      \"options\": [\n        {\n          \"feedback\": \"This validates the wrong mental model. Defaults affect everyone, including experts. Organ donation defaults work across all education levels. Don't concede to the power user myth.\",\n          \"isCorrect\": false,\n          \"text\": \"Agree — defaults help average users most\"\n        },\n        {\n          \"feedback\": \"Correct. Behavioral biases affect all humans. Even experts stick with defaults due to inertia and cognitive load. She changed it because she had strong motivation — most people don't.\",\n          \"isCorrect\": true,\n          \"text\": \"Defaults work for everyone, not just novices\"\n        },\n        {\n          \"feedback\": \"Don't create complexity to satisfy one user's self-image. Defaults with choice already serve both audiences. Adding modes fragments the experience.\",\n          \"isCorrect\": false,\n          \"text\": \"Suggest we add a 'power user' mode\"\n        },\n        {\n          \"feedback\": \"Don't abandon sound behavioral design because one person — even the CEO — had a preference. Wait for the data. Evidence, not opinions, should drive decisions.\",\n          \"isCorrect\": false,\n          \"text\": \"Tell her we'll reconsider the approach\"\n        }\n      ],\n      \"question\": \"How do you respond to this?\"\n    },\n    {\n      \"context\": \"'Hm. Fair point. Okay, run the test. I'll be curious to see the results.' Crisis averted. {{NAME}}, that was stressful. But also... kind of perfect? She literally proved that defaults preserve choice. She just didn't like being defaulted.\",\n      \"options\": [\n        {\n          \"feedback\": \"There's truth here, but the deeper insight is more specific. She didn't object to being nudged — she objected after experiencing it personally. The principle is broader.\",\n          \"isCorrect\": false,\n          \"text\": \"People resist feeling manipulated\"\n        },\n        {\n          \"feedback\": \"Exactly. Understanding defaults intellectually versus experiencing one yourself creates different reactions. Good behavioral design accepts this tension — outcomes matter more than everyone loving the mechanism.\",\n          \"isCorrect\": true,\n          \"text\": \"Behavioral design feels different as a subject\"\n        },\n        {\n          \"feedback\": \"No. Announcing defaults defeats their purpose. The test measures real behavior. If you tell people 'we're using behavioral science on you,' you contaminate the results.\",\n          \"isCorrect\": false,\n          \"text\": \"We should have warned power users first\"\n        },\n        {\n          \"feedback\": \"Actually, having your CEO experience the intervention firsthand created understanding. The insight is broader: being nudged feels different than discussing nudges academically.\",\n          \"isCorrect\": false,\n          \"text\": \"CEOs make bad test subjects\"\n        }\n      ],\n      \"question\": \"What's the key insight here?\"\n    },\n    {\n      \"context\": \"Fourteen days later... {{NAME}}! The results are in. Treatment group: 47% took action, average first deposit $24, 31% still saving after 30 days. Control group: still 12%, $18, and 4%. This is incredible.\",\n      \"options\": [\n        {\n          \"feedback\": \"Tempting, but good behavioral design iterates. You've proven the bundle works. Now test variations: different default amounts, different social proof copy, different framings. Optimize further.\",\n          \"isCorrect\": false,\n          \"text\": \"Roll out to 100% immediately\"\n        },\n        {\n          \"feedback\": \"You can't isolate them — they work together. Defaults got people started, framing reduced pain, social proof normalized it, loss aversion sustained it. The bundle is the insight.\",\n          \"isCorrect\": false,\n          \"text\": \"Analyze which principle drove the most impact\"\n        },\n        {\n          \"feedback\": \"Perfect. Document what worked, share the behavioral design framework with the team, then iterate. Maybe test $20 vs $25 defaults, or different goal framings. Keep learning.\",\n          \"isCorrect\": true,\n          \"text\": \"Share findings and plan next iterations\"\n        },\n        {\n          \"feedback\": \"Don't get greedy. You've found something that works. Pushing defaults too high will increase override rates. Better to optimize the experience around this success.\",\n          \"isCorrect\": false,\n          \"text\": \"Test even more aggressive defaults\"\n        }\n      ],\n      \"question\": \"What should you do next?\"\n    },\n    {\n      \"context\": \"I'm writing up the case study now. '47% action rate with behavioral design interventions.' {{NAME}}, the CEO just messaged again. 'Saw the results. I was wrong about defaults being just for average users. Nice work.'\",\n      \"options\": [\n        {\n          \"feedback\": \"True, but surface-level. The deeper lesson is more specific about how these principles combine and how to implement them in real products.\",\n          \"isCorrect\": false,\n          \"text\": \"Behavioral economics works in practice\"\n        },\n        {\n          \"feedback\": \"Good insight, but still general. Think about what you specifically learned about combining defaults, framing, social proof, loss aversion, and present bias in one intervention.\",\n          \"isCorrect\": false,\n          \"text\": \"Small changes in design create big behavior shifts\"\n        },\n        {\n          \"feedback\": \"Yes. Defaults got them started, framing reduced friction, social proof made it feel normal, loss aversion kept them going, and you diagnosed present bias first. Real behavioral design orchestrates multiple principles.\",\n          \"isCorrect\": true,\n          \"text\": \"Behavioral principles work together, not alone\"\n        },\n        {\n          \"feedback\": \"Testing matters, but that's methodology. The bigger insight is how you strategically combined five different behavioral principles to address one problem. That's the art of behavioral design.\",\n          \"isCorrect\": false,\n          \"text\": \"Always A/B test behavioral interventions\"\n        }\n      ],\n      \"question\": \"What's your main takeaway from this whole experience?\"\n    },\n    {\n      \"context\": \"Exactly. It all worked together. {{NAME}}, remember three weeks ago when we had a feature-rich app that nobody used? Turns out understanding human psychology matters more than adding features. Who knew? Well... we did. Now we've got the data to prove it.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. You just learned that behavioral design isn't theoretical — it's practical, measurable, and powerful. Every product interaction is an opportunity to work with human psychology instead of against it.\",\n          \"isCorrect\": true,\n          \"text\": \"Ready to apply this to other products\"\n        },\n        {\n          \"feedback\": \"You preserved choice and dramatically improved outcomes. Users are saving money they wanted to save. Ethical behavioral design helps people achieve their own goals — that's not manipulation.\",\n          \"isCorrect\": false,\n          \"text\": \"Worried users will feel manipulated\"\n        },\n        {\n          \"feedback\": \"Don't be surprised — be confident. These principles are backed by decades of research. When applied thoughtfully to real problems, behavioral design consistently produces results.\",\n          \"isCorrect\": false,\n          \"text\": \"Surprised it worked this well\"\n        },\n        {\n          \"feedback\": \"Valid question for ongoing monitoring, but your 30-day retention already quadrupled. The interventions address fundamental human psychology. Focus on optimization, not doubt.\",\n          \"isCorrect\": false,\n          \"text\": \"Unsure if results will last long-term\"\n        }\n      ],\n      \"question\": \"How do you feel right now?\"\n    }\n  ]\n}",
      "outputTokens": 6374,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-economics-behavioral-design-1",
      "userPrompt": "LESSON_TITLE: Behavioral Design in Practice\nLESSON_DESCRIPTION: Applying behavioral economics principles to design products and systems that work with human psychology\nCHAPTER_TITLE: Applied Behavioral Economics\nCOURSE_TITLE: Product Psychology\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Loss Aversion: Loss aversion means losses hurt more than equivalent gains feel good — roughly twice as much. People will take irrational risks to avoid losses they wouldn't take to achieve gains.\n2. Framing Effects: Framing effects show that how you present options matters as much as what the options are. '90% survival rate' and '10% mortality rate' are logically identical but feel different.\n3. Default Effects: Default effects are powerful because people tend to stick with pre-selected options. Changing the default can dramatically change outcomes without restricting choice.\n4. Present Bias: Present bias makes us overvalue immediate rewards over future ones. We know we should save for retirement, but the money feels more valuable now. Commitment devices help.\n5. Social Proof: Social proof drives behavior — we look to others to decide what's appropriate. Showing that 'most people do X' is often more effective than explaining why X is good."
    },
    {
      "duration": 142990.088208,
      "inputTokens": 4335,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, olha só essa síntese que o orientador me passou. Precisamos converter esse álcool terciário em éter, mas ele quer rendimento alto e sem racemização. Estou pensando em usar um mecanismo de substituição, mas não sei qual caminho seguir.\",\n      \"options\": [\n        {\n          \"feedback\": \"SN2 não funciona bem com substratos terciários — o carbono está muito impedido estericamente. O nucleófilo não consegue se aproximar por trás para fazer o ataque concertado.\",\n          \"isCorrect\": false,\n          \"text\": \"SN2 com nucleófilo forte\"\n        },\n        {\n          \"feedback\": \"SN1 formaria um carbocátion planar que pode ser atacado de ambos os lados, gerando mistura racêmica. Se ele quer evitar racemização, esse não é o caminho.\",\n          \"isCorrect\": false,\n          \"text\": \"SN1 em solvente polar prótico\"\n        },\n        {\n          \"feedback\": \"Exatamente! OH⁻ é base forte e péssimo grupo de saída. Precisamos protonar ou converter em tosilato primeiro. Aí sim conseguimos fazer a substituição eficientemente.\",\n          \"isCorrect\": true,\n          \"text\": \"Converter OH em grupo de saída melhor\"\n        },\n        {\n          \"feedback\": \"Usar base forte vai desprotonear o álcool e formar um alcóxido — um nucleófilo excelente, mas isso não ajuda na substituição. Precisamos melhorar o grupo de saída, não criar outro nucleófilo.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar base forte para desprotonação\"\n        }\n      ],\n      \"question\": \"Qual mecanismo você sugere que a gente use?\"\n    },\n    {\n      \"context\": \"Boa! Vou converter em tosilato então. Mas agora estou em dúvida sobre a etapa seguinte. Tenho esse tosilato terciário e preciso reagir com metóxido. O problema é que o centro quiral precisa manter a configuração original.\",\n      \"options\": [\n        {\n          \"feedback\": \"SN2 causaria inversão, mas não funciona com substratos terciários devido ao impedimento estérico. O nucleófilo não consegue fazer o ataque por trás característico do mecanismo concertado.\",\n          \"isCorrect\": false,\n          \"text\": \"Inversão completa via SN2\"\n        },\n        {\n          \"feedback\": \"Exato. Com substrato terciário, vai acontecer SN1 — formação de carbocátion planar seguido de ataque de ambos os lados. Você vai perder a quiralidade e obter mistura racêmica.\",\n          \"isCorrect\": true,\n          \"text\": \"Racemização via SN1\"\n        },\n        {\n          \"feedback\": \"Nenhum mecanismo de substituição nucleofílica clássico mantém a configuração. SN2 inverte, SN1 racemiza. Retenção só acontece em mecanismos especiais como SNi, que não é o caso aqui.\",\n          \"isCorrect\": false,\n          \"text\": \"Retenção de configuração\"\n        },\n        {\n          \"feedback\": \"Vai reagir sim! Tosilato é excelente grupo de saída (base fraca, muito estável após sair). O problema não é reatividade, é que SN1 vai racemizar o produto.\",\n          \"isCorrect\": false,\n          \"text\": \"Não vai reagir\"\n        }\n      ],\n      \"question\": \"O que vai acontecer nessa reação?\"\n    },\n    {\n      \"context\": \"Droga. Então não dá pra fazer isso e manter a quiralidade? O orientador vai me matar se eu entregar uma mistura racêmica. Tem que ter algum jeito de contornar isso.\",\n      \"options\": [\n        {\n          \"feedback\": \"Nucleófilo mais fraco só vai tornar a reação mais lenta, mas não muda o mecanismo. Com substrato terciário, ainda vai ser SN1 e ainda vai racemizar.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar nucleófilo mais fraco\"\n        },\n        {\n          \"feedback\": \"Baixar temperatura pode diminuir a velocidade de SN1, mas não elimina o problema da racemização. Quando a reação finalmente acontecer, ainda vai ser via carbocátion planar.\",\n          \"isCorrect\": false,\n          \"text\": \"Baixar a temperatura drasticamente\"\n        },\n        {\n          \"feedback\": \"Isso mesmo! Se precisamos manter quiralidade com centro terciário, substituição nucleofílica direta não é o caminho. Talvez uma rota que não envolva carbocátion — eliminação seguida de adição, ou outra abordagem.\",\n          \"isCorrect\": true,\n          \"text\": \"Mudar a estratégia sintética completamente\"\n        },\n        {\n          \"feedback\": \"Mais nucleófilo não resolve o problema fundamental — o carbocátion intermediário é planar e será atacado de ambos os lados. A quantidade de nucleófilo não afeta a estereoquímica do mecanismo.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar mais equivalentes de nucleófilo\"\n        }\n      ],\n      \"question\": \"Como podemos resolver esse problema?\"\n    },\n    {\n      \"context\": \"Verdade, vou repensar a rota. Mas já que estamos nisso, deixa eu te mostrar outro caso. Tenho esse brometo de etila primário e quero substituir por cianeto. Parece bem mais simples que o anterior.\",\n      \"options\": [\n        {\n          \"feedback\": \"Haletos primários não formam carbocátions facilmente — o carbocátion primário seria muito instável. SN1 precisa de estabilização, que vem de substratos terciários ou secundários.\",\n          \"isCorrect\": false,\n          \"text\": \"SN1 por ser haleto reativo\"\n        },\n        {\n          \"feedback\": \"Perfeito! Substrato primário + nucleófilo forte (CN⁻) = SN2 clássico. Ataque concertado por trás, saída do brometo (ótimo grupo de saída), inversão completa. Rápido e limpo.\",\n          \"isCorrect\": true,\n          \"text\": \"SN2 com inversão de configuração\"\n        },\n        {\n          \"feedback\": \"Com substrato primário e bom nucleófilo, SN2 domina completamente. SN1 nem seria competitivo porque o carbocátion primário é energeticamente desfavorável.\",\n          \"isCorrect\": false,\n          \"text\": \"Mistura de SN1 e SN2\"\n        },\n        {\n          \"feedback\": \"Eliminação compete com substituição, mas cianeto é nucleófilo forte e não muito básico. Com substrato primário e sem impedimento, substituição SN2 vai predominar muito sobre E2.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminação ao invés de substituição\"\n        }\n      ],\n      \"question\": \"Qual mecanismo vai predominar aqui?\"\n    },\n    {\n      \"context\": \"Legal, então essa é tranquila. Mas olha essa questão que caiu na prova prática que eu bombeei: tinham dois frascos, um com brometo de metila e outro com brometo de terc-butila. Mesmas condições, mesmo nucleófilo — iodeto em acetona. Um reagiu em minutos, o outro levou horas.\",\n      \"options\": [\n        {\n          \"feedback\": \"SN1 com terc-butila até acontece, mas não é necessariamente mais rápido que SN2. A formação do carbocátion tem energia de ativação considerável. Você está confundindo 'favorecido' com 'mais rápido'.\",\n          \"isCorrect\": false,\n          \"text\": \"Terc-butila, SN1 é mais rápido\"\n        },\n        {\n          \"feedback\": \"Exato! Brometo de metila é o substrato perfeito para SN2 — zero impedimento estérico, iodeto é ótimo nucleófilo. Reação concertada rápida. Terc-butila é impedido e precisa de SN1 lento.\",\n          \"isCorrect\": true,\n          \"text\": \"Metila, SN2 sem impedimento\"\n        },\n        {\n          \"feedback\": \"Grupo de saída é o mesmo (Br⁻), mas a velocidade depende MUITO do mecanismo. SN2 em metila é rapidíssimo. SN1 em terc-butila precisa esperar a formação do carbocátion.\",\n          \"isCorrect\": false,\n          \"text\": \"Mesma velocidade, mesmo grupo de saída\"\n        },\n        {\n          \"feedback\": \"Carbocátion terciário é mais estável que primário, sim, mas isso não significa que a reação seja mais rápida. A etapa de formação do carbocátion ainda é lenta comparada ao ataque direto SN2.\",\n          \"isCorrect\": false,\n          \"text\": \"Terc-butila, carbocátion mais estável\"\n        }\n      ],\n      \"question\": \"Qual reagiu mais rápido e por quê?\"\n    },\n    {\n      \"context\": \"Ah, entendi! O impedimento estérico faz toda diferença. Mas então me diz uma coisa — se eu pegar um substrato secundário, fica naquela zona cinzenta entre SN1 e SN2, certo? Como eu controlo qual mecanismo vai acontecer?\",\n      \"options\": [\n        {\n          \"feedback\": \"Importam MUITO! Solvente polar prótico estabiliza carbocátion e favorece SN1. Solvente polar aprótico favorece SN2. Nucleófilo forte puxa pra SN2, nucleófilo fraco pra SN1.\",\n          \"isCorrect\": false,\n          \"text\": \"Solvente e nucleófilo não importam\"\n        },\n        {\n          \"feedback\": \"Temperatura afeta a velocidade, mas não é o fator principal pra escolher mecanismo. Solvente e força do nucleófilo são muito mais determinantes em substratos secundários.\",\n          \"isCorrect\": false,\n          \"text\": \"Temperatura determina tudo\"\n        },\n        {\n          \"feedback\": \"Isso! Quer SN2? Use DMSO ou acetona (polar aprótico) com nucleófilo forte. Quer SN1? Use água ou etanol (polar prótico) com nucleófilo fraco. O solvente e nucleófilo direcionam o mecanismo.\",\n          \"isCorrect\": true,\n          \"text\": \"Solvente e força do nucleófilo\"\n        },\n        {\n          \"feedback\": \"Concentração do substrato afeta a velocidade geral, mas não direciona o mecanismo. SN1 é primeira ordem no substrato, SN2 é segunda ordem, mas ambos podem acontecer em várias concentrações.\",\n          \"isCorrect\": false,\n          \"text\": \"Apenas concentração do substrato\"\n        }\n      ],\n      \"question\": \"Como podemos favorecer um mecanismo específico?\"\n    },\n    {\n      \"context\": \"Perfeito! Agora tá fazendo sentido. Deixa eu aplicar isso então. Tenho brometo de isopropila (secundário). Quero fazer SN2 limpo pra garantir inversão. Vou usar metóxido em metanol. Deve funcionar, né?\",\n      \"options\": [\n        {\n          \"feedback\": \"Metóxido É forte, mas metanol é solvente polar PRÓTICO. Ele vai estabilizar o carbocátion e favorecer SN1, exatamente o oposto do que você quer! O solvente matou sua estratégia.\",\n          \"isCorrect\": false,\n          \"text\": \"Sim, metóxido é nucleófilo forte\"\n        },\n        {\n          \"feedback\": \"Exatamente! Metanol é polar prótico — vai solvatam íons e estabilizar carbocátion, puxando pra SN1. Pra SN2 limpo você precisa de solvente aprótico tipo DMSO ou DMF com seu metóxido.\",\n          \"isCorrect\": true,\n          \"text\": \"Não, metanol favorece SN1\"\n        },\n        {\n          \"feedback\": \"Substrato secundário pode fazer SN1 OU SN2 dependendo das condições! É justamente a zona ambígua. Com metanol você vai puxar pra SN1.\",\n          \"isCorrect\": false,\n          \"text\": \"Sim, substrato secundário sempre faz SN2\"\n        },\n        {\n          \"feedback\": \"Brometo é excelente grupo de saída! Br⁻ é base fraca e estável. O problema aqui não é o grupo de saída, é a escolha do solvente polar prótico.\",\n          \"isCorrect\": false,\n          \"text\": \"Não, bromo é grupo de saída ruim\"\n        }\n      ],\n      \"question\": \"Essa escolha vai funcionar como planejado?\"\n    },\n    {\n      \"context\": \"Nossa, que erro básico! Então se eu trocar pra DMSO mantendo o metóxido, aí sim fica SN2 limpo. Mas espera... {{NAME}}, acabei de olhar o estoque do lab. Não tem DMSO. Tem DMF, acetona, THF e acetonitrila. Qual desses serve?\",\n      \"options\": [\n        {\n          \"feedback\": \"Acetona é polar aprótica, mas metóxido não é muito solúvel nela. Ia ter problema de solubilidade. Tecnicamente poderia funcionar, mas não é a melhor escolha prática.\",\n          \"isCorrect\": false,\n          \"text\": \"Acetona, é polar\"\n        },\n        {\n          \"feedback\": \"THF é aprótico e dissolve bem compostos orgânicos, mas é pouco polar. Para SN2 com íons como metóxido, você quer algo mais polar pra solubilizar bem o nucleófilo.\",\n          \"isCorrect\": false,\n          \"text\": \"THF, dissolve bem orgânicos\"\n        },\n        {\n          \"feedback\": \"Perfeito! DMF é polar aprótico clássico, junto com DMSO. Dissolve bem íons como metóxido, não estabiliza carbocátion, favorece SN2. Substitui DMSO perfeitamente aqui.\",\n          \"isCorrect\": true,\n          \"text\": \"DMF, polar aprótico\"\n        },\n        {\n          \"feedback\": \"Acetonitrila é aprótica, mas muito menos polar que DMF ou DMSO. Não solubiliza tão bem nucleófilos iônicos. DMF seria muito melhor escolha pra essa reação.\",\n          \"isCorrect\": false,\n          \"text\": \"Acetonitrila, menos prótico que metanol\"\n        }\n      ],\n      \"question\": \"Qual solvente alternativo funcionaria melhor?\"\n    },\n    {\n      \"context\": \"DMF então! Valeu, {{NAME}}. Mas agora olha esse problema que o grupo de síntese do lab vizinho tá enfrentando. Eles têm um haleto quiral e querem fazer substituição, mas quando analisam o produto, sempre sai mistura 50-50 dos dois enantiômeros.\",\n      \"options\": [\n        {\n          \"feedback\": \"Improvável. Produtos de substituição normalmente são estáveis. Mistura 50-50 perfeita é sinal clássico de ataque em carbocátion planar durante a reação, não racemização posterior.\",\n          \"isCorrect\": false,\n          \"text\": \"O produto está racemizando depois\"\n        },\n        {\n          \"feedback\": \"Com certeza! Mistura racêmica 50-50 é assinatura de SN1. O carbocátion intermediário é planar e aquiral — o nucleófilo ataca de ambos os lados com igual probabilidade. Estereoquímica perdida.\",\n          \"isCorrect\": true,\n          \"text\": \"Mecanismo SN1 com carbocátion planar\"\n        },\n        {\n          \"feedback\": \"SN2 não faz 'inversão incompleta' — ou é SN2 concertado com inversão total, ou não é SN2. Mistura 50-50 indica mecanismo por carbocátion (SN1), não ataque direto.\",\n          \"isCorrect\": false,\n          \"text\": \"SN2 com inversão incompleta\"\n        },\n        {\n          \"feedback\": \"Se o reagente fosse racêmico, eles não estariam surpresos com o resultado. A questão é que eles TÊM um haleto quiral puro e estão perdendo a quiralidade — clássico SN1.\",\n          \"isCorrect\": false,\n          \"text\": \"Reagente de partida já era racêmico\"\n        }\n      ],\n      \"question\": \"O que provavelmente está acontecendo?\"\n    },\n    {\n      \"context\": \"Faz sentido. Eles devem estar usando condições que favorecem SN1 sem perceber. Mas me tira uma dúvida, {{NAME}}, que sempre me confunde: se eu tenho um álcool e quero fazer substituição, por que raios tenho que converter em tosilato ou mesilato? Não dá pra reagir direto com HBr?\",\n      \"options\": [\n        {\n          \"feedback\": \"HBr não sempre causa eliminação — em muitos casos até funciona pra substituição. O problema é que as condições ácidas e quentes podem causar rearranjos e reações paralelas indesejadas.\",\n          \"isCorrect\": false,\n          \"text\": \"HBr sempre causa eliminação\"\n        },\n        {\n          \"feedback\": \"Exato! Tosilato é ótimo grupo de saída em condições brandas e neutras. Você controla solvente e nucleófilo pra direcionar SN1 ou SN2. HBr força condições ácidas que podem causar rearranjos.\",\n          \"isCorrect\": true,\n          \"text\": \"Tosilato permite controle do mecanismo\"\n        },\n        {\n          \"feedback\": \"HBr converte álcoois sim! A reação de álcool com HBr é clássica pra fazer haletos. O problema não é que não funciona, é que funciona em condições mais agressivas com menos controle.\",\n          \"isCorrect\": false,\n          \"text\": \"HBr não converte álcoois\"\n        },\n        {\n          \"feedback\": \"Tosilato não é nucleófilo — é grupo de SAÍDA! Confusão conceitual aqui. Tosilato (OTs) sai bem porque a base conjugada é estável. Ele não ataca nada.\",\n          \"isCorrect\": false,\n          \"text\": \"Tosilato é nucleófilo mais forte\"\n        }\n      ],\n      \"question\": \"Por que conversão em tosilato é preferível ao uso direto de HBr?\"\n    },\n    {\n      \"context\": \"Ah, é questão de controle! Faz sentido. Bom, acho que agora eu entendo bem melhor esses mecanismos. Vou refazer a síntese do orientador com a estratégia certa. Mas antes, última pergunta — tenho que escolher entre fazer um brometo ou um cloreto pra usar como intermediário.\",\n      \"options\": [\n        {\n          \"feedback\": \"Tamanho não determina qualidade de grupo de saída diretamente. O que importa é estabilidade da base conjugada. Cl⁻ é mais básico que Br⁻, então é PIOR grupo de saída.\",\n          \"isCorrect\": false,\n          \"text\": \"Cloreto, Cl⁻ é menor\"\n        },\n        {\n          \"feedback\": \"Isso! Br⁻ é base mais fraca que Cl⁻ (mais estável, menos reativa). Grupos de saída bons são bases fracas — quanto mais estável o ânion após sair, melhor o grupo de saída.\",\n          \"isCorrect\": true,\n          \"text\": \"Brometo, Br⁻ é base mais fraca\"\n        },\n        {\n          \"feedback\": \"Nem todos haletos são iguais como grupos de saída! A ordem é I > Br > Cl > F (iodeto melhor). Isso segue a basicidade decrescente e estabilidade crescente dos ânions.\",\n          \"isCorrect\": false,\n          \"text\": \"Iguais, ambos são haletos\"\n        },\n        {\n          \"feedback\": \"Eletronegatividade não é o fator determinante pra grupo de saída. O que importa é estabilidade do ânion após a saída. Br⁻ é maior, mais polarizável, mais estável — melhor grupo de saída.\",\n          \"isCorrect\": false,\n          \"text\": \"Cloreto, é mais eletronegativo\"\n        }\n      ],\n      \"question\": \"Qual é melhor grupo de saída e por quê?\"\n    },\n    {\n      \"context\": \"Brometo então. Ótimo! {{NAME}}, você acabou de me salvar dessa síntese. Vou refazer tudo: tosilato do álcool, DMF como solvente, nucleófilo apropriado... Ah, espera. O orientador deixou uma nota aqui. 'Atenção: substrato propenso a rearranjo de carbocátion'. Hmm.\",\n      \"options\": [\n        {\n          \"feedback\": \"Rearranjos são MUITO comuns em carbocátions! Hidrogênios e grupos alquila podem migrar pra formar carbocátions mais estáveis. Se o orientador avisou, é porque já viu isso acontecer.\",\n          \"isCorrect\": false,\n          \"text\": \"Não afeta, rearranjos são raros\"\n        },\n        {\n          \"feedback\": \"Exatamente! Rearranjo de carbocátion só acontece em SN1 (precisa do intermediário carbocátion). Se o substrato é propenso a isso, você PRECISA usar condições SN2 pra evitar formação de carbocátion.\",\n          \"isCorrect\": true,\n          \"text\": \"Devemos evitar SN1 completamente\"\n        },\n        {\n          \"feedback\": \"Aumentar temperatura ia PIORAR o problema! Temperatura alta favorece formação de carbocátion (SN1) onde o rearranjo acontece. Você quer evitar carbocátion, não facilitar sua formação.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar temperatura pra acelerar\"\n        },\n        {\n          \"feedback\": \"Solvente polar prótico estabiliza carbocátion e favorece SN1 — exatamente onde rearranjos acontecem! Isso seria jogar gasolina no fogo. Você precisa de aprótico + SN2.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar solvente polar prótico\"\n        }\n      ],\n      \"question\": \"O que essa nota significa pra nossa estratégia?\"\n    },\n    {\n      \"context\": \"Ufa, que bom que você pegou isso! Então a estratégia final é: tosilato do álcool, DMF, nucleófilo forte, condições que garantam SN2 pra evitar qualquer chance de carbocátion e rearranjo. Acho que agora vai dar certo. Aliás, {{NAME}}, você já percebeu que mecanismos de substituição são tipo... diagnóstico médico? Você olha os sintomas — estereoquímica, velocidade, produtos — e deduz o que aconteceu.\",\n      \"options\": [\n        {\n          \"feedback\": \"Mesma configuração não é típico de SN2 — na verdade, SN2 INVERTE a configuração (ataque por trás). Se viu retenção, provavelmente não foi SN2 clássico.\",\n          \"isCorrect\": false,\n          \"text\": \"Produto com mesma configuração\"\n        },\n        {\n          \"feedback\": \"Perfeito! Inversão de configuração (inversão de Walden) é a assinatura inequívoca de SN2. Ataque por trás, um único passo, inversão total. Se viu inversão limpa, foi SN2.\",\n          \"isCorrect\": true,\n          \"text\": \"Inversão completa de configuração\"\n        },\n        {\n          \"feedback\": \"Mistura racêmica é assinatura de SN1, não SN2! Indica ataque em carbocátion planar de ambos os lados. SN2 dá inversão completa, não racemização.\",\n          \"isCorrect\": false,\n          \"text\": \"Mistura racêmica de produtos\"\n        },\n        {\n          \"feedback\": \"Produtos de rearranjo indicam SN1 (rearranjo do carbocátion intermediário). SN2 é concertado, não forma carbocátion, então não tem como rearranjar.\",\n          \"isCorrect\": false,\n          \"text\": \"Produtos de rearranjo\"\n        }\n      ],\n      \"question\": \"Qual 'sintoma' é diagnóstico definitivo de SN2?\"\n    },\n    {\n      \"context\": \"Exatamente! Inversão é a impressão digital do SN2. Sabe, {{NAME}}, eu devia ter prestado mais atenção nessas aulas. Agora tá tudo conectado — estrutura do substrato, força do nucleófilo, solvente, estereoquímica... tudo conta uma história sobre o mecanismo. Ah! Plot twist — acabei de receber email do orientador. Ele mudou de ideia. Agora quer que eu sintetize o OUTRO enantiômero do produto, não o que invertem do substrato atual daria.\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso mesmo! SN2 inverte configuração de forma previsível. Se você quer o outro enantiômero do produto, precisa começar com o outro enantiômero do reagente. Simples e elegante.\",\n          \"isCorrect\": true,\n          \"text\": \"Partir do enantiômero oposto do substrato\"\n        },\n        {\n          \"feedback\": \"SN1 dá mistura racêmica, não o enantiômero oposto puro. Você ia obter 50-50 dos dois, não selectividade pro enantiômero desejado. Não resolve o problema.\",\n          \"isCorrect\": false,\n          \"text\": \"Mudar o mecanismo pra SN1\"\n        },\n        {\n          \"feedback\": \"Duas inversões consecutivas te trazem DE VOLTA pra configuração original! Inversão + inversão = retenção líquida. Você acabaria com a estereoquímica do ponto de partida.\",\n          \"isCorrect\": false,\n          \"text\": \"Fazer SN2 duas vezes consecutivas\"\n        },\n        {\n          \"feedback\": \"O nucleófilo geralmente não é quiral (ou se for, não afeta dessa forma). A estereoquímica do produto vem do centro que sofre substituição, não do nucleófilo atacante.\",\n          \"isCorrect\": false,\n          \"text\": \"Trocar o nucleófilo por seu enantiômero\"\n        }\n      ],\n      \"question\": \"Como você consegue o enantiômero oposto via substituição?\"\n    }\n  ]\n}",
      "outputTokens": 7143,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-chemistry-organic-reactions-1",
      "userPrompt": "LESSON_TITLE: Mecanismos de Substituicao\nLESSON_DESCRIPTION: Aplicando mecanismos de reacao organica para prever e otimizar sinteses quimicas\nCHAPTER_TITLE: Reacoes Organicas\nCOURSE_TITLE: Quimica Organica II\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Nucleofilos e Eletrofilos: Nucleofilos sao especies ricas em eletrons que doam pares de eletrons. Eletrofilos sao especies pobres em eletrons que aceitam. Reacoes organicas sao geralmente nucleofilos atacando eletrofilos.\n2. Mecanismo SN2: SN2 e um mecanismo concertado — o nucleofilo ataca enquanto o grupo de saida sai, em um unico passo. Funciona melhor com substratos primarios e nucleofilos fortes.\n3. Mecanismo SN1: SN1 ocorre em dois passos: primeiro o grupo de saida sai formando um carbocation, depois o nucleofilo ataca. Favorecido por substratos terciarios e solventes polares proticos.\n4. Estereoquimica: A estereoquimica revela o mecanismo. SN2 inverte a configuracao (ataque por tras). SN1 pode dar mistura racemicacon (carbocation planar atacado de ambos os lados).\n5. Grupos de Saida: Grupos de saida precisam ser estaveis apos sair. Bons grupos de saida sao bases fracas — haletos, tosilatos, agua protonada. Grupos de saida ruins sao bases fortes."
    },
    {
      "duration": 132244.032917,
      "inputTokens": 4310,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, mira esto. El cliente nos pide clasificar rayos X de tórax para detectar neumonía. Tenemos solo 2,000 imágenes etiquetadas. Si entrenamos una CNN desde cero con tan pocos datos, va a sobreajustar horrible.\",\n      \"options\": [\n        {\n          \"feedback\": \"Con solo 2,000 imágenes, una red profunda memorizaría los datos de entrenamiento sin aprender patrones generalizables. Necesitamos aprovechar conocimiento previo.\",\n          \"isCorrect\": false,\n          \"text\": \"Entrenar desde cero con muchas capas\"\n        },\n        {\n          \"feedback\": \"Exacto. Un modelo pre-entrenado en ImageNet ya aprendió a detectar bordes, texturas y formas. Solo necesitamos ajustar las capas finales para rayos X — ideal con pocos datos.\",\n          \"isCorrect\": true,\n          \"text\": \"Usar transfer learning con modelo pre-entrenado\"\n        },\n        {\n          \"feedback\": \"Una red muy superficial no capturará la complejidad necesaria para diagnóstico médico. Transfer learning nos da profundidad sin necesitar millones de imágenes.\",\n          \"isCorrect\": false,\n          \"text\": \"Reducir capas para evitar sobreajuste\"\n        },\n        {\n          \"feedback\": \"Filtros más grandes no resuelven el problema de datos insuficientes. Transfer learning nos permite aprovechar patrones ya aprendidos en millones de imágenes.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar el tamaño de los filtros\"\n        }\n      ],\n      \"question\": \"¿Qué enfoque deberíamos usar con este dataset pequeño?\"\n    },\n    {\n      \"context\": \"Perfecto, {{NAME}}. Voy a cargar ResNet-50 pre-entrenada. Ahora, ¿qué capas deberíamos congelar y cuáles reentrenar? Las primeras capas detectan bordes y texturas básicas, las últimas detectan objetos específicos de ImageNet.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Los filtros tempranos detectan patrones universales (bordes, texturas) que sirven para rayos X. Las capas tardías necesitan adaptarse de objetos cotidianos a patrones médicos.\",\n          \"isCorrect\": true,\n          \"text\": \"Congelar capas tempranas, reentrenar tardías\"\n        },\n        {\n          \"feedback\": \"Eso desperdiciaría el conocimiento pre-entrenado y con 2,000 imágenes sobreajustaríamos. Las capas tempranas ya saben detectar características visuales básicas.\",\n          \"isCorrect\": false,\n          \"text\": \"Reentrenar todas las capas desde cero\"\n        },\n        {\n          \"feedback\": \"Las capas finales están especializadas en objetos de ImageNet (perros, autos), no en patrones de neumonía. Necesitamos adaptarlas a nuestro dominio médico.\",\n          \"isCorrect\": false,\n          \"text\": \"Congelar todas las capas completamente\"\n        },\n        {\n          \"feedback\": \"Al revés. Las capas tempranas aprenden características generales reutilizables. Las tardías son específicas de ImageNet y deben adaptarse a rayos X.\",\n          \"isCorrect\": false,\n          \"text\": \"Congelar capas tardías, reentrenar tempranas\"\n        }\n      ],\n      \"question\": \"¿Cómo deberíamos configurar el transfer learning?\"\n    },\n    {\n      \"context\": \"Bien pensado. Congelé las primeras 40 capas y dejé las últimas 10 entrenables. Ahora estoy agregando capas personalizadas al final. Después de las convolucionales, necesitamos reducir la dimensionalidad espacial antes de la clasificación final.\",\n      \"options\": [\n        {\n          \"feedback\": \"Las fully connected esperan entrada 1D, no mapas 2D. Primero necesitamos pooling para reducir los mapas de características espacialmente de forma eficiente.\",\n          \"isCorrect\": false,\n          \"text\": \"Varias capas fully connected\"\n        },\n        {\n          \"feedback\": \"Perfecto. Global Average Pooling convierte cada mapa de características en un solo número, reduciendo de (H, W, C) a (1, 1, C) sin parámetros. Ideal antes del clasificador.\",\n          \"isCorrect\": true,\n          \"text\": \"Una capa de pooling global\"\n        },\n        {\n          \"feedback\": \"Eso modificaría las capas congeladas de ResNet. Necesitamos agregar algo nuevo que reduzca dimensiones sin alterar la arquitectura pre-entrenada.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar el stride de las convoluciones\"\n        },\n        {\n          \"feedback\": \"Batch normalization normaliza valores pero no reduce dimensiones espaciales. Necesitamos pooling para colapsar los mapas 2D a vectores.\",\n          \"isCorrect\": false,\n          \"text\": \"Batch normalization adicional\"\n        }\n      ],\n      \"question\": \"¿Qué deberíamos agregar para reducir dimensiones espacialmente?\"\n    },\n    {\n      \"context\": \"Listo, agregué Global Average Pooling. Ahora tengo un vector de 2048 características. {{NAME}}, estoy pensando en la capa de clasificación final. Con datos médicos limitados, me preocupa el sobreajuste en estas últimas capas densas.\",\n      \"options\": [\n        {\n          \"feedback\": \"Más capas densas significan más parámetros, lo que aumentaría el riesgo de sobreajuste con solo 2,000 imágenes. Necesitamos regularización, no más complejidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Agregar más capas fully connected\"\n        },\n        {\n          \"feedback\": \"Exacto. Dropout apaga aleatoriamente neuronas durante entrenamiento, forzando a la red a no depender de características específicas. Esto reduce dramáticamente el sobreajuste.\",\n          \"isCorrect\": true,\n          \"text\": \"Aplicar dropout antes de la capa final\"\n        },\n        {\n          \"feedback\": \"Ya pasamos la fase convolucional. Estamos en las capas densas finales. Dropout es la regularización estándar para prevenir sobreajuste aquí.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar filtros convolucionales más pequeños\"\n        },\n        {\n          \"feedback\": \"Sin activación no lineal, la red sería solo una transformación lineal. Perdemos capacidad de modelar patrones complejos. Dropout es lo que previene sobreajuste.\",\n          \"isCorrect\": false,\n          \"text\": \"Remover la función de activación\"\n        }\n      ],\n      \"question\": \"¿Qué técnica deberíamos aplicar para prevenir sobreajuste?\"\n    },\n    {\n      \"context\": \"Perfecto. Agregué Dropout(0.5) antes de la capa de clasificación. Empecé a entrenar y... {{NAME}}, algo anda mal. La pérdida oscila violentamente entre batches. Un batch baja a 0.3, el siguiente salta a 1.8. El entrenamiento es caótico.\",\n      \"options\": [\n        {\n          \"feedback\": \"Batches más pequeños harían las actualizaciones aún más ruidosas. Necesitamos normalizar las activaciones para estabilizar la distribución de datos entre capas.\",\n          \"isCorrect\": false,\n          \"text\": \"Reducir el tamaño de batch\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Batch normalization normaliza activaciones entre capas, estabilizando la distribución interna. Esto reduce las oscilaciones y permite entrenar de forma más suave y rápida.\",\n          \"isCorrect\": true,\n          \"text\": \"Agregar batch normalization\"\n        },\n        {\n          \"feedback\": \"La activación no es el problema. Las oscilaciones vienen de distribuciones inestables entre capas. Batch normalization estabiliza esto normalizando activaciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar la función de activación\"\n        },\n        {\n          \"feedback\": \"Más dropout aumentaría la varianza del entrenamiento, empeorando las oscilaciones. Batch normalization es lo que estabiliza la distribución de activaciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar dropout a 0.8\"\n        }\n      ],\n      \"question\": \"¿Qué podría estabilizar estas oscilaciones durante entrenamiento?\"\n    },\n    {\n      \"context\": \"Agregué batch normalization después de cada capa densa nueva y el entrenamiento se estabilizó completamente. Ahora la pérdida baja suave. Pero {{NAME}}, tengo una duda — agregué batch norm después de las activaciones ReLU. ¿Eso está bien?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. El orden típico es: capa densa → batch norm → ReLU. Normalizas las salidas lineales antes de aplicar no-linealidad. Esto maximiza los beneficios de estabilización.\",\n          \"isCorrect\": true,\n          \"text\": \"Antes de ReLU (normalizar primero)\"\n        },\n        {\n          \"feedback\": \"Funciona pero es subóptimo. Batch norm después de ReLU normaliza valores ya no-lineales (muchos ceros). Es mejor normalizar antes de la activación para mejor estabilidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Después de ReLU (como lo tienes)\"\n        },\n        {\n          \"feedback\": \"Sí importa. Normalizar antes de ReLU permite que batch norm vea la distribución completa de salidas lineales, no valores ya cortados por ReLU.\",\n          \"isCorrect\": false,\n          \"text\": \"No importa el orden en absoluto\"\n        },\n        {\n          \"feedback\": \"Eso es redundante y añade parámetros innecesarios. Una sola batch norm antes de ReLU es suficiente y es la práctica estándar.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar dos batch norms, antes y después\"\n        }\n      ],\n      \"question\": \"¿Dónde debería ir batch normalization respecto a la activación?\"\n    },\n    {\n      \"context\": \"Ajusté el orden: ahora es Dense → BatchNorm → ReLU → Dropout. El entrenamiento va genial, {{NAME}}. Precisión en validación alcanzó 89%. Pero quiero exprimir más rendimiento. ¿Recuerdas que batch norm también permite tasas de aprendizaje más altas?\",\n      \"options\": [\n        {\n          \"feedback\": \"Batch norm agrega parámetros (gamma, beta), no los reduce. Permite LR altos porque estabiliza gradientes al normalizar activaciones, evitando actualizaciones explosivas.\",\n          \"isCorrect\": false,\n          \"text\": \"Reduce el número de parámetros totales\"\n        },\n        {\n          \"feedback\": \"Exacto. Al normalizar activaciones, los gradientes no explotan ni desaparecen tan fácilmente. Esto permite usar learning rates más agresivos sin desestabilizar el entrenamiento.\",\n          \"isCorrect\": true,\n          \"text\": \"Estabiliza gradientes normalizando activaciones\"\n        },\n        {\n          \"feedback\": \"Batch norm tiene efecto regularizador pero no reemplaza dropout completamente. Permite LR altos por estabilización de gradientes, no por regularización.\",\n          \"isCorrect\": false,\n          \"text\": \"Elimina la necesidad de dropout\"\n        },\n        {\n          \"feedback\": \"Batch norm no cambia cómo funciona ReLU. Permite LR altos porque mantiene las distribuciones de activaciones estables, evitando gradientes extremos durante backpropagation.\",\n          \"isCorrect\": false,\n          \"text\": \"Hace que ReLU sea más efectivo\"\n        }\n      ],\n      \"question\": \"¿Por qué batch normalization permite usar learning rates más altos?\"\n    },\n    {\n      \"context\": \"Aumenté el learning rate de 0.001 a 0.01 y el modelo converge aún más rápido. Estamos en 91% de precisión ahora. {{NAME}}, el cliente acaba de enviar un mensaje. Quieren procesar 10,000 radiografías por hora en producción. Con el modelo actual tardamos demasiado.\",\n      \"options\": [\n        {\n          \"feedback\": \"Batch norm en inferencia es extremadamente rápida (solo normalización). El cuello de botella son las convoluciones de ResNet-50. Considera arquitecturas más eficientes.\",\n          \"isCorrect\": false,\n          \"text\": \"Remover todas las batch norms\"\n        },\n        {\n          \"feedback\": \"¡Excelente idea! MobileNet usa convoluciones separables que reducen cómputo ~9x vs convoluciones estándar. Puedes mantener precisión con mucha menos latencia.\",\n          \"isCorrect\": true,\n          \"text\": \"Usar una arquitectura más ligera (MobileNet)\"\n        },\n        {\n          \"feedback\": \"Batch size mayor mejora throughput pero no reduce latencia por imagen. Para 10,000 imágenes/hora necesitas una arquitectura más eficiente computacionalmente.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar el batch size de inferencia\"\n        },\n        {\n          \"feedback\": \"Pooling es rápido y esencial para reducir dimensiones. El costo computacional está en las convoluciones profundas. Arquitecturas eficientes como MobileNet son la solución.\",\n          \"isCorrect\": false,\n          \"text\": \"Remover capas de pooling\"\n        }\n      ],\n      \"question\": \"¿Qué podríamos hacer para acelerar la inferencia manteniendo precisión?\"\n    },\n    {\n      \"context\": \"Buena idea, {{NAME}}. Probé MobileNetV2 con transfer learning igual que antes. La inferencia es 5x más rápida y sorprendentemente... la precisión bajó solo a 89.5%. El cliente estará feliz. Ahora estoy replicando toda esta arquitectura en el código.\",\n      \"options\": [\n        {\n          \"feedback\": \"Batch norm debería ir antes de ReLU para normalizar las activaciones lineales. El orden correcto es Dense → BatchNorm → ReLU → Dropout.\",\n          \"isCorrect\": false,\n          \"text\": \"Dense → ReLU → BatchNorm → Dropout\"\n        },\n        {\n          \"feedback\": \"¡Perfecto! Este es el patrón estándar: transformación lineal, normalización, no-linealidad, regularización. Cada componente en su lugar óptimo.\",\n          \"isCorrect\": true,\n          \"text\": \"Dense → BatchNorm → ReLU → Dropout\"\n        },\n        {\n          \"feedback\": \"Batch norm necesita aplicarse después de la capa densa (normaliza sus salidas). Tampoco dropout va antes de ReLU. El orden correcto es Dense → BatchNorm → ReLU → Dropout.\",\n          \"isCorrect\": false,\n          \"text\": \"BatchNorm → Dense → Dropout → ReLU\"\n        },\n        {\n          \"feedback\": \"Dropout debe aplicarse al final del bloque, no al principio. El orden estándar es Dense → BatchNorm → ReLU → Dropout.\",\n          \"isCorrect\": false,\n          \"text\": \"Dropout → Dense → ReLU → BatchNorm\"\n        }\n      ],\n      \"question\": \"¿Cuál es el orden correcto de las capas en nuestro clasificador final?\"\n    },\n    {\n      \"context\": \"Código implementado. {{NAME}}, ejecuté el pipeline completo de entrenamiento y... espera. Acabé de darme cuenta de algo. Durante entrenamiento, dropout desactiva neuronas aleatoriamente. ¿Pero en producción, cuando hacemos predicciones sobre rayos X reales?\",\n      \"options\": [\n        {\n          \"feedback\": \"Eso haría las predicciones aleatorias — la misma imagen daría resultados diferentes. En inferencia, dropout se desactiva y los pesos se escalan automáticamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Mantener dropout activo igual que entrenamiento\"\n        },\n        {\n          \"feedback\": \"Correcto. En inferencia usamos toda la red (dropout = 0). Los frameworks modernos escalan automáticamente los pesos para compensar. Así las predicciones son determinísticas.\",\n          \"isCorrect\": true,\n          \"text\": \"Desactivar dropout completamente\"\n        },\n        {\n          \"feedback\": \"Cualquier dropout en inferencia introduce aleatoriedad no deseada. Debe estar completamente desactivado. Los frameworks manejan esto automáticamente en modo evaluación.\",\n          \"isCorrect\": false,\n          \"text\": \"Reducir dropout a 0.1 para estabilidad\"\n        },\n        {\n          \"feedback\": \"Eso es 'Monte Carlo Dropout' para estimar incertidumbre, pero para predicción estándar simplemente desactivamos dropout. Es más rápido y determinístico.\",\n          \"isCorrect\": false,\n          \"text\": \"Ejecutar 10 veces y promediar resultados\"\n        }\n      ],\n      \"question\": \"¿Cómo debería comportarse dropout durante inferencia en producción?\"\n    },\n    {\n      \"context\": \"Perfecto, ya tengo model.eval() antes de inferencia para desactivar dropout. {{NAME}}, terminé el código y estoy escribiendo la documentación. Quiero explicar por qué elegimos cada componente arquitectónico. ¿Cómo resumirías el rol de las capas convolucionales?\",\n      \"options\": [\n        {\n          \"feedback\": \"Las convolucionales detectan patrones, no normalizan. Su ventaja es compartir pesos — el mismo filtro detecta patrones en cualquier posición, reduciendo parámetros enormemente.\",\n          \"isCorrect\": false,\n          \"text\": \"Normalizan la entrada automáticamente\"\n        },\n        {\n          \"feedback\": \"Exacto. Un filtro aprende un patrón (como un borde) y se aplica en toda la imagen. Esto captura patrones sin importar posición, con muchísimos menos parámetros que fully connected.\",\n          \"isCorrect\": true,\n          \"text\": \"Detectan patrones locales compartiendo pesos\"\n        },\n        {\n          \"feedback\": \"Esa es la función del pooling, no de las convolucionales. Las convolucionales detectan patrones espaciales locales usando filtros compartidos.\",\n          \"isCorrect\": false,\n          \"text\": \"Reducen dimensionalidad espacial rápidamente\"\n        },\n        {\n          \"feedback\": \"Las convolucionales reducen parámetros vs fully connected, pero no son principalmente regularización. Su ventaja es detectar patrones espaciales eficientemente compartiendo pesos.\",\n          \"isCorrect\": false,\n          \"text\": \"Previenen sobreajuste mejor que dropout\"\n        }\n      ],\n      \"question\": \"¿Cuál es la ventaja clave de las capas convolucionales para imágenes?\"\n    },\n    {\n      \"context\": \"Escribí: 'Las convolucionales detectan patrones espaciales con peso compartido, reduciendo parámetros'. Ahora la sección de pooling. {{NAME}}, más allá de reducir dimensiones, ¿cuál es el beneficio conceptual del max pooling para visión?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Si un patrón se mueve unos píxeles, max pooling seguirá capturando el máximo. Esto hace la red más robusta a variaciones menores de posición en la imagen.\",\n          \"isCorrect\": true,\n          \"text\": \"Invarianza a pequeñas traslaciones\"\n        },\n        {\n          \"feedback\": \"Pooling toma máximo o promedio, no normaliza. Su beneficio es hacer la representación algo invariante a traslaciones pequeñas del patrón detectado.\",\n          \"isCorrect\": false,\n          \"text\": \"Normaliza los valores de activación\"\n        },\n        {\n          \"feedback\": \"Las funciones de activación (ReLU) añaden no-linealidad. Pooling reduce dimensiones espaciales y aporta invarianza a pequeños desplazamientos.\",\n          \"isCorrect\": false,\n          \"text\": \"Introduce no-linealidad adicional\"\n        },\n        {\n          \"feedback\": \"Pooling sí reduce cómputo al bajar dimensiones, pero su beneficio conceptual es hacer la representación más robusta a traslaciones menores de patrones.\",\n          \"isCorrect\": false,\n          \"text\": \"Acelera el backpropagation significativamente\"\n        }\n      ],\n      \"question\": \"¿Qué propiedad importante aporta el pooling a la representación?\"\n    },\n    {\n      \"context\": \"Documentado: 'Max pooling aporta invarianza a traslaciones pequeñas'. Sección de activaciones ahora. {{NAME}}, usamos ReLU en todas partes. Antes se usaba sigmoid o tanh. ¿Por qué ReLU se convirtió en el estándar para redes profundas?\",\n      \"options\": [\n        {\n          \"feedback\": \"ReLU no está acotada superiormente (sale de 0 a infinito). Su ventaja es evitar gradiente desvaneciente — para x > 0, el gradiente es siempre 1, no un valor pequeño.\",\n          \"isCorrect\": false,\n          \"text\": \"Produce valores normalizados entre 0 y 1\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Sigmoid y tanh saturan (gradiente → 0) en extremos. ReLU tiene gradiente constante 1 para x > 0, permitiendo entrenar redes mucho más profundas sin gradientes microscópicos.\",\n          \"isCorrect\": true,\n          \"text\": \"Evita el problema del gradiente desvaneciente\"\n        },\n        {\n          \"feedback\": \"ReLU es no-lineal (piecewise linear). Su ventaja vs sigmoid/tanh es mantener gradientes fuertes en capas profundas, evitando el problema del gradiente desvaneciente.\",\n          \"isCorrect\": false,\n          \"text\": \"Es una función lineal más simple\"\n        },\n        {\n          \"feedback\": \"ReLU sí es más barata (solo max(0,x)), pero su adopción principal es porque evita gradiente desvaneciente, permitiendo entrenar redes profundas efectivamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Requiere menos recursos computacionales\"\n        }\n      ],\n      \"question\": \"¿Cuál es la ventaja principal de ReLU sobre sigmoid o tanh?\"\n    },\n    {\n      \"context\": \"Perfecto. 'ReLU evita gradiente desvaneciente manteniendo gradiente constante para valores positivos'. {{NAME}}, una última cosa antes de enviar todo al cliente. Estoy mirando las métricas finales. ¿Hay algo raro aquí? Precisión entrenamiento: 99.2%. Precisión validación: 89.5%.\",\n      \"options\": [\n        {\n          \"feedback\": \"99.2% en entrenamiento vs 89.5% validación muestra sobreajuste moderado. El modelo memoriza parcialmente los datos de entrenamiento. Aunque dropout ayuda, hay margen de mejora.\",\n          \"isCorrect\": false,\n          \"text\": \"El modelo está perfectamente entrenado\"\n        },\n        {\n          \"feedback\": \"Correcto. La brecha de ~10% indica algo de sobreajuste, pero 89.5% en validación es sólido para datos médicos limitados. Dropout y batch norm están ayudando — es un balance razonable.\",\n          \"isCorrect\": true,\n          \"text\": \"Hay sobreajuste moderado, pero aceptable\"\n        },\n        {\n          \"feedback\": \"La brecha es moderada y 89.5% validación es buena precisión. Más dropout podría reducir rendimiento general. Este nivel de sobreajuste es aceptable con 2,000 imágenes.\",\n          \"isCorrect\": false,\n          \"text\": \"Necesitamos más dropout urgentemente\"\n        },\n        {\n          \"feedback\": \"Subajuste sería precisión baja en ambos sets. 99.2% entrenamiento muestra que el modelo aprende bien — solo hay sobreajuste moderado normal con datasets pequeños.\",\n          \"isCorrect\": false,\n          \"text\": \"El modelo está subajustado gravemente\"\n        }\n      ],\n      \"question\": \"¿Qué indican estas métricas sobre nuestro modelo?\"\n    },\n    {\n      \"context\": \"Tienes razón, {{NAME}}. Con solo 2,000 imágenes médicas, 89.5% en validación es excelente. El cliente acaba de confirmar — el modelo está en producción procesando radiografías reales. Y mira esto... acaban de enviarnos una botella de champán como agradecimiento. ¿Una botella? Por un modelo de deep learning.\",\n      \"options\": [\n        {\n          \"feedback\": \"Usamos MobileNet (ligera) con transfer learning. La lección es combinar sabiamente componentes: transfer learning para datos limitados, arquitecturas eficientes para producción, regularización para evitar sobreajuste.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar las arquitecturas más grandes posibles\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Transfer learning aprovechó conocimiento previo con pocos datos. Batch norm estabilizó entrenamiento. Dropout previno sobreajuste. MobileNet dio eficiencia. La arquitectura correcta combina componentes estratégicamente.\",\n          \"isCorrect\": true,\n          \"text\": \"Combinar transfer learning con regularización\"\n        },\n        {\n          \"feedback\": \"Más capas no siempre es mejor. Usamos una arquitectura pre-entrenada moderada (MobileNet) y la adaptamos inteligentemente. La clave fue combinar componentes complementarios correctamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Maximizar el número de capas siempre\"\n        },\n        {\n          \"feedback\": \"Batch norm fue crucial para estabilizar entrenamiento y permitir learning rates altos. La lección es usar cada componente estratégicamente: transfer learning, regularización y normalización trabajando juntos.\",\n          \"isCorrect\": false,\n          \"text\": \"Evitar batch normalization en producción\"\n        }\n      ],\n      \"question\": \"¿Qué lección arquitectónica clave hizo posible este proyecto?\"\n    }\n  ]\n}",
      "outputTokens": 6953,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-cs-neural-network-architecture-1",
      "userPrompt": "LESSON_TITLE: Arquitecturas de Deep Learning\nLESSON_DESCRIPTION: Disenando y optimizando arquitecturas de redes neuronales para problemas reales\nCHAPTER_TITLE: Arquitecturas de Redes Neuronales\nCOURSE_TITLE: Deep Learning Aplicado\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Capas Convolucionales: Las capas convolucionales detectan patrones locales usando filtros que se deslizan sobre la entrada. El mismo filtro se aplica en todas partes, lo que reduce parametros y captura patrones sin importar su posicion.\n2. Pooling: El pooling reduce la dimension espacial tomando el maximo o promedio de regiones. Esto hace la representacion mas compacta y algo invariante a pequenas traslaciones.\n3. Activaciones: Las funciones de activacion introducen no-linealidad. ReLU (max(0,x)) es popular por ser simple y evitar el problema del gradiente desvaneciente en capas profundas.\n4. Dropout: El dropout desactiva neuronas aleatoriamente durante el entrenamiento. Esto fuerza redundancia y reduce el sobreajuste — la red no puede depender de ninguna neurona especifica.\n5. Transfer Learning: El transfer learning usa redes pre-entrenadas en grandes datasets. Las capas tempranas aprenden patrones generales; las tardias se ajustan a tu tarea especifica.\n6. Batch Normalization: El batch normalization normaliza activaciones entre capas. Estabiliza el entrenamiento, permite tasas de aprendizaje mas altas, y actua como regularizador."
    },
    {
      "duration": 183676.42274999997,
      "inputTokens": 4237,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we just got the A/B test results back. The new checkout button has a p-value of 0.03. Marketing is already celebrating and wants to roll it out tomorrow. But something feels off to me.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. A p-value tells us the result is unlikely due to chance, but not whether the effect size matters. We could have statistical significance with a practically meaningless 0.1% improvement.\",\n          \"isCorrect\": true,\n          \"text\": \"What's the actual conversion rate difference?\"\n        },\n        {\n          \"feedback\": \"It is (0.03), but that only tells us it's statistically significant. With large samples, even tiny, meaningless differences can be 'significant.' We need to check the actual effect size.\",\n          \"isCorrect\": false,\n          \"text\": \"Is the p-value below 0.05?\"\n        },\n        {\n          \"feedback\": \"The p-value doesn't tell us that. It's not the probability the null is true or false — it's the probability of seeing data this extreme IF the null were true. Different thing entirely.\",\n          \"isCorrect\": false,\n          \"text\": \"What's the probability the new button works?\"\n        },\n        {\n          \"feedback\": \"Changing alpha after seeing results is p-hacking. We set the significance level before the test. The real question is whether the effect size is large enough to matter in practice.\",\n          \"isCorrect\": false,\n          \"text\": \"Should we lower the significance level?\"\n        }\n      ],\n      \"question\": \"What should we check first before celebrating?\"\n    },\n    {\n      \"context\": \"Good call. The conversion rate went from 12.4% to 12.7% — a 0.3 percentage point increase. We had 50,000 users in each group, so we detected it easily. Marketing says 'a win is a win,' but I'm not sure the effort to redesign is worth it.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. With 50,000 users per group, we had massive power to detect even tiny effects. A 0.3 percentage point increase might not justify the engineering and design costs. Statistical ≠ practical.\",\n          \"isCorrect\": true,\n          \"text\": \"Statistically significant, not practically\"\n        },\n        {\n          \"feedback\": \"No, we rejected the null (p=0.03). There IS a real effect — it's just tiny. The question is whether a 0.3 percentage point improvement matters enough to act on.\",\n          \"isCorrect\": false,\n          \"text\": \"The null hypothesis is probably true\"\n        },\n        {\n          \"feedback\": \"We already have 100,000 users total — plenty. The issue isn't sample size; it's that the effect, while real and detectable, might be too small to justify the implementation effort.\",\n          \"isCorrect\": false,\n          \"text\": \"We need a larger sample size\"\n        },\n        {\n          \"feedback\": \"Type I error means rejecting a true null (false positive). But with p=0.03, we likely did find a real effect — just a tiny one that might not matter practically.\",\n          \"isCorrect\": false,\n          \"text\": \"We made a Type I error\"\n        }\n      ],\n      \"question\": \"How should we interpret this result?\"\n    },\n    {\n      \"context\": \"That makes sense. I'll tell them it's real but probably not worth the effort. Oh, but {{NAME}}, while you're here — we also tested new button colors, different text, icon placement, and animation speed. Five tests total. The color one has p=0.04. Should we ship that?\",\n      \"options\": [\n        {\n          \"feedback\": \"Bingo. Testing 5 hypotheses at alpha=0.05 means we expect 0.25 false positives — about 1 in 4 runs. With p=0.04 on one of five tests, this could easily be a Type I error. We need correction methods.\",\n          \"isCorrect\": true,\n          \"text\": \"Multiple comparisons inflate false positives\"\n        },\n        {\n          \"feedback\": \"Testing simultaneously doesn't solve multiple comparisons. The problem is running 5 separate tests — each has a 5% false positive rate, so collectively we're much more likely to get spurious results.\",\n          \"isCorrect\": false,\n          \"text\": \"We should test them all together\"\n        },\n        {\n          \"feedback\": \"We don't know if sample size is the issue. The real problem is multiple testing: with 5 tests at alpha=0.05, we expect about 1 false positive every 4 experiments even if nothing works.\",\n          \"isCorrect\": false,\n          \"text\": \"The sample size is too small\"\n        },\n        {\n          \"feedback\": \"0.04 is below the standard 0.05 threshold. The problem isn't the individual p-value — it's that running multiple tests inflates the overall Type I error rate. We need multiple comparison corrections.\",\n          \"isCorrect\": false,\n          \"text\": \"P-values above 0.01 aren't valid\"\n        }\n      ],\n      \"question\": \"What's the problem with this approach?\"\n    },\n    {\n      \"context\": \"Oh no. So that p=0.04 might just be random noise because we tested so many things? How do we handle this? Should we throw out all the results?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Bonferroni divides alpha by number of tests (0.05/5 = 0.01), so we'd need p<0.01. Or use FDR methods that are less conservative. Either way, p=0.04 wouldn't pass with 5 tests.\",\n          \"isCorrect\": true,\n          \"text\": \"Apply Bonferroni or FDR correction\"\n        },\n        {\n          \"feedback\": \"That's cherry-picking and p-hacking. If we only report the 'significant' result from 5 tests without correction, we're likely reporting a false positive. We need to account for multiple comparisons.\",\n          \"isCorrect\": false,\n          \"text\": \"Just report the one with p=0.04\"\n        },\n        {\n          \"feedback\": \"More data won't fix multiple testing bias. We'd still have the same problem: 5 tests means inflated false positive rate. We need to apply corrections like Bonferroni, not just gather more data.\",\n          \"isCorrect\": false,\n          \"text\": \"Increase the sample size and retest\"\n        },\n        {\n          \"feedback\": \"While more conservative, arbitrarily choosing 0.001 isn't the solution. Proper multiple comparison corrections (Bonferroni, FDR) mathematically adjust for the number of tests. That's the rigorous approach.\",\n          \"isCorrect\": false,\n          \"text\": \"Accept only p-values below 0.001\"\n        }\n      ],\n      \"question\": \"What's the right way forward?\"\n    },\n    {\n      \"context\": \"Got it. So with Bonferroni, we'd need p<0.01 for 5 tests. The color test doesn't make the cut. I'll let marketing know. Actually, {{NAME}}, they're now asking about our pricing test from last month. We tested a $5 price increase and got p=0.18. They want to run it longer to 'get significance.'\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly right. Looking at results, seeing they're not significant, then collecting more data inflates Type I error. We should have determined sample size upfront based on the effect we wanted to detect.\",\n          \"isCorrect\": true,\n          \"text\": \"That's p-hacking — don't peek and continue\"\n        },\n        {\n          \"feedback\": \"No, p=0.18 means we failed to reject the null. We don't have evidence the price increase has an effect. Running longer to 'get significance' is p-hacking — it invalidates the test.\",\n          \"isCorrect\": false,\n          \"text\": \"P=0.18 means the price increase works\"\n        },\n        {\n          \"feedback\": \"Lowering alpha would make it HARDER to achieve significance, not easier. The real issue is that peeking at results and continuing the test until it's significant is a form of p-hacking.\",\n          \"isCorrect\": false,\n          \"text\": \"We should lower the significance level\"\n        },\n        {\n          \"feedback\": \"We can't conclude the null is true from failing to reject it. We simply lack evidence of an effect. The problem is their plan to keep testing until they get significance — that's p-hacking.\",\n          \"isCorrect\": false,\n          \"text\": \"The null hypothesis is definitely true\"\n        }\n      ],\n      \"question\": \"What's wrong with their plan?\"\n    },\n    {\n      \"context\": \"Right, I remember now — we're supposed to calculate sample size before we start. But they're saying p=0.18 is 'close enough' and just want to call it significant anyway. What do I even say to that?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect framing. P>0.05 means we failed to reject the null — we don't have evidence of an effect. It's not 'almost an A.' We can't conclude the price increase works based on this data.\",\n          \"isCorrect\": true,\n          \"text\": \"P-values aren't grades; 0.18 means no evidence\"\n        },\n        {\n          \"feedback\": \"No, that's the classic p-value misinterpretation. P=0.18 means IF there's no effect, we'd see data this extreme 18% of the time. It's not the probability the hypothesis is true.\",\n          \"isCorrect\": false,\n          \"text\": \"0.18 means there's 18% chance it works\"\n        },\n        {\n          \"feedback\": \"Type I error is rejecting a true null (false positive). Here we DIDN'T reject the null (p=0.18), so no Type I error. We might have made a Type II error if there's a real effect we missed.\",\n          \"isCorrect\": false,\n          \"text\": \"We made a Type I error\"\n        },\n        {\n          \"feedback\": \"We don't change the significance level after seeing results to make them 'work.' That's p-hacking. Alpha is set beforehand. P=0.18 means we don't have evidence of an effect at standard thresholds.\",\n          \"isCorrect\": false,\n          \"text\": \"We should use 0.20 as the cutoff instead\"\n        }\n      ],\n      \"question\": \"How do you explain why p=0.18 isn't 'close enough'?\"\n    },\n    {\n      \"context\": \"Okay, I'll explain it's not evidence of an effect. Though honestly, {{NAME}}, I'm wondering if maybe we just didn't have enough data. We only had 800 users in that pricing test. Could it be a Type II error — there IS an effect but we missed it?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Statistical power depends on all three. With only 800 users, we might have low power to detect a small effect. We should have calculated required sample size based on the minimum effect size we care about.\",\n          \"isCorrect\": true,\n          \"text\": \"Sample size, effect size, and alpha\"\n        },\n        {\n          \"feedback\": \"The p-value tells us what we observed, not whether we had adequate power. Power depends on sample size, the true effect size, and our alpha level — all factors we should consider when designing the test.\",\n          \"isCorrect\": false,\n          \"text\": \"Just the p-value we got\"\n        },\n        {\n          \"feedback\": \"Rejecting or not doesn't tell us about power. Power is the probability of detecting a real effect. With small samples, we might fail to reject even when there's a meaningful effect — that's a Type II error.\",\n          \"isCorrect\": false,\n          \"text\": \"Whether we rejected the null\"\n        },\n        {\n          \"feedback\": \"Multiple comparisons affect Type I error rate, not power. Power depends on sample size, the effect size we're trying to detect, and our significance level. It's about avoiding Type II errors.\",\n          \"isCorrect\": false,\n          \"text\": \"The number of comparisons we made\"\n        }\n      ],\n      \"question\": \"What determines if we had enough power to detect the effect?\"\n    },\n    {\n      \"context\": \"That makes sense. So we might have had too few users to detect a realistic price effect. I should have planned better. Hey, speaking of planning — the product team just asked me to analyze user engagement. They want to test if each of 30 new features improves daily active users. What's my move here, {{NAME}}?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. With 30 tests, use False Discovery Rate (less conservative than Bonferroni) to control false positives, and do a power analysis to ensure you can detect meaningful effects. Plan both error types upfront.\",\n          \"isCorrect\": true,\n          \"text\": \"Use FDR correction and plan for power\"\n        },\n        {\n          \"feedback\": \"With 30 tests at alpha=0.05, you'd expect 1.5 false positives even if nothing works. You need multiple comparison corrections (Bonferroni, FDR) to control the family-wise error rate.\",\n          \"isCorrect\": false,\n          \"text\": \"Test each at alpha=0.05 independently\"\n        },\n        {\n          \"feedback\": \"Cherry-picking which features to test based on preliminary data is a form of p-hacking. If you must test 30 features, do it properly with multiple comparison corrections and adequate power.\",\n          \"isCorrect\": false,\n          \"text\": \"Only test the 5 most promising features\"\n        },\n        {\n          \"feedback\": \"While conservative, arbitrarily picking 0.001 isn't the right solution for 30 tests. You need proper multiple comparison corrections like Bonferroni (0.05/30≈0.0017) or FDR methods that mathematically account for multiple testing.\",\n          \"isCorrect\": false,\n          \"text\": \"Use p<0.001 to be extra safe\"\n        }\n      ],\n      \"question\": \"What's the smart approach for testing 30 features?\"\n    },\n    {\n      \"context\": \"Got it — FDR correction and power analysis before I start. I'm learning so much today. Okay, last question, {{NAME}}. The CEO just forwarded me a competitor's press release. They claim their new feature 'significantly increases user satisfaction, p<0.05.' Should I be worried?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. 'Significant' with no effect size might be tiny and meaningless. And if they tested dozens of features and only reported p<0.05 on one, that could be a false positive from multiple comparisons. Need more info.\",\n          \"isCorrect\": true,\n          \"text\": \"We don't know effect size or how many tests they ran\"\n        },\n        {\n          \"feedback\": \"P<0.05 doesn't 'prove' anything — it means the data is unlikely under the null. But we don't know the effect size (could be tiny), whether they corrected for multiple tests, or if the study was adequately powered.\",\n          \"isCorrect\": false,\n          \"text\": \"P<0.05 proves their feature works\"\n        },\n        {\n          \"feedback\": \"The threshold isn't the main issue. The concern is we don't know: the actual effect size, whether they tested multiple features and only reported the significant one, or if it's practically meaningful. 'Significant' tells us very little.\",\n          \"isCorrect\": false,\n          \"text\": \"They should have used p<0.01 instead\"\n        },\n        {\n          \"feedback\": \"P<0.05 is a standard threshold. The real issues are: What's the actual effect? Did they run multiple tests? Is the effect large enough to matter? Marketing claims often cherry-pick significant results without context.\",\n          \"isCorrect\": false,\n          \"text\": \"P-values above 0.001 aren't trustworthy\"\n        }\n      ],\n      \"question\": \"What should make you skeptical of their claim?\"\n    },\n    {\n      \"context\": \"True. They probably tested everything and only announced what 'worked.' Classic. Actually, wait — I just realized something. We should probably check our own tests. Remember that checkout button with the 0.3% improvement? We had TWO different analytics platforms tracking it, and I just saw the other one shows p=0.09. Same test, different result.\",\n      \"options\": [\n        {\n          \"feedback\": \"Most likely. One platform might exclude bots differently, handle returning users differently, or filter sessions differently. Same test, different data preprocessing = different p-values. Need to investigate the methods.\",\n          \"isCorrect\": true,\n          \"text\": \"Different user counting or filtering methods\"\n        },\n        {\n          \"feedback\": \"Possible but less likely than different data processing. Platforms probably filter users, sessions, or events differently. Small differences in who's included can change results, especially near significance thresholds.\",\n          \"isCorrect\": false,\n          \"text\": \"One platform has a bug in p-value calculation\"\n        },\n        {\n          \"feedback\": \"Never average p-values — that's not statistically valid. We need to understand WHY they differ: likely different data filtering, user definitions, or session counting. Investigate the methodology, don't just combine results.\",\n          \"isCorrect\": false,\n          \"text\": \"We should average the two p-values\"\n        },\n        {\n          \"feedback\": \"P-values have sampling variability, but two analyses of the SAME test shouldn't differ this much unless they're processing data differently. The platforms likely use different user filters, bot detection, or session definitions.\",\n          \"isCorrect\": false,\n          \"text\": \"P-values are random so this is normal\"\n        }\n      ],\n      \"question\": \"What could explain the different p-values?\"\n    },\n    {\n      \"context\": \"Ah, I bet it's the bot filtering. One platform is way more aggressive about it. Okay, I'll dig into that. {{NAME}}, this has been incredibly helpful. I feel like I was about to make so many mistakes — shipping tiny effects, ignoring multiple comparisons, the whole thing.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect summary. Statistical significance doesn't mean practical importance. Plan sample size upfront, correct for multiple tests, consider effect sizes, and don't p-hack. Good hypothesis testing requires thinking, not just checking p<0.05.\",\n          \"isCorrect\": true,\n          \"text\": \"Significance ≠ importance; plan tests properly\"\n        },\n        {\n          \"feedback\": \"No, p-values aren't a score to minimize. The lesson is: check effect sizes for practical significance, plan tests with adequate power, correct for multiple comparisons, and don't manipulate tests to get p<0.05.\",\n          \"isCorrect\": false,\n          \"text\": \"Always use the smallest p-value possible\"\n        },\n        {\n          \"feedback\": \"That's too extreme. The lesson is about proper test design: consider effect size (not just p-value), plan sample size, correct for multiple tests, and avoid p-hacking. It's about rigorous methodology, not arbitrary thresholds.\",\n          \"isCorrect\": false,\n          \"text\": \"Never trust any p-value under 0.001\"\n        },\n        {\n          \"feedback\": \"No, that's the misinterpretation we're trying to avoid. P-values show how surprising data would be IF the null were true. The real lesson: focus on effect sizes, plan properly, and understand what significance actually means.\",\n          \"isCorrect\": false,\n          \"text\": \"P-values tell us if hypotheses are true\"\n        }\n      ],\n      \"question\": \"What's the biggest takeaway from all this?\"\n    },\n    {\n      \"context\": \"Wait, {{NAME}}... I just got a Slack from the data science lead. Apparently, someone on the marketing team has been running A/B tests, checking results daily, and stopping tests early when they hit p<0.05. They've 'shipped' seven 'winning' features in the past month. Oh no.\",\n      \"options\": [\n        {\n          \"feedback\": \"Classic optional stopping problem. Peeking repeatedly and stopping when you hit significance dramatically increases false positives. Those seven 'wins' are likely mostly noise. They need proper sequential testing methods or fixed sample sizes.\",\n          \"isCorrect\": true,\n          \"text\": \"Sequential testing inflates Type I errors\"\n        },\n        {\n          \"feedback\": \"Those are likely false positives. Checking daily and stopping at p<0.05 (optional stopping) inflates Type I error far beyond 5%. With repeated peeking, you'll eventually hit 'significance' by chance even when nothing works.\",\n          \"isCorrect\": false,\n          \"text\": \"They're doing great — 7 wins is impressive\"\n        },\n        {\n          \"feedback\": \"Changing the threshold doesn't fix optional stopping. The problem is peeking repeatedly and stopping when you hit significance — that inflates false positives regardless of alpha. They need to commit to sample sizes upfront.\",\n          \"isCorrect\": false,\n          \"text\": \"They should stop at p<0.01 instead\"\n        },\n        {\n          \"feedback\": \"No, this is the opposite. Type II is missing real effects. Optional stopping (peeking and stopping early when significant) inflates Type I errors — false positives. They're probably 'finding' effects that don't exist.\",\n          \"isCorrect\": false,\n          \"text\": \"They're making Type II errors\"\n        }\n      ],\n      \"question\": \"What's happening with their tests?\"\n    },\n    {\n      \"context\": \"This is a disaster. Seven features shipped that probably don't work. I need to talk to them. How do I explain why they can't just peek at the results and stop when they like what they see?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. With no real effect, p-values jump around randomly. Peek enough times and you'll eventually see p<0.05 by pure chance. Then stopping makes it look 'significant' when it's just noise. Decide sample size upfront and stick to it.\",\n          \"isCorrect\": true,\n          \"text\": \"P-values fluctuate; peeking until p<0.05 guarantees it eventually\"\n        },\n        {\n          \"feedback\": \"Time waste isn't the problem — inflated false positives are. When you peek repeatedly and stop at p<0.05, you're way more likely than 5% to get spurious significance. The tests are statistically invalid, not just inefficient.\",\n          \"isCorrect\": false,\n          \"text\": \"It wastes time checking results too often\"\n        },\n        {\n          \"feedback\": \"The frequency isn't the issue — optional stopping itself is the problem. Whether daily or weekly, peeking and stopping when you hit significance inflates false positive rates. Use sequential testing methods or commit to fixed sample sizes upfront.\",\n          \"isCorrect\": false,\n          \"text\": \"They should peek weekly, not daily\"\n        },\n        {\n          \"feedback\": \"Actually, optional stopping inflates Type I errors (false positives), not Type II. The problem is you'll eventually hit p<0.05 by chance if you peek enough times, even with no real effect. It's not about power — it's about invalid tests.\",\n          \"isCorrect\": false,\n          \"text\": \"Early stopping reduces statistical power\"\n        }\n      ],\n      \"question\": \"What's the clearest explanation of why optional stopping is wrong?\"\n    },\n    {\n      \"context\": \"Got it. Random fluctuation means if you peek enough times, you'll hit p<0.05 eventually, even with zero effect. I'll explain that. {{NAME}}, I'm going to suggest they retest these features properly. But here's the twist — the CEO LOVES two of them. They're her favorite features now. This is going to be awkward.\",\n      \"options\": [\n        {\n          \"feedback\": \"That's the only ethical path. Calculate proper sample sizes, don't peek, and report results transparently — even if they contradict the CEO's intuition. Good data culture means following the method, not the desired outcome.\",\n          \"isCorrect\": true,\n          \"text\": \"Run properly powered tests, report honestly regardless\"\n        },\n        {\n          \"feedback\": \"That's confirmation bias institutionalized. If the original tests were invalid due to optional stopping, ALL seven features need retesting — regardless of who likes them. Selective retesting defeats the purpose of rigorous testing.\",\n          \"isCorrect\": false,\n          \"text\": \"Skip retesting features the CEO likes\"\n        },\n        {\n          \"feedback\": \"You can't change alpha to get desired results — that's the opposite of scientific thinking. Run the test properly with predetermined sample size and alpha, then accept the results. Integrity matters more than politics.\",\n          \"isCorrect\": false,\n          \"text\": \"Use a lower alpha to 'prove' they work\"\n        },\n        {\n          \"feedback\": \"Lying undermines the entire point of data-driven decisions. If leadership can't handle honest results, the organization has bigger problems. Run proper tests and communicate results transparently — that's how you build trust in data.\",\n          \"isCorrect\": false,\n          \"text\": \"Tell the CEO they worked, run secret tests\"\n        }\n      ],\n      \"question\": \"How should you approach retesting the CEO's favorite features?\"\n    },\n    {\n      \"context\": \"You're right. I'll test them all properly and present the results honestly. If her favorites don't hold up, better to know now than after they're fully built out. Okay, running the power analysis now... {{NAME}}, this is interesting. To detect a 0.5% conversion lift with 80% power, I need 64,000 users per group. That's two months of traffic per test.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Chasing 0.5% improvements requires massive samples and time. Better to focus testing resources on changes expected to have larger effects, and accept you can't rigorously test every tiny tweak. Trade-offs are real.\",\n          \"isCorrect\": true,\n          \"text\": \"Small effects need huge samples; prioritize bigger bets\"\n        },\n        {\n          \"feedback\": \"Increasing alpha (like 0.10) reduces required sample size but increases false positives. That doesn't solve the fundamental issue: detecting tiny effects requires huge samples. Better to focus on testing changes with larger expected impacts.\",\n          \"isCorrect\": false,\n          \"text\": \"Use a higher alpha to reduce sample size\"\n        },\n        {\n          \"feedback\": \"Cutting the planned sample size in half leaves you underpowered — you'll miss real 0.5% effects most of the time. The lesson is that tiny effects need huge samples, so focus testing on bigger changes where you can achieve adequate power.\",\n          \"isCorrect\": false,\n          \"text\": \"Just test for one month instead of two\"\n        },\n        {\n          \"feedback\": \"Decreasing the target effect size requires even MORE data, not less. The point is: if you only have enough traffic for smaller tests, focus on changes expected to have larger effects. You can't rigorously test everything.\",\n          \"isCorrect\": false,\n          \"text\": \"Decrease the effect size to 0.3%\"\n        }\n      ],\n      \"question\": \"What does this tell you about your testing strategy?\"\n    },\n    {\n      \"context\": \"That makes sense. Test the big swings, not every tiny button color. I'll reprioritize. Actually, {{NAME}}, plot twist — I just found the original test plan document for those seven 'winning' features. Somebody had written down proper sample sizes and everything. They just... ignored it and started peeking. Why do people do this?\",\n      \"options\": [\n        {\n          \"feedback\": \"Probably. Waiting weeks for proper sample sizes is hard when stakeholders want results now. But cutting corners invalidates the tests. The solution is education and cultural buy-in that rigorous testing is worth the wait.\",\n          \"isCorrect\": true,\n          \"text\": \"Impatience and pressure for quick wins\"\n        },\n        {\n          \"feedback\": \"We don't know that. More likely they got impatient or felt pressure for fast results. Proper testing takes time, and there's always temptation to peek early. This is why process discipline and understanding matter.\",\n          \"isCorrect\": false,\n          \"text\": \"The plan was statistically incorrect\"\n        },\n        {\n          \"feedback\": \"Optional stopping doesn't increase power — it inflates false positives. They likely peeked early due to impatience or pressure for results, not any statistical reasoning. The plan was abandoned for human reasons, not methodological ones.\",\n          \"isCorrect\": false,\n          \"text\": \"They wanted to increase statistical power\"\n        },\n        {\n          \"feedback\": \"No, optional stopping (peeking and stopping at significance) invalidates tests by inflating Type I error. They likely abandoned the plan due to impatience or pressure, not because peeking is better — it's strictly worse.\",\n          \"isCorrect\": false,\n          \"text\": \"Peeking actually improves test accuracy\"\n        }\n      ],\n      \"question\": \"Why do you think they abandoned the plan?\"\n    },\n    {\n      \"context\": \"Yeah, probably pressure from above to show results fast. I get it, but... the consequences. Okay, I'm going to present all of this to the team next week — proper testing protocols, no peeking, effect sizes matter, the whole thing. {{NAME}}, any final advice before I walk into that meeting?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. Emphasize that rigorous testing saves time in the long run by preventing bad decisions. Plan sample sizes, set alpha beforehand, don't peek, correct for multiple tests, and always check effect sizes. Slow down to go fast.\",\n          \"isCorrect\": true,\n          \"text\": \"Plan tests properly; discipline beats speed\"\n        },\n        {\n          \"feedback\": \"Arbitrary thresholds won't fix the culture. The message should be: plan tests properly with power analysis, commit to sample sizes, don't peek, correct for multiple tests, and always consider practical significance. It's about process, not thresholds.\",\n          \"isCorrect\": false,\n          \"text\": \"Only report p-values below 0.01\"\n        },\n        {\n          \"feedback\": \"Testing isn't the problem — misuse is. The message is how to do it RIGHT: proper planning, adequate power, no optional stopping, multiple comparison corrections, and checking effect sizes. Fix the process, don't abandon the tool.\",\n          \"isCorrect\": false,\n          \"text\": \"Ban all hypothesis testing completely\"\n        },\n        {\n          \"feedback\": \"Bigger isn't always better — huge samples detect tiny meaningless effects. The message is: plan for adequate power to detect effects you CARE about, prioritize tests on bigger changes, and always check if significance is also practical significance.\",\n          \"isCorrect\": false,\n          \"text\": \"Always maximize sample size no matter what\"\n        }\n      ],\n      \"question\": \"What's the key message for building a better testing culture?\"\n    },\n    {\n      \"context\": \"Plan properly, stay disciplined, focus on effects that matter. I can do this. Thanks, {{NAME}}. Alright, I'm writing up the new testing guidelines now. And just between us? I'm kind of excited to tell marketing their seven wins were probably flukes. Is that bad?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect approach. Frame it as 'the process had issues' not 'you messed up,' explain why optional stopping invalidates results, and offer a path forward with proper retesting. Education and solutions, not blame. Build the culture you want.\",\n          \"isCorrect\": true,\n          \"text\": \"Diplomatically explain the method was flawed, offer to retest\"\n        },\n        {\n          \"feedback\": \"That'll create defensiveness and hurt the culture. Better to explain the methodological issues diplomatically, acknowledge pressure they faced, and focus on how everyone can do better testing going forward. You want allies, not enemies.\",\n          \"isCorrect\": false,\n          \"text\": \"Publicly call out their mistakes in the meeting\"\n        },\n        {\n          \"feedback\": \"Transparency matters. They need to understand WHY the original tests were flawed so they don't repeat the mistakes. Explain optional stopping gently, involve them in proper retesting, and build shared understanding of rigorous methods.\",\n          \"isCorrect\": false,\n          \"text\": \"Just quietly retest without telling them\"\n        },\n        {\n          \"feedback\": \"That perpetuates bad practices and erodes trust in data. Communicate the methodological issues diplomatically but clearly, explain the need for retesting, and help everyone understand how to test properly. Short-term harmony isn't worth long-term dysfunction.\",\n          \"isCorrect\": false,\n          \"text\": \"Say the wins are valid to avoid conflict\"\n        }\n      ],\n      \"question\": \"How should you communicate that their wins might be false positives?\"\n    },\n    {\n      \"context\": \"Diplomatic, educational, solutions-focused. Got it. {{NAME}}, I genuinely think this is going to make our whole testing program better. Well, assuming I survive the meeting. Worst case, I'll see you at the next company that values statistical rigor, right?\",\n      \"options\": [\n        {\n          \"feedback\": \"Absolutely. Organizations that embrace rigorous hypothesis testing make better decisions and build better products. It's not always easy, but it's always worth it. You've got this, {{NAME}}. Go build that culture.\",\n          \"isCorrect\": true,\n          \"text\": \"Good testing culture is worth fighting for\"\n        },\n        {\n          \"feedback\": \"That's giving up on data-driven culture. Yes, it's hard to deliver unwelcome truths, but that's exactly when integrity matters most. Stick to rigorous methods, communicate well, and trust that good process wins in the long run.\",\n          \"isCorrect\": false,\n          \"text\": \"Just tell them what they want to hear\"\n        },\n        {\n          \"feedback\": \"It absolutely matters — it's the difference between decisions based on evidence vs noise. The challenge is doing it right: proper planning, adequate power, no p-hacking, considering effect sizes. That rigor is what separates good teams from great ones.\",\n          \"isCorrect\": false,\n          \"text\": \"Statistical testing doesn't really matter\"\n        },\n        {\n          \"feedback\": \"Bad testing leads to bad decisions that cost real time and money. Yes, the conversation might be uncomfortable, but the alternative is shipping features that don't work. Be diplomatic but firm — rigorous testing is worth the effort.\",\n          \"isCorrect\": false,\n          \"text\": \"Avoid conflict by dropping the whole thing\"\n        }\n      ],\n      \"question\": \"What's your final encouragement?\"\n    }\n  ]\n}",
      "outputTokens": 8442,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-statistics-hypothesis-testing-1",
      "userPrompt": "LESSON_TITLE: Hypothesis Testing in Practice\nLESSON_DESCRIPTION: Applying statistical hypothesis testing correctly to make sound data-driven decisions\nCHAPTER_TITLE: Statistical Inference\nCOURSE_TITLE: Applied Statistics\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Null Hypothesis: The null hypothesis (H0) is the default assumption of no effect. We try to reject it. The p-value measures how surprising the data would be IF the null were true.\n2. P-Value Meaning: A p-value is NOT the probability the null is true. It's the probability of seeing data this extreme (or more) if the null IS true. A common and dangerous misinterpretation.\n3. Error Types: Type I error (false positive) is rejecting a true null. Type II error (false negative) is failing to reject a false null. You can't minimize both — there's a trade-off.\n4. Statistical Power: Statistical power is the probability of detecting a real effect. It depends on sample size, effect size, and significance level. Low-powered studies miss real effects.\n5. Practical Significance: Statistical significance doesn't mean practical significance. A huge sample can detect tiny effects that don't matter in practice. Always consider effect size.\n6. Multiple Comparisons: Multiple comparisons inflate Type I errors. Testing 20 hypotheses at alpha=0.05 expects one false positive. Corrections like Bonferroni or FDR control this."
    },
    {
      "duration": 120564.510167,
      "inputTokens": 4227,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we have a situation. The VP of product just asked if we should build our recommendation engine on our new quantum computer. She heard quantum parallelism means we can process all user preferences simultaneously. Marketing already promised clients it'll be 'infinitely faster.' I need your help before this goes off the rails.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Quantum parallelism evaluates functions on all inputs simultaneously, but measurement collapses to ONE result. You can't just 'read out' all recommendations — the algorithm needs interference to amplify useful answers.\",\n          \"isCorrect\": true,\n          \"text\": \"Quantum parallelism doesn't give direct access to all results\"\n        },\n        {\n          \"feedback\": \"Speed isn't the issue — it's accessing results. Quantum parallelism explores exponentially many states, but measurement only gives you one outcome. Without the right interference pattern, you gain nothing.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum computers are too slow for real-time tasks\"\n        },\n        {\n          \"feedback\": \"Data structures aren't the problem. The issue is that quantum parallelism doesn't let you extract all computed values — measurement collapses the superposition to a single result. You need interference to make that result useful.\",\n          \"isCorrect\": false,\n          \"text\": \"Recommendation engines need classical data structures\"\n        },\n        {\n          \"feedback\": \"Power isn't the issue. Even with perfect quantum hardware, you can't directly access all parallel computation results — measurement gives you one outcome. The algorithm must use interference to amplify the answer you want.\",\n          \"isCorrect\": false,\n          \"text\": \"The quantum computer isn't powerful enough yet\"\n        }\n      ],\n      \"question\": \"What's the core issue with using quantum computing for this recommendation engine?\"\n    },\n    {\n      \"context\": \"Right, so I need to explain to the VP that we can't just 'read all the answers.' She's going to ask what quantum computers ARE good for then. I'm looking at our project list — we've got user authentication, database indexing, a new cryptography system, and molecular simulation for our pharma partner.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. Simulating quantum systems (molecules, materials) is where quantum computers shine — classical computers struggle with exponentially growing quantum states. This is a problem type that benefits from quantum advantage.\",\n          \"isCorrect\": true,\n          \"text\": \"Molecular simulation for the pharma partner\"\n        },\n        {\n          \"feedback\": \"Authentication is a classical algorithm that works efficiently now. Quantum advantage requires specific problem types like factoring, simulation, or certain optimization — not general-purpose computing tasks.\",\n          \"isCorrect\": false,\n          \"text\": \"User authentication system\"\n        },\n        {\n          \"feedback\": \"Database indexing is well-solved classically. Quantum computers excel at specific problems — simulating quantum systems, factoring, certain optimizations — not replacing efficient classical algorithms.\",\n          \"isCorrect\": false,\n          \"text\": \"Database indexing optimization\"\n        },\n        {\n          \"feedback\": \"Implementing cryptography is classical work. Quantum computers threaten certain crypto (like RSA) through factoring algorithms, but building crypto systems doesn't match where quantum provides advantage.\",\n          \"isCorrect\": false,\n          \"text\": \"New cryptography system implementation\"\n        }\n      ],\n      \"question\": \"Which project actually matches quantum computing's strengths?\"\n    },\n    {\n      \"context\": \"Okay, the pharma simulation makes sense. But now she's asking about timelines. She wants to know if we can run a 500-qubit simulation next month on our quantum system. I just checked — our current quantum computer has 50 physical qubits available.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. With decoherence and noise, you need thousands of physical qubits per logical qubit for fault tolerance. 50 physical qubits might give you only a handful of error-corrected logical qubits — nowhere near 500.\",\n          \"isCorrect\": true,\n          \"text\": \"We need way more physical qubits for error correction\"\n        },\n        {\n          \"feedback\": \"Simulation algorithms exist. The problem is error correction overhead — noisy physical qubits need massive redundancy to create reliable logical qubits. 50 physical qubits can't support 500 logical qubits.\",\n          \"isCorrect\": false,\n          \"text\": \"The simulation algorithm hasn't been invented yet\"\n        },\n        {\n          \"feedback\": \"Processing time isn't the issue. Decoherence and noise mean each logical qubit requires thousands of physical qubits for error correction. You can't get 500 reliable logical qubits from just 50 physical ones.\",\n          \"isCorrect\": false,\n          \"text\": \"500 qubits would take too long to process\"\n        },\n        {\n          \"feedback\": \"Entanglement will happen in the algorithm, but the real constraint is error correction. Physical qubits are noisy — you need massive overhead (thousands per logical qubit) to maintain coherence. 50 physical qubits won't support 500 logical ones.\",\n          \"isCorrect\": false,\n          \"text\": \"We need to entangle all 500 qubits first\"\n        }\n      ],\n      \"question\": \"What's the real constraint here?\"\n    },\n    {\n      \"context\": \"I told her about the error correction overhead and she looked horrified. 'Thousands of physical qubits for ONE logical qubit? Why is it so bad?' I mentioned decoherence, but I need to explain what's actually happening when these qubits fail.\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. Decoherence happens when qubits interact with their environment — stray photons, vibrations, temperature fluctuations. This destroys the delicate superposition and entanglement states before computation finishes.\",\n          \"isCorrect\": true,\n          \"text\": \"Environment interaction destroys quantum information rapidly\"\n        },\n        {\n          \"feedback\": \"It's not random bit flips like classical errors. Decoherence is environmental interaction destroying quantum information — the superposition and entanglement collapse. This is why error correction requires such massive overhead.\",\n          \"isCorrect\": false,\n          \"text\": \"Qubits randomly flip between 0 and 1 states\"\n        },\n        {\n          \"feedback\": \"Measurements do collapse superposition, but decoherence is different — it's unwanted environmental interaction destroying quantum states. This happens constantly during computation, not just when measuring, requiring heavy error correction.\",\n          \"isCorrect\": false,\n          \"text\": \"Measurements collapse the qubits too early\"\n        },\n        {\n          \"feedback\": \"Entanglement is a resource, not the error source. Decoherence comes from environmental interaction destroying quantum information. This noise requires massive error correction overhead to maintain coherent computation.\",\n          \"isCorrect\": false,\n          \"text\": \"Entanglement spreads errors across all qubits\"\n        }\n      ],\n      \"question\": \"How should you explain decoherence's impact?\"\n    },\n    {\n      \"context\": \"She gets it now — noisy qubits need tons of overhead. But then she asked something that stumped me: 'If we can't do 500 qubits yet, what CAN we do with 50 physical qubits?' I know some of those will go to error correction, but I'm not sure what's realistic for actual computation right now.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. With current error correction overhead, 50 physical qubits might support 5-10 noisy logical qubits for demonstrations, or fewer fault-tolerant ones. We're in the 'noisy intermediate-scale quantum' era — useful but limited.\",\n          \"isCorrect\": true,\n          \"text\": \"Maybe a few logical qubits for small demonstrations\"\n        },\n        {\n          \"feedback\": \"Without error correction, decoherence destroys quantum information too quickly for useful computation. 50 physical qubits need to be divided — most for error correction, leaving only a few logical qubits for actual computation.\",\n          \"isCorrect\": false,\n          \"text\": \"All 50 qubits for computation, no error correction needed\"\n        },\n        {\n          \"feedback\": \"Error correction overhead is way larger than 2:1. You need hundreds or thousands of physical qubits per fault-tolerant logical qubit. 50 physical qubits might give you just a few useful logical qubits.\",\n          \"isCorrect\": false,\n          \"text\": \"25 logical qubits after standard error correction\"\n        },\n        {\n          \"feedback\": \"50 physical qubits can't support commercial applications yet. After error correction overhead, you're left with very few logical qubits — enough for research and small demonstrations, not production workloads.\",\n          \"isCorrect\": false,\n          \"text\": \"50 qubits is enough for basic commercial applications\"\n        }\n      ],\n      \"question\": \"What's a realistic assessment of 50 physical qubits' computational capacity?\"\n    },\n    {\n      \"context\": \"{{NAME}}, she just pivoted the conversation. 'Forget the big simulation then. Our security team wants to know if we should worry about quantum computers breaking our RSA encryption. They're using 2048-bit keys. Should we panic now or can this wait?'\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Breaking 2048-bit RSA needs thousands of logical qubits running for hours without errors — requiring millions of physical qubits with error correction. We're years away, but organizations should plan transitions now since deployment takes time.\",\n          \"isCorrect\": true,\n          \"text\": \"We need fault-tolerant systems with millions of qubits first\"\n        },\n        {\n          \"feedback\": \"No way. Breaking RSA requires thousands of logical qubits with error correction — millions of physical qubits. Current systems have dozens of noisy qubits. The threat is real but not immediate.\",\n          \"isCorrect\": false,\n          \"text\": \"Current 50-qubit systems can already break RSA\"\n        },\n        {\n          \"feedback\": \"Quantum computers CAN break RSA using Shor's algorithm — that's a proven quantum advantage for factoring. But it requires fault-tolerant systems with thousands of logical qubits, which need millions of physical qubits. We're not there yet.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum computers can't actually break RSA encryption\"\n        },\n        {\n          \"feedback\": \"Decoherence is why we don't have the threat YET — current systems can't maintain coherence long enough. But error correction will eventually solve this, creating fault-tolerant systems capable of breaking RSA. Plan transitions now.\",\n          \"isCorrect\": false,\n          \"text\": \"RSA is safe because decoherence prevents long computations\"\n        }\n      ],\n      \"question\": \"What's the real timeline concern for RSA vulnerability?\"\n    },\n    {\n      \"context\": \"Good, so we have time but should start planning. Now the VP wants to make a statement to the board about our quantum strategy. She's drafting something about how 'quantum superposition lets our qubits be both 0 and 1 at once, doubling our computational power with each qubit.'\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. Superposition is a weighted combination with probability amplitudes that interfere before measurement — not 'both values simultaneously.' And you can't just double power — measurement collapses to one outcome. The value is in interference patterns.\",\n          \"isCorrect\": true,\n          \"text\": \"Superposition isn't 'both at once' — it's probability amplitudes\"\n        },\n        {\n          \"feedback\": \"It doesn't multiply power at all. Superposition is probability amplitudes that interfere, not 'multiple values at once.' Measurement gives ONE result — the power comes from designing algorithms where interference amplifies correct answers.\",\n          \"isCorrect\": false,\n          \"text\": \"Superposition actually triples the computational power\"\n        },\n        {\n          \"feedback\": \"Single qubits can be in superposition without entanglement. The real issue is describing it as 'both at once' — superposition is probability amplitudes that interfere. Measurement collapses to one result, so the benefit requires careful interference design.\",\n          \"isCorrect\": false,\n          \"text\": \"Only entangled qubits can be in superposition states\"\n        },\n        {\n          \"feedback\": \"Superposition is fundamental to all quantum algorithms, not just simulation. The error is calling it 'both at once' — it's probability amplitudes that interfere before measurement. You get one result, so algorithms must use interference cleverly.\",\n          \"isCorrect\": false,\n          \"text\": \"Superposition only works for quantum simulation problems\"\n        }\n      ],\n      \"question\": \"What's wrong with this description of superposition?\"\n    },\n    {\n      \"context\": \"I just rewrote her statement to focus on probability amplitudes and interference. But now she's asking me to prioritize our quantum projects for the next quarter. We've got: training the team on quantum algorithms, upgrading to a 100-qubit system, developing error correction protocols, and building that molecular simulation for pharma.\",\n      \"options\": [\n        {\n          \"feedback\": \"Smart choice. Hardware will keep improving, but understanding which problems benefit from quantum advantage and how to design interference patterns matters more. The bottleneck is knowing WHEN quantum helps, not just having qubits.\",\n          \"isCorrect\": true,\n          \"text\": \"Training the team on quantum algorithms\"\n        },\n        {\n          \"feedback\": \"More qubits help, but without understanding which problems match quantum strengths and how to design algorithms with interference, the hardware sits idle. Team knowledge is the constraint — you need to know WHEN quantum provides advantage.\",\n          \"isCorrect\": false,\n          \"text\": \"Upgrading to the 100-qubit system immediately\"\n        },\n        {\n          \"feedback\": \"Error correction is crucial but extremely complex — major research institutions are working on this. For most organizations, learning which problems suit quantum computing and how to design effective algorithms is more practical right now.\",\n          \"isCorrect\": false,\n          \"text\": \"Developing proprietary error correction protocols\"\n        },\n        {\n          \"feedback\": \"Molecular simulation is a great quantum application, but jumping to implementation without understanding superposition, interference, and error correction limitations will lead to failure. Build team knowledge first — then tackle complex applications.\",\n          \"isCorrect\": false,\n          \"text\": \"Building the molecular simulation immediately\"\n        }\n      ],\n      \"question\": \"Which project should be the priority given current quantum computing reality?\"\n    },\n    {\n      \"context\": \"Perfect, I'll pitch the training program. But wait — {{NAME}}, I just got an email from our infrastructure team. They're claiming they can use quantum entanglement to send data between our datacenters faster than light. They want budget for 'quantum communication infrastructure.' This sounds... wrong?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly! Measuring one entangled qubit determines the other instantly, but that's correlation, not information transfer. You can't control what value you measure, so you can't send messages. Entanglement is a resource for algorithms, not faster-than-light communication.\",\n          \"isCorrect\": true,\n          \"text\": \"Entanglement creates correlation, not communication\"\n        },\n        {\n          \"feedback\": \"Entanglement can work across distances (that's quantum key distribution). But it doesn't transmit information faster than light — measuring one qubit correlates with the other, but you can't control the outcome to send messages.\",\n          \"isCorrect\": false,\n          \"text\": \"Entanglement only works within the same quantum computer\"\n        },\n        {\n          \"feedback\": \"Quantum communication does use entanglement (like in quantum key distribution), but it doesn't break the light-speed barrier. Entanglement creates correlation — measuring one determines the other — but you can't control results to transmit information.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum communication needs superposition, not entanglement\"\n        },\n        {\n          \"feedback\": \"Decoherence is a challenge, but the fundamental issue is that entanglement doesn't transmit information. Measurement correlation is instant, but you can't control what you measure, so you can't send messages faster than light.\",\n          \"isCorrect\": false,\n          \"text\": \"Decoherence prevents long-distance entanglement communication\"\n        }\n      ],\n      \"question\": \"What's the misconception about entanglement here?\"\n    },\n    {\n      \"context\": \"I just sent them a very polite email explaining they can't break physics. {{NAME}}, this has been quite a day. Before I meet with the VP tomorrow, I want to make sure I've got the big picture right. What's the one thing I should emphasize about when quantum computing actually helps?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. Quantum advantage requires problems where superposition and interference provide leverage — factoring, quantum simulation, certain optimizations. Most classical algorithms won't be replaced. The art is recognizing WHEN quantum fits.\",\n          \"isCorrect\": true,\n          \"text\": \"Quantum helps specific problem types, not general computing\"\n        },\n        {\n          \"feedback\": \"It's not about raw power. Quantum computers excel at specific problem types where interference can amplify correct answers — simulation, factoring, certain optimizations. For most tasks, classical computers remain better. Match the tool to the problem.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum is better when you need more processing power\"\n        },\n        {\n          \"feedback\": \"Dataset size isn't the key. Quantum advantage comes from problem structure — can superposition and interference provide leverage? Factoring, quantum simulation, and specific optimizations benefit. Most problems, regardless of data size, stay classical.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum works best for problems with massive datasets\"\n        },\n        {\n          \"feedback\": \"Parallelization doesn't mean quantum advantage. You can't just 'read out' all parallel results — measurement gives one answer. Quantum helps specific problems where interference patterns amplify solutions, like factoring and simulation, not general parallel tasks.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum helps any problem that can be parallelized\"\n        }\n      ],\n      \"question\": \"What's the core principle for quantum advantage?\"\n    },\n    {\n      \"context\": \"Excellent. I think I'm ready for tomorrow's meeting. Oh, one more thing — the VP just texted me. 'Quick question: should we pivot the whole company to quantum? Saw an article saying it'll replace all classical computing by 2027.' {{NAME}}... please tell me you have a good response for this.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect answer. Quantum excels at specific problems — most computing stays classical. Even when quantum helps, you'll likely use hybrid approaches. It's a specialized tool for certain problem types, not a replacement for general-purpose computing.\",\n          \"isCorrect\": true,\n          \"text\": \"Quantum complements classical, doesn't replace it\"\n        },\n        {\n          \"feedback\": \"The timeline isn't the issue — the premise is wrong. Quantum won't replace classical computing. It addresses specific problems where interference provides leverage. Most algorithms, databases, web servers, etc. will remain classical indefinitely.\",\n          \"isCorrect\": false,\n          \"text\": \"The timeline is wrong — it'll actually happen by 2030\"\n        },\n        {\n          \"feedback\": \"Maturity isn't the point. Even perfect quantum computers won't replace classical computing — they solve different problem types. Learn where quantum provides advantage (simulation, factoring, certain optimizations) and use it as a specialized complement.\",\n          \"isCorrect\": false,\n          \"text\": \"We should wait until quantum computers are more mature\"\n        },\n        {\n          \"feedback\": \"No one should 'pivot entirely' to quantum. It's not a replacement for classical computing — it's a tool for specific problems like simulation and factoring. Even quantum-ready organizations will use it alongside classical systems for different tasks.\",\n          \"isCorrect\": false,\n          \"text\": \"Only companies with quantum expertise should make this pivot\"\n        }\n      ],\n      \"question\": \"How should you address the 'quantum will replace everything' hype?\"\n    },\n    {\n      \"context\": \"I just replied: 'Quantum is a specialized tool, not a replacement. Let's focus on where it actually helps.' She sent back a thumbs up emoji. {{NAME}}, plot twist — she just forwarded me an email from our CTO. He's been secretly running our entire customer database query system on the quantum computer for the past week 'as an experiment.' The queries are taking 10,000 times longer than on classical systems and he's confused why. He's asking if he needs more qubits.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Database queries are efficiently solved classically. Quantum computers excel at specific problems — factoring, simulation, certain optimizations — where interference amplifies answers. Using quantum for classical problems that work fine adds overhead with no benefit.\",\n          \"isCorrect\": true,\n          \"text\": \"Database queries don't match quantum advantage patterns\"\n        },\n        {\n          \"feedback\": \"Entanglement won't help — the problem itself doesn't suit quantum computing. Database queries work efficiently on classical systems. Quantum advantage requires specific problem structures where interference provides leverage, not general data operations.\",\n          \"isCorrect\": false,\n          \"text\": \"He needed to entangle the database entries first\"\n        },\n        {\n          \"feedback\": \"Superposition doesn't magically parallelize classical tasks. Measurement gives one result, and you need interference to make that result useful. Database queries are efficiently classical — forcing them onto quantum hardware adds overhead without matching quantum's strengths.\",\n          \"isCorrect\": false,\n          \"text\": \"He should have used superposition for parallel queries\"\n        },\n        {\n          \"feedback\": \"Decoherence makes it worse, but the core mistake is using quantum for a classical problem. Database queries don't match quantum advantage patterns. Even perfect qubits wouldn't help — the problem structure doesn't benefit from superposition and interference.\",\n          \"isCorrect\": false,\n          \"text\": \"The quantum computer's decoherence time was too short\"\n        }\n      ],\n      \"question\": \"What's the fundamental mistake the CTO made?\"\n    },\n    {\n      \"context\": \"I just called him and gently explained that quantum computers aren't magic faster classical computers. He laughed and said, 'Well, at least I learned something. Moving it back to classical now.' {{NAME}}, thanks for talking this through with me. I think we've covered everything — except, wait, the VP just scheduled a final meeting and wants a one-sentence summary of our quantum strategy.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. This captures the essence: quantum addresses specific problem types where it provides advantage, while classical computing handles the vast majority of tasks. It's about matching the right tool to the problem, not replacing everything.\",\n          \"isCorrect\": true,\n          \"text\": \"Use quantum for simulation and specific optimization; keep classical for everything else\"\n        },\n        {\n          \"feedback\": \"This implies eventual full migration, which misses the point. Quantum solves specific problems — simulation, factoring, certain optimizations. Most systems stay classical forever. The strategy is selective application, not gradual replacement.\",\n          \"isCorrect\": false,\n          \"text\": \"Invest in quantum hardware and migrate systems gradually over time\"\n        },\n        {\n          \"feedback\": \"Waiting for perfection misses current opportunities. You can start identifying quantum-suitable problems (simulation, etc.) and building expertise now. The strategy is understanding WHEN quantum helps, not waiting for future hardware.\",\n          \"isCorrect\": false,\n          \"text\": \"Wait for fault-tolerant systems before any quantum adoption\"\n        },\n        {\n          \"feedback\": \"'Quantum supremacy' is a research milestone, not a business strategy. The right approach is identifying specific problems (simulation, certain optimizations) where quantum provides advantage and using it selectively alongside classical systems.\",\n          \"isCorrect\": false,\n          \"text\": \"Focus on quantum supremacy to stay ahead of competitors\"\n        }\n      ],\n      \"question\": \"What's the clearest one-sentence quantum strategy?\"\n    }\n  ]\n}",
      "outputTokens": 5847,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-physics-quantum-computing-basics-1",
      "userPrompt": "LESSON_TITLE: Quantum Computing Fundamentals\nLESSON_DESCRIPTION: Understanding quantum computing capabilities and limitations for practical problem-solving\nCHAPTER_TITLE: Quantum Information\nCOURSE_TITLE: Quantum Computing Fundamentals\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Superposition: Qubits can exist in superposition — a weighted combination of 0 and 1 states. This isn't 'both at once' — it's a probability amplitude that interferes before measurement.\n2. Entanglement: Entanglement links qubits so measuring one instantly determines the other, regardless of distance. This correlation is a resource for quantum algorithms.\n3. Quantum Parallelism: Quantum parallelism lets algorithms evaluate functions on all inputs simultaneously. But you can only read one result — the art is using interference to amplify the right answer.\n4. Decoherence: Decoherence destroys quantum information when qubits interact with their environment. Real qubits are noisy and maintain coherence only briefly.\n5. Error Correction: Quantum error correction encodes logical qubits in many physical qubits. The overhead is huge — thousands of physical qubits per logical qubit for fault tolerance.\n6. Where Quantum Helps: Quantum advantage requires the right problem type. Factoring, simulation, and certain optimization problems benefit. Most classical algorithms won't be replaced."
    },
    {
      "duration": 125895.11579199997,
      "inputTokens": 4306,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, acabei de receber uma ligação do VP de Produto. O monólito tá travando toda vez que a promoção do app dispara. Pagamento, estoque, notificações... tudo junto. Ele quer migrar pra microserviços ontem. Tenho uma reunião com ele em duas horas.\",\n      \"options\": [\n        {\n          \"feedback\": \"Microserviços não são bala de prata. Eles trazem complexidade operacional, debugging mais difícil e latência de rede. Precisamos ser honestos sobre os trade-offs desde o início.\",\n          \"isCorrect\": false,\n          \"text\": \"Explicar que microserviços resolvem tudo\"\n        },\n        {\n          \"feedback\": \"Exato! Antes de propor arquitetura, precisamos entender qual problema específico estamos resolvendo e se microserviços são realmente a solução certa considerando os custos.\",\n          \"isCorrect\": true,\n          \"text\": \"Mostrar trade-offs e entender a dor real\"\n        },\n        {\n          \"feedback\": \"Monólitos têm vantagens, mas nem sempre são a melhor escolha. Se diferentes partes do sistema precisam escalar independentemente ou têm ritmos de deploy diferentes, microserviços fazem sentido.\",\n          \"isCorrect\": false,\n          \"text\": \"Recusar — monólitos são sempre melhores\"\n        },\n        {\n          \"feedback\": \"Dividir por camadas técnicas (UI, Lógica, Dados) cria acoplamento. Microserviços devem seguir domínios de negócio, não arquitetura técnica.\",\n          \"isCorrect\": false,\n          \"text\": \"Aceitar e começar a dividir por camadas\"\n        }\n      ],\n      \"question\": \"Como devemos começar essa conversa com o VP?\"\n    },\n    {\n      \"context\": \"Boa. Então mapeei os problemas: pagamento trava quando estoque demora, notificações atrasam todo o checkout, e cada deploy de qualquer feature derruba tudo por 10 minutos. {{NAME}}, se formos dividir isso, por onde começamos a traçar as fronteiras?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso é dividir por camadas técnicas, não por domínios. Gera acoplamento porque toda funcionalidade de negócio atravessa todos os três serviços.\",\n          \"isCorrect\": false,\n          \"text\": \"Um serviço de API, um de lógica, um de BD\"\n        },\n        {\n          \"feedback\": \"Perfeito! Cada um é um domínio de negócio independente com responsabilidades claras. Podem evoluir, deployar e escalar separadamente sem afetar os outros.\",\n          \"isCorrect\": true,\n          \"text\": \"Pagamentos, Estoque, Notificações separados\"\n        },\n        {\n          \"feedback\": \"Isso cria nano-serviços sem coesão. Serviços devem encapsular capacidades de negócio completas, não apenas dados. Você acabaria com centenas de serviços sem propósito claro.\",\n          \"isCorrect\": false,\n          \"text\": \"Um serviço pra cada tabela do banco\"\n        },\n        {\n          \"feedback\": \"Containerizar um monólito não o transforma em microserviços. Você continuaria com deploy acoplado e impossibilidade de escalar partes independentemente.\",\n          \"isCorrect\": false,\n          \"text\": \"Tudo em um serviço só, mas containerizado\"\n        }\n      ],\n      \"question\": \"Como devemos definir os limites dos serviços?\"\n    },\n    {\n      \"context\": \"Certo, então teríamos Pagamentos, Estoque e Notificações. Agora a pergunta de milhões: quando um pedido é criado, Pagamentos precisa verificar Estoque e depois disparar Notificações. Como eles conversam entre si?\",\n      \"options\": [\n        {\n          \"feedback\": \"Se Estoque estiver lento, Pagamentos trava esperando. Se Notificações cair, o pedido falha. Comunicação síncrona cria acoplamento temporal e cascata de falhas.\",\n          \"isCorrect\": false,\n          \"text\": \"REST síncrono para tudo\"\n        },\n        {\n          \"feedback\": \"Excelente! Pagamentos emite evento 'PedidoCriado', Estoque e Notificações reagem independentemente. Se Notificações cair, o pedido não falha — a mensagem fica na fila até processar.\",\n          \"isCorrect\": true,\n          \"text\": \"Eventos assíncronos via fila de mensagens\"\n        },\n        {\n          \"feedback\": \"Banco compartilhado é o maior anti-padrão em microserviços. Cria acoplamento de dados — qualquer mudança de schema afeta todos os serviços. Você continuaria com um monólito distribuído.\",\n          \"isCorrect\": false,\n          \"text\": \"Banco de dados compartilhado entre todos\"\n        },\n        {\n          \"feedback\": \"Isso só funciona se todos estiverem no mesmo processo, o que contradiz a ideia de serviços independentes. Além disso, impossibilita deploy e escalabilidade separados.\",\n          \"isCorrect\": false,\n          \"text\": \"Chamadas diretas de função entre serviços\"\n        }\n      ],\n      \"question\": \"Qual estratégia de comunicação faz mais sentido aqui?\"\n    },\n    {\n      \"context\": \"Gostei. Eventos assíncronos desacoplam bem. Mas espera — se cada serviço tem seu próprio banco, como garantimos que quando um pedido é aprovado, o estoque é debitado e o pagamento é processado... tudo ou nada? Transações distribuídas, né?\",\n      \"options\": [\n        {\n          \"feedback\": \"2PC é lento, frágil e bloqueia recursos. Se um serviço cair no meio, todos ficam esperando. Em microserviços distribuídos, 2PC é praticamente inviável em produção.\",\n          \"isCorrect\": false,\n          \"text\": \"Two-phase commit entre todos os bancos\"\n        },\n        {\n          \"feedback\": \"Correto! Sagas orquestram passos independentes. Se Pagamento falhar após Estoque debitar, uma transação compensatória reestoca. Consistência eventual é a realidade de sistemas distribuídos.\",\n          \"isCorrect\": true,\n          \"text\": \"Sagas com compensação e consistência eventual\"\n        },\n        {\n          \"feedback\": \"Isso destrói a independência dos serviços. Banco compartilhado significa acoplamento de dados e impossibilidade de evoluir schemas separadamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Voltar pro banco compartilhado por segurança\"\n        },\n        {\n          \"feedback\": \"Isso gera inconsistências graves: estoque debitado mas pagamento não processado, dinheiro cobrado mas produto não reservado. Precisamos de estratégia de compensação.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorar — se der erro, usuário tenta de novo\"\n        }\n      ],\n      \"question\": \"Como lidar com consistência entre os serviços?\"\n    },\n    {\n      \"context\": \"Sagas, entendi. Consistência eventual dá nervoso no começo, mas faz sentido. Outra coisa: se o serviço de Estoque começar a responder em 30 segundos porque o banco dele travou, o que acontece com os outros serviços que dependem dele?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso só adia o problema. Threads ficam bloqueadas esperando, conexões se esgotam e a lentidão se propaga. Em minutos, todos os serviços travam esperando Estoque.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar timeout pra 60s e esperar\"\n        },\n        {\n          \"feedback\": \"Perfeito! Timeout de 2-3s, se Estoque falhar muito, circuit abre e retorna fallback (ex: 'estoque indisponível'). Protege o sistema e permite que Estoque se recupere sem derrubar tudo.\",\n          \"isCorrect\": true,\n          \"text\": \"Circuit breaker com timeout e fallback\"\n        },\n        {\n          \"feedback\": \"Retry agressivo sob carga alta piora tudo. Você bombardeia um serviço já sobrecarregado, impedindo recuperação. Retries devem ter backoff exponencial e limite.\",\n          \"isCorrect\": false,\n          \"text\": \"Retry infinito até Estoque responder\"\n        },\n        {\n          \"feedback\": \"Desligar manualmente não escala e não resolve a causa raiz. Circuit breakers automatizam isso e permitem recuperação gradual quando o serviço volta a responder.\",\n          \"isCorrect\": false,\n          \"text\": \"Desligar Estoque até ele se recuperar sozinho\"\n        }\n      ],\n      \"question\": \"Como protegemos o sistema de falhas em cascata?\"\n    },\n    {\n      \"context\": \"Circuit breaker salvando vidas. {{NAME}}, implementamos tudo isso e fomos pra produção na sexta. Segunda de manhã: usuários reclamando que pedidos somem. Checo os logs... Pagamentos diz que enviou o pedido. Estoque diz que nunca recebeu. Como debugamos isso?\",\n      \"options\": [\n        {\n          \"feedback\": \"Com dezenas de serviços e milhares de requisições por minuto, correlacionar logs manualmente é impossível. Você nunca saberá se aquele log de Estoque corresponde àquele de Pagamentos.\",\n          \"isCorrect\": false,\n          \"text\": \"Ler logs de cada serviço manualmente\"\n        },\n        {\n          \"feedback\": \"Exato! Correlation ID propaga por todos os serviços da requisição. Com ferramentas como Jaeger ou Zipkin, você vê o caminho completo: onde travou, quanto tempo cada hop levou, onde a mensagem se perdeu.\",\n          \"isCorrect\": true,\n          \"text\": \"Tracing distribuído com correlation ID\"\n        },\n        {\n          \"feedback\": \"Prints poluem logs sem estrutura. Sem correlation ID, você não consegue rastrear uma requisição específica através de múltiplos serviços. E redeploy pra adicionar logs demora demais.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar mais prints de debug no código\"\n        },\n        {\n          \"feedback\": \"Filas podem perder mensagens por vários motivos: configuração errada de persistência, consumidor com bug que dá ACK antes de processar, mensagens expiradas. Sempre precisamos observabilidade.\",\n          \"isCorrect\": false,\n          \"text\": \"Confiar que a fila de mensagens não perde nada\"\n        }\n      ],\n      \"question\": \"O que precisamos para rastrear requisições entre serviços?\"\n    },\n    {\n      \"context\": \"Instalamos Jaeger e achamos o problema: a fila de mensagens tava perdendo eventos quando o Estoque reiniciava. Corrigimos a configuração de persistência. Agora os traces mostram latências estranhas — alguns pedidos levam 50ms, outros 5 segundos, aparentemente aleatório.\",\n      \"options\": [\n        {\n          \"feedback\": \"Médias escondem problemas. Você pode ter 90% em 50ms e 10% em 30s, resultando em média 'aceitável' mas experiência péssima pra 10% dos usuários. Use percentis (p95, p99).\",\n          \"isCorrect\": false,\n          \"text\": \"Olhar média de latência no dashboard geral\"\n        },\n        {\n          \"feedback\": \"Correto! Percentis revelam outliers. P99 de 5s significa 1% dos usuários sofre. Traces individuais dos requests lentos mostram qual serviço/operação é o gargalo específico.\",\n          \"isCorrect\": true,\n          \"text\": \"Analisar percentis p95/p99 e traces lentos\"\n        },\n        {\n          \"feedback\": \"Variação grande não é 'normal' — é sintoma de problema: garbage collection pausando JVM, queries N+1, cold starts, retries, connection pool esgotado. Sempre investigue.\",\n          \"isCorrect\": false,\n          \"text\": \"Assumir que é normal em microserviços\"\n        },\n        {\n          \"feedback\": \"Cache sem entender a causa raiz pode mascarar problemas e criar inconsistências. Primeiro descubra por que a latência varia, depois decida se cache é a solução certa.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar cache em todos os serviços\"\n        }\n      ],\n      \"question\": \"Como investigamos variação de latência em sistemas distribuídos?\"\n    },\n    {\n      \"context\": \"Encontramos! O p99 alto vinha de cold starts — containers novos de Estoque levavam 4s pra conectar no banco. Configuramos connection pooling e warm-up. Agora tá estável. {{NAME}}... acabei de ver o budget de infra. Estamos rodando 15 containers quando antes era 1 monólito. O CEO tá perguntando se valeu a pena.\",\n      \"options\": [\n        {\n          \"feedback\": \"Tecnologia por tecnologia não justifica custo. Precisamos mostrar valor de negócio concreto: deploys mais rápidos, menos downtime, escalabilidade independente, times autônomos.\",\n          \"isCorrect\": false,\n          \"text\": \"Explicar que é tecnologia moderna, então vale\"\n        },\n        {\n          \"feedback\": \"Perfeito! Antes, 10min de downtime a cada deploy. Agora, zero. Antes, escalar Notificações significava escalar tudo. Agora, só o necessário. Calcule economia de tempo e recursos.\",\n          \"isCorrect\": true,\n          \"text\": \"Mostrar ganhos: deploy sem downtime, escala independente\"\n        },\n        {\n          \"feedback\": \"Se microserviços resolveram problemas reais (escalabilidade, deploy, autonomia), voltar recria esses problemas. O custo pode ser otimizado (autoscaling, rightsizing) sem regredir.\",\n          \"isCorrect\": false,\n          \"text\": \"Voltar pro monólito pra economizar\"\n        },\n        {\n          \"feedback\": \"Isso desfaz os benefícios conquistados. Você voltaria a ter acoplamento de deploy, impossibilidade de escalar partes independentemente e times bloqueados entre si.\",\n          \"isCorrect\": false,\n          \"text\": \"Reduzir serviços de 3 pra 1 grande novamente\"\n        }\n      ],\n      \"question\": \"Como justificamos o custo adicional de microserviços?\"\n    },\n    {\n      \"context\": \"Apresentamos os números: downtime caiu 95%, tempo de deploy de feature caiu de 2 semanas pra 3 dias, e Black Friday rodou suave porque escalamos só Pagamentos. CEO aprovou budget. Mas agora o time de Marketing quer um serviço novo: Recomendações. {{NAME}}, eles querem dados de Pedidos, Estoque e Usuários.\",\n      \"options\": [\n        {\n          \"feedback\": \"Acessar banco de outro serviço quebra encapsulamento. Se Pedidos mudar schema, Recomendações quebra. Bancos são detalhes de implementação — serviços devem expor APIs.\",\n          \"isCorrect\": false,\n          \"text\": \"Queries diretas nos bancos dos outros serviços\"\n        },\n        {\n          \"feedback\": \"Excelente! Para dados em tempo real, chama APIs. Para analytics/recomendações, serviços emitem eventos de mudanças e Recomendações mantém réplica otimizada. Desacoplado e performático.\",\n          \"isCorrect\": true,\n          \"text\": \"APIs dos serviços ou réplica via eventos\"\n        },\n        {\n          \"feedback\": \"Um 'serviço agregador' vira gargalo e ponto único de falha. Se ele precisa chamar 3 serviços sincronamente pra cada request, latência triplica e resiliência despenca.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar serviço de agregação que une tudo\"\n        },\n        {\n          \"feedback\": \"Isso desfaz a arquitetura de microserviços. Banco compartilhado cria acoplamento de dados — todos os serviços dependem do mesmo schema e não podem evoluir independentemente.\",\n          \"isCorrect\": false,\n          \"text\": \"Migrar tudo pra banco compartilhado centralizado\"\n        }\n      ],\n      \"question\": \"Como o serviço de Recomendações deve acessar dados de outros serviços?\"\n    },\n    {\n      \"context\": \"Implementamos! Recomendações consome eventos e mantém sua própria visão dos dados. Tá funcionando. Três meses depois, temos 8 serviços em produção. O estagiário novo me perguntou: '{{NAME}}, por que não fizemos tudo em microserviços desde o começo?' O que você responderia?\",\n      \"options\": [\n        {\n          \"feedback\": \"Microserviços têm custo: complexidade operacional, debugging distribuído, latência de rede. Startups early-stage ou MVPs geralmente se beneficiam mais de monólitos simples até validar o produto.\",\n          \"isCorrect\": false,\n          \"text\": \"Sempre — microserviços são best practice universal\"\n        },\n        {\n          \"feedback\": \"Exato! Comece com monólito bem modularizado. Quando surgirem dores reais (deploy acoplado, escala diferenciada, times bloqueados), extraia serviços estrategicamente. Arquitetura evolui com o problema.\",\n          \"isCorrect\": true,\n          \"text\": \"Raramente — comece simples, evolua com evidência\"\n        },\n        {\n          \"feedback\": \"Monólitos têm limites. Quando times crescem, domínios se diversificam e necessidades de escala divergem, microserviços permitem autonomia e evolução independente que monólitos não conseguem.\",\n          \"isCorrect\": false,\n          \"text\": \"Nunca — monólitos são sempre superiores\"\n        },\n        {\n          \"feedback\": \"Tamanho de equipe influencia, mas não é o único fator. Necessidades de escala diferenciada, ritmos de deploy distintos e domínios bem separados também justificam microserviços, independente do tamanho do time.\",\n          \"isCorrect\": false,\n          \"text\": \"Só quando você tem equipe muito grande\"\n        }\n      ],\n      \"question\": \"Quando microserviços fazem sentido desde o início?\"\n    },\n    {\n      \"context\": \"Expliquei isso pra ele. Na verdade, {{NAME}}, lembra quando começamos essa conversa? O VP queria migrar tudo 'ontem'. Se tivéssemos aceitado cegamente sem discutir trade-offs, onde estaríamos agora?\",\n      \"options\": [\n        {\n          \"feedback\": \"Importante, mas não foi o mais crítico. Eventos vs REST é decisão tática. A decisão estratégica foi entender o problema antes de prescrever solução e aceitar conscientemente os custos.\",\n          \"isCorrect\": false,\n          \"text\": \"Escolher event-driven em vez de REST puro\"\n        },\n        {\n          \"feedback\": \"Isso mesmo! Arquitetura não é sobre escolher a 'melhor' tecnologia, mas sobre entender contexto, mapear trade-offs e evoluir com evidência. Essa mentalidade nos salvou de over-engineering e under-engineering.\",\n          \"isCorrect\": true,\n          \"text\": \"Entender o problema e aceitar trade-offs conscientemente\"\n        },\n        {\n          \"feedback\": \"Observabilidade foi crucial, mas veio depois de decisões sobre quando e como dividir serviços. Sem clareza sobre trade-offs, teríamos observabilidade perfeita de uma arquitetura errada.\",\n          \"isCorrect\": false,\n          \"text\": \"Implementar observabilidade desde o início\"\n        },\n        {\n          \"feedback\": \"Sagas foram tecnicamente corretas, mas é decisão de implementação. A decisão fundamental foi reconhecer que microserviços resolvem problemas específicos e custam complexidade — só valem quando o benefício supera o custo.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar sagas em vez de transações distribuídas\"\n        }\n      ],\n      \"question\": \"Qual foi a decisão mais importante que tomamos?\"\n    },\n    {\n      \"context\": \"Exato. E olha só a ironia, {{NAME}}: acabei de ver no Slack que o time de Analytics quer migrar o serviço deles... de microserviços de volta pra um monólito. Aparentemente eles dividiram demais e agora têm 40 serviços que ninguém entende mais. A arquitetura é cíclica!\",\n      \"options\": [\n        {\n          \"feedback\": \"Não é que microserviços falham — é que foram aplicados onde não faziam sentido. 40 serviços sem domínios claros é over-engineering. Arquitetura deve servir o problema, não seguir hype.\",\n          \"isCorrect\": false,\n          \"text\": \"Microserviços sempre falham eventualmente\"\n        },\n        {\n          \"feedback\": \"Perfeito! Não existe arquitetura universalmente 'certa'. Analytics possivelmente tinha domínio coeso que não precisava de 40 serviços. Consolidar de volta é evolução legítima, não fracasso. Pragmatismo > Purismo.\",\n          \"isCorrect\": true,\n          \"text\": \"Arquitetura deve servir o problema, não dogma\"\n        },\n        {\n          \"feedback\": \"Também seria dogma. Nosso caso de Pagamentos/Estoque/Notificações se beneficiou de separação. Analytics errou na granularidade, não na escolha de microserviços em si. Contexto importa.\",\n          \"isCorrect\": false,\n          \"text\": \"Sempre escolher monólitos pra evitar isso\"\n        },\n        {\n          \"feedback\": \"Mais serviços não é melhor — é apenas mais complexo. Eles provavelmente têm nano-serviços sem coesão. Consolidar em torno de domínios claros reduz complexidade sem perder benefícios.\",\n          \"isCorrect\": false,\n          \"text\": \"Analytics devia ter dividido ainda mais\"\n        }\n      ],\n      \"question\": \"O que o caso de Analytics nos ensina?\"\n    }\n  ]\n}",
      "outputTokens": 5912,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-cs-microservices-architecture-1",
      "userPrompt": "LESSON_TITLE: Microservicos na Pratica\nLESSON_DESCRIPTION: Projetando e implementando arquiteturas de microservicos com consciencia dos trade-offs\nCHAPTER_TITLE: Arquitetura de Software\nCOURSE_TITLE: Engenharia de Software Avancada\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Definicao de Microservicos: Microservicos sao servicos pequenos e independentes que fazem uma coisa bem. Cada um pode ser desenvolvido, implantado e escalado separadamente.\n2. Limites de Servico: Limites de servico devem seguir dominios de negocio, nao camadas tecnicas. Um servico de 'Pedidos' faz sentido; um servico de 'Banco de Dados' nao.\n3. Comunicacao: A comunicacao entre servicos pode ser sincrona (REST, gRPC) ou assincrona (filas, eventos). Assincrona e mais resiliente mas mais complexa de debugar.\n4. Dados Descentralizados: Dados descentralizados significam que cada servico tem seu banco. Consistencia eventual e a realidade — transacoes distribuidas sao dificeis e devem ser evitadas.\n5. Resiliencia: Falhas em cascata acontecem quando um servico lento trava outros. Circuit breakers, timeouts e fallbacks sao essenciais para resiliencia.\n6. Observabilidade: Observabilidade requer logs centralizados, metricas e tracing distribuido. Sem isso, debugar problemas em producao e quase impossivel."
    },
    {
      "duration": 146213.06283399998,
      "inputTokens": 4277,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, tengo un problema urgente. El equipo de producción quiere maximizar las ganancias de nuestra nueva línea de productos. Me dieron costos, demanda, todo... pero no sé ni por dónde empezar. Hay tantos números aquí.\",\n      \"options\": [\n        {\n          \"feedback\": \"Primero necesitas SABER qué estás derivando. Sin un modelo claro, derivar números al azar no te llevará a ninguna parte. Define primero la función objetivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Calcular la derivada de todo inmediatamente\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Modelar el problema correctamente es la mitad del trabajo. Necesitas expresar la ganancia en términos de variables relevantes antes de aplicar técnicas de cálculo.\",\n          \"isCorrect\": true,\n          \"text\": \"Definir la función de ganancia a optimizar\"\n        },\n        {\n          \"feedback\": \"Aún no sabes cuál es el dominio ni qué estás optimizando. Primero necesitas construir el modelo matemático — la función objetivo y sus restricciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Buscar los extremos del dominio primero\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores de Lagrange son para restricciones específicas, pero todavía no has identificado ni la función objetivo ni las restricciones. Primero modela el problema.\",\n          \"isCorrect\": false,\n          \"text\": \"Aplicar multiplicadores de Lagrange\"\n        }\n      ],\n      \"question\": \"¿Qué debemos hacer primero?\"\n    },\n    {\n      \"context\": \"Perfecto. Tengo que la ganancia es G(x) = -2x² + 120x - 500, donde x es la cantidad de unidades producidas en miles. La capacidad de la planta limita x entre 0 y 40. Ahora sí, ¿qué hacemos?\",\n      \"options\": [\n        {\n          \"feedback\": \"Los extremos del dominio son importantes, pero NO son los únicos candidatos. Primero necesitas encontrar los puntos críticos en el interior — donde la derivada es cero.\",\n          \"isCorrect\": false,\n          \"text\": \"Evaluar G(0) y G(40) solamente\"\n        },\n        {\n          \"feedback\": \"¡Correcto! Los puntos críticos (donde la derivada es cero) son candidatos a extremos. Necesitas encontrarlos antes de comparar con los bordes del intervalo.\",\n          \"isCorrect\": true,\n          \"text\": \"Encontrar donde G'(x) = 0\"\n        },\n        {\n          \"feedback\": \"La segunda derivada sirve para CLASIFICAR puntos críticos, pero primero necesitas encontrarlos. Calcula dónde G'(x) = 0 antes de usar la prueba de segunda derivada.\",\n          \"isCorrect\": false,\n          \"text\": \"Aplicar la segunda derivada primero\"\n        },\n        {\n          \"feedback\": \"¿De dónde salió x = 20? No puedes adivinar. Necesitas calcular sistemáticamente dónde la derivada es cero para encontrar los puntos críticos.\",\n          \"isCorrect\": false,\n          \"text\": \"Concluir que x = 20 es el óptimo\"\n        }\n      ],\n      \"question\": \"¿Cuál es el siguiente paso?\"\n    },\n    {\n      \"context\": \"Calculé G'(x) = -4x + 120. Igualando a cero me da x = 30. Entonces ahí está nuestro máximo, ¿no? Producir 30 mil unidades.\",\n      \"options\": [\n        {\n          \"feedback\": \"Un punto crítico es solo un CANDIDATO a extremo. Podría ser máximo, mínimo, o ninguno. También debes verificar los extremos del dominio (x=0 y x=40) antes de concluir.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, es donde la derivada es cero\"\n        },\n        {\n          \"feedback\": \"G''(x) te diría si es máximo o mínimo LOCAL, pero para el máximo GLOBAL necesitas comparar G(30) con los valores en los extremos del intervalo: G(0) y G(40).\",\n          \"isCorrect\": false,\n          \"text\": \"No, falta verificar G''(x) para confirmar\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Los extremos globales pueden estar en puntos críticos O en los bordes del dominio. Debes evaluar G(30), G(0), y G(40) para determinar el máximo absoluto.\",\n          \"isCorrect\": true,\n          \"text\": \"No, hay que comparar con G(0) y G(40)\"\n        },\n        {\n          \"feedback\": \"Solo hay un punto crítico (x=30) porque G'(x) = 0 tiene una única solución. El problema es que no has verificado los extremos del intervalo — ahí también pueden estar los óptimos.\",\n          \"isCorrect\": false,\n          \"text\": \"No, necesitamos más puntos críticos\"\n        }\n      ],\n      \"question\": \"¿Estás seguro de que x = 30 es el máximo global?\"\n    },\n    {\n      \"context\": \"Tienes razón. Calculé: G(30) = 1300, G(0) = -500, G(40) = 900. Entonces x = 30 da el máximo global con ganancia de $1,300,000. ¡Listo para reportar!\",\n      \"options\": [\n        {\n          \"feedback\": \"x=30 está dentro del dominio [0,40], así que es factible. Los cálculos están bien. La comparación muestra claramente que x=30 da el máximo global.\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar que x=30 es factible\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores de Lagrange son para restricciones de igualdad explícitas (g(x)=0). Aquí solo tienes límites de intervalo, que ya manejaste evaluando los extremos.\",\n          \"isCorrect\": false,\n          \"text\": \"Calcular los multiplicadores de Lagrange\"\n        },\n        {\n          \"feedback\": \"¡Correcto! Encontraste el punto crítico, comparaste con los extremos del dominio, e identificaste el máximo global. El análisis de optimización está completo y listo para reportar.\",\n          \"isCorrect\": true,\n          \"text\": \"Nada, el análisis está completo\"\n        },\n        {\n          \"feedback\": \"Ya comparaste G(30) con todos los otros candidatos y es claramente el mayor. G''(30) solo confirmaría que es máximo LOCAL, pero ya verificaste que es el máximo GLOBAL.\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar G''(30) para confirmar\"\n        }\n      ],\n      \"question\": \"¿Qué le falta a tu análisis antes de reportar?\"\n    },\n    {\n      \"context\": \"Perfecto, {{NAME}}. Pero espera... el jefe de producción acaba de llamar. Dice que hay una restricción nueva: el costo de materiales y mano de obra debe ser exactamente $800,000. Eso cambia todo, ¿verdad?\",\n      \"options\": [\n        {\n          \"feedback\": \"Una restricción de igualdad (costo = 800) cambia completamente el problema. Ya no puedes elegir x libremente — ahora estás optimizando SUJETO a una condición específica.\",\n          \"isCorrect\": false,\n          \"text\": \"No cambia nada, ya tenemos el óptimo\"\n        },\n        {\n          \"feedback\": \"No optimizas la restricción — usas la restricción para LIMITAR las opciones. Necesitas maximizar la ganancia G(x,y) sujeto a que el costo C(x,y) = 800.\",\n          \"isCorrect\": false,\n          \"text\": \"Buscamos puntos críticos de la restricción\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Optimización con restricciones de igualdad requiere multiplicadores de Lagrange. Necesitas que los gradientes de G y C sean paralelos en el óptimo restringido.\",\n          \"isCorrect\": true,\n          \"text\": \"Usamos multiplicadores de Lagrange\"\n        },\n        {\n          \"feedback\": \"No estás minimizando el costo — el costo es FIJO en 800. Necesitas maximizar la ganancia sujeto a esa restricción usando multiplicadores de Lagrange.\",\n          \"isCorrect\": false,\n          \"text\": \"Evaluamos G(x) donde costo sea mínimo\"\n        }\n      ],\n      \"question\": \"¿Cómo cambia esto nuestro enfoque?\"\n    },\n    {\n      \"context\": \"Ahora resulta que la ganancia depende de dos productos: G(x,y) = -x² - 2y² + 80x + 100y. Y la restricción de costo es 2x + 3y = 80. Configuré ∇G = λ∇C. Esto da -2x+80 = 2λ y -4y+100 = 3λ.\",\n      \"options\": [\n        {\n          \"feedback\": \"No puedes igualarlas directamente — tienen coeficientes diferentes de λ. Necesitas resolver para λ en cada ecuación y luego igualar, o usar la restricción 2x+3y=80 junto con el sistema.\",\n          \"isCorrect\": false,\n          \"text\": \"Igualar las dos ecuaciones directamente\"\n        },\n        {\n          \"feedback\": \"¡Correcto! Tienes tres incógnitas (x, y, λ) y tres ecuaciones (las dos de los gradientes más la restricción 2x+3y=80). Resuelves el sistema para encontrar el óptimo restringido.\",\n          \"isCorrect\": true,\n          \"text\": \"Resolver para x, y, λ con la restricción\"\n        },\n        {\n          \"feedback\": \"Si olvidas la restricción 2x+3y=80, tienes solo 2 ecuaciones para 3 incógnitas — sistema indeterminado. La restricción es esencial para encontrar la solución única.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminar λ y olvidar la restricción\"\n        },\n        {\n          \"feedback\": \"La prueba de segunda derivada es para puntos críticos libres. Con restricciones, primero resuelves el sistema de Lagrange. Ya verificarás después si es máximo o mínimo.\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar la segunda derivada de G\"\n        }\n      ],\n      \"question\": \"¿Qué haces con este sistema de ecuaciones?\"\n    },\n    {\n      \"context\": \"{{NAME}}, resolví el sistema y obtuve x = 10, y = 20, λ = 30. Verifiqué y satisface 2(10) + 3(20) = 80. Pero... ¿qué significa ese λ = 30? ¿Es importante para algo?\",\n      \"options\": [\n        {\n          \"feedback\": \"λ tiene un significado económico profundo: es la tasa de cambio de la ganancia óptima respecto al límite del presupuesto. Te dice cuánto aumentaría G si tuvieras $1 más.\",\n          \"isCorrect\": false,\n          \"text\": \"Es solo una variable auxiliar sin sentido\"\n        },\n        {\n          \"feedback\": \"¡Exacto! λ es la sensibilidad de la ganancia al presupuesto. λ=30 significa que si aumentas el presupuesto en $1, la ganancia óptima aumentaría aproximadamente $30. Es muy valioso.\",\n          \"isCorrect\": true,\n          \"text\": \"Indica cuánto aumenta G por unidad de C\"\n        },\n        {\n          \"feedback\": \"No, λ no es la ganancia. La ganancia es G(10,20). El multiplicador λ mide cuánto cambiaría la ganancia ÓPTIMA si modificaras ligeramente la restricción de presupuesto.\",\n          \"isCorrect\": false,\n          \"text\": \"Es el valor máximo de la ganancia\"\n        },\n        {\n          \"feedback\": \"El signo de λ no determina si es máximo o mínimo. λ mide la sensibilidad al presupuesto. Para clasificar el punto necesitarías analizar la segunda derivada o el contexto del problema.\",\n          \"isCorrect\": false,\n          \"text\": \"Confirma que (10,20) es un máximo\"\n        }\n      ],\n      \"question\": \"¿Qué representa el valor de λ?\"\n    },\n    {\n      \"context\": \"Fascinante. Entonces podríamos argumentar que vale la pena aumentar el presupuesto. Pero espera, {{NAME}}... acabo de revisar los datos originales. Creo que cometí un error al plantear la función de ganancia.\",\n      \"options\": [\n        {\n          \"feedback\": \"¡Nunca ignores errores en el modelo! Si la función objetivo está mal planteada, toda la optimización matemática es inútil. El resultado será óptimo de un problema equivocado.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorarlo, ya hicimos todo el trabajo\"\n        },\n        {\n          \"feedback\": \"¡Correcto! Un modelo incorrecto lleva a decisiones incorrectas, sin importar cuán perfecta sea tu matemática. Modelar el problema correctamente es la mitad del trabajo — rehaz el modelo.\",\n          \"isCorrect\": true,\n          \"text\": \"Rehacer el modelo desde el principio\"\n        },\n        {\n          \"feedback\": \"λ es resultado del sistema, no un parámetro ajustable. Si la función G está mal, debes corregirla y resolver todo de nuevo. No hay atajos para arreglar un modelo defectuoso.\",\n          \"isCorrect\": false,\n          \"text\": \"Ajustar λ para compensar el error\"\n        },\n        {\n          \"feedback\": \"Si la función de ganancia está mal desde el inicio, recalcular puntos críticos de la función incorrecta no sirve. Necesitas corregir el modelo completo antes de aplicar cualquier técnica.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo recalcular los puntos críticos\"\n        }\n      ],\n      \"question\": \"¿Qué deberías hacer ahora?\"\n    },\n    {\n      \"context\": \"Tienes razón. Revisé a fondo y resulta que la demanda tiene un componente que no había considerado. La función correcta es G(x,y) = -x² - y² + 60x + 80y - xy. Misma restricción: 2x + 3y = 80.\",\n      \"options\": [\n        {\n          \"feedback\": \"El óptimo depende de la función G. Si G cambió, el óptimo también cambia. Debes resolver el sistema de Lagrange completamente de nuevo con la función corregida.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar el mismo x=10, y=20 de antes\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Con una nueva función objetivo, recalculas los gradientes y planteas el sistema de Lagrange desde cero. Este es un problema nuevo que requiere solución completa.\",\n          \"isCorrect\": true,\n          \"text\": \"Plantear ∇G = λ∇C nuevamente\"\n        },\n        {\n          \"feedback\": \"No derivas respecto a λ — λ es el multiplicador que aparece al igualar gradientes. Necesitas calcular ∇G de la nueva función y plantear ∇G = λ∇C con la restricción.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo derivar respecto a λ\"\n        },\n        {\n          \"feedback\": \"No tiene sentido evaluar la segunda derivada en (10,20) de la función antigua. Necesitas encontrar el NUEVO óptimo resolviendo ∇G = λ∇C con la función corregida.\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar G''(10,20) con la nueva G\"\n        }\n      ],\n      \"question\": \"¿Cómo procedemos ahora con este modelo corregido?\"\n    },\n    {\n      \"context\": \"Bien, {{NAME}}. Planteé el nuevo sistema. Tengo ∇G = (-2x+60-y, -2y+80-x) y ∇C = (2, 3). Entonces -2x+60-y = 2λ, -2y+80-x = 3λ, y 2x+3y = 80. Esto se ve... complicado.\",\n      \"options\": [\n        {\n          \"feedback\": \"Este es un sistema algebraico determinado — tiene solución exacta. Usa métodos sistemáticos: despeja λ en ambas ecuaciones, iguálalas, y resuelve junto con la restricción.\",\n          \"isCorrect\": false,\n          \"text\": \"Adivinar valores hasta que funcione\"\n        },\n        {\n          \"feedback\": \"¡Perfecto! Despeja λ de cada ecuación gradiente, iguala las expresiones para eliminar λ, y usa la restricción. Es sistemático y te lleva a la solución exacta del óptimo restringido.\",\n          \"isCorrect\": true,\n          \"text\": \"Despejar λ en ambas y combinar ecuaciones\"\n        },\n        {\n          \"feedback\": \"La restricción 2x+3y=80 es ESENCIAL — define el problema. Sin ella, estás resolviendo un problema diferente. No puedes eliminar restricciones para 'simplificar'.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminar la restricción para simplificar\"\n        },\n        {\n          \"feedback\": \"Tienes dos variables (x,y) y un multiplicador (λ). Necesitas las TRES ecuaciones (dos gradientes + restricción) para determinar la solución única. Una ecuación no es suficiente.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar solo la primera ecuación gradiente\"\n        }\n      ],\n      \"question\": \"¿Cuál es el mejor enfoque para resolver este sistema?\"\n    },\n    {\n      \"context\": \"Perfecto, {{NAME}}. Resolví y obtuve x = 14, y = 17.33. Evaluando: G(14, 17.33) ≈ 1089. Ahora sí tenemos el plan óptimo de producción considerando la restricción de presupuesto.\",\n      \"options\": [\n        {\n          \"feedback\": \"¡Correcto! Siempre verifica que tu solución cumpla la restricción: 2(14)+3(17.33)=28+52=80 ✓. Esta verificación detecta errores algebraicos antes de reportar resultados erróneos.\",\n          \"isCorrect\": true,\n          \"text\": \"Que satisfaga 2x + 3y = 80\"\n        },\n        {\n          \"feedback\": \"No tiene sentido verificar si es punto crítico del problema SIN restricción — ese es un problema diferente. Verifica que satisfaga la restricción 2x+3y=80 del problema ACTUAL.\",\n          \"isCorrect\": false,\n          \"text\": \"Que x=14 es punto crítico de G sin C\"\n        },\n        {\n          \"feedback\": \"El signo de λ indica sensibilidad, pero no invalida la solución. Lo crucial es verificar que (x,y) satisfaga la restricción 2x+3y=80 — eso confirma que es factible.\",\n          \"isCorrect\": false,\n          \"text\": \"Que λ sea positivo\"\n        },\n        {\n          \"feedback\": \"Para funciones de dos variables con restricción, la prueba de segunda derivada es más compleja (matriz Hessiana orlada). Lo esencial ahora es verificar que 2x+3y=80.\",\n          \"isCorrect\": false,\n          \"text\": \"Que G''(14, 17.33) < 0\"\n        }\n      ],\n      \"question\": \"¿Qué deberíamos verificar antes de presentar esta solución?\"\n    },\n    {\n      \"context\": \"Verificado: 2(14) + 3(17.33) = 79.99 ≈ 80 ✓. Listo para el reporte. Aunque... {{NAME}}, ¿no deberíamos verificar también si hay soluciones en los bordes del dominio factible? Como cuando x=0 o y=0.\",\n      \"options\": [\n        {\n          \"feedback\": \"Lagrange encuentra puntos críticos en el INTERIOR de la restricción. Si el óptimo está en un borde (x=0 o y=0), Lagrange podría no detectarlo. Sí deberías verificar bordes.\",\n          \"isCorrect\": false,\n          \"text\": \"No, Lagrange ya encuentra el óptimo global\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Los multiplicadores de Lagrange encuentran óptimos interiores. Si x≥0 y y≥0 son restricciones, verifica los bordes: (x,0) y (0,y) satisfaciendo 2x+3y=80. Compara esos valores con G(14,17.33).\",\n          \"isCorrect\": true,\n          \"text\": \"Sí, el óptimo podría estar en un borde\"\n        },\n        {\n          \"feedback\": \"Que tu solución sea interior no garantiza que sea el óptimo GLOBAL. Podrías tener mayor ganancia en un borde. Siempre compara puntos críticos interiores con candidatos en los bordes.\",\n          \"isCorrect\": false,\n          \"text\": \"No, porque x=14 y y=17.33 son positivos\"\n        },\n        {\n          \"feedback\": \"No calculas λ en los bordes — simplemente evalúas G directamente en los puntos factibles del borde (como x=0, y=80/3) y comparas con G(14,17.33) para ver cuál es mayor.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, para calcular nuevos multiplicadores λ\"\n        }\n      ],\n      \"question\": \"¿Es necesario verificar los bordes en este problema?\"\n    },\n    {\n      \"context\": \"Buena observación. Evalué los bordes: si x=0, entonces y=80/3≈26.67 y G(0,26.67)≈746. Si y=0, entonces x=40 y G(40,0)=400. Ambos menores que G(14,17.33)=1089. Nuestro óptimo interior es definitivamente el mejor.\",\n      \"options\": [\n        {\n          \"feedback\": \"¡Perfecto! Verificaste puntos críticos, bordes, y la restricción. x=14 mil del producto 1, y≈17.33 mil del producto 2 maximiza la ganancia a $1,089,000 bajo el presupuesto de $800k.\",\n          \"isCorrect\": true,\n          \"text\": \"Producir x=14, y=17.33 con ganancia $1089k\"\n        },\n        {\n          \"feedback\": \"Ese era el óptimo del problema ANTERIOR (una variable, sin restricción de presupuesto). El problema actual es completamente diferente — dos productos con restricción de presupuesto.\",\n          \"isCorrect\": false,\n          \"text\": \"Producir x=30 del análisis original\"\n        },\n        {\n          \"feedback\": \"Ya evaluaste todos los candidatos: punto crítico interior y bordes del dominio factible. No hay más puntos que verificar — tienes el óptimo global bajo las restricciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Evaluar más puntos para estar seguros\"\n        },\n        {\n          \"feedback\": \"λ no es la ganancia — es la sensibilidad de la ganancia al presupuesto. La ganancia máxima es G(14,17.33)≈1089. Reporta las cantidades óptimas y la ganancia esperada.\",\n          \"isCorrect\": false,\n          \"text\": \"El valor λ=30 indica la ganancia máxima\"\n        }\n      ],\n      \"question\": \"Ahora sí, ¿qué reportamos al equipo de producción?\"\n    },\n    {\n      \"context\": \"Excelente, {{NAME}}. Pero... espera. El jefe de producción acaba de responder. Dice: '¿17.33 mil unidades? No podemos producir fracciones. ¿Qué hacemos, redondeamos a 17?' Ay no, no había pensado en eso.\",\n      \"options\": [\n        {\n          \"feedback\": \"Redondear puede violar la restricción de presupuesto. Si y=17, entonces 2x+3(17)=80 da 2x=29, x=14.5 (no entero tampoco). Optimización entera es un problema DIFERENTE — más complejo.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, simplemente redondear a 17\"\n        },\n        {\n          \"feedback\": \"¡Correcto! Prueba combinaciones enteras que satisfagan 2x+3y≤80 cercanas a (14,17.33): como (13,18), (14,17), (16,16), etc. Evalúa G en cada una y elige la mejor factible.\",\n          \"isCorrect\": true,\n          \"text\": \"Evaluar combinaciones enteras cercanas\"\n        },\n        {\n          \"feedback\": \"Lagrange es para funciones continuas. Restricciones de enteros requieren optimización entera (programación entera mixta) — mucho más compleja. Para casos pequeños, evalúa candidatos enteros directamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar Lagrange con restricción de enteros\"\n        },\n        {\n          \"feedback\": \"No hay 'recálculo' con métodos de cálculo — las derivadas son continuas. Para restricciones de enteros, prueba combinaciones enteras factibles cercanas al óptimo continuo y evalúa directamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Recalcular todo desde cero con enteros\"\n        }\n      ],\n      \"question\": \"¿Cómo respondemos a esta restricción de números enteros?\"\n    },\n    {\n      \"context\": \"Probé varias combinaciones enteras factibles. (14,17) da G=1086, (13,18) da G=1083, (15,16) da G=1074. La mejor es (14,17) con ganancia $1,086,000. Solo $3k menos que el óptimo continuo. Viable y realista.\",\n      \"options\": [\n        {\n          \"feedback\": \"Las derivadas son herramientas poderosas, pero el mundo real tiene restricciones prácticas (enteros, bordes, factibilidad). El análisis matemático debe INTEGRARSE con el contexto del problema.\",\n          \"isCorrect\": false,\n          \"text\": \"Las derivadas siempre dan la respuesta final\"\n        },\n        {\n          \"feedback\": \"¡Exacto! Viste que un modelo incorrecto arruina todo. Y restricciones realistas (enteros, presupuesto, bordes) son parte del modelo. Técnica matemática + modelo correcto = decisiones óptimas.\",\n          \"isCorrect\": true,\n          \"text\": \"Modelar bien es tan importante como resolver\"\n        },\n        {\n          \"feedback\": \"Lagrange fue esencial para encontrar el óptimo continuo (14, 17.33), que guió la búsqueda de la mejor solución entera. Sin ese punto de referencia, buscarías a ciegas entre infinitas combinaciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Lagrange es innecesario en la práctica\"\n        },\n        {\n          \"feedback\": \"Viste que también evaluaste bordes del dominio y restricciones prácticas (enteros). La optimización real considera puntos críticos, bordes, y factibilidad — no solo derivadas en el interior.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo importan los puntos críticos interiores\"\n        }\n      ],\n      \"question\": \"¿Qué aprendizaje clave sacarías de todo este proceso?\"\n    },\n    {\n      \"context\": \"Totalmente de acuerdo, {{NAME}}. Ya envié el reporte: producir 14 mil unidades del producto 1 y 17 mil del producto 2, ganancia proyectada de $1,086,000. El equipo está feliz. Y yo aprendí que las matemáticas sin contexto son solo... matemáticas.\",\n      \"options\": [\n        {\n          \"feedback\": \"Las fórmulas son herramientas, pero sin entender QUÉ optimizas, POR QUÉ, y QUÉ restricciones importan, las fórmulas no sirven. Lo crítico fue integrar técnica matemática con razonamiento del problema.\",\n          \"isCorrect\": false,\n          \"text\": \"Dominar las fórmulas de Lagrange\"\n        },\n        {\n          \"feedback\": \"¡Perfecto! Optimización efectiva combina modelado correcto, técnicas de cálculo, verificación de bordes, y restricciones prácticas. Matemáticas SIN contexto son estériles; contexto SIN matemáticas es impreciso.\",\n          \"isCorrect\": true,\n          \"text\": \"Integrar técnica matemática y contexto real\"\n        },\n        {\n          \"feedback\": \"λ es valioso para análisis de sensibilidad, pero no fue lo MÁS crítico. Lo esencial fue modelar correctamente, encontrar el óptimo, verificar bordes, y adaptar a restricciones reales (enteros).\",\n          \"isCorrect\": false,\n          \"text\": \"Calcular λ para interpretar sensibilidad\"\n        },\n        {\n          \"feedback\": \"La segunda derivada ayuda a clasificar puntos críticos, pero aquí lo crítico fue comparar candidatos (interiores y bordes), respetar restricciones, y adaptar la solución al mundo real (enteros).\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar G''(x) en todos los puntos\"\n        }\n      ],\n      \"question\": \"Última reflexión: ¿qué fue lo más crítico en este problema?\"\n    }\n  ]\n}",
      "outputTokens": 7918,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-math-calculus-optimization-1",
      "userPrompt": "LESSON_TITLE: Optimizacion con Calculo\nLESSON_DESCRIPTION: Aplicando tecnicas de calculo para encontrar optimos en problemas de ingenieria y negocios\nCHAPTER_TITLE: Aplicaciones del Calculo\nCOURSE_TITLE: Calculo para Ingenieria\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Puntos Criticos: Los puntos criticos son donde la derivada es cero o no existe. Son CANDIDATOS a extremos — no todos los puntos criticos son maximos o minimos.\n2. Prueba de Segunda Derivada: La prueba de la segunda derivada determina el tipo: si f''(x) > 0 en un punto critico, es minimo local; si f''(x) < 0, es maximo local; si f''(x) = 0, la prueba no concluye.\n3. Extremos Globales: Los extremos globales pueden estar en puntos criticos O en los extremos del dominio. Siempre evalua tambien los bordes del intervalo.\n4. Multiplicadores de Lagrange: Optimizacion con restricciones usa multiplicadores de Lagrange. Maximizar f(x,y) sujeto a g(x,y)=0 requiere que los gradientes sean paralelos.\n5. Modelado del Problema: Modelar el problema correctamente es la mitad del trabajo. Define la funcion objetivo, identifica las restricciones, y expresa todo en terminos de las variables relevantes."
    }
  ],
  "taskId": "activity-story"
}
