{
  "generatedAt": "2026-01-17T15:48:31.556Z",
  "modelId": "openai/gpt-5.2",
  "outputs": [
    {
      "duration": 45983.089958000055,
      "inputTokens": 3143,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"\\\"{{NAME}}, production just threw a 'Cannot read properties of undefined (reading \\\\\\\"length\\\\\\\")' in the checkout flow. The stack points to `formatPromoCode(code)`. The payload is coming from a third-party promo service and our code assumes `code` is a string.\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"This is the fastest band-aid, but it pushes the bug to runtime and hides bad data. Type safety means modeling the possibility of missing/invalid fields so you’re forced to handle it.\",\n          \"isCorrect\": false,\n          \"text\": \"Add `code?.length` and move on\"\n        },\n        {\n          \"feedback\": \"Correct. Model the input as possibly missing (e.g., `string | undefined`) and let the compiler force handling before calling `.length`. Then decide: default, reject, or log.\",\n          \"isCorrect\": true,\n          \"text\": \"Type input as `string | undefined`\"\n        },\n        {\n          \"feedback\": \"This silences the compiler and guarantees nothing. If the value is actually undefined, you’re right back to runtime errors—exactly what we’re trying to prevent.\",\n          \"isCorrect\": false,\n          \"text\": \"Cast it: `code as string`\"\n        },\n        {\n          \"feedback\": \"Non-null assertions bypass checks. It may compile, but you’re telling TypeScript “trust me” when the whole problem is you can’t trust the payload.\",\n          \"isCorrect\": false,\n          \"text\": \"Use `code!.length`\"\n        }\n      ],\n      \"question\": \"How do we stop this bug using types?\"\n    },\n    {\n      \"context\": \"\\\"Okay, I changed `formatPromoCode(code: string | undefined)`. Now the compiler is yelling where we call it: `formatPromoCode(promo.code)`. What should we do at the call site?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Narrow the type before calling: check `typeof promo.code === 'string'` (and maybe non-empty). That turns a runtime uncertainty into a compile-time-enforced branch.\",\n          \"isCorrect\": true,\n          \"text\": \"Guard: `if (typeof code==='string')`\"\n        },\n        {\n          \"feedback\": \"Defaulting can be okay, but doing it blindly changes behavior (empty promo accepted?) and can mask upstream issues. Better to explicitly branch and decide policy.\",\n          \"isCorrect\": false,\n          \"text\": \"Default to empty string: `code ?? ''`\"\n        },\n        {\n          \"feedback\": \"Converting everything to string turns `undefined` into 'undefined' or '' depending on coercion, which can create invalid promo codes and hard-to-trace logic bugs.\",\n          \"isCorrect\": false,\n          \"text\": \"Coerce: `String(code)`\"\n        },\n        {\n          \"feedback\": \"`any` removes the safety net and invites the same class of bugs elsewhere. The compiler warning is valuable here; don’t throw it away.\",\n          \"isCorrect\": false,\n          \"text\": \"Make `promo` type `any` here\"\n        }\n      ],\n      \"question\": \"What’s the best fix at the call site?\"\n    },\n    {\n      \"context\": \"\\\"Nice, now we’re branching. But I also see `promo` itself can be null when the promo service times out. The call site now has `promo?.code`, and TypeScript still complains. What narrowing do you want?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. First narrow `promo` away from null/undefined, then narrow `promo.code` to string. Two-step narrowing keeps the compiler honest and the logic clear.\",\n          \"isCorrect\": true,\n          \"text\": \"Check `if (!promo) return` then code guard\"\n        },\n        {\n          \"feedback\": \"Optional chaining avoids a crash, but it still leaves you with `string | undefined` and doesn’t define behavior. You need an explicit branch for the failure case.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep `promo?.code` and ignore warning\"\n        },\n        {\n          \"feedback\": \"Non-null assertions are risky here because timeouts are real. You’ll compile, then crash when `promo` is null.\",\n          \"isCorrect\": false,\n          \"text\": \"Use `promo!.code`\"\n        },\n        {\n          \"feedback\": \"Casting to `any` again removes checks. You’ll “fix” errors by hiding them and ship the same runtime failure modes.\",\n          \"isCorrect\": false,\n          \"text\": \"Cast `promo as any` and proceed\"\n        }\n      ],\n      \"question\": \"How do we narrow this safely?\"\n    },\n    {\n      \"context\": \"\\\"While we’re here… the promo service returns different shapes depending on promo type. Sometimes it’s `{ code: string }`, sometimes `{ codes: string[] }`. Our current type is a messy union and the code is getting gross.\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Use a discriminated union (e.g., `kind: 'single' | 'multi'`) or a reliable property check, then narrow based on it. This keeps each branch type-safe and readable.\",\n          \"isCorrect\": true,\n          \"text\": \"Use a union + narrowing by property check\"\n        },\n        {\n          \"feedback\": \"Index signatures make everything look present but untyped. You’ll lose guarantees about `code` vs `codes` and reintroduce runtime surprises.\",\n          \"isCorrect\": false,\n          \"text\": \"Use `{[k:string]: any}` to simplify\"\n        },\n        {\n          \"feedback\": \"`any` is the nuclear option; it erases the whole point of TypeScript. The complexity is telling you to model the data better, not to give up.\",\n          \"isCorrect\": false,\n          \"text\": \"Make the response `any`\"\n        },\n        {\n          \"feedback\": \"Keeping both optional makes you handle tons of `undefined` everywhere and doesn’t ensure the service actually sent a coherent shape.\",\n          \"isCorrect\": false,\n          \"text\": \"Make both optional: `{code?: string; codes?: string[]}`\"\n        }\n      ],\n      \"question\": \"How should we model the two response shapes?\"\n    },\n    {\n      \"context\": \"\\\"We don’t control the vendor types, and they didn’t give us a `kind` field. We only get raw JSON. I’m thinking we write a helper that checks shape and then narrows. What’s the most TypeScript-friendly approach?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Write a type guard like `function hasCodes(x: unknown): x is { codes: string[] }` and validate arrays properly. Then TS narrows inside the branch safely.\",\n          \"isCorrect\": true,\n          \"text\": \"Write a type guard with a type predicate\"\n        },\n        {\n          \"feedback\": \"`instanceof` won’t work for plain JSON objects (and arrays/objects from JSON don’t have custom classes). It’ll be brittle and often wrong.\",\n          \"isCorrect\": false,\n          \"text\": \"Use `instanceof` checks\"\n        },\n        {\n          \"feedback\": \"Checking a single property without validating its type can narrow incorrectly. You want to confirm `Array.isArray(x.codes)` and element types to avoid false positives.\",\n          \"isCorrect\": false,\n          \"text\": \"Just check `'codes' in obj`\"\n        },\n        {\n          \"feedback\": \"Casting makes the compiler quiet but doesn’t ensure the JSON matches. If the vendor changes shape, you’ll fail at runtime again.\",\n          \"isCorrect\": false,\n          \"text\": \"Assert type: `resp as PromoMulti`\"\n        }\n      ],\n      \"question\": \"How do we safely narrow vendor JSON shapes?\"\n    },\n    {\n      \"context\": \"\\\"Cool. Another issue: we have a generic helper `pickFirst(items)` used for `codes`. It currently returns `any`, and downstream we’re doing string ops that might not be valid. How do we fix `pickFirst`?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Make it generic: `function pickFirst<T>(items: T[]): T | undefined`. You preserve element type and force handling of empty arrays.\",\n          \"isCorrect\": true,\n          \"text\": \"Use generics: `pickFirst<T>(T[]): T|undefined`\"\n        },\n        {\n          \"feedback\": \"Returning `unknown` is safer than `any`, but without generics you lose the relationship between input and output, making callers do extra narrowing unnecessarily.\",\n          \"isCorrect\": false,\n          \"text\": \"Return `unknown` from `pickFirst`\"\n        },\n        {\n          \"feedback\": \"This is lying to the compiler. If the array is empty, you’ll return undefined at runtime but claim it’s a `string`, causing the same crash class.\",\n          \"isCorrect\": false,\n          \"text\": \"Force `string`: `pickFirst(items): string`\"\n        },\n        {\n          \"feedback\": \"Overloads can work, but generics are simpler here and scale across types. Overloads without a generic still tends to leak `any`/duplication.\",\n          \"isCorrect\": false,\n          \"text\": \"Use many function overloads only\"\n        }\n      ],\n      \"question\": \"What signature should `pickFirst` have?\"\n    },\n    {\n      \"context\": \"\\\"Now, parsing. The vendor payload comes in as `unknown` from `fetch().json()`. Someone suggested making it `any` so we stop fighting TypeScript. I’m not thrilled. What’s our move?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Keep it `unknown`, validate/guard it, then narrow into your internal types. This is the sweet spot: safe boundaries with strong types inside your app.\",\n          \"isCorrect\": true,\n          \"text\": \"Keep `unknown` and validate with guards\"\n        },\n        {\n          \"feedback\": \"`any` turns off checking right where data is most untrusted. You’ll ship runtime errors when the vendor sends unexpected shapes.\",\n          \"isCorrect\": false,\n          \"text\": \"Switch to `any` for speed\"\n        },\n        {\n          \"feedback\": \"Casting to your desired type is wishful thinking. It compiles but doesn’t validate reality—vendor changes will break prod again.\",\n          \"isCorrect\": false,\n          \"text\": \"Cast `unknown as PromoResponse`\"\n        },\n        {\n          \"feedback\": \"`never` is for impossible states, not unknown external input. You’d just make everything unusable without actually adding safety.\",\n          \"isCorrect\": false,\n          \"text\": \"Type it as `never` to be strict\"\n        }\n      ],\n      \"question\": \"How should we type external JSON at the boundary?\"\n    },\n    {\n      \"context\": \"\\\"Heads-up, {{NAME}}: support says users with 'multi-code promos' are getting rejected. Our logs show the payload has `codes: [12345, 67890]`—numbers. Vendor swears it’s 'valid'. That breaks our guard expecting `string[]`.\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Update the guard to accept `string | number` elements and normalize to `string[]` internally. Type safety isn’t about rejecting reality; it’s about modeling it and making conversions explicit.\",\n          \"isCorrect\": true,\n          \"text\": \"Widen guard + normalize to strings\"\n        },\n        {\n          \"feedback\": \"Casting hides the mismatch. You’ll later call string methods on numbers and get subtle bugs (or implicit coercion). Normalize explicitly instead of pretending.\",\n          \"isCorrect\": false,\n          \"text\": \"Just cast numbers to `string[]`\"\n        },\n        {\n          \"feedback\": \"Accepting `any[]` loses guarantees everywhere and invites bad downstream assumptions. Keep types precise and do conversion at the boundary.\",\n          \"isCorrect\": false,\n          \"text\": \"Change to `codes: any[]`\"\n        },\n        {\n          \"feedback\": \"Ignoring it means users stay broken. Also you’ll keep getting runtime surprises. The whole point is to handle unexpected-but-real data safely.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore; vendor is wrong, not us\"\n        }\n      ],\n      \"question\": \"How do we handle numeric codes safely?\"\n    },\n    {\n      \"context\": \"\\\"Okay, after normalization, checkout is stable. One last thing: our internal promo types are now clean, and the compiler forced us to handle nulls and empty arrays. What should we do to prevent regressions next time the vendor payload shifts?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Lock the boundary: keep `unknown` at ingress, validate with type guards, normalize into strict internal types, and add tests around the guards. That’s type safety in practice: strong contracts at edges.\",\n          \"isCorrect\": true,\n          \"text\": \"Add guard tests + strict internal types\"\n        },\n        {\n          \"feedback\": \"Banning `unknown` pushes you toward `any` or casts. `unknown` is the correct boundary type; the discipline is validating and narrowing it.\",\n          \"isCorrect\": false,\n          \"text\": \"Ban `unknown` so everyone uses typed models\"\n        },\n        {\n          \"feedback\": \"Strict null checks help, but without boundary validation you’ll still get wrong shapes. Types don’t magically validate JSON; guards do.\",\n          \"isCorrect\": false,\n          \"text\": \"Rely on `strictNullChecks` only\"\n        },\n        {\n          \"feedback\": \"Optional everything reduces errors but also removes guarantees and spreads `undefined` handling everywhere. Better to validate once and keep internals tight.\",\n          \"isCorrect\": false,\n          \"text\": \"Make fields optional to avoid failures\"\n        }\n      ],\n      \"question\": \"What’s the best long-term safeguard?\"\n    }\n  ]\n}",
      "outputTokens": 2438,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-cs-typescript-type-safety-1",
      "userPrompt": "LESSON_TITLE: Type Safety in Practice\nLESSON_DESCRIPTION: Applying TypeScript's type system to catch bugs early and write more maintainable code\nCHAPTER_TITLE: Type Systems\nCOURSE_TITLE: Advanced TypeScript\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Compile-Time Safety: Type safety catches errors at compile time instead of runtime. When TypeScript knows a variable's type, it can prevent operations that would fail — like calling .length on undefined.\n2. Structural Typing: TypeScript uses structural typing — it cares about shape, not names. Two types are compatible if they have the same structure, even if defined separately.\n3. Type Narrowing: Type narrowing lets TypeScript understand more specific types after checks. Inside an if-block that checks for null, TypeScript knows the value isn't null.\n4. Generics: Generic types let you write reusable code that works with multiple types while preserving type information. Array<T> knows what's inside, unlike just 'Array'.\n5. Any vs Unknown: The 'any' type disables type checking entirely. It's an escape hatch but defeats the purpose of TypeScript. Use 'unknown' when the type truly isn't known.\n6. Type Guards: Type guards are functions that narrow types. They return a type predicate that tells TypeScript what the type is after the check passes."
    },
    {
      "duration": 40350.698040999996,
      "inputTokens": 3109,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, emergency. Our competitor just dropped their price 15% this morning, and Sales is begging us to match by noon. If we match, margin tanks. If we don’t, we might lose the whole quarter. Before we panic—how do we frame this strategically?\",\n      \"options\": [\n        {\n          \"feedback\": \"Too impulsive. In strategic interdependence, your best move depends on their likely response and your next moves too, not just today’s revenue.\",\n          \"isCorrect\": false,\n          \"text\": \"Match price immediately\"\n        },\n        {\n          \"feedback\": \"Yes. Treat it like a strategic interaction: list players, actions, payoffs, and likely responses before choosing.\",\n          \"isCorrect\": true,\n          \"text\": \"Model it as a game with payoffs\"\n        },\n        {\n          \"feedback\": \"Market share matters, but ignoring the rival’s incentives misses the point of game theory.\",\n          \"isCorrect\": false,\n          \"text\": \"Focus only on market share targets\"\n        },\n        {\n          \"feedback\": \"Delaying can be a tactic, but first you need the structure of the interaction to know if delay helps or hurts.\",\n          \"isCorrect\": false,\n          \"text\": \"Do nothing until next week\"\n        }\n      ],\n      \"question\": \"What’s our first move?\"\n    },\n    {\n      \"context\": \"Okay, so players: us and RivalCo. Actions: Keep price, Match cut, or maybe a smaller cut + bundle. Payoffs: profit and share. But we need a clean first pass—what’s the simplest matrix we should build right now?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Start with a 2x2: Cut vs Hold for each firm. It captures interdependence and makes equilibrium reasoning possible.\",\n          \"isCorrect\": true,\n          \"text\": \"2x2: Cut or Hold for both\"\n        },\n        {\n          \"feedback\": \"A single-player forecast ignores RivalCo’s best responses, which is exactly what game theory adds.\",\n          \"isCorrect\": false,\n          \"text\": \"Single-firm demand forecast only\"\n        },\n        {\n          \"feedback\": \"Too detailed too soon. You can extend later, but start simple to find incentives and stability.\",\n          \"isCorrect\": false,\n          \"text\": \"Full decision tree with 20 moves\"\n        },\n        {\n          \"feedback\": \"Contracts might matter later, but first you need the basic strategic structure of the price interaction.\",\n          \"isCorrect\": false,\n          \"text\": \"Assume we can collude legally\"\n        }\n      ],\n      \"question\": \"What game representation should we start with?\"\n    },\n    {\n      \"context\": \"I sketched payoffs. If both hold: we each keep high profit. If we cut while they hold: we steal share and do great. If they cut while we hold: we get crushed. If both cut: ugly low profit for both. This feels familiar. What does it look like to you?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Temptation to cut dominates, but mutual cutting makes both worse off than mutual holding.\",\n          \"isCorrect\": true,\n          \"text\": \"Prisoner’s dilemma\"\n        },\n        {\n          \"feedback\": \"Not really. This isn’t about matching pennies; it’s about a mutual race to lower payoffs.\",\n          \"isCorrect\": false,\n          \"text\": \"Matching pennies\"\n        },\n        {\n          \"feedback\": \"Coordination games have multiple good equilibria; here the incentive to undercut drives the outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"Pure coordination game\"\n        },\n        {\n          \"feedback\": \"Chicken is about swerving vs crashing with asymmetric worst outcomes; price wars usually map better to PD.\",\n          \"isCorrect\": false,\n          \"text\": \"Game of chicken\"\n        }\n      ],\n      \"question\": \"What classic game is this closest to?\"\n    },\n    {\n      \"context\": \"Right, prisoner’s dilemma vibes. Sales says, 'If cutting is the dominant move, just cut.' But I want to be precise. In this payoff story, what’s the dominant strategy in a one-shot version?\",\n      \"options\": [\n        {\n          \"feedback\": \"In PD, cutting beats holding whether they cut or hold, so it’s dominant—even though it’s bad collectively.\",\n          \"isCorrect\": true,\n          \"text\": \"Cut price\"\n        },\n        {\n          \"feedback\": \"Holding is better only if they also hold; it’s not best regardless of their action.\",\n          \"isCorrect\": false,\n          \"text\": \"Hold price\"\n        },\n        {\n          \"feedback\": \"A mixed strategy isn’t needed if a dominant strategy exists in the payoff ordering.\",\n          \"isCorrect\": false,\n          \"text\": \"Randomize: cut sometimes\"\n        },\n        {\n          \"feedback\": \"“Wait and see” isn’t one of the modeled actions; and it doesn’t resolve the dominance logic anyway.\",\n          \"isCorrect\": false,\n          \"text\": \"Delay decision\"\n        }\n      ],\n      \"question\": \"What’s the dominant strategy in the one-shot game?\"\n    },\n    {\n      \"context\": \"So if it’s one-shot, we both cut, and everyone’s miserable. But… we sell in this category every week. RivalCo isn’t disappearing tomorrow. How does repeated interaction change what we should consider?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. In repeated games, future retaliation/reward can sustain cooperation, changing incentives away from always defecting.\",\n          \"isCorrect\": true,\n          \"text\": \"Future consequences can support cooperation\"\n        },\n        {\n          \"feedback\": \"Not necessarily. Dominance in a one-shot doesn’t guarantee the same outcome when future payoffs matter.\",\n          \"isCorrect\": false,\n          \"text\": \"Nothing changes; dominant always wins\"\n        },\n        {\n          \"feedback\": \"Repeated games don’t automatically create collusion; you still need credible incentives and monitoring.\",\n          \"isCorrect\": false,\n          \"text\": \"We can collude without any risk\"\n        },\n        {\n          \"feedback\": \"Repeated interaction can soften price wars, but it doesn’t guarantee a monopoly outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"Prices always jump to monopoly level\"\n        }\n      ],\n      \"question\": \"What changes in a repeated version?\"\n    },\n    {\n      \"context\": \"Exactly. If we want to avoid a race to the bottom, we need a strategy that makes undercutting unattractive over time. What kind of approach fits repeated-game logic without being… cartoon-villain collusion?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. A contingent strategy (reward cooperation, punish defection) can stabilize higher prices if it’s credible and observable.\",\n          \"isCorrect\": true,\n          \"text\": \"Contingent punishments for price cuts\"\n        },\n        {\n          \"feedback\": \"Pre-committing to always cut invites a permanent war and gives up the leverage of future punishment.\",\n          \"isCorrect\": false,\n          \"text\": \"Commit to always cutting\"\n        },\n        {\n          \"feedback\": \"Empty threats don’t work. If you won’t actually punish, RivalCo will ignore it.\",\n          \"isCorrect\": false,\n          \"text\": \"Threaten vaguely, no follow-through\"\n        },\n        {\n          \"feedback\": \"Apologizing doesn’t change incentives. Game theory needs payoff-changing consequences, not vibes.\",\n          \"isCorrect\": false,\n          \"text\": \"Send a friendly note asking to stop\"\n        }\n      ],\n      \"question\": \"What repeated-game strategy idea should guide us?\"\n    },\n    {\n      \"context\": \"Cool, but we can’t literally say, 'We’ll punish you.' Legal will have a meltdown. We need a market-safe move that still changes incentives. Which action best signals 'we won’t start a war, but we can respond'?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Hold list price but add targeted, time-limited offers (bundles/loyalty) to defend share while avoiding an industry-wide price collapse.\",\n          \"isCorrect\": true,\n          \"text\": \"Targeted promos while holding list price\"\n        },\n        {\n          \"feedback\": \"Matching publicly resets the market price lower and makes mutual cutting the new normal.\",\n          \"isCorrect\": false,\n          \"text\": \"Publicly match across the board\"\n        },\n        {\n          \"feedback\": \"Going lower escalates. It’s a harsher defection that invites retaliation and locks in low payoffs.\",\n          \"isCorrect\": false,\n          \"text\": \"Undercut them by an extra 5%\"\n        },\n        {\n          \"feedback\": \"Ignoring entirely can look like weakness; if share falls, you may lose the ability to sustain any cooperative outcome later.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore it and hope they stop\"\n        }\n      ],\n      \"question\": \"What move best avoids a price-war equilibrium?\"\n    },\n    {\n      \"context\": \"Nice. If we do targeted promos, we still need to think through stability: what outcome do we expect if both firms act 'rationally' given the strategy? What’s our checkpoint concept for a stable outcome?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. We’re looking for a stable set of strategies where neither side wants to deviate given the other’s strategy.\",\n          \"isCorrect\": true,\n          \"text\": \"Nash equilibrium\"\n        },\n        {\n          \"feedback\": \"Market clearing is about supply-demand overall, not strategic best responses between rivals.\",\n          \"isCorrect\": false,\n          \"text\": \"Market-clearing price\"\n        },\n        {\n          \"feedback\": \"Pareto efficiency is about overall welfare; games can be stuck in inefficient equilibria.\",\n          \"isCorrect\": false,\n          \"text\": \"Pareto optimum\"\n        },\n        {\n          \"feedback\": \"A dominant strategy may not exist in repeated/contingent settings; stability is the key test.\",\n          \"isCorrect\": false,\n          \"text\": \"Dominant strategy\"\n        }\n      ],\n      \"question\": \"What concept checks whether the outcome is stable?\"\n    },\n    {\n      \"context\": \"Okay, plot twist. Ops just told me RivalCo’s cut isn’t a 'strategy'—they accidentally triggered a coupon stack bug, and it’ll auto-expire in 48 hours. If that’s true, our earlier game changes. What should we do with this new info?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Update the game: their action may be temporary/involuntary, so matching could be needless defection. Recompute best responses with the 48-hour horizon.\",\n          \"isCorrect\": true,\n          \"text\": \"Re-model payoffs with a 48-hour shock\"\n        },\n        {\n          \"feedback\": \"Overreacting locks in low prices even after their bug expires; you’d be choosing a worse equilibrium for no reason.\",\n          \"isCorrect\": false,\n          \"text\": \"Still match immediately; price is price\"\n        },\n        {\n          \"feedback\": \"Assuming they’re lying without evidence can push you into escalation; treat it as a belief to test, not a fact to dismiss.\",\n          \"isCorrect\": false,\n          \"text\": \"Assume they’re lying; start a war\"\n        },\n        {\n          \"feedback\": \"Doing nothing might be fine, but only after you assess whether short-run loss threatens long-run position; you still need the updated game logic.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore the info; wait it out blindly\"\n        }\n      ],\n      \"question\": \"How do we adjust given the coupon-bug twist?\"\n    },\n    {\n      \"context\": \"If the cut is temporary, the 'repeat game' move is to avoid locking the market into low prices. We can defend key accounts for 48 hours, then revert. So what do we tell Sales as the decision—clean and defensible?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. It preserves long-run pricing while protecting short-run share, and it’s consistent with repeated-game thinking: avoid mutual defection becoming the norm.\",\n          \"isCorrect\": true,\n          \"text\": \"Targeted 48-hour promos, no list cut\"\n        },\n        {\n          \"feedback\": \"Matching creates a new reference price and can trigger retaliation cycles even after the bug ends.\",\n          \"isCorrect\": false,\n          \"text\": \"Match across the board for 48 hours\"\n        },\n        {\n          \"feedback\": \"Undercutting is escalation; it invites a tit-for-tat spiral and makes recovery harder.\",\n          \"isCorrect\": false,\n          \"text\": \"Undercut them until they stop\"\n        },\n        {\n          \"feedback\": \"If you lose key accounts now, you may weaken future credibility; pure inaction can be costly.\",\n          \"isCorrect\": false,\n          \"text\": \"Do nothing at all\"\n        }\n      ],\n      \"question\": \"What’s our final call to Sales?\"\n    }\n  ]\n}",
      "outputTokens": 2255,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-economics-game-theory-strategy-1",
      "userPrompt": "LESSON_TITLE: Strategic Thinking with Game Theory\nLESSON_DESCRIPTION: Using game theory to analyze competitive situations and make better strategic decisions\nCHAPTER_TITLE: Strategic Decision Making\nCOURSE_TITLE: Microeconomics\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Strategic Interdependence: Game theory studies strategic interactions where your outcome depends on others' choices too. It's not about games — it's about any situation where what you should do depends on what others do.\n2. Nash Equilibrium: A Nash equilibrium is a stable state where no player can improve by changing only their own strategy. Everyone is doing their best given what everyone else is doing.\n3. Dominant Strategies: A dominant strategy is best regardless of what others do. If you have one, use it. But most real situations don't have dominant strategies — you must anticipate others.\n4. The Prisoner's Dilemma: The prisoner's dilemma shows how individual rationality can lead to collective irrationality. Both players choosing their dominant strategy leaves both worse off.\n5. Repeated Interactions: Repeated games change the calculus. When you'll interact again, cooperation becomes rational because future punishment makes defection costly."
    },
    {
      "duration": 35337.69991699996,
      "inputTokens": 3137,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, the PI wants a plan in 30 minutes. Our patient-derived liver cells have a dominant mutation. We need to disrupt the mutant allele, but keep the wild-type working. CRISPR seems doable, but only if we’re smart about targeting. What’s our first move?\",\n      \"options\": [\n        {\n          \"feedback\": \"That’s backwards. You need to start from the exact mutation/allele context and choose a target that spares wild-type, not start with delivery.\",\n          \"isCorrect\": false,\n          \"text\": \"Pick delivery first, then pick gRNA\"\n        },\n        {\n          \"feedback\": \"Correct. Confirm the allele sequence context, then design guides that exploit the mutation/PAM differences so Cas9 preferentially cuts the mutant allele.\",\n          \"isCorrect\": true,\n          \"text\": \"Sequence locus; design allele-specific gRNA\"\n        },\n        {\n          \"feedback\": \"Not ideal. NHEJ is useful, but you still need an allele-specific cut site; otherwise you’ll knock out both alleles.\",\n          \"isCorrect\": false,\n          \"text\": \"Use NHEJ knockout; hope it spares WT\"\n        },\n        {\n          \"feedback\": \"Too risky. A generic guide will likely cut both alleles and create loss-of-function in the healthy copy.\",\n          \"isCorrect\": false,\n          \"text\": \"Use a high-activity generic gRNA\"\n        }\n      ],\n      \"question\": \"What should we do first?\"\n    },\n    {\n      \"context\": \"Okay, sequencing’s back. The mutant allele creates a new PAM right next to the mutation. Wild-type doesn’t have that PAM. That’s… weirdly convenient. How should we exploit that for specificity?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. A PAM unique to the mutant allele is a clean way to make cutting allele-specific, minimizing risk to the wild-type allele.\",\n          \"isCorrect\": true,\n          \"text\": \"Target the mutant-only PAM site\"\n        },\n        {\n          \"feedback\": \"Mismatch tolerance can still allow cutting. Relying only on “one mismatch” without PAM discrimination can be unsafe.\",\n          \"isCorrect\": false,\n          \"text\": \"Target both; rely on mismatch tolerance\"\n        },\n        {\n          \"feedback\": \"Distance doesn’t ensure allele specificity. Off-target and on-target WT cutting can still happen if sequence is shared.\",\n          \"isCorrect\": false,\n          \"text\": \"Choose a guide far from the mutation\"\n        },\n        {\n          \"feedback\": \"PAM availability is a constraint. Ignoring PAM rules can leave you with a guide that can’t recruit Cas9.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore PAM; Cas9 will still cut\"\n        }\n      ],\n      \"question\": \"How do we maximize allele-specific cutting?\"\n    },\n    {\n      \"context\": \"Nice. Next question: do we want a clean knockout of the mutant allele, or try to correct it? The PI leans toward ‘disable the bad copy’ because it’s dominant-negative. What repair strategy matches that goal best?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. For disrupting a mutant allele, inducing a DSB and letting NHEJ introduce indels is the typical knockout approach.\",\n          \"isCorrect\": true,\n          \"text\": \"NHEJ to introduce indels (knockout)\"\n        },\n        {\n          \"feedback\": \"HDR is for precise correction/knock-in, but it’s less efficient and more timing-sensitive, especially in many primary cells.\",\n          \"isCorrect\": false,\n          \"text\": \"HDR with a donor to rewrite the allele\"\n        },\n        {\n          \"feedback\": \"Base editors can help in some cases, but the stated plan is to disable via DSB-driven disruption using CRISPR-Cas9.\",\n          \"isCorrect\": false,\n          \"text\": \"Use base editing regardless of mutation\"\n        },\n        {\n          \"feedback\": \"Silencing isn’t CRISPR editing. Also it may be transient and doesn’t directly address allele-specific disruption.\",\n          \"isCorrect\": false,\n          \"text\": \"Skip CRISPR; use RNAi silencing\"\n        }\n      ],\n      \"question\": \"Which repair pathway fits a knockout plan?\"\n    },\n    {\n      \"context\": \"Cool, but I’m nervous about off-target cuts. If we’re editing anything therapeutic-adjacent, we need a defensible specificity plan. What’s the most practical next step before we order reagents?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Use in silico off-target prediction plus guide redesign (and optionally high-fidelity Cas9) to reduce risk before wet lab work.\",\n          \"isCorrect\": true,\n          \"text\": \"Run off-target prediction; redesign if needed\"\n        },\n        {\n          \"feedback\": \"Not enough. “Shorter exposure” can help, but you still need guide-level specificity assessment first.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore predictions; just limit exposure time\"\n        },\n        {\n          \"feedback\": \"Risky. Waiting for phenotypes doesn’t prevent unsafe edits; you want to anticipate and avoid off-targets early.\",\n          \"isCorrect\": false,\n          \"text\": \"Proceed; check off-target later by phenotype\"\n        },\n        {\n          \"feedback\": \"Viral delivery can increase duration of Cas9 expression and potentially off-target risk; it’s not automatically safer.\",\n          \"isCorrect\": false,\n          \"text\": \"Switch to viral vectors; they’re safer\"\n        }\n      ],\n      \"question\": \"What’s the best pre-flight specificity step?\"\n    },\n    {\n      \"context\": \"Delivery time. We need CRISPR into patient-derived liver cells. The PI suggested AAV because it’s popular, but the team also mentioned lipid nanoparticles. Given off-target concerns and wanting transient activity, what do you recommend?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. LNP delivery of RNP/mRNA can be transient, reducing prolonged Cas9 expression and potentially lowering off-target risk versus long-lasting expression vectors.\",\n          \"isCorrect\": true,\n          \"text\": \"LNP delivery with transient Cas9 activity\"\n        },\n        {\n          \"feedback\": \"AAV can be effective, but it often yields longer expression; that can raise off-target risk and complicate control.\",\n          \"isCorrect\": false,\n          \"text\": \"AAV with strong promoter for high expression\"\n        },\n        {\n          \"feedback\": \"Plasmids can integrate rarely and often drive longer expression; also delivery into primary cells can be inefficient.\",\n          \"isCorrect\": false,\n          \"text\": \"Plasmid transfection for simplicity\"\n        },\n        {\n          \"feedback\": \"Electroporation can work ex vivo, but “always” is wrong; viability can suffer and it’s not the only reasonable choice here.\",\n          \"isCorrect\": false,\n          \"text\": \"Electroporate; it’s always best ex vivo\"\n        }\n      ],\n      \"question\": \"Which delivery best supports transient editing?\"\n    },\n    {\n      \"context\": \"We’ve got a guide targeting the mutant PAM, NHEJ knockout plan, and transient delivery. Now QA asks: how do we prove we didn’t smash the wild-type allele or create messy edits? What’s the most convincing readout package?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. You’d want on-target deep sequencing to quantify indels per allele plus targeted off-target sequencing at predicted sites; add protein/function assays as confirmation.\",\n          \"isCorrect\": true,\n          \"text\": \"Deep-seq on-target + predicted off-target sites\"\n        },\n        {\n          \"feedback\": \"Too shallow. Sanger can miss low-frequency edits and won’t reliably quantify mosaic outcomes in a cell population.\",\n          \"isCorrect\": false,\n          \"text\": \"Sanger sequencing of the locus only\"\n        },\n        {\n          \"feedback\": \"Expression changes are indirect and can be confounded; you need direct evidence of edits at DNA level.\",\n          \"isCorrect\": false,\n          \"text\": \"qPCR of mRNA expression only\"\n        },\n        {\n          \"feedback\": \"Cell viability doesn’t confirm allele specificity or off-target safety. You could be alive and still genomically wrong.\",\n          \"isCorrect\": false,\n          \"text\": \"Just check viability and morphology\"\n        }\n      ],\n      \"question\": \"How do we validate specificity and safety?\"\n    },\n    {\n      \"context\": \"Uh oh. Plot twist: the sequencing data shows the ‘wild-type’ allele in these cells has a silent SNP that *also* creates a PAM at the same spot. So our mutant-only PAM isn’t mutant-only in this patient line. If we proceed, we’ll likely cut both alleles. What’s our best pivot?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Redesign the guide to leverage a truly allele-distinguishing feature (e.g., guide overlaps mutation in seed region) or use paired strategies to require dual recognition.\",\n          \"isCorrect\": true,\n          \"text\": \"Redesign gRNA to overlap mutation seed region\"\n        },\n        {\n          \"feedback\": \"Not safe. Betting on efficiency differences is unreliable and could still knock out the functional allele.\",\n          \"isCorrect\": false,\n          \"text\": \"Proceed; hope mutant cuts more efficiently\"\n        },\n        {\n          \"feedback\": \"Overkill and risky. Multiple guides can increase off-targets and doesn’t guarantee allele specificity without design logic.\",\n          \"isCorrect\": false,\n          \"text\": \"Add a second gRNA to “average out” risk\"\n        },\n        {\n          \"feedback\": \"Partial measure. Lower dose may reduce overall cutting but doesn’t fix the core problem of non-specific targeting.\",\n          \"isCorrect\": false,\n          \"text\": \"Lower dose until WT cutting seems low\"\n        }\n      ],\n      \"question\": \"How do we recover allele specificity?\"\n    },\n    {\n      \"context\": \"Okay, new guide overlaps the mutation in the seed region and drops predicted off-targets. We run the edit with transient LNP delivery and deep sequencing looks clean: mutant allele indels high, wild-type mostly intact, predicted off-targets quiet. The PI’s asking what we learned to bake into our SOP. What’s the key takeaway?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. The workflow is: confirm patient-specific sequence context, design allele-discriminating guides, choose repair pathway to match the goal, manage off-target risk, and pick delivery that fits safety/control.\",\n          \"isCorrect\": true,\n          \"text\": \"Sequence-first design + specificity + controlled delivery\"\n        },\n        {\n          \"feedback\": \"Not reliable. You can’t “deliver your way out” of a bad target; guide/target choice is foundational.\",\n          \"isCorrect\": false,\n          \"text\": \"Delivery choice matters more than guide design\"\n        },\n        {\n          \"feedback\": \"Too narrow. HDR isn’t always better; the right pathway depends on the therapeutic goal and cell context.\",\n          \"isCorrect\": false,\n          \"text\": \"Always prefer HDR for therapeutic edits\"\n        },\n        {\n          \"feedback\": \"Dangerous. Off-target assessment is a core safety step, not optional, especially near therapeutic use.\",\n          \"isCorrect\": false,\n          \"text\": \"Off-target checks are optional if edits work\"\n        }\n      ],\n      \"question\": \"What principle should our SOP emphasize?\"\n    }\n  ]\n}",
      "outputTokens": 2002,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-biology-crispr-applications-1",
      "userPrompt": "LESSON_TITLE: CRISPR Gene Editing in Practice\nLESSON_DESCRIPTION: Understanding how to apply CRISPR gene editing technology effectively and responsibly\nCHAPTER_TITLE: Genetic Engineering\nCOURSE_TITLE: Modern Biotechnology\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. The Molecular Scissors: CRISPR-Cas9 is a molecular scissors that cuts DNA at specific locations. The Cas9 protein does the cutting; a guide RNA tells it exactly where to cut.\n2. Guide RNA Targeting: Guide RNA is a short sequence that matches the target DNA. It base-pairs with the DNA sequence you want to edit, bringing Cas9 to the exact spot.\n3. Cellular Repair Pathways: After CRISPR cuts, the cell's repair machinery fixes the break. Non-homologous end joining often introduces errors (knockouts). Homology-directed repair can insert new sequences (knock-ins).\n4. Off-Target Effects: Off-target effects occur when CRISPR cuts unintended locations. Guide RNA design and delivery methods affect specificity. This is a major safety concern for therapeutic applications.\n5. Delivery Challenges: Delivery is a key challenge. Getting CRISPR components into the right cells in a living organism is harder than in a lab dish. Viral vectors and lipid nanoparticles are common approaches."
    },
    {
      "duration": 33898.86841599998,
      "inputTokens": 3148,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, socorro: o cliente quer que a gente transforme um PDF de 60 páginas em um microcurso pro time de vendas até sexta. Eles dizem que o time “não aprende nada”. Se a gente só resumir, vai continuar ruim. Por onde você atacaria primeiro?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso aumenta a carga extrínseca: mais elementos competindo por atenção. Melhor é reduzir ruído e guiar o foco.\",\n          \"isCorrect\": false,\n          \"text\": \"Encher de animações pra “engajar”\"\n        },\n        {\n          \"feedback\": \"Isso mira direto na carga extrínseca: cortar confusão, excesso visual e caminhos tortos antes de mexer no conteúdo em si.\",\n          \"isCorrect\": true,\n          \"text\": \"Identificar e cortar carga extrínseca\"\n        },\n        {\n          \"feedback\": \"Resumo ajuda, mas pode cortar coisa essencial e não resolve design ruim. Primeiro remove atrito; depois ajusta intrínseca e germânica.\",\n          \"isCorrect\": false,\n          \"text\": \"Só resumir o PDF e pronto\"\n        },\n        {\n          \"feedback\": \"Testes sem redesenho só medem frustração. Primeiro organize a experiência; depois avalie com atividades alinhadas.\",\n          \"isCorrect\": false,\n          \"text\": \"Aplicar um teste final bem difícil\"\n        }\n      ],\n      \"question\": \"Qual é o primeiro passo mais inteligente?\"\n    },\n    {\n      \"context\": \"Beleza. Eu abri o módulo 1 e tá assim: texto denso + 3 caixas “curiosidade” + um infográfico lotado. E o áudio lê o texto palavra por palavra. O cliente acha “multimídia”. O que você mudaria primeiro?\",\n      \"options\": [\n        {\n          \"feedback\": \"Duplicar canais com o mesmo conteúdo aumenta extrínseca (efeito redundância). Melhor é áudio complementar ou retirar.\",\n          \"isCorrect\": true,\n          \"text\": \"Remover redundância áudio + texto igual\"\n        },\n        {\n          \"feedback\": \"Infográfico pode ajudar se simplificado, mas se mantiver redundância e ruído, o problema continua.\",\n          \"isCorrect\": false,\n          \"text\": \"Manter tudo e só aumentar a fonte\"\n        },\n        {\n          \"feedback\": \"Áudio sozinho pode funcionar, mas sem roteiro e segmentação ainda pode sobrecarregar. O ponto crítico aqui é redundância.\",\n          \"isCorrect\": false,\n          \"text\": \"Tirar o texto e deixar só o áudio\"\n        },\n        {\n          \"feedback\": \"Mais elementos “de apoio” geralmente aumentam extrínseca se não forem essenciais e integrados ao objetivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar mais exemplos na mesma tela\"\n        }\n      ],\n      \"question\": \"Qual ajuste reduz carga extrínseca mais rápido?\"\n    },\n    {\n      \"context\": \"Ok, limpamos a tela. Só que o conteúdo é realmente complexo: objeções, proposta de valor, pricing, negociação… tudo junto. O cliente quer “tudo em 15 min”. Como você lidaria com a carga intrínseca sem jogar fora o essencial?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso ignora limites da memória de trabalho. Intrínseca alta pede gerenciamento, não compressão agressiva.\",\n          \"isCorrect\": false,\n          \"text\": \"Acelerar: falar mais rápido e pronto\"\n        },\n        {\n          \"feedback\": \"Chunking e segmentação gerenciam a intrínseca: quebra em partes com sequência lógica, mantendo a complexidade sob controle.\",\n          \"isCorrect\": true,\n          \"text\": \"Chunking + segmentar por etapas da venda\"\n        },\n        {\n          \"feedback\": \"Retirar conteúdo pode comprometer o objetivo. Melhor é ordenar e apoiar com prática, não amputar sem critério.\",\n          \"isCorrect\": false,\n          \"text\": \"Cortar pricing e negociação (muito difícil)\"\n        },\n        {\n          \"feedback\": \"“Descobrir sozinho” pode explodir a intrínseca e extrínseca. Precisa de estrutura e guias graduais.\",\n          \"isCorrect\": false,\n          \"text\": \"Deixar livre: o aluno explora do jeito dele\"\n        }\n      ],\n      \"question\": \"Como gerenciar a carga intrínseca aqui?\"\n    },\n    {\n      \"context\": \"Fiz um rascunho com 5 microlições: 1) Diagnóstico, 2) Valor, 3) Objeções, 4) Preço, 5) Fechamento. Só que o cliente pediu “mais reflexão”. Como aumentar carga germânica sem reintroduzir bagunça?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso aumenta tempo e pode virar extrínseca se não for guiado. Germânica pede esforço produtivo, não volume.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar leitura extra de 20 páginas por lição\"\n        },\n        {\n          \"feedback\": \"Atividades de aplicação (cenários, perguntas de decisão) forçam elaboração e conexão com o trabalho: germânica alta, extrínseca baixa.\",\n          \"isCorrect\": true,\n          \"text\": \"Inserir cenários curtos com decisão + feedback\"\n        },\n        {\n          \"feedback\": \"Dificultar sem propósito vira frustração e pode aumentar extrínseca. O ideal é desafio alinhado ao objetivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar pegadinhas para “fixar”\"\n        },\n        {\n          \"feedback\": \"Memorizar scripts pode até ajudar, mas sem contextualizar não promove construção de esquemas de forma robusta.\",\n          \"isCorrect\": false,\n          \"text\": \"Pedir pra decorar um script inteiro\"\n        }\n      ],\n      \"question\": \"Qual atividade aumenta carga germânica do jeito certo?\"\n    },\n    {\n      \"context\": \"Agora vem o detalhe chato: o time de vendas acessa no celular, entre uma ligação e outra. Se colocarmos muita coisa na tela, já era. Qual decisão de design protege a memória de trabalho (limite ~4 itens)?\",\n      \"options\": [\n        {\n          \"feedback\": \"Texto em bloco estoura a memória de trabalho e aumenta extrínseca. Mobile pede foco e segmentação.\",\n          \"isCorrect\": false,\n          \"text\": \"Uma tela única com tudo “pra não clicar”\"\n        },\n        {\n          \"feedback\": \"Microsegmentos com 1 objetivo por tela reduz extrínseca e respeita capacidade limitada; você controla o ritmo e o foco.\",\n          \"isCorrect\": true,\n          \"text\": \"Uma ideia por tela + progresso claro\"\n        },\n        {\n          \"feedback\": \"Navegação “livre” pode aumentar extrínseca (decisão constante). Melhor guiar o fluxo e reduzir escolhas desnecessárias.\",\n          \"isCorrect\": false,\n          \"text\": \"Menu gigante com todas as opções visíveis\"\n        },\n        {\n          \"feedback\": \"Gamificação pode ajudar, mas não substitui estrutura. Sem segmentação, badges viram ruído.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar badges e rankings em todas as telas\"\n        }\n      ],\n      \"question\": \"O que melhor respeita o limite da memória?\"\n    },\n    {\n      \"context\": \"Estou revisando a lição de objeções. Tem 12 objeções comuns com respostas. Se mostrarmos as 12 de uma vez, vira lista telefônica. Como você faria chunking sem perder utilidade?\",\n      \"options\": [\n        {\n          \"feedback\": \"Alfabética ajuda a achar, mas não cria significado. Chunking bom agrupa por lógica (tipo de objeção) e uso real.\",\n          \"isCorrect\": false,\n          \"text\": \"Ordenar em ordem alfabética\"\n        },\n        {\n          \"feedback\": \"Agrupar por categorias (preço, urgência, confiança etc.) cria unidades significativas e reduz carga na navegação mental.\",\n          \"isCorrect\": true,\n          \"text\": \"Agrupar por tipo de objeção (3–4 blocos)\"\n        },\n        {\n          \"feedback\": \"Mais itens por tela piora. O objetivo é reduzir itens simultâneos e facilitar recuperação.\",\n          \"isCorrect\": false,\n          \"text\": \"Colocar tudo em um infográfico maior\"\n        },\n        {\n          \"feedback\": \"Aleatório aumenta extrínseca: o aluno gasta energia procurando padrão que não existe.\",\n          \"isCorrect\": false,\n          \"text\": \"Sortear 12 objeções aleatoriamente\"\n        }\n      ],\n      \"question\": \"Qual chunking faz mais sentido aqui?\"\n    },\n    {\n      \"context\": \"Tá ficando bom. Mas o cliente voltou com uma exigência: “precisamos colocar o texto completo do PDF como material obrigatório, senão o jurídico reclama”. Plot twist. Se a gente enfiar isso no fluxo, mata o curso. Como você resolve sem explodir a carga extrínseca?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso piora tudo: redundância, volume e distração no fluxo principal. Não precisa ser obrigatório no mesmo caminho.\",\n          \"isCorrect\": false,\n          \"text\": \"Colocar o PDF inteiro em cada lição\"\n        },\n        {\n          \"feedback\": \"Deixar como recurso anexo opcional (ou seção “Referência/Jurídico”) mantém conformidade sem poluir o caminho de aprendizagem.\",\n          \"isCorrect\": true,\n          \"text\": \"Mover o PDF para “Referência” fora do fluxo\"\n        },\n        {\n          \"feedback\": \"Tornar obrigatório aumenta extrínseca e tempo, e ainda não garante compreensão. Melhor separar compliance de aprendizagem.\",\n          \"isCorrect\": false,\n          \"text\": \"Obrigar leitura do PDF antes de cada quiz\"\n        },\n        {\n          \"feedback\": \"Isso remove rastreabilidade e pode falhar com jurídico. A solução é acomodar sem atrapalhar o design instrucional.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorar o jurídico e publicar assim mesmo\"\n        }\n      ],\n      \"question\": \"Como manter compliance sem matar o curso?\"\n    },\n    {\n      \"context\": \"Fechamos: fluxo limpo, conteúdo segmentado, atividades de cenário, e o PDF ficou em “Referência”. Última decisão: como você valida com o cliente que reduzimos extrínseca e aumentamos germânica, sem fazer um “curso mais fácil” no sentido ruim?\",\n      \"options\": [\n        {\n          \"feedback\": \"Só satisfação é frágil: pode gostar e não aprender. Precisamos evidência de aplicação e menos atrito.\",\n          \"isCorrect\": false,\n          \"text\": \"Só pedir nota de satisfação no fim\"\n        },\n        {\n          \"feedback\": \"Medir desempenho em cenários + tempo/erros de navegação mostra aprendizagem aplicada (germânica) e menor atrito (extrínseca).\",\n          \"isCorrect\": true,\n          \"text\": \"Rodar piloto: cenários + métricas de atrito\"\n        },\n        {\n          \"feedback\": \"Tempo assistido não prova entendimento. Pode ficar vendo e continuar sem schema útil.\",\n          \"isCorrect\": false,\n          \"text\": \"Medir apenas tempo total no curso\"\n        },\n        {\n          \"feedback\": \"Prova de memorização pode desalinha com a prática de vendas e aumentar extrínseca com decoreba.\",\n          \"isCorrect\": false,\n          \"text\": \"Aplicar prova de múltipla escolha de definição\"\n        }\n      ],\n      \"question\": \"Como provar eficácia sem confundir com “facilidade”?\"\n    }\n  ]\n}",
      "outputTokens": 2024,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-psychology-cognitive-load-1",
      "userPrompt": "LESSON_TITLE: Carga Cognitiva na Pratica\nLESSON_DESCRIPTION: Aplicando a teoria da carga cognitiva para criar materiais de aprendizagem mais eficazes\nCHAPTER_TITLE: Psicologia da Aprendizagem\nCOURSE_TITLE: Design Instrucional\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Limites da Memoria: A memoria de trabalho tem capacidade limitada — cerca de 4 itens simultaneamente. Quando sobrecarregada, a aprendizagem para. O cerebro nao consegue processar mais.\n2. Carga Intrinseca: Carga intrinseca vem da complexidade inerente do conteudo. Algumas coisas sao simplesmente dificeis. Nao da para eliminar, mas da para gerenciar.\n3. Carga Extrinseca: Carga extrinseca vem do design ruim — instrucoes confusas, distracao visual, navegacao complicada. Essa carga pode e deve ser eliminada.\n4. Carga Germanica: Carga germanica e o esforco produtivo de aprender — criar conexoes, elaborar, integrar. Queremos maximizar essa carga enquanto minimizamos a extrinseca.\n5. Chunking: Chunking agrupa informacoes em unidades significativas. Um numero de telefone e mais facil de lembrar como blocos (99-8765-4321) do que como 10 digitos soltos."
    },
    {
      "duration": 44003.95316700003,
      "inputTokens": 3151,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, tenemos que cerrar hoy el diseño del sistema de recuperación de calor para la planta. El jefe quiere “ahorro energético garantizado”, pero si prometemos de más nos revientan en la auditoría. Tengo datos: el proceso caliente sale a 520 K y podemos rechazar a ambiente a 300 K.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: antes de hablar de ahorros, acotas el máximo teórico con Carnot. Si ya estás cerca de ese límite, cualquier promesa grande es sospechosa.\",\n          \"isCorrect\": true,\n          \"text\": \"Estimar eficiencia máxima tipo Carnot\"\n        },\n        {\n          \"feedback\": \"Eso ayuda al balance energético, pero sin un límite de 2ª ley podrías proponer algo que “cierra” en energía y aun así es imposible o exagerado.\",\n          \"isCorrect\": false,\n          \"text\": \"Hacer solo balance con 1ª ley\"\n        },\n        {\n          \"feedback\": \"Bajar Tfría ayuda, pero no siempre es viable ni te da un marco para prometer desempeño del sistema completo.\",\n          \"isCorrect\": false,\n          \"text\": \"Buscar bajar Tfría sin cálculos\"\n        },\n        {\n          \"feedback\": \"El fabricante da datos útiles, pero primero necesitas saber si lo que pides es físicamente alcanzable con esas temperaturas.\",\n          \"isCorrect\": false,\n          \"text\": \"Pedir al proveedor “la mejor eficiencia”\"\n        }\n      ],\n      \"question\": \"¿Qué cálculo haces primero para no prometer imposibles?\"\n    },\n    {\n      \"context\": \"Ok, usando 520 K como fuente caliente y 300 K como fría, el jefe quiere saber “cuánto como mínimo gastamos o máximo sacamos”. Si esto fuera un motor ideal entre esas temperaturas, ¿qué número te sirve como techo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: η_Carnot = 1 - Tfría/Tcaliente = 1 - 300/520 ≈ 0.423. Ningún motor real entre esas T lo supera.\",\n          \"isCorrect\": true,\n          \"text\": \"ηmax ≈ 1 - 300/520 ≈ 0.42\"\n        },\n        {\n          \"feedback\": \"Eso sería 1ª ley mal aplicada: no puedes convertir todo el calor en trabajo si Tfría>0. La 2ª ley lo impide.\",\n          \"isCorrect\": false,\n          \"text\": \"ηmax = 1 (100%)\"\n        },\n        {\n          \"feedback\": \"Eso es la razón inversa y no representa eficiencia. Además daría un número sin interpretación correcta.\",\n          \"isCorrect\": false,\n          \"text\": \"ηmax = 520/300\"\n        },\n        {\n          \"feedback\": \"Ese cálculo no aplica: temperaturas iguales implican η=0, y aquí no son iguales. Estarías tirando el dato clave.\",\n          \"isCorrect\": false,\n          \"text\": \"ηmax = 0 porque hay pérdidas\"\n        }\n      ],\n      \"question\": \"¿Cuál es la eficiencia máxima teórica entre 520 K y 300 K?\"\n    },\n    {\n      \"context\": \"Perfecto. Ahora el jefe insiste: “Entonces metamos un motor y ya, así generamos electricidad”. Pero el proceso no puede bajar de 420 K porque afecta la calidad del producto. O sea, nuestra fuente caliente útil es 520→420 K. ¿Qué hacemos con esa restricción?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: defines el rango real de operación. Tu Tcaliente efectiva baja; el máximo trabajo extraíble cae. Hay que recalcular el techo con las temperaturas realmente disponibles.\",\n          \"isCorrect\": true,\n          \"text\": \"Recalcular límite con T real del proceso\"\n        },\n        {\n          \"feedback\": \"La 1ª ley no basta: aunque haya energía, la 2ª ley limita el trabajo. Prometer “usar todo” es vender humo.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar todo el calor igual por 1ª ley\"\n        },\n        {\n          \"feedback\": \"No puedes “ignorar” la temperatura final; es justo lo que define la calidad y el potencial de trabajo disponible.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorar 420 K y usar 520 K\"\n        },\n        {\n          \"feedback\": \"Una turbina puede ser adecuada o no, pero la decisión viene después de fijar el potencial termodinámico con las T disponibles.\",\n          \"isCorrect\": false,\n          \"text\": \"Elegir turbina y ajustar después\"\n        }\n      ],\n      \"question\": \"¿Cómo incorporas que no podemos bajar de 420 K?\"\n    },\n    {\n      \"context\": \"Bien. Hice un estimado rápido y el potencial de generación no es tan alto. Entonces el jefe cambia el guion: “ok, usemos una bomba de calor para subir ese calor a 600 K y así reutilizarlo en el horno”. Suena mágico. ¿Qué le contestamos con 2ª ley en mente?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: una bomba de calor puede mover calor de menor a mayor T, pero requiere trabajo. No es magia; hay que calcular COP y costo eléctrico.\",\n          \"isCorrect\": true,\n          \"text\": \"Se puede, pero requiere trabajo; calculemos COP\"\n        },\n        {\n          \"feedback\": \"Falso: no viola la 2ª ley si hay trabajo de entrada. Decir “imposible” te hace perder una opción viable.\",\n          \"isCorrect\": false,\n          \"text\": \"Imposible: calor no sube nunca de T\"\n        },\n        {\n          \"feedback\": \"La 1ª ley no demuestra viabilidad. Podrías “cerrar” energía y aun así necesitar trabajo enorme o un COP irreal.\",\n          \"isCorrect\": false,\n          \"text\": \"Si el balance de energía cierra, sirve\"\n        },\n        {\n          \"feedback\": \"No hay “free lunch”: mayor T de entrega suele bajar el COP y subir el consumo. No es necesariamente ‘siempre mejor’.\",\n          \"isCorrect\": false,\n          \"text\": \"Subir a 600 K siempre es mejor\"\n        }\n      ],\n      \"question\": \"¿Qué respuesta es correcta sobre usar bomba de calor?\"\n    },\n    {\n      \"context\": \"Te paso números para aterrizarlo: queremos entregar calor a 600 K y tomarlo de 420 K. Si fuera una bomba de calor reversible, ¿qué expresión usas para el COP de calefacción como límite superior?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: para bomba de calor reversible, COP_H,max = Th/(Th-Tc). Aquí sería 600/(600-420)=600/180≈3.33.\",\n          \"isCorrect\": true,\n          \"text\": \"COP_H,max = Th/(Th−Tc)\"\n        },\n        {\n          \"feedback\": \"Esa es la eficiencia de Carnot para motores, no COP. Estás mezclando dispositivos distintos (motor vs bomba de calor).\",\n          \"isCorrect\": false,\n          \"text\": \"η = 1 − Tc/Th\"\n        },\n        {\n          \"feedback\": \"Eso no es COP; daría un número sin unidades mal interpretado. El COP relaciona calor entregado con trabajo.\",\n          \"isCorrect\": false,\n          \"text\": \"COP = Th/Tc\"\n        },\n        {\n          \"feedback\": \"Eso es COP de refrigerador reversible (Tc/(Th−Tc)), no el de calefacción. Para calefacción es mayor por 1.\",\n          \"isCorrect\": false,\n          \"text\": \"COP_R,max = Tc/(Th−Tc)\"\n        }\n      ],\n      \"question\": \"¿Qué fórmula te da el COP máximo de una bomba de calor?\"\n    },\n    {\n      \"context\": \"Con COP≈3.3 ideal, el real será menor. El jefe quiere aún así prometer “ahorro neto garantizado”. Pero la planta ya tiene electricidad cara y el horno usa gas barato. ¿Qué criterio aplicamos para decidir si conviene?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: comparas energía y costos: trabajo eléctrico requerido vs ahorro de combustible, considerando COP real y eficiencias. La termodinámica te da límites; la economía decide.\",\n          \"isCorrect\": true,\n          \"text\": \"Comparar costo: Weléctrico vs gas ahorrado\"\n        },\n        {\n          \"feedback\": \"Un COP alto ayuda, pero no garantiza ahorro económico. Si la electricidad es cara, puedes perder dinero aunque el COP sea “bueno”.\",\n          \"isCorrect\": false,\n          \"text\": \"Si COP>1, siempre conviene\"\n        },\n        {\n          \"feedback\": \"El límite de Carnot es un techo, no un valor real. Decidir con el máximo teórico te lleva a sobreprometer.\",\n          \"isCorrect\": false,\n          \"text\": \"Decidir solo con COP máximo reversible\"\n        },\n        {\n          \"feedback\": \"La entropía no “se reduce” globalmente; solo se puede mover a costa de trabajo y generación de entropía total. No es un criterio económico directo.\",\n          \"isCorrect\": false,\n          \"text\": \"Elegir lo que minimice entropía del proceso\"\n        }\n      ],\n      \"question\": \"¿Qué criterio usas para afirmar “conviene” o no?\"\n    },\n    {\n      \"context\": \"Ok, armamos el caso con números realistas. Pero aparece otro tema: el área ambiental pide justificar que “no aumentamos el impacto térmico al entorno”. Necesitamos argumentar qué pasa con entropía cuando hacemos recuperación vs cuando simplemente rechazamos calor. ¿Cómo lo planteas?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: comparas generación de entropía. Recuperar energía útil reduce exergía destruida, pero siempre hay irreversibilidades; el total (sistema+entorno) aumenta.\",\n          \"isCorrect\": true,\n          \"text\": \"Analizar Sgen: total siempre aumenta\"\n        },\n        {\n          \"feedback\": \"Falso: la 2ª ley dice que la entropía total no disminuye. Puedes bajar entropía localmente solo exportándola y con trabajo.\",\n          \"isCorrect\": false,\n          \"text\": \"La recuperación baja la entropía total\"\n        },\n        {\n          \"feedback\": \"Falso: aun con equipos “eficientes” hay irreversibilidades. Solo un proceso reversible tendría Sgen=0, idealizado.\",\n          \"isCorrect\": false,\n          \"text\": \"Con buen diseño, Sgen=0\"\n        },\n        {\n          \"feedback\": \"No necesariamente: recuperar calor a mayor T puede reducir rechazo, pero una bomba de calor también puede aumentar el rechazo eléctrico aguas arriba. Hay que cuantificar.\",\n          \"isCorrect\": false,\n          \"text\": \"Recuperar siempre reduce calor rechazado\"\n        }\n      ],\n      \"question\": \"¿Cómo respondes usando entropía sin decir barbaridades?\"\n    },\n    {\n      \"context\": \"Te va el giro raro, {{NAME}}: el proveedor manda una simulación “milagrosa” donde el motor saca más trabajo del que permite nuestro límite de Carnot. Dice que es por un ‘intercambiador patentado’ y que la fuente fría “se mantiene a 280 K” porque usan agua de torre. ¿Qué hacemos antes de firmar nada?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: verificas temperaturas reales y definiciones: la fuente fría no puede ser menor que el sumidero efectivo; revisa ΔT de intercambio, datos de torre, y si están confundiendo K con °C o usando promedios. Si excede Carnot, hay error o trampa.\",\n          \"isCorrect\": true,\n          \"text\": \"Auditar supuestos de T y el balance completo\"\n        },\n        {\n          \"feedback\": \"No: si supera Carnot, no es “innovación”, es inconsistencia. Firmar te expone a un desastre técnico y legal.\",\n          \"isCorrect\": false,\n          \"text\": \"Confiar: si es patentado, debe ser posible\"\n        },\n        {\n          \"feedback\": \"No resuelve el problema. El límite de Carnot no depende del tipo de ciclo; si lo superan en papel, el papel está mal.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar a ciclo Rankine y listo\"\n        },\n        {\n          \"feedback\": \"La 1ª ley sola no detecta violaciones de 2ª ley. Puedes tener balance energético y aun así eficiencia imposible.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo revisar 1ª ley: Q−W=ΔU\"\n        }\n      ],\n      \"question\": \"El proveedor “supera Carnot”. ¿Tu siguiente paso?\"\n    },\n    {\n      \"context\": \"Listo: encontramos el “milagro”. Usaron 280 como si fuera 280 °C en una hoja, y además tomaron Tfría como la del agua de entrada, no la del sumidero efectivo. Ahora el jefe quiere que redactemos la recomendación final en una frase clara: qué sí podemos prometer y qué no. ¿Qué dices?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: prometes dentro de límites físicos (Carnot/COP), con T reales, y aclaras irreversibilidades. Es la aplicación completa: 1ª ley para balances, 2ª ley para viabilidad y techo de desempeño.\",\n          \"isCorrect\": true,\n          \"text\": \"Prometer solo dentro de límites 1ª+2ª ley\"\n        },\n        {\n          \"feedback\": \"No: “máxima eficiencia” sin números y sin límites es receta para reclamos. La auditoría pedirá fundamento termodinámico.\",\n          \"isCorrect\": false,\n          \"text\": \"Prometer “máxima eficiencia posible” sin más\"\n        },\n        {\n          \"feedback\": \"No: descartar todo por un error del proveedor te hace perder una solución viable. La respuesta es corregir supuestos y rediseñar.\",\n          \"isCorrect\": false,\n          \"text\": \"Cancelar el proyecto completo\"\n        },\n        {\n          \"feedback\": \"No: enfocarte solo en costos ignora viabilidad física. Primero límites termodinámicos, luego evaluación económica.\",\n          \"isCorrect\": false,\n          \"text\": \"Prometer según costos, sin hablar de límites\"\n        }\n      ],\n      \"question\": \"¿Qué promesa final es responsable y correcta?\"\n    }\n  ]\n}",
      "outputTokens": 2670,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-physics-thermodynamics-applications-1",
      "userPrompt": "LESSON_TITLE: Termodinamica Aplicada\nLESSON_DESCRIPTION: Aplicando las leyes de la termodinamica para entender y disenar sistemas energeticos\nCHAPTER_TITLE: Termodinamica\nCOURSE_TITLE: Fisica para Ingenieros\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Conservacion de Energia: La primera ley dice que la energia se conserva — no se crea ni destruye, solo se transforma. El calor que entra menos el trabajo que sale iguala el cambio de energia interna.\n2. Direccion del Calor: La segunda ley establece una direccion: el calor fluye espontaneamente de caliente a frio, nunca al reves. Esto limita la eficiencia de cualquier motor termico.\n3. Entropia: La entropia mide la dispersion de energia. Cuando la energia se dispersa (calor fluyendo a lo frio), la entropia aumenta. Concentrar energia requiere trabajo externo.\n4. Limite de Carnot: El ciclo de Carnot define la eficiencia maxima teorica. Ningun motor real puede ser mas eficiente. La eficiencia depende de las temperaturas de las fuentes caliente y fria.\n5. Refrigeracion: Los refrigeradores y bombas de calor mueven calor de frio a caliente usando trabajo. No violan la segunda ley — el trabajo compensa el flujo 'antinatural' de calor."
    },
    {
      "duration": 36459.167874999985,
      "inputTokens": 3143,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we’ve got a live incident. Users say they added items to cart, refreshed, and the cart goes empty on one device but not the other. Support says it happens more during peak traffic. If we pick the wrong consistency posture, we either drop writes or show ghosts. What do we optimize for right now?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not quite. Prioritizing C means you may reject requests during partitions, which can feel like outages. That might be okay for payments, but carts usually prefer staying usable.\",\n          \"isCorrect\": false,\n          \"text\": \"Strict consistency everywhere\"\n        },\n        {\n          \"feedback\": \"Yes. For carts, it’s usually better to stay available and converge. Users tolerate brief staleness more than hard failures, and we can resolve conflicts with merge logic.\",\n          \"isCorrect\": true,\n          \"text\": \"Availability with eventual consistency\"\n        },\n        {\n          \"feedback\": \"Not enough. Caching can reduce load, but it doesn’t address replica divergence or partitions. It can also amplify stale reads if not designed carefully.\",\n          \"isCorrect\": false,\n          \"text\": \"Just add a cache in front\"\n        },\n        {\n          \"feedback\": \"Too broad. Lowering latency helps, but it doesn’t choose behavior during partitions. You still need a consistency/availability decision.\",\n          \"isCorrect\": false,\n          \"text\": \"Optimize latency first\"\n        }\n      ],\n      \"question\": \"What stance should we take for carts?\"\n    },\n    {\n      \"context\": \"Okay, if we’re going eventual, we still need to stop the “empty cart” shock. Right now reads can hit any replica. During replication lag, you can read a replica that hasn’t seen the latest add-item. How do we reduce stale reads without going fully strong-consistent?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Quorums can reduce staleness: require R+W>N so reads overlap recent writes. It’s not absolute strong consistency, but much better than random replica reads.\",\n          \"isCorrect\": true,\n          \"text\": \"Use quorum reads/writes (R+W>N)\"\n        },\n        {\n          \"feedback\": \"Not reliable. Sticky reads help within a session, but if that replica is behind or fails over, you can still see stale/empty carts.\",\n          \"isCorrect\": false,\n          \"text\": \"Always read from the same replica\"\n        },\n        {\n          \"feedback\": \"Too heavy. Cross-region synchronous replication pushes toward strong consistency and adds latency; it can also reduce availability during partitions.\",\n          \"isCorrect\": false,\n          \"text\": \"Synchronous replicate to all regions\"\n        },\n        {\n          \"feedback\": \"Backwards. More replicas can increase the chance a read hits a lagging node unless you also change read/write rules.\",\n          \"isCorrect\": false,\n          \"text\": \"Increase replicas and keep random reads\"\n        }\n      ],\n      \"question\": \"How do we reduce staleness pragmatically?\"\n    },\n    {\n      \"context\": \"Cool, but product just pinged: “If a user hits checkout, the cart must be accurate.” They’re fine if browsing is slightly stale, but checkout can’t miss items. How do we handle that without making the whole cart system CP?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Use different consistency levels by operation: AP-ish for browsing, but stronger (quorum/leader/transactional) reads at checkout to avoid stale carts at the critical moment.\",\n          \"isCorrect\": true,\n          \"text\": \"Stronger reads only for checkout\"\n        },\n        {\n          \"feedback\": \"Too much. Making everything strongly consistent increases latency and hurts availability for a feature where staleness is often acceptable.\",\n          \"isCorrect\": false,\n          \"text\": \"Make all cart ops strongly consistent\"\n        },\n        {\n          \"feedback\": \"Not sufficient. Delaying UI updates doesn’t guarantee backend accuracy; you can still have divergent replicas and lose items at checkout.\",\n          \"isCorrect\": false,\n          \"text\": \"Delay UI until replication completes\"\n        },\n        {\n          \"feedback\": \"Wrong direction. Letting checkout use stale reads is exactly what product said we can’t do; it risks missing items and revenue loss.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep eventual consistency even at checkout\"\n        }\n      ],\n      \"question\": \"What’s the best way to treat checkout?\"\n    },\n    {\n      \"context\": \"Now the ugly part: we’re seeing “double-add” and “missing remove” when users spam add/remove quickly on two devices. That’s classic concurrent writes. We need a conflict resolution strategy that matches cart semantics. What should we do?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Carts often merge by item-id with per-item quantities, using commutative ops (add/remove as deltas) or app-specific merge so concurrent updates converge predictably.\",\n          \"isCorrect\": true,\n          \"text\": \"App-specific merge per item/quantity\"\n        },\n        {\n          \"feedback\": \"Risky. Last-write-wins can drop a remove or add depending on clocks and races—exactly the symptoms you’re seeing.\",\n          \"isCorrect\": false,\n          \"text\": \"Last-write-wins timestamps\"\n        },\n        {\n          \"feedback\": \"Not a resolution strategy. Quorums reduce divergence but don’t eliminate concurrent writes; you still need a merge rule when conflicts happen.\",\n          \"isCorrect\": false,\n          \"text\": \"Rely on quorums to prevent conflicts\"\n        },\n        {\n          \"feedback\": \"Overkill for carts. Two-phase commit is expensive, hurts availability, and still struggles under partitions; carts don’t usually justify it.\",\n          \"isCorrect\": false,\n          \"text\": \"Two-phase commit across replicas\"\n        }\n      ],\n      \"question\": \"How should we resolve cart write conflicts?\"\n    },\n    {\n      \"context\": \"One more: ops says we had a brief inter-region partition. If we keep accepting writes on both sides, we’ll get divergent versions. If we reject writes, users see errors. During the next partition, what should our system do for cart updates?\",\n      \"options\": [\n        {\n          \"feedback\": \"No. Rejecting all writes preserves consistency but turns a cart into an outage during partitions. Usually too costly for this domain.\",\n          \"isCorrect\": false,\n          \"text\": \"Reject all writes until healed\"\n        },\n        {\n          \"feedback\": \"Yes. Accept writes to stay available, track concurrency (versions/vector-ish metadata), then reconcile using merge logic when connectivity returns.\",\n          \"isCorrect\": true,\n          \"text\": \"Accept writes + reconcile after heal\"\n        },\n        {\n          \"feedback\": \"Not safe. Routing all traffic to one region can fail if the partition prevents reaching it, and it can overload the remaining region.\",\n          \"isCorrect\": false,\n          \"text\": \"Force all traffic to one region\"\n        },\n        {\n          \"feedback\": \"Not enough. Retries can amplify load and still won’t resolve concurrent updates; you’ll just repeat conflicting writes.\",\n          \"isCorrect\": false,\n          \"text\": \"Retry until success everywhere\"\n        }\n      ],\n      \"question\": \"During a partition, what’s our move?\"\n    },\n    {\n      \"context\": \"We implemented per-item merge, but analytics shows “cart item count” flickers because updates arrive out of order. Someone suggested “just use last-write-wins on the whole cart document” to stop flicker. Tempting… do we take it?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Whole-document LWW may reduce flicker but can drop concurrent edits (e.g., one device removes, another adds). Better: keep per-item merge and fix UI with monotonic reads/session guarantees if needed.\",\n          \"isCorrect\": true,\n          \"text\": \"No—keep merge; improve read experience\"\n        },\n        {\n          \"feedback\": \"Wrong. Whole-cart LWW trades flicker for correctness regressions: lost updates become common under concurrency and clock skew.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes—LWW on entire cart\"\n        },\n        {\n          \"feedback\": \"Not targeted. A bigger quorum might reduce some staleness, but it won’t stop out-of-order delivery effects or eliminate concurrent writes.\",\n          \"isCorrect\": false,\n          \"text\": \"Increase quorum sizes aggressively\"\n        },\n        {\n          \"feedback\": \"Misguided. Turning off replication “fixes” divergence by removing redundancy; it destroys durability and availability and won’t scale.\",\n          \"isCorrect\": false,\n          \"text\": \"Disable replication during peaks\"\n        }\n      ],\n      \"question\": \"Do we switch to LWW for the whole cart?\"\n    },\n    {\n      \"context\": \"Plot twist, {{NAME}}: I found the root cause of the “empty cart” reports. It’s not replication lag. Our checkout service reads from a read-replica with R=1 because someone optimized latency last month. So checkout can read stale even if cart service is fine. What’s the fastest safe fix?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. For checkout, enforce stronger consistency: read from leader or use a quorum read that overlaps recent writes. That directly addresses stale checkout views.\",\n          \"isCorrect\": true,\n          \"text\": \"Make checkout read leader/quorum\"\n        },\n        {\n          \"feedback\": \"Not safe. Caching can serve stale data even longer unless you add strict invalidation and consistency controls; it’s the opposite of what checkout needs.\",\n          \"isCorrect\": false,\n          \"text\": \"Add a cache to speed up checkout\"\n        },\n        {\n          \"feedback\": \"Too slow and risky during an incident. Repartitioning doesn’t address the consistency level choice causing stale reads.\",\n          \"isCorrect\": false,\n          \"text\": \"Re-shard the cart data immediately\"\n        },\n        {\n          \"feedback\": \"Bad trade-off here. Removing replicas increases load on primary and reduces resilience; plus you still need correct read routing/consistency.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove read replicas for checkout\"\n        }\n      ],\n      \"question\": \"What’s the best immediate checkout fix?\"\n    },\n    {\n      \"context\": \"Nice. If we roll that out, we’ll have AP-ish cart browsing, but CP-ish checkout reads. Before we close the incident, we need to explain it to leadership: why we didn’t just “pick consistency” universally. What’s the clearest takeaway?\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Partitions are inevitable, so you choose trade-offs per operation: keep carts available with convergence, and enforce stronger reads where correctness is critical (checkout). Quorums + merge logic make it workable.\",\n          \"isCorrect\": true,\n          \"text\": \"Choose C vs A per operation and semantics\"\n        },\n        {\n          \"feedback\": \"Incorrect. CAP isn’t “pick two and forget it.” You still design behaviors during partitions and can vary consistency by endpoint and workflow.\",\n          \"isCorrect\": false,\n          \"text\": \"CAP means we can ignore partitions\"\n        },\n        {\n          \"feedback\": \"Too simplistic. Strong consistency isn’t always “best”; it can harm availability/latency. The right choice depends on business semantics.\",\n          \"isCorrect\": false,\n          \"text\": \"Strong consistency is always best\"\n        },\n        {\n          \"feedback\": \"Misleading. Eventual consistency doesn’t mean “inconsistent forever.” With good conflict resolution and read strategies, replicas converge and user experience can be stable.\",\n          \"isCorrect\": false,\n          \"text\": \"Eventual consistency means random results\"\n        }\n      ],\n      \"question\": \"What’s the key principle we report up?\"\n    }\n  ]\n}",
      "outputTokens": 2042,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-cs-distributed-systems-consistency-1",
      "userPrompt": "LESSON_TITLE: Consistency in Distributed Systems\nLESSON_DESCRIPTION: Navigating consistency and availability trade-offs in distributed systems\nCHAPTER_TITLE: Distributed Data\nCOURSE_TITLE: System Design\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. CAP Theorem: The CAP theorem states you can only have two of three: Consistency, Availability, and Partition tolerance. Since network partitions happen, you're really choosing between C and A.\n2. Strong Consistency: Strong consistency means all nodes see the same data at the same time. Every read returns the most recent write. This requires coordination that can slow things down.\n3. Eventual Consistency: Eventual consistency means replicas will converge given enough time without new writes. Reads might return stale data temporarily, but the system stays available.\n4. Partition Handling: Network partitions occur when nodes can't communicate. The system must decide: reject requests (maintain consistency) or accept requests that might conflict (maintain availability).\n5. Quorum Systems: Quorum-based systems use voting. A write succeeds if enough replicas acknowledge it. Read quorum + write quorum > total nodes ensures reading at least one up-to-date copy.\n6. Conflict Resolution: Conflict resolution strategies handle divergent writes: last-write-wins, vector clocks, or application-specific merge logic. The right choice depends on your data semantics."
    },
    {
      "duration": 48849.45870799996,
      "inputTokens": 3113,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"\\\"{{NAME}}, signup conversion dropped 12% this week. The product didn’t change… but we did add a ‘Save your progress’ banner that mentions ‘you could lose your setup if you leave.’ It felt helpful. Now I’m worried it’s doing the opposite. What do we check first?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Before we ‘fix,’ isolate what actually changed and where the drop happens. A quick funnel cut + A/B rollback tells us whether the new message (or placement) is the cause.\",\n          \"isCorrect\": true,\n          \"text\": \"Compare funnel steps pre/post change\"\n        },\n        {\n          \"feedback\": \"Surveys are slow and people rationalize. You’ll miss the behavioral effect and waste time if the issue is simply where the drop occurs in the funnel.\",\n          \"isCorrect\": false,\n          \"text\": \"Run a user survey to ask why\"\n        },\n        {\n          \"feedback\": \"If the issue is framing or loss aversion, more benefits can still backfire. First diagnose where the friction increased.\",\n          \"isCorrect\": false,\n          \"text\": \"Add more benefit copy to balance it\"\n        },\n        {\n          \"feedback\": \"A bigger redesign adds variables. You’ll learn less, slower, and risk compounding the problem.\",\n          \"isCorrect\": false,\n          \"text\": \"Redesign the entire signup flow\"\n        }\n      ],\n      \"question\": \"What’s the best first move?\"\n    },\n    {\n      \"context\": \"\\\"Okay, funnel cut: the biggest drop is on the plan selection screen. The new banner sits above it. It says ‘Don’t lose your setup—finish signup now.’ If it’s behavioral, what’s the most likely mechanism?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Highlighting a potential loss can create anxiety and reactance, especially early in the journey when trust is low. People may avoid the situation entirely to avoid feeling ‘at risk.’\",\n          \"isCorrect\": true,\n          \"text\": \"Loss aversion is triggering avoidance\"\n        },\n        {\n          \"feedback\": \"Present bias is about preferring immediate rewards over future ones; here we’re adding urgency via loss language, not offering an immediate reward.\",\n          \"isCorrect\": false,\n          \"text\": \"Present bias: they want instant rewards\"\n        },\n        {\n          \"feedback\": \"Default effect would matter if a plan or choice is pre-selected. The issue appears before a default decision exists.\",\n          \"isCorrect\": false,\n          \"text\": \"Default effect: defaults are wrong\"\n        },\n        {\n          \"feedback\": \"Social proof would require cues about what others do. The banner is about personal loss, not norms.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof: they need popularity cues\"\n        }\n      ],\n      \"question\": \"Which principle best explains the drop?\"\n    },\n    {\n      \"context\": \"\\\"If it’s loss aversion, we still need urgency so people don’t abandon. How do we rewrite that banner so it motivates without spooking them?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Reframing into a gain and competence cue keeps motivation but reduces threat. You’re still encouraging completion, just not by implying danger or loss.\",\n          \"isCorrect\": true,\n          \"text\": \"Frame it as a benefit of finishing\"\n        },\n        {\n          \"feedback\": \"This intensifies threat. Stronger loss language often increases stress and can worsen abandonment, especially for new users.\",\n          \"isCorrect\": false,\n          \"text\": \"Make the loss message more explicit\"\n        },\n        {\n          \"feedback\": \"Guilt and shame can boost short-term compliance but hurt trust and long-term retention; also risky for brand perception.\",\n          \"isCorrect\": false,\n          \"text\": \"Use guilt: ‘Don’t waste what you did’\"\n        },\n        {\n          \"feedback\": \"Removing it may help, but you’d lose a chance to test a better frame. The question is how to keep intent without loss framing.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove the banner entirely\"\n        }\n      ],\n      \"question\": \"Which rewrite direction is best?\"\n    },\n    {\n      \"context\": \"\\\"Cool. Next: plan selection has three tiers. Right now nothing is pre-selected. People stall. We want more people on the mid-tier without forcing it. What’s the cleanest behavioral lever?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Setting a reasonable default (with clear ability to change) leverages default effects to reduce decision friction and shifts outcomes without removing choice.\",\n          \"isCorrect\": true,\n          \"text\": \"Preselect mid-tier as the default\"\n        },\n        {\n          \"feedback\": \"Hiding options is coercive and will likely create backlash, cancellations, and support tickets. It’s not a nudge; it’s dark pattern territory.\",\n          \"isCorrect\": false,\n          \"text\": \"Hide the cheapest option behind a link\"\n        },\n        {\n          \"feedback\": \"This adds complexity and can cause choice overload. More attributes rarely reduce stalling.\",\n          \"isCorrect\": false,\n          \"text\": \"Add more comparison details on tiers\"\n        },\n        {\n          \"feedback\": \"Discounts can work, but it’s not the cleanest behavioral lever and may train users to wait for promos; also changes pricing economics.\",\n          \"isCorrect\": false,\n          \"text\": \"Offer a limited-time discount pop-up\"\n        }\n      ],\n      \"question\": \"What should we change on plan selection?\"\n    },\n    {\n      \"context\": \"\\\"Legal is picky: if we preselect mid-tier, we need to keep it transparent. What’s the best way to do that while still benefiting from defaults?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Transparent defaults + easy switching preserves autonomy and trust. You still get the default effect because many won’t change it, but it’s defensible and user-friendly.\",\n          \"isCorrect\": true,\n          \"text\": \"Preselect + ‘You can change anytime’\"\n        },\n        {\n          \"feedback\": \"Hiding the ability to change makes it deceptive, increases chargebacks, and can violate consent norms.\",\n          \"isCorrect\": false,\n          \"text\": \"Preselect and hide ‘change’ controls\"\n        },\n        {\n          \"feedback\": \"Multiple preselected options isn’t possible; it adds confusion and breaks the point of a default.\",\n          \"isCorrect\": false,\n          \"text\": \"Preselect all tiers via carousel\"\n        },\n        {\n          \"feedback\": \"Calling it ‘Recommended’ can help, but without clear change affordance it can feel pushy. Transparency is the key requirement mentioned.\",\n          \"isCorrect\": false,\n          \"text\": \"Label it ‘Recommended’ only\"\n        }\n      ],\n      \"question\": \"How do we implement the default ethically?\"\n    },\n    {\n      \"context\": \"\\\"One more issue: users who choose annual save money long-term, but most pick monthly. We need a nudge that respects choice. Which behavioral approach fits best?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Present bias favors short-term pain avoidance. A commitment device (e.g., ‘Try annual with a 30-day switch-back guarantee’ or ‘lock in price’) reduces perceived risk and makes the future benefit feel safer now.\",\n          \"isCorrect\": true,\n          \"text\": \"Add a commitment device to annual\"\n        },\n        {\n          \"feedback\": \"Pure loss framing (‘you lose money monthly’) can backfire like earlier—creates threat and resentment rather than informed choice.\",\n          \"isCorrect\": false,\n          \"text\": \"Use stronger loss framing vs monthly\"\n        },\n        {\n          \"feedback\": \"Social proof can help, but if you don’t have strong, truthful data it’s risky; also it won’t directly solve present bias about upfront cost.\",\n          \"isCorrect\": false,\n          \"text\": \"Add ‘Most users choose annual’\"\n        },\n        {\n          \"feedback\": \"More features doesn’t address time-inconsistency; it may increase cognitive load instead of reducing the immediate barrier.\",\n          \"isCorrect\": false,\n          \"text\": \"Add more annual-only features to list\"\n        }\n      ],\n      \"question\": \"What’s the best nudge for annual plans?\"\n    },\n    {\n      \"context\": \"\\\"We shipped: benefit-framed banner, mid-tier default with clear change link, and an annual ‘switch back in 30 days’ promise. Conversion is up… but churn spiked for mid-tier. Support says people ‘didn’t mean to pick it.’ Oof. What do we adjust first?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. If people didn’t notice the default, the fix is salience + friction reduction to change, not removing choice. Make the selection step explicit and confirm the chosen plan before payment.\",\n          \"isCorrect\": true,\n          \"text\": \"Add explicit plan confirmation step\"\n        },\n        {\n          \"feedback\": \"Removing the default may drop conversion and doesn’t address the core issue: users didn’t realize the choice. Better to improve clarity and agency.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove the default entirely\"\n        },\n        {\n          \"feedback\": \"Burying pricing increases accidental signups and worsens churn/chargebacks. It’s the opposite of informed choice.\",\n          \"isCorrect\": false,\n          \"text\": \"Hide pricing until after account creation\"\n        },\n        {\n          \"feedback\": \"A longer trial can help retention, but it doesn’t fix accidental selection. You’ll just delay the churn and increase costs.\",\n          \"isCorrect\": false,\n          \"text\": \"Extend the trial to 30 days for all\"\n        }\n      ],\n      \"question\": \"How do we fix the churn spike?\"\n    },\n    {\n      \"context\": \"\\\"Plot twist: analytics shows something weird. New users on mobile are 3x more likely to end up mid-tier than desktop, and many never scroll the plan cards. That means our ‘default’ is effectively invisible on mobile. What’s the smartest next change?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. On mobile, the default is acting like a hidden preselection. You need a forced, visible choice (or a clear selector) so the user consciously picks—still can recommend mid-tier, but not silently.\",\n          \"isCorrect\": true,\n          \"text\": \"Make plan choice unavoidable & visible\"\n        },\n        {\n          \"feedback\": \"This doubles down on invisibility. Making the default even more automatic increases accidental selection and churn.\",\n          \"isCorrect\": false,\n          \"text\": \"Auto-advance with the preselected plan\"\n        },\n        {\n          \"feedback\": \"Removing mid-tier reduces revenue potential and doesn’t solve the real issue: users must see and understand the choice.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove mid-tier option on mobile\"\n        },\n        {\n          \"feedback\": \"Social proof can help, but if users aren’t seeing the choice, adding badges won’t fix the core usability/visibility problem.\",\n          \"isCorrect\": false,\n          \"text\": \"Add ‘Most popular’ badge only\"\n        }\n      ],\n      \"question\": \"What should we change given the mobile data?\"\n    },\n    {\n      \"context\": \"\\\"Alright, we added a clear, above-the-fold picker on mobile with ‘Recommended’ on mid-tier, plus a final confirmation screen that states the price and billing period. Churn normalized and conversion stayed strong. If you had to summarize the takeaway for the team, what is it?\\\"\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Behavioral design works best when nudges are aligned with user goals and paired with transparency and easy opt-out. Defaults and framing can help, but hidden or scary nudges create backlash and churn.\",\n          \"isCorrect\": true,\n          \"text\": \"Nudge with psychology + explicit consent\"\n        },\n        {\n          \"feedback\": \"Overgeneralizing. Loss framing can work in the right context; the lesson is about fit, ethics, and clarity—not banning a tool.\",\n          \"isCorrect\": false,\n          \"text\": \"Never use loss aversion in UX\"\n        },\n        {\n          \"feedback\": \"Discounts can help, but they’re not the core learning here. We solved it with framing, defaults, and commitment devices plus visibility.\",\n          \"isCorrect\": false,\n          \"text\": \"Only pricing incentives reliably change behavior\"\n        },\n        {\n          \"feedback\": \"Defaults matter, but so do framing, present bias, and social proof—and the twist showed defaults can become deceptive if not visible.\",\n          \"isCorrect\": false,\n          \"text\": \"Default effects are the only thing that matters\"\n        }\n      ],\n      \"question\": \"What’s the key principle we learned?\"\n    }\n  ]\n}",
      "outputTokens": 2208,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-economics-behavioral-design-1",
      "userPrompt": "LESSON_TITLE: Behavioral Design in Practice\nLESSON_DESCRIPTION: Applying behavioral economics principles to design products and systems that work with human psychology\nCHAPTER_TITLE: Applied Behavioral Economics\nCOURSE_TITLE: Product Psychology\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Loss Aversion: Loss aversion means losses hurt more than equivalent gains feel good — roughly twice as much. People will take irrational risks to avoid losses they wouldn't take to achieve gains.\n2. Framing Effects: Framing effects show that how you present options matters as much as what the options are. '90% survival rate' and '10% mortality rate' are logically identical but feel different.\n3. Default Effects: Default effects are powerful because people tend to stick with pre-selected options. Changing the default can dramatically change outcomes without restricting choice.\n4. Present Bias: Present bias makes us overvalue immediate rewards over future ones. We know we should save for retirement, but the money feels more valuable now. Commitment devices help.\n5. Social Proof: Social proof drives behavior — we look to others to decide what's appropriate. Showing that 'most people do X' is often more effective than explaining why X is good."
    },
    {
      "duration": 41271.82949999999,
      "inputTokens": 3204,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, a síntese do intermediário pro fármaco deu errado de novo. Era pra trocar o Br por OEt no nosso haleto… mas o GC tá cheio de subprodutos. O chefe quer um plano hoje: qual mecanismo a gente deve mirar pra prever o resultado e ajustar as condições?\",\n      \"options\": [\n        {\n          \"feedback\": \"Faz sentido: em orgânica, você prevê caminho pensando em nucleófilo/eletrofílo. Mas ainda falta escolher SN1 vs SN2 pelas condições e substrato.\",\n          \"isCorrect\": false,\n          \"text\": \"Começar por nucleófilo vs eletrofílo\"\n        },\n        {\n          \"feedback\": \"Certo. A escolha SN1 vs SN2 guia tudo: solvente, força do nucleófilo, tipo de substrato e até estereoquímica/efeitos colaterais.\",\n          \"isCorrect\": true,\n          \"text\": \"Decidir entre SN1 e SN2\"\n        },\n        {\n          \"feedback\": \"Estereoquímica ajuda a diagnosticar depois, mas primeiro precisamos prever qual caminho é plausível e ajustar condições pra evitar subprodutos.\",\n          \"isCorrect\": false,\n          \"text\": \"Olhar só a estereoquímica do produto\"\n        },\n        {\n          \"feedback\": \"Grupo de saída importa, mas aqui Br já é razoável. O maior impacto agora é o tipo de substrato/condições definindo SN1 ou SN2.\",\n          \"isCorrect\": false,\n          \"text\": \"Trocar o grupo de saída primeiro\"\n        }\n      ],\n      \"question\": \"Qual é a primeira decisão mecanística?\"\n    },\n    {\n      \"context\": \"O substrato é 2-bromobutano, e a gente usou etóxido de sódio em etanol. Eu tô vendo eliminação E2 competindo. Pensando só em substituição: o carbono é secundário… qual mecanismo de substituição parece mais provável nessas condições?\",\n      \"options\": [\n        {\n          \"feedback\": \"Com secundário e base/nucleófilo forte, SN2 pode ocorrer, mas E2 compete forte. Ainda assim, entre SN1 e SN2, SN2 tende a ser mais plausível aqui.\",\n          \"isCorrect\": true,\n          \"text\": \"SN2 (com competição de E2)\"\n        },\n        {\n          \"feedback\": \"SN1 pede formação de carbocátion e é favorecido por solvente prótico, ok, mas etóxido forte tende a puxar pra SN2/E2. SN1 não é o principal aqui.\",\n          \"isCorrect\": false,\n          \"text\": \"SN1, porque etanol é prótico\"\n        },\n        {\n          \"feedback\": \"Não existe “misto” como mecanismo único aqui; você escolhe o caminho dominante e ajusta condições pra empurrar SN2 e reduzir E2.\",\n          \"isCorrect\": false,\n          \"text\": \"Meio SN1 e meio SN2 ao mesmo tempo\"\n        },\n        {\n          \"feedback\": \"Brometo é um bom grupo de saída. O problema não é ele; é a competição entre substituição e eliminação em substrato secundário.\",\n          \"isCorrect\": false,\n          \"text\": \"Nenhum: Br é grupo de saída ruim\"\n        }\n      ],\n      \"question\": \"Qual mecanismo de substituição domina?\"\n    },\n    {\n      \"context\": \"Beleza, se é SN2 com E2 na cola… o chefe quer aumentar o rendimento de substituição. A gente não pode mudar o substrato, mas pode mudar solvente e nucleófilo. O que você mudaria primeiro pra favorecer SN2 e desincentivar E2?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. Solvente aprótico polar (DMSO/DMF/acetona) aumenta nucleofilicidade em SN2 e, com um nucleófilo menos básico (tipo I⁻/N3⁻/AcO⁻), reduz E2.\",\n          \"isCorrect\": true,\n          \"text\": \"Aprótico polar + nucleófilo menos básico\"\n        },\n        {\n          \"feedback\": \"Mais base forte e mais calor geralmente aumentam E2. Isso piora a mistura de subprodutos.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar a concentração de etóxido e aquecer\"\n        },\n        {\n          \"feedback\": \"Água/protico solva muito o nucleófilo e pode empurrar pra SN1/solvólise. E ainda pode gerar hidrólise competindo.\",\n          \"isCorrect\": false,\n          \"text\": \"Trocar etanol por água pra “ajudar”\"\n        },\n        {\n          \"feedback\": \"Diluição pode reduzir velocidade geral, mas não resolve o ponto principal: basicidade e solvente controlam SN2 vs E2 de forma mais decisiva.\",\n          \"isCorrect\": false,\n          \"text\": \"Só diluir bastante a reação\"\n        }\n      ],\n      \"question\": \"Qual ajuste favorece SN2 e reduz E2?\"\n    },\n    {\n      \"context\": \"Ok, vou sugerir acetona + iodeto (tipo NaI) pra fazer uma troca tipo Finkelstein e puxar SN2. Mas o QC perguntou de estereoquímica: se o nosso 2-bromobutano for enantiomericamente puro, o que a gente espera ver no produto se for SN2 mesmo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. SN2 é ataque por trás e dá inversão de configuração no centro quiral, então o produto sai com configuração invertida (se não houver racemização por outros caminhos).\",\n          \"isCorrect\": true,\n          \"text\": \"Inversão de configuração\"\n        },\n        {\n          \"feedback\": \"Retenção pura sugere outro caminho (dupla inversão, participação vizinha, etc.). SN2 típico não retém.\",\n          \"isCorrect\": false,\n          \"text\": \"Retenção de configuração\"\n        },\n        {\n          \"feedback\": \"Racemização é mais cara de SN1 (carbocátion planar). Em SN2, o ataque é direcionado e inverte.\",\n          \"isCorrect\": false,\n          \"text\": \"Mistura racêmica\"\n        },\n        {\n          \"feedback\": \"Estereoquímica não some: SN2 tem assinatura clara (inversão). “Sem relação” seria ignorar uma evidência-chave de mecanismo.\",\n          \"isCorrect\": false,\n          \"text\": \"Nada dá pra concluir pela estereoquímica\"\n        }\n      ],\n      \"question\": \"Qual assinatura estereoquímica indica SN2?\"\n    },\n    {\n      \"context\": \"Outra coisa: a equipe anterior tentou substituir um álcool secundário direto por OEt e foi um desastre. ‘Mas é o mesmo esqueleto’, eles disseram. Eu queria explicar por que álcool, do jeito que tá, não funciona bem como substrato de substituição. Qual é o ponto mecanístico?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. OH⁻ é base forte e grupo de saída ruim. Você precisa transformar em um bom grupo de saída (tosilato) ou protonar (H2O como saída).\",\n          \"isCorrect\": true,\n          \"text\": \"OH é grupo de saída ruim; precisa ativar\"\n        },\n        {\n          \"feedback\": \"Álcool pode ser nucleófilo fraco ou forte dependendo, mas o problema central aqui é ele sair. Sem bom grupo de saída, substituição emperra.\",\n          \"isCorrect\": false,\n          \"text\": \"Álcool é nucleófilo fraco demais\"\n        },\n        {\n          \"feedback\": \"Carbocátion não “aparece sempre”. Em muitos casos, especialmente primários/secundários, você tenta SN2 ou ativa o grupo de saída; SN1 é caso específico.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque sempre forma carbocátion e rearranja\"\n        },\n        {\n          \"feedback\": \"Oxidação pode acontecer, mas não é a razão geral do fracasso em substituição. O gargalo é a habilidade do grupo de saída.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque álcool oxida facilmente na reação\"\n        }\n      ],\n      \"question\": \"Por que álcool costuma falhar sem ativação?\"\n    },\n    {\n      \"context\": \"Então: se for álcool, podemos tosilá-lo. Mas o gerente perguntou ‘tosilato é só enfeite?’ Quero responder rápido: por que transformar OH em OTs ajuda tanto numa substituição?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. OTs (tosilato) sai como ânion estabilizado por ressonância; é uma base fraca e, portanto, um ótimo grupo de saída.\",\n          \"isCorrect\": true,\n          \"text\": \"OTs é base fraca e sai estabilizado\"\n        },\n        {\n          \"feedback\": \"Tosilação não “deixa mais positivo” por milagre; ela troca um grupo de saída ruim por um excelente, mudando a cinética/mecanismo possível.\",\n          \"isCorrect\": false,\n          \"text\": \"OTs deixa o carbono “mais positivo” sempre\"\n        },\n        {\n          \"feedback\": \"Nucleófilos fortes ajudam, mas sem bom grupo de saída o passo de saída/ataque não anda. OTs resolve o gargalo real.\",\n          \"isCorrect\": false,\n          \"text\": \"OTs só importa se o nucleófilo for fraco\"\n        },\n        {\n          \"feedback\": \"OTs não é oxidante. Ele é um substituinte que melhora a saída. Confundir função leva a escolhas ruins de reagente.\",\n          \"isCorrect\": false,\n          \"text\": \"OTs oxida o álcool e ativa\"\n        }\n      ],\n      \"question\": \"Qual a vantagem do tosilato?\"\n    },\n    {\n      \"context\": \"{{NAME}}, plot twist: acabei de ver a ficha do lote. Nosso ‘2-bromobutano’ veio com 20% de terc-butil brometo como impureza. Isso explica um pico estranho… Se tiver terc-butil brometo no meio, qual mecanismo de substituição vai explodir em paralelo em etanol?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. Terc-butil é terciário: SN2 é estéricamente bloqueado. Em solvente prótico como etanol, SN1 (solvólise) é muito favorecido, gerando mistura e possivelmente racemização (se quiral).\",\n          \"isCorrect\": true,\n          \"text\": \"SN1 (solvólise) no terciário\"\n        },\n        {\n          \"feedback\": \"SN2 em terciário é praticamente inviável por impedimento estérico. Apostar nisso te faz ignorar a impureza que está bagunçando tudo.\",\n          \"isCorrect\": false,\n          \"text\": \"SN2 no terciário, por ser rápido\"\n        },\n        {\n          \"feedback\": \"E1 pode ocorrer, mas em etanol e sem aquecimento forte, o SN1 compete pesado formando éter. O “explodir” aqui é a solvólise SN1.\",\n          \"isCorrect\": false,\n          \"text\": \"E1 exclusivamente\"\n        },\n        {\n          \"feedback\": \"Grupo de saída não é o problema: Br é bom. O problema é o tipo de substrato (terciário) que muda o mecanismo dominante.\",\n          \"isCorrect\": false,\n          \"text\": \"Nenhum: brometo não sai\"\n        }\n      ],\n      \"question\": \"Que mecanismo a impureza favorece?\"\n    },\n    {\n      \"context\": \"Então o plano é: purificar o haleto (tirar o terc-butil), mudar pra solvente aprótico e nucleófilo menos básico pra empurrar SN2 no secundário. Pra fechar a recomendação pro chefe: qual ‘regra prática’ você colocaria como takeaway do mecanismo de substituição aqui?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. Essa regra amarra substrato+solvente+nucleófilo+grupo de saída e prevê produto/estereoquímica: primário+Nu forte/aprótico → SN2 (inversão); terciário+prótico → SN1 (mistura); bons LG são bases fracas.\",\n          \"isCorrect\": true,\n          \"text\": \"Escolha por substrato/solvente/Nu/LG\"\n        },\n        {\n          \"feedback\": \"Nucleófilo forte não garante SN2: em terciário não rola, e em secundário pode virar E2. Precisa do conjunto de condições.\",\n          \"isCorrect\": false,\n          \"text\": \"Nucleófilo forte sempre dá SN2\"\n        },\n        {\n          \"feedback\": \"Solvente prótico pode favorecer SN1, mas não ‘sempre’. Primários ainda tendem a SN2, e a base/nucleófilo muda tudo.\",\n          \"isCorrect\": false,\n          \"text\": \"Solvente prótico sempre dá SN1\"\n        },\n        {\n          \"feedback\": \"Grupo de saída é crucial, mas sozinho não decide mecanismo. Substrato e solvente podem inverter totalmente o caminho.\",\n          \"isCorrect\": false,\n          \"text\": \"Só o grupo de saída define tudo\"\n        }\n      ],\n      \"question\": \"Qual regra resume melhor a tomada de decisão?\"\n    }\n  ]\n}",
      "outputTokens": 2470,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-chemistry-organic-reactions-1",
      "userPrompt": "LESSON_TITLE: Mecanismos de Substituicao\nLESSON_DESCRIPTION: Aplicando mecanismos de reacao organica para prever e otimizar sinteses quimicas\nCHAPTER_TITLE: Reacoes Organicas\nCOURSE_TITLE: Quimica Organica II\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Nucleofilos e Eletrofilos: Nucleofilos sao especies ricas em eletrons que doam pares de eletrons. Eletrofilos sao especies pobres em eletrons que aceitam. Reacoes organicas sao geralmente nucleofilos atacando eletrofilos.\n2. Mecanismo SN2: SN2 e um mecanismo concertado — o nucleofilo ataca enquanto o grupo de saida sai, em um unico passo. Funciona melhor com substratos primarios e nucleofilos fortes.\n3. Mecanismo SN1: SN1 ocorre em dois passos: primeiro o grupo de saida sai formando um carbocation, depois o nucleofilo ataca. Favorecido por substratos terciarios e solventes polares proticos.\n4. Estereoquimica: A estereoquimica revela o mecanismo. SN2 inverte a configuracao (ataque por tras). SN1 pode dar mistura racemicacon (carbocation planar atacado de ambos os lados).\n5. Grupos de Saida: Grupos de saida precisam ser estaveis apos sair. Bons grupos de saida sao bases fracas — haletos, tosilatos, agua protonada. Grupos de saida ruins sao bases fortes."
    },
    {
      "duration": 107460.17924999999,
      "inputTokens": 3183,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, el demo es mañana y el modelo de imágenes está fallando feo. En entrenamiento llegamos a 98% y en validación nos quedamos en 62%. Suena a sobreajuste total. Si no lo arreglamos hoy, el cliente nos va a cocinar.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Si el gap train/val es enorme, primero atacas sobreajuste con regularización/capacidad, no con trucos de optimización. Luego ya afinamos LR, etc.\",\n          \"isCorrect\": true,\n          \"text\": \"Priorizar reducir sobreajuste\"\n        },\n        {\n          \"feedback\": \"No es la primera palanca. Más capacidad suele empeorar el sobreajuste si el problema es generalización, no falta de representatividad.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar profundidad y filtros\"\n        },\n        {\n          \"feedback\": \"Con ese gap, el issue no es velocidad de entrenamiento. BatchNorm ayuda, pero no es el primer diagnóstico ni garantiza cerrar 36 puntos.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo meter BatchNorm en todo\"\n        },\n        {\n          \"feedback\": \"Transfer learning puede ayudar, pero antes confirmemos el régimen: si ya sobreajusta, congelar/regularizar suele ser el primer paso. Hacer TL sin plan puede no arreglar el gap.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar ya a transfer learning\"\n        }\n      ],\n      \"question\": \"¿Qué atacamos primero?\"\n    },\n    {\n      \"context\": \"Ok, entonces: nuestro dataset son 12k fotos de producto, variación de iluminación y fondo. La red actual es una CNN desde cero con muchas capas. Necesitamos una decisión concreta: ¿cómo la regularizamos sin matar rendimiento?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Dropout reduce co-adaptación y ayuda a generalizar, especialmente en capas densas o bloques finales; es una medida directa contra sobreajuste.\",\n          \"isCorrect\": true,\n          \"text\": \"Agregar Dropout en el bloque final\"\n        },\n        {\n          \"feedback\": \"Pooling reduce dimensión, pero no es una bala anti-overfitting por sí sola; puede perder señal útil si ya hay suficiente reducción.\",\n          \"isCorrect\": false,\n          \"text\": \"Duplicar el pooling en cada bloque\"\n        },\n        {\n          \"feedback\": \"ReLU no es una técnica de regularización; cambia dinámica de gradientes, pero no cierra un gap tan grande por sí sola.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar activación a ReLU\"\n        },\n        {\n          \"feedback\": \"Entrenar más suele empeorar el sobreajuste si ya estás memorizando; necesitarías early stopping, no solo más épocas.\",\n          \"isCorrect\": false,\n          \"text\": \"Entrenar más épocas\"\n        }\n      ],\n      \"question\": \"¿Qué cambio metemos ya para generalizar mejor?\"\n    },\n    {\n      \"context\": \"Bien. Otra cosa: la entrada es 256x256. La CNN tiene un par de capas densas enormes al final porque alguien quiso “más capacidad”. Sospecho que ahí se nos va medio overfitting.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Reemplazar densas grandes por Global Average Pooling reduce parámetros brutalmente y fuerza a usar mapas de características, mejorando generalización.\",\n          \"isCorrect\": true,\n          \"text\": \"Cambiar densas por Global Avg Pooling\"\n        },\n        {\n          \"feedback\": \"Más filtros aumentan parámetros/capacidad y pueden empeorar el sobreajuste si no controlas regularización.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar filtros para compensar\"\n        },\n        {\n          \"feedback\": \"Quitar pooling sube dimensión y parámetros en capas siguientes; suele empeorar el problema y además encarece cómputo.\",\n          \"isCorrect\": false,\n          \"text\": \"Quitar pooling para “no perder info”\"\n        },\n        {\n          \"feedback\": \"BatchNorm estabiliza, pero si el problema principal son millones de parámetros en densas, BN no lo arregla por sí solo.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo añadir BatchNorm antes de densas\"\n        }\n      ],\n      \"question\": \"¿Qué harías con el “head” del modelo?\"\n    },\n    {\n      \"context\": \"Ok, ahora entrenamiento: con los cambios, el loss baja pero hay inestabilidad; a veces se dispara y vuelve. Me suena a que el flujo de activaciones cambia por capa. ¿Metemos algo para estabilizar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. BatchNorm normaliza activaciones, estabiliza gradientes y permite entrenar más suave con LR razonables; además aporta regularización ligera.\",\n          \"isCorrect\": true,\n          \"text\": \"Añadir BatchNorm en bloques conv\"\n        },\n        {\n          \"feedback\": \"Dropout ayuda generalización, pero no arregla directamente inestabilidad de activaciones/gradientes; puede incluso aumentar ruido si ya está inestable.\",\n          \"isCorrect\": false,\n          \"text\": \"Subir Dropout al 0.7 en todo\"\n        },\n        {\n          \"feedback\": \"Más pooling cambia la arquitectura pero no ataca la causa típica de explosiones/inestabilidad; puedes perder precisión por exceso de reducción.\",\n          \"isCorrect\": false,\n          \"text\": \"Más pooling para “suavizar”\"\n        },\n        {\n          \"feedback\": \"ReLU es buena, pero si ya usas ReLU, el problema es más de distribución interna y optimización. Cambiar activación no es lo más directo.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar ReLU por tanh\"\n        }\n      ],\n      \"question\": \"¿Qué meterías para estabilizar el entrenamiento?\"\n    },\n    {\n      \"context\": \"Ya se ve mejor: train 91%, val 84%. Pero el cliente pidió que corra en un móvil. Latencia objetivo: <40 ms. Nuestra CNN sigue pesada. Necesitamos bajar cómputo sin romper accuracy.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Aumentar pooling/strides reduce resolución temprano y baja FLOPs; bien dosificado mantiene patrones útiles y recorta latencia.\",\n          \"isCorrect\": true,\n          \"text\": \"Ajustar strides/pooling para reducir FLOPs\"\n        },\n        {\n          \"feedback\": \"Transfer learning no garantiza menor latencia; muchas redes preentrenadas son pesadas. Hay que elegir arquitectura móvil o comprimir.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar a cualquier modelo preentrenado\"\n        },\n        {\n          \"feedback\": \"Más filtros aumenta costo y latencia. Va en contra de la restricción móvil.\",\n          \"isCorrect\": false,\n          \"text\": \"Subir filtros para mantener precisión\"\n        },\n        {\n          \"feedback\": \"BatchNorm ayuda a entrenar, pero en inferencia no reduce FLOPs de forma significativa; no es una estrategia de compresión.\",\n          \"isCorrect\": false,\n          \"text\": \"Meter más BatchNorm para acelerar\"\n        }\n      ],\n      \"question\": \"¿Cómo recortamos latencia de forma razonable?\"\n    },\n    {\n      \"context\": \"El PM está feliz… hasta que pregunta: “¿por qué falla justo con fotos en un fondo naranja?” Revisé: en entrenamiento casi no hay fondos naranjas. O sea, el modelo aprendió atajos del fondo. Necesitamos robustez ya.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Si el modelo usa correlaciones espurias (fondo), necesitas variar esos factores (augmentations/datos) para que aprenda rasgos del objeto, no del contexto.\",\n          \"isCorrect\": true,\n          \"text\": \"Aumentar diversidad de datos/augmentación\"\n        },\n        {\n          \"feedback\": \"Dropout ayuda, pero no crea ejemplos de fondos naranjas; si el sesgo viene del dataset, regularización sola no lo borra.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo subir Dropout\"\n        },\n        {\n          \"feedback\": \"Más pooling no arregla sesgo de datos; puede incluso borrar detalles útiles del producto.\",\n          \"isCorrect\": false,\n          \"text\": \"Más pooling para “ignorar fondo”\"\n        },\n        {\n          \"feedback\": \"BatchNorm no corrige un sesgo de distribución de entrenamiento; estabiliza entrenamiento, no reemplaza datos representativos.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo BatchNorm en entrada\"\n        }\n      ],\n      \"question\": \"¿Qué hacemos para no depender del fondo?\"\n    },\n    {\n      \"context\": \"Ok, pero hay otro giro: legal nos acaba de decir que no podemos usar esas 12k fotos para seguir entrenando. Solo nos dejan 800 imágenes nuevas con permisos claros. Con tan poco, entrenar desde cero vuelve a ser mala idea.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Con pocos datos, transfer learning es ideal: aprovechas features generales y ajustas capas finales; reduce riesgo de sobreajuste y acelera convergencia.\",\n          \"isCorrect\": true,\n          \"text\": \"Usar transfer learning con backbone preentrenado\"\n        },\n        {\n          \"feedback\": \"Entrenar desde cero con 800 imágenes casi seguro sobreajusta; aunque regularices, te faltará cobertura de variaciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Entrenar desde cero con más dropout\"\n        },\n        {\n          \"feedback\": \"BatchNorm no compensa falta de datos; además con batch pequeño puede ser ruidoso si no lo manejas bien.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo BatchNorm y listo\"\n        },\n        {\n          \"feedback\": \"Más pooling reduce capacidad espacial y puede degradar; no reemplaza el conocimiento previo que da un preentrenado.\",\n          \"isCorrect\": false,\n          \"text\": \"Arquitectura más agresiva con pooling\"\n        }\n      ],\n      \"question\": \"Con 800 imágenes, ¿qué estrategia eliges?\"\n    },\n    {\n      \"context\": \"Perfecto. Último detalle: ¿cómo lo configuramos? Si ajustamos todo el backbone con 800 imágenes, podemos arruinar features útiles. Pero si congelamos todo, quizá no se adapte al tipo de producto. Necesitamos equilibrio.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Congelas capas tempranas (features generales) y afinas las últimas (features específicas). Es el balance típico para pocos datos y cambio moderado de dominio.\",\n          \"isCorrect\": true,\n          \"text\": \"Congelar primeras capas y afinar las últimas\"\n        },\n        {\n          \"feedback\": \"Afinar todo con pocos datos aumenta riesgo de overfitting y catastrophic forgetting; requiere mucho cuidado y generalmente más datos.\",\n          \"isCorrect\": false,\n          \"text\": \"Afinar todo el modelo desde el inicio\"\n        },\n        {\n          \"feedback\": \"Congelar todo limita adaptación; si el dominio difiere, te quedas corto y la validación se estanca.\",\n          \"isCorrect\": false,\n          \"text\": \"Congelar todo y solo cambiar la capa final\"\n        },\n        {\n          \"feedback\": \"Quitar BatchNorm no es una regla general; puedes dejarla en modo inference o manejarla, pero el punto principal aquí es qué capas entrenar.\",\n          \"isCorrect\": false,\n          \"text\": \"Quitar BatchNorm para evitar ruido\"\n        }\n      ],\n      \"question\": \"¿Qué plan de fine-tuning aplicas?\"\n    },\n    {\n      \"context\": \"Listo, {{NAME}}: con backbone preentrenado, fine-tuning parcial, augmentación fuerte y un head liviano con GAP+Dropout, ya estamos en 86% val y la latencia bajó a 38 ms. El cliente pregunta qué aprendimos para el próximo proyecto.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Esa es la síntesis: elegir arquitectura y técnicas (conv/pooling, activaciones, dropout, BN, transfer) según datos, sesgos y restricciones (latencia), no por moda.\",\n          \"isCorrect\": true,\n          \"text\": \"Arquitectura = trade-offs datos, sesgo y costo\"\n        },\n        {\n          \"feedback\": \"No. “Más profundo” no es una estrategia universal; puede sobreajustar, aumentar latencia y complicar entrenamiento.\",\n          \"isCorrect\": false,\n          \"text\": \"Siempre hacerlo más profundo\"\n        },\n        {\n          \"feedback\": \"No. BatchNorm ayuda, pero no sustituye datos representativos ni decisiones de capacidad/latencia.\",\n          \"isCorrect\": false,\n          \"text\": \"BatchNorm es la solución a todo\"\n        },\n        {\n          \"feedback\": \"No. Transfer learning es potente, pero no siempre aplica (dominio muy distinto, restricciones, privacidad). Es una herramienta, no un comodín.\",\n          \"isCorrect\": false,\n          \"text\": \"Transfer learning siempre gana\"\n        }\n      ],\n      \"question\": \"¿Cuál es el takeaway principal?\"\n    }\n  ]\n}",
      "outputTokens": 2364,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-cs-neural-network-architecture-1",
      "userPrompt": "LESSON_TITLE: Arquitecturas de Deep Learning\nLESSON_DESCRIPTION: Disenando y optimizando arquitecturas de redes neuronales para problemas reales\nCHAPTER_TITLE: Arquitecturas de Redes Neuronales\nCOURSE_TITLE: Deep Learning Aplicado\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Capas Convolucionales: Las capas convolucionales detectan patrones locales usando filtros que se deslizan sobre la entrada. El mismo filtro se aplica en todas partes, lo que reduce parametros y captura patrones sin importar su posicion.\n2. Pooling: El pooling reduce la dimension espacial tomando el maximo o promedio de regiones. Esto hace la representacion mas compacta y algo invariante a pequenas traslaciones.\n3. Activaciones: Las funciones de activacion introducen no-linealidad. ReLU (max(0,x)) es popular por ser simple y evitar el problema del gradiente desvaneciente en capas profundas.\n4. Dropout: El dropout desactiva neuronas aleatoriamente durante el entrenamiento. Esto fuerza redundancia y reduce el sobreajuste — la red no puede depender de ninguna neurona especifica.\n5. Transfer Learning: El transfer learning usa redes pre-entrenadas en grandes datasets. Las capas tempranas aprenden patrones generales; las tardias se ajustan a tu tarea especifica.\n6. Batch Normalization: El batch normalization normaliza activaciones entre capas. Estabiliza el entrenamiento, permite tasas de aprendizaje mas altas, y actua como regularizador."
    },
    {
      "duration": 73834.99295799999,
      "inputTokens": 3162,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we’ve got 40 minutes before the exec review. The PM is claiming the new checkout flow “wins” because the dashboard shows p=0.04 on conversion. If we ship and it’s a fluke, we’re toast. If we don’t ship and it’s real, we look slow. What’s our first move?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Start by stating H0/H1 and the metric definition so the p-value has a clear meaning. Otherwise you can’t tell what was actually tested—or whether the test matches the decision.\",\n          \"isCorrect\": true,\n          \"text\": \"Clarify H0/H1 and primary metric first\"\n        },\n        {\n          \"feedback\": \"Not quite. A smaller alpha reduces Type I error but increases Type II error and needs to be set ahead of time. Changing thresholds post hoc is decision-based p-hacking.\",\n          \"isCorrect\": false,\n          \"text\": \"Lower alpha to 0.01 to be safer\"\n        },\n        {\n          \"feedback\": \"Not quite. p=0.04 already implies rejection at 0.05 for that specific test, but only if assumptions and setup were valid. The issue is what test, how many tests, and what effect size.\",\n          \"isCorrect\": false,\n          \"text\": \"Ship since p<0.05 is significant\"\n        },\n        {\n          \"feedback\": \"Not ideal. Re-running until it “stays significant” is basically fishing for significance. Better: audit design, power, multiple comparisons, and effect size, then decide next steps.\",\n          \"isCorrect\": false,\n          \"text\": \"Run it again until the p-value stabilizes\"\n        }\n      ],\n      \"question\": \"What do you do first?\"\n    },\n    {\n      \"context\": \"Okay, here’s what I see in the doc: primary metric is conversion. H0: no difference between variants. H1: variant changes conversion. They ran 12 metrics though—conversion, AOV, latency, drop-off, you name it—and highlighted the smallest p-value. How do we handle that?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Multiple comparisons inflate false positives. If they looked at many metrics and picked the smallest p, we need a correction (Bonferroni or FDR) or a pre-registered primary metric.\",\n          \"isCorrect\": true,\n          \"text\": \"Apply multiple-comparison correction\"\n        },\n        {\n          \"feedback\": \"Wrong. “Picking the best p-value” is exactly the problem—it increases Type I error. It turns one test into many hidden tests.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep conversion only since it’s business-y\"\n        },\n        {\n          \"feedback\": \"Wrong. A p-value doesn’t account for multiple testing unless you correct for it. 12 looks means the nominal 0.05 isn’t really 0.05 anymore.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore it; p-values already handle this\"\n        },\n        {\n          \"feedback\": \"Not the right fix. Confidence intervals don’t magically remove multiplicity; you still need to adjust interpretation or adjust intervals if you’re scanning many metrics.\",\n          \"isCorrect\": false,\n          \"text\": \"Switch to CIs so multiple tests don’t matter\"\n        }\n      ],\n      \"question\": \"What’s the right response to 12 metrics?\"\n    },\n    {\n      \"context\": \"Cool, so if we do a quick Bonferroni with 12 tests, alpha becomes about 0.0042. That p=0.04 wouldn’t pass. The PM is going to ask, “So does that mean there’s definitely no effect?” How do we answer without stepping in it?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Failing to reject H0 isn’t proof H0 is true. It may be underpowered or the effect smaller than detectable. We should talk about power and effect size, not certainty.\",\n          \"isCorrect\": true,\n          \"text\": \"Say: not enough evidence, not “no effect”\"\n        },\n        {\n          \"feedback\": \"Wrong. That’s a classic misinterpretation. You can’t conclude “no effect” just because p isn’t below a threshold—especially after correction and with unknown power.\",\n          \"isCorrect\": false,\n          \"text\": \"Say: correction proves it’s no effect\"\n        },\n        {\n          \"feedback\": \"Wrong. p-values don’t give P(H0 true). They’re P(data as extreme | H0). That wording will get shredded in the review.\",\n          \"isCorrect\": false,\n          \"text\": \"Say: p is probability H0 is true\"\n        },\n        {\n          \"feedback\": \"Not quite. “Still publish” ignores decision risk. The right next step is quantify uncertainty (CI), assess power, and decide whether more data is worth it.\",\n          \"isCorrect\": false,\n          \"text\": \"Say: it’s messy, but ship anyway\"\n        }\n      ],\n      \"question\": \"How do you explain the corrected non-significance?\"\n    },\n    {\n      \"context\": \"Now the PM says, “But the conversion lift is +0.2% and statistically significant in our dashboard earlier.” Our baseline is 3.0% conversion. Leadership cares about revenue impact and engineering cost. What do we focus on next?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Statistical significance isn’t practical significance. Translate +0.2% into absolute/relative lift, revenue, and compare to cost/risks. Show an effect size with CI.\",\n          \"isCorrect\": true,\n          \"text\": \"Assess practical significance + effect size CI\"\n        },\n        {\n          \"feedback\": \"Wrong. p-value alone doesn’t tell you business impact or reliability. With huge N, tiny effects can be ‘significant’ but meaningless.\",\n          \"isCorrect\": false,\n          \"text\": \"Focus on p-value; it already summarizes it\"\n        },\n        {\n          \"feedback\": \"Not enough. A ‘bigger sample’ may make tiny effects significant, but that doesn’t address whether it matters. You need an MDE or business threshold first.\",\n          \"isCorrect\": false,\n          \"text\": \"Increase sample to get a smaller p-value\"\n        },\n        {\n          \"feedback\": \"Wrong. Removing “outliers” in experiments often biases results unless pre-specified and justified. It can also look like manipulating the outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"Drop outliers to see if lift improves\"\n        }\n      ],\n      \"question\": \"What should we evaluate given +0.2% lift?\"\n    },\n    {\n      \"context\": \"I pulled counts: control 100,000 users, 3,000 conversions. variant 100,000 users, 3,200 conversions. So +200 conversions. But the experiment ran only 2 days and traffic is weird on weekends. PM asks if we can call it today. What’s the most defensible angle?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Short windows can be noisy and violate assumptions (seasonality). Emphasize uncertainty: compute CI for the lift, check stability across time segments, and ensure the test duration covers typical cycles.\",\n          \"isCorrect\": true,\n          \"text\": \"Quantify uncertainty; check time stability\"\n        },\n        {\n          \"feedback\": \"Wrong. Two days can be misleading if user mix changes. “Large N” doesn’t automatically protect you from bias or non-stationarity.\",\n          \"isCorrect\": false,\n          \"text\": \"Call it; N=200k is always enough\"\n        },\n        {\n          \"feedback\": \"Wrong. Stopping early based on significance inflates Type I error unless you planned sequential testing. This is a common way teams fool themselves.\",\n          \"isCorrect\": false,\n          \"text\": \"Stop only if p<0.05 at any check\"\n        },\n        {\n          \"feedback\": \"Not quite. Segmenting can be useful, but if you slice repeatedly without adjustment you create multiple comparisons again. Do it carefully and predefine what “stable” means.\",\n          \"isCorrect\": false,\n          \"text\": \"Split into many segments until one is clear\"\n        }\n      ],\n      \"question\": \"How do we make a defensible call with 2 days?\"\n    },\n    {\n      \"context\": \"One more thing: I checked the planning doc. They expected a +1% absolute lift and powered the test for that. If the true lift is +0.2%, what does that imply about Type II error and what we should recommend?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Power was high for +1% but likely low for +0.2%. That means a higher Type II error risk for small effects—so non-significance wouldn’t be informative, and detecting +0.2% reliably would require more sample/time.\",\n          \"isCorrect\": true,\n          \"text\": \"Low power for small effects; need more data\"\n        },\n        {\n          \"feedback\": \"Wrong. Underpowered studies miss real effects; they don’t create false positives (that’s Type I). The big risk here is failing to detect a real small lift.\",\n          \"isCorrect\": false,\n          \"text\": \"It means Type I error is higher now\"\n        },\n        {\n          \"feedback\": \"Wrong. This mixes up concepts. Power is P(reject H0 | H1 true). It doesn’t mean “p-value should be small.” You can have real effects with p>0.05 in low power.\",\n          \"isCorrect\": false,\n          \"text\": \"It means p-values should be smaller\"\n        },\n        {\n          \"feedback\": \"Not necessarily. You can design for smaller MDE, but you must decide if +0.2% is worth detecting. If it’s not practically meaningful, don’t chase significance.\",\n          \"isCorrect\": false,\n          \"text\": \"It means we should test even smaller metrics\"\n        }\n      ],\n      \"question\": \"What does the power plan imply about a +0.2% true lift?\"\n    },\n    {\n      \"context\": \"Okay, I’m drafting the slide: ‘After correcting for multiple metrics, conversion is not significant; observed lift +0.2% (CI includes 0); test duration too short for weekly seasonality; current design powered for +1% so small lifts uncertain.’ PM pings: “Can you just say the p-value is 4%, so there’s a 96% chance it works?” What do you reply?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. p-value is P(data as extreme | H0), not P(H1 true). Translate it into what it actually means and pivot to effect size + CI + decision thresholds.\",\n          \"isCorrect\": true,\n          \"text\": \"Correct the p-value interpretation plainly\"\n        },\n        {\n          \"feedback\": \"Wrong. That’s exactly the misinterpretation. It will mislead leadership into thinking we have near-certainty, which p-values do not provide.\",\n          \"isCorrect\": false,\n          \"text\": \"Agree; 96% chance the variant wins\"\n        },\n        {\n          \"feedback\": \"Wrong. p-values aren’t “chance the result is noise.” They’re conditional on H0. Better to explain properly and avoid overclaiming.\",\n          \"isCorrect\": false,\n          \"text\": \"Say: p is chance the result is noise\"\n        },\n        {\n          \"feedback\": \"Not great. Dodging invites someone else to oversimplify. A crisp correction builds trust and keeps the decision grounded in evidence.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore the question and keep the slide technical\"\n        }\n      ],\n      \"question\": \"How do you handle the “96% chance it works” claim?\"\n    },\n    {\n      \"context\": \"New message from data engineering: “Heads up—about 15% of variant users were accidentally served the control experience due to a caching bug. Logging still labeled them as variant.” So our assignment is contaminated. This is… not in the PM’s doc. What do we do right now?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Misclassification biases the estimated effect toward zero and breaks assumptions. We need to fix logging, re-estimate using actual exposure (if recoverable), and likely rerun. This is the kind of twist that makes p-values meaningless.\",\n          \"isCorrect\": true,\n          \"text\": \"Audit exposure; redo analysis / rerun test\"\n        },\n        {\n          \"feedback\": \"Wrong. You can’t ‘correct’ contamination by just loosening alpha. The data generating process is wrong; changing thresholds won’t fix biased labels.\",\n          \"isCorrect\": false,\n          \"text\": \"Just use alpha=0.10 to compensate\"\n        },\n        {\n          \"feedback\": \"Wrong. Dropping users post hoc can introduce bias unless you can identify true exposure cleanly. The right move is reconstruct actual treatment assignment or rerun.\",\n          \"isCorrect\": false,\n          \"text\": \"Exclude 15% at random to clean it\"\n        },\n        {\n          \"feedback\": \"Not quite. Shipping based on corrupted assignment is risky. This problem affects validity, not just precision—so it can mislead in either direction.\",\n          \"isCorrect\": false,\n          \"text\": \"Ship; contamination only makes it conservative\"\n        }\n      ],\n      \"question\": \"What’s the move after discovering contamination?\"\n    },\n    {\n      \"context\": \"Alright, we can reconstruct exposure from edge logs for most users. If we redo it as an intent-to-treat vs as-treated analysis, leadership will ask for a single recommendation. Given everything—multiplicity, power, practical impact, and the logging bug—what’s the clean conclusion for today’s meeting?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. The defensible takeaway: current evidence is inconclusive due to validity issues and small practical effect; fix instrumentation, predefine primary metric and decision threshold, run long enough for seasonality, and power for the minimum meaningful lift.\",\n          \"isCorrect\": true,\n          \"text\": \"Don’t ship yet; rerun with proper design\"\n        },\n        {\n          \"feedback\": \"Wrong. A single uncorrected p-value from a contaminated test isn’t enough to justify rollout. This ignores Type I risk, multiplicity, and validity problems.\",\n          \"isCorrect\": false,\n          \"text\": \"Ship now; initial p=0.04 is good enough\"\n        },\n        {\n          \"feedback\": \"Wrong. Saying “no effect” overstates what we know. With contamination and low power for small lifts, we can’t conclude absence—only insufficient evidence.\",\n          \"isCorrect\": false,\n          \"text\": \"Cancel; conclude the idea doesn’t work\"\n        },\n        {\n          \"feedback\": \"Not ideal. Partial rollout is still a decision; without valid evidence you may deploy a change with unknown impact. Better to rerun or use a limited, monitored ramp only after measurement is fixed.\",\n          \"isCorrect\": false,\n          \"text\": \"Roll out to 10% and see what happens\"\n        }\n      ],\n      \"question\": \"What do we recommend in the exec review?\"\n    }\n  ]\n}",
      "outputTokens": 2718,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-statistics-hypothesis-testing-1",
      "userPrompt": "LESSON_TITLE: Hypothesis Testing in Practice\nLESSON_DESCRIPTION: Applying statistical hypothesis testing correctly to make sound data-driven decisions\nCHAPTER_TITLE: Statistical Inference\nCOURSE_TITLE: Applied Statistics\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Null Hypothesis: The null hypothesis (H0) is the default assumption of no effect. We try to reject it. The p-value measures how surprising the data would be IF the null were true.\n2. P-Value Meaning: A p-value is NOT the probability the null is true. It's the probability of seeing data this extreme (or more) if the null IS true. A common and dangerous misinterpretation.\n3. Error Types: Type I error (false positive) is rejecting a true null. Type II error (false negative) is failing to reject a false null. You can't minimize both — there's a trade-off.\n4. Statistical Power: Statistical power is the probability of detecting a real effect. It depends on sample size, effect size, and significance level. Low-powered studies miss real effects.\n5. Practical Significance: Statistical significance doesn't mean practical significance. A huge sample can detect tiny effects that don't matter in practice. Always consider effect size.\n6. Multiple Comparisons: Multiple comparisons inflate Type I errors. Testing 20 hypotheses at alpha=0.05 expects one false positive. Corrections like Bonferroni or FDR control this."
    },
    {
      "duration": 36049.21754200006,
      "inputTokens": 3131,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, the VP just Slacked me: 'Can we use quantum to speed up our weekly route-planning and cut fuel 30%?' Sales already promised a pilot in 6 weeks. I need your gut-check: do we even say yes to 'quantum will solve it'?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. Start by framing quantum as problem-specific, not a universal accelerator. Otherwise we’ll design a pilot that can’t possibly succeed.\",\n          \"isCorrect\": true,\n          \"text\": \"Say it depends on problem structure\"\n        },\n        {\n          \"feedback\": \"Not quite. Quantum parallelism isn’t 'try all routes and read them out'—measurement gives one result. Without interference, this doesn’t work.\",\n          \"isCorrect\": false,\n          \"text\": \"Promise quantum tries all routes at once\"\n        },\n        {\n          \"feedback\": \"Too absolute. Some optimization problems may see advantage, but not automatically, and likely not in 6 weeks on real hardware.\",\n          \"isCorrect\": false,\n          \"text\": \"Say quantum can’t help optimization\"\n        },\n        {\n          \"feedback\": \"Risky. The first move is scoping: what kind of optimization, what constraints, and what success metric. Hardware choice comes after.\",\n          \"isCorrect\": false,\n          \"text\": \"Ask for a quantum vendor and move fast\"\n        }\n      ],\n      \"question\": \"What’s the best first response?\"\n    },\n    {\n      \"context\": \"Okay, so we need to scope it. The team’s problem is basically: 'given 2,000 deliveries, time windows, driver breaks, traffic… minimize cost.' They want 'quantum parallelism' to brute-force routes. How do we correct that idea without sounding like a buzzkill?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. Parallelism is real, but you can’t extract all evaluations. You need interference (and the right oracle structure) to amplify good solutions.\",\n          \"isCorrect\": true,\n          \"text\": \"Explain readout limits + interference need\"\n        },\n        {\n          \"feedback\": \"Wrong. Decoherence is real, but it’s not the conceptual reason brute force fails; measurement limits and algorithm design are.\",\n          \"isCorrect\": false,\n          \"text\": \"Blame decoherence and end it there\"\n        },\n        {\n          \"feedback\": \"Misleading. Superposition isn’t 'both at once' in a way you can inspect. The point is amplitudes that interfere before measurement.\",\n          \"isCorrect\": false,\n          \"text\": \"Say it’s just 'both 0 and 1' magic\"\n        },\n        {\n          \"feedback\": \"Too optimistic. There is no guarantee. Many instances won’t beat classical heuristics, especially with constraints and noise.\",\n          \"isCorrect\": false,\n          \"text\": \"Say quantum guarantees global optimum\"\n        }\n      ],\n      \"question\": \"How do we frame 'quantum parallelism' correctly?\"\n    },\n    {\n      \"context\": \"Cool. Next: they asked for a demo on real hardware. We have access to a 50–100 qubit noisy device. They’re imagining encoding the whole routing instance directly. What do we say about feasibility?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. NISQ devices are noisy; large constrained routing needs far more qubits and depth than we can run reliably. We should target toy instances or hybrid demos.\",\n          \"isCorrect\": true,\n          \"text\": \"NISQ can’t hold full problem; do scaled demo\"\n        },\n        {\n          \"feedback\": \"Wrong. Entanglement doesn’t magically remove qubit requirements. Encoding still costs qubits and circuit depth.\",\n          \"isCorrect\": false,\n          \"text\": \"Entangle qubits to fit 2,000 stops\"\n        },\n        {\n          \"feedback\": \"Wrong. Measurement doesn’t 'freeze' decoherence; noise acts during the computation. Mid-circuit measurement can help some schemes, but not fix scale.\",\n          \"isCorrect\": false,\n          \"text\": \"Measure more often to prevent noise\"\n        },\n        {\n          \"feedback\": \"Too vague. Hardware choice isn’t the core issue; algorithm depth vs coherence time and qubit count vs encoding are the blockers.\",\n          \"isCorrect\": false,\n          \"text\": \"Say 'hardware isn’t mature' and stop\"\n        }\n      ],\n      \"question\": \"What’s the most accurate feasibility message?\"\n    },\n    {\n      \"context\": \"They push back: 'Can’t error correction fix the noise? Just add it.' They’re treating it like adding retries in cloud computing. How do we respond?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. Fault tolerance needs huge overhead (many physical per logical qubit) plus long coherent operation. We don’t have that scale today.\",\n          \"isCorrect\": true,\n          \"text\": \"Explain QEC overhead and fault-tolerance gap\"\n        },\n        {\n          \"feedback\": \"Wrong. QEC doesn’t multiply speed; it increases qubit count and gate operations to protect information.\",\n          \"isCorrect\": false,\n          \"text\": \"Say QEC makes it exponentially faster\"\n        },\n        {\n          \"feedback\": \"Wrong. QEC doesn’t depend on 'internet speed'; it depends on physical error rates, code distance, and architecture.\",\n          \"isCorrect\": false,\n          \"text\": \"Say we just need faster connections\"\n        },\n        {\n          \"feedback\": \"Not quite. Some near-term error mitigation exists, but it’s not the same as full QEC and won’t enable massive routing instances.\",\n          \"isCorrect\": false,\n          \"text\": \"Say mitigation equals full error correction\"\n        }\n      ],\n      \"question\": \"How do we handle the 'just add error correction' idea?\"\n    },\n    {\n      \"context\": \"Alright. Let’s salvage this with a pilot that still looks credible. If we can’t solve the whole thing, what’s a realistic 'quantum helps' angle for optimization that won’t get us roasted?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. A realistic pilot is comparing hybrid approaches on small instances and focusing on benchmarking vs strong classical baselines, not claiming universal speedups.\",\n          \"isCorrect\": true,\n          \"text\": \"Hybrid small-instance benchmark vs baselines\"\n        },\n        {\n          \"feedback\": \"Wrong. Grover helps unstructured search; routing isn’t a simple unstructured search oracle, and noise/depth still bite.\",\n          \"isCorrect\": false,\n          \"text\": \"Use Grover to speed up routing directly\"\n        },\n        {\n          \"feedback\": \"Wrong. Shor’s is for factoring/discrete log, not vehicle routing. Using it here is a category error.\",\n          \"isCorrect\": false,\n          \"text\": \"Use Shor’s algorithm on the routes\"\n        },\n        {\n          \"feedback\": \"Wrong. 'More entanglement' isn’t a plan. Entanglement is a resource, but without the right algorithm/encoding it doesn’t deliver advantage.\",\n          \"isCorrect\": false,\n          \"text\": \"Maximize entanglement and hope\"\n        }\n      ],\n      \"question\": \"What pilot approach is most defensible?\"\n    },\n    {\n      \"context\": \"Good. Now we need to pick a storyline: what are we actually demonstrating? The VP wants a simple message: 'quantum did something useful.' What do we anchor on so it’s honest?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. The honest win is a measured result: performance/quality tradeoffs on constrained toy problems, plus a clear statement of scaling limits and next steps.\",\n          \"isCorrect\": true,\n          \"text\": \"Show measurable tradeoffs + scaling caveats\"\n        },\n        {\n          \"feedback\": \"Wrong. A black-box 'quantum beats classical' claim will collapse under scrutiny unless the baseline is strong and the instance isn’t cherry-picked.\",\n          \"isCorrect\": false,\n          \"text\": \"Cherry-pick an easy case to 'win'\"\n        },\n        {\n          \"feedback\": \"Wrong. Superposition isn’t customer value. Customers care about solution quality, runtime, cost, and robustness.\",\n          \"isCorrect\": false,\n          \"text\": \"Market 'superposition' as the advantage\"\n        },\n        {\n          \"feedback\": \"Wrong. Ignoring decoherence is how demos die live. Noise must be part of the plan, especially on real devices.\",\n          \"isCorrect\": false,\n          \"text\": \"Avoid discussing noise to keep it simple\"\n        }\n      ],\n      \"question\": \"What should the demo narrative focus on?\"\n    },\n    {\n      \"context\": \"We’re drafting the slide. I wrote: 'Quantum evaluates all routes simultaneously.' You’re going to hate that. What’s a better phrasing that’s still understandable?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. This keeps the truth: amplitudes + interference are the mechanism, and readout gives sampled outcomes, not a full table of answers.\",\n          \"isCorrect\": true,\n          \"text\": \"‘Interference steers probability to good answers’\"\n        },\n        {\n          \"feedback\": \"Wrong. That’s the classic misconception. It implies we can read all results, which is exactly what measurement prevents.\",\n          \"isCorrect\": false,\n          \"text\": \"‘It computes all answers at once’\"\n        },\n        {\n          \"feedback\": \"Wrong. Entanglement correlates qubits; it doesn’t mean 'instant answers.' This would trigger instant skepticism.\",\n          \"isCorrect\": false,\n          \"text\": \"‘Entanglement makes solutions appear instantly’\"\n        },\n        {\n          \"feedback\": \"Wrong. Decoherence is the opposite of a feature; it destroys the quantum state we need for computation.\",\n          \"isCorrect\": false,\n          \"text\": \"‘Decoherence helps it converge’\"\n        }\n      ],\n      \"question\": \"Which phrasing best avoids the parallelism trap?\"\n    },\n    {\n      \"context\": \"Quick twist, {{NAME}}: Legal forwarded the customer’s data policy. We can’t send real routing data to any external quantum cloud. That nukes the vendor demo. How do we adapt without faking results?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. Use synthetic or anonymized instances and keep the evaluation pipeline local. We can still test algorithms honestly without violating policy.\",\n          \"isCorrect\": true,\n          \"text\": \"Use synthetic/anonymized data + local eval\"\n        },\n        {\n          \"feedback\": \"Wrong. That’s a compliance nightmare. 'It’s just routes' still counts as sensitive operational data.\",\n          \"isCorrect\": false,\n          \"text\": \"Upload anyway; routes aren’t personal data\"\n        },\n        {\n          \"feedback\": \"Wrong. You still need to show something repeatable. Hand-waving 'theory says so' won’t satisfy leadership or customers.\",\n          \"isCorrect\": false,\n          \"text\": \"Skip experiments and present theory only\"\n        },\n        {\n          \"feedback\": \"Wrong. Screenshots without reproducibility will backfire. Better to run a clean, shareable benchmark with controlled data.\",\n          \"isCorrect\": false,\n          \"text\": \"Use vendor screenshots as proof\"\n        }\n      ],\n      \"question\": \"What’s the best compliance-safe pivot?\"\n    },\n    {\n      \"context\": \"Okay, last step: we need to message the VP. We can propose a 6-week pilot, but we need to set expectations: where quantum helps, where it doesn’t, and why. What do you want to say in the closing note?\\n\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. This ties everything together: quantum is problem-specific, relies on interference, is limited by decoherence today, and QEC overhead makes full-scale routing unrealistic short-term.\",\n          \"isCorrect\": true,\n          \"text\": \"Promise a scoped hybrid pilot + clear limits\"\n        },\n        {\n          \"feedback\": \"Wrong. Overpromising 'advantage' invites failure and distrust. Better to define measurable goals and uncertainty up front.\",\n          \"isCorrect\": false,\n          \"text\": \"Guarantee advantage to secure budget\"\n        },\n        {\n          \"feedback\": \"Wrong. Dismissing it outright loses a chance to learn and de-risks nothing. A scoped benchmark is the rational middle path.\",\n          \"isCorrect\": false,\n          \"text\": \"Kill the idea; say quantum is hype\"\n        },\n        {\n          \"feedback\": \"Wrong. Jargon without outcomes won’t land. Leadership needs what we’ll test, success metrics, and what would change our mind.\",\n          \"isCorrect\": false,\n          \"text\": \"Send a technical essay on qubits\"\n        }\n      ],\n      \"question\": \"What’s the best VP message?\"\n    }\n  ]\n}",
      "outputTokens": 2255,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-physics-quantum-computing-basics-1",
      "userPrompt": "LESSON_TITLE: Quantum Computing Fundamentals\nLESSON_DESCRIPTION: Understanding quantum computing capabilities and limitations for practical problem-solving\nCHAPTER_TITLE: Quantum Information\nCOURSE_TITLE: Quantum Computing Fundamentals\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Superposition: Qubits can exist in superposition — a weighted combination of 0 and 1 states. This isn't 'both at once' — it's a probability amplitude that interferes before measurement.\n2. Entanglement: Entanglement links qubits so measuring one instantly determines the other, regardless of distance. This correlation is a resource for quantum algorithms.\n3. Quantum Parallelism: Quantum parallelism lets algorithms evaluate functions on all inputs simultaneously. But you can only read one result — the art is using interference to amplify the right answer.\n4. Decoherence: Decoherence destroys quantum information when qubits interact with their environment. Real qubits are noisy and maintain coherence only briefly.\n5. Error Correction: Quantum error correction encodes logical qubits in many physical qubits. The overhead is huge — thousands of physical qubits per logical qubit for fault tolerance.\n6. Where Quantum Helps: Quantum advantage requires the right problem type. Factoring, simulation, and certain optimization problems benefit. Most classical algorithms won't be replaced."
    },
    {
      "duration": 40044.163,
      "inputTokens": 3181,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, o checkout tá falhando em produção. A taxa de erro subiu pra 18% e o time de suporte tá recebendo print de “pedido criado, mas pagamento recusado… e o carrinho esvaziou”. A gente tem Pedidos, Pagamentos e Estoque separados. Por onde você começa?\",\n      \"options\": [\n        {\n          \"feedback\": \"Boa. Antes de mexer na arquitetura, precisamos enxergar o caminho da requisição e onde quebra. Tracing + logs correlacionados dão o “filme” do pedido entre serviços.\",\n          \"isCorrect\": true,\n          \"text\": \"Checar tracing e logs correlacionados\"\n        },\n        {\n          \"feedback\": \"Pode aliviar carga, mas é chute. Sem entender o fluxo, você pode escalar o serviço errado e mascarar a causa raiz.\",\n          \"isCorrect\": false,\n          \"text\": \"Escalar Pagamentos pra mais pods\"\n        },\n        {\n          \"feedback\": \"Rollback pode ser necessário, mas primeiro confirme se a regressão veio do deploy. Sem evidência, você perde tempo e pode reintroduzir bugs antigos.\",\n          \"isCorrect\": false,\n          \"text\": \"Rollback imediato do último deploy\"\n        },\n        {\n          \"feedback\": \"Trocar pra monólito agora é reação extrema e não resolve o incidente. Microserviços exigem observabilidade pra diagnosticar.\",\n          \"isCorrect\": false,\n          \"text\": \"Planejar voltar pro monólito agora\"\n        }\n      ],\n      \"question\": \"Qual o primeiro passo mais eficaz?\"\n    },\n    {\n      \"context\": \"Achei um trace. Pedidos chama Pagamentos via REST e, na sequência, chama Estoque. O span de Pagamentos demora 9–12s e às vezes dá timeout. Pedidos fica preso e a fila de requisições cresce. O que você ajusta primeiro pra evitar falha em cascata?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. Timeouts curtos + circuit breaker evitam que Pedidos fique aguardando indefinidamente e derrube o sistema inteiro. Fallback pode marcar pedido como “pendente de pagamento”.\",\n          \"isCorrect\": true,\n          \"text\": \"Timeout + circuit breaker em Pedidos\"\n        },\n        {\n          \"feedback\": \"Retry sem limites piora tempestade de requisições quando Pagamentos está lento. Retry só com backoff e dentro de uma estratégia de resiliência.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar retry infinito em Pedidos\"\n        },\n        {\n          \"feedback\": \"Batch pode reduzir chamadas, mas não resolve o travamento imediato nem a latência de Pagamentos. Primeiro contenha o efeito cascata.\",\n          \"isCorrect\": false,\n          \"text\": \"Juntar chamadas em batch pra Pagamentos\"\n        },\n        {\n          \"feedback\": \"Migrar o banco é grande demais pro incidente e não ataca o problema: dependência síncrona lenta e sem proteções.\",\n          \"isCorrect\": false,\n          \"text\": \"Unificar banco de Pedidos e Pagamentos\"\n        }\n      ],\n      \"question\": \"Como conter a cascata de falhas agora?\"\n    },\n    {\n      \"context\": \"Ok, com timeout e breaker o checkout não “congela” mais. Só que agora temos pedidos ficando como “PENDENTE” quando Pagamentos falha. O diretor quer: “ou confirma tudo ou desfaz tudo”. Como lidar com isso em microserviços sem cair em transação distribuída?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso é o caminho típico: saga/orquestração ou coreografia com compensações. Você aceita consistência eventual e define ações de desfazer (ex.: liberar reserva de estoque).\",\n          \"isCorrect\": true,\n          \"text\": \"Implementar saga com ações compensatórias\"\n        },\n        {\n          \"feedback\": \"2PC/XA em microserviços aumenta acoplamento e fragilidade, além de ser difícil de operar. Geralmente evitado.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar 2PC/XA entre os bancos\"\n        },\n        {\n          \"feedback\": \"Resolver tudo num único serviço vira um “mini-monólito” e perde autonomia. Pode até ser válido em alguns domínios, mas aqui é fuga do trade-off sem análise.\",\n          \"isCorrect\": false,\n          \"text\": \"Mover Pagamentos pra dentro de Pedidos\"\n        },\n        {\n          \"feedback\": \"“Reprocessar até dar certo” pode cobrar cliente duas vezes ou criar inconsistências. Precisa de idempotência e fluxo controlado, não torcida.\",\n          \"isCorrect\": false,\n          \"text\": \"Reprocessar automaticamente até aprovar\"\n        }\n      ],\n      \"question\": \"Qual abordagem mantém autonomia e coerência?\"\n    },\n    {\n      \"context\": \"Beleza, vamos de saga. Só que o time de Estoque diz: “a gente não quer receber chamada síncrona de Pedidos, isso derruba a gente quando o tráfego sobe”. Eles sugerem eventos. Qual desenho reduz acoplamento e melhora resiliência?\",\n      \"options\": [\n        {\n          \"feedback\": \"Certo. Publicar evento e consumir de forma assíncrona reduz dependência em tempo real e evita travar o fluxo. Você paga com eventual consistency e necessidade de idempotência.\",\n          \"isCorrect\": true,\n          \"text\": \"Pedidos publica evento; Estoque consome\"\n        },\n        {\n          \"feedback\": \"GRPC pode ser mais rápido, mas continua síncrono: ainda há risco de cascata e acoplamento temporal.\",\n          \"isCorrect\": false,\n          \"text\": \"Trocar REST por gRPC e manter síncrono\"\n        },\n        {\n          \"feedback\": \"Um “serviço de banco” é limite técnico, não de domínio. Vira gargalo e quebra o princípio de limites por negócio.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar serviço “Banco de Dados” comum\"\n        },\n        {\n          \"feedback\": \"Compartilhar o mesmo banco elimina fronteiras e cria acoplamento forte. Você troca problemas de consistência por problemas de governança e evolução.\",\n          \"isCorrect\": false,\n          \"text\": \"Compartilhar o banco entre os serviços\"\n        }\n      ],\n      \"question\": \"Qual desenho de comunicação faz mais sentido?\"\n    },\n    {\n      \"context\": \"Certo, evento assíncrono. Só que agora surgiu um bug: alguns pedidos acabam com estoque reservado duas vezes. Nos logs, vejo reentrega de mensagem na fila. Como você evita duplicidade sem quebrar o modelo assíncrono?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. Em sistemas com at-least-once, duplicatas acontecem. Consumidor idempotente (chave de dedupe, estado, outbox/inbox) garante processamento seguro.\",\n          \"isCorrect\": true,\n          \"text\": \"Tornar o consumidor idempotente\"\n        },\n        {\n          \"feedback\": \"“Exactly-once” costuma ser caro/limitado e não elimina duplicatas ponta a ponta. Ainda precisa idempotência no consumidor.\",\n          \"isCorrect\": false,\n          \"text\": \"Configurar fila pra exactly-once e pronto\"\n        },\n        {\n          \"feedback\": \"Desligar retry pode perder mensagens e criar buracos no fluxo. Melhor aceitar reentrega e lidar corretamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Desativar retries na fila\"\n        },\n        {\n          \"feedback\": \"Voltar ao síncrono reintroduz acoplamento temporal e risco de cascata. O problema é semântica de entrega, não “evento vs REST”.\",\n          \"isCorrect\": false,\n          \"text\": \"Voltar pra chamada síncrona no Estoque\"\n        }\n      ],\n      \"question\": \"Como lidar com reentrega e duplicatas?\"\n    },\n    {\n      \"context\": \"Agora a saga funciona, eventos ok, idempotência ok. Mas o suporte ainda reclama: “às vezes o cliente vê ‘aprovado’, mas o e-mail diz ‘pendente’”. A gente precisa enxergar o fluxo inteiro. O que você prioriza pra observabilidade real?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfeito. Tracing distribuído com correlation IDs + logs centralizados e métricas por etapa da saga permitem entender divergências entre serviços e tempos/erros por hop.\",\n          \"isCorrect\": true,\n          \"text\": \"Tracing distribuído + correlation IDs\"\n        },\n        {\n          \"feedback\": \"Logs locais ajudam pouco: você não correlaciona entre serviços e perde contexto quando tem múltiplas instâncias.\",\n          \"isCorrect\": false,\n          \"text\": \"Apenas logs locais em cada serviço\"\n        },\n        {\n          \"feedback\": \"Aumentar nível de log sem correlação vira ruído e custo. O problema é conectar eventos do mesmo pedido, não só “logar mais”.\",\n          \"isCorrect\": false,\n          \"text\": \"Colocar log DEBUG em tudo\"\n        },\n        {\n          \"feedback\": \"Um dashboard genérico sem tracing e IDs não explica causação. Métricas são necessárias, mas não suficientes sozinhas.\",\n          \"isCorrect\": false,\n          \"text\": \"Só dashboard de CPU/memória por serviço\"\n        }\n      ],\n      \"question\": \"O que dá visibilidade ponta a ponta?\"\n    },\n    {\n      \"context\": \"Plot twist, {{NAME}}: olhando os traces, Pagamentos não tá lento sempre. Quando fica lento, é porque ele chama… Pedidos pra validar cupom. Ou seja: Pedidos -> Pagamentos -> Pedidos. Um loop síncrono lindo. Qual a melhor correção arquitetural?\",\n      \"options\": [\n        {\n          \"feedback\": \"Certo. Quebre a dependência circular: extraia um serviço de domínio (Promoções/Cupons) ou replique dado necessário. Dependências devem seguir capacidades de negócio, não conveniência.\",\n          \"isCorrect\": true,\n          \"text\": \"Criar serviço de Cupons e remover o loop\"\n        },\n        {\n          \"feedback\": \"Aumentar timeout só prolonga o sofrimento e piora cascata. Loop continua existindo.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar timeouts pra 30s\"\n        },\n        {\n          \"feedback\": \"Colocar tudo num único serviço resolve o loop, mas destrói limites e deploy independente. Só se a análise de domínio indicar que realmente é um único contexto.\",\n          \"isCorrect\": false,\n          \"text\": \"Fundir Pedidos e Pagamentos num serviço só\"\n        },\n        {\n          \"feedback\": \"Retry com backoff reduz pico, mas não remove o acoplamento circular nem a causa da latência intermitente.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar retries com backoff no loop\"\n        }\n      ],\n      \"question\": \"Como quebrar o ciclo sem perder autonomia?\"\n    },\n    {\n      \"context\": \"Boa. Separando Cupons, o checkout estabilizou e a latência caiu. Agora precisamos fechar o post-mortem: qual principal takeaway você colocaria pra evitar repetir isso em microserviços?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso. Microserviços funcionam quando limites seguem o domínio, comunicação e dados aceitam consistência eventual, e resiliência/observabilidade são primeira classe. Sem isso, vira monólito distribuído.\",\n          \"isCorrect\": true,\n          \"text\": \"Evitar monólito distribuído: limites+resiliência\"\n        },\n        {\n          \"feedback\": \"Microserviços não são “sempre ruins”; o ponto é conhecer trade-offs e operar bem. O incidente veio de dependências e falta de proteções, não do conceito em si.\",\n          \"isCorrect\": false,\n          \"text\": \"Microserviços são sempre uma má ideia\"\n        },\n        {\n          \"feedback\": \"Async ajuda, mas não resolve tudo: ainda precisa idempotência, sagas, observabilidade e bons limites. Caso contrário, vira caos silencioso.\",\n          \"isCorrect\": false,\n          \"text\": \"Tudo deve ser assíncrono sempre\"\n        },\n        {\n          \"feedback\": \"Compartilhar banco simplifica no curto prazo, mas aumenta acoplamento e conflitos de evolução. Não é a lição central aqui.\",\n          \"isCorrect\": false,\n          \"text\": \"Compartilhar banco é o segredo da estabilidade\"\n        }\n      ],\n      \"question\": \"Qual lição resume melhor o que aconteceu?\"\n    }\n  ]\n}",
      "outputTokens": 2262,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-cs-microservices-architecture-1",
      "userPrompt": "LESSON_TITLE: Microservicos na Pratica\nLESSON_DESCRIPTION: Projetando e implementando arquiteturas de microservicos com consciencia dos trade-offs\nCHAPTER_TITLE: Arquitetura de Software\nCOURSE_TITLE: Engenharia de Software Avancada\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Definicao de Microservicos: Microservicos sao servicos pequenos e independentes que fazem uma coisa bem. Cada um pode ser desenvolvido, implantado e escalado separadamente.\n2. Limites de Servico: Limites de servico devem seguir dominios de negocio, nao camadas tecnicas. Um servico de 'Pedidos' faz sentido; um servico de 'Banco de Dados' nao.\n3. Comunicacao: A comunicacao entre servicos pode ser sincrona (REST, gRPC) ou assincrona (filas, eventos). Assincrona e mais resiliente mas mais complexa de debugar.\n4. Dados Descentralizados: Dados descentralizados significam que cada servico tem seu banco. Consistencia eventual e a realidade — transacoes distribuidas sao dificeis e devem ser evitadas.\n5. Resiliencia: Falhas em cascata acontecem quando um servico lento trava outros. Circuit breakers, timeouts e fallbacks sao essenciais para resiliencia.\n6. Observabilidade: Observabilidade requer logs centralizados, metricas e tracing distribuido. Sem isso, debugar problemas em producao e quase impossivel."
    },
    {
      "duration": 39546.30999999994,
      "inputTokens": 3171,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, el director comercial acaba de pedir “el punto de precio perfecto” para el nuevo plan. Tenemos datos de demanda y un costo variable por usuario. Si lo sacamos mal, nos revientan el margen. ¿Por dónde arrancamos sin inventarnos cosas?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: primero defines la función objetivo (ganancia) y las variables, y luego impones restricciones. Sin ese modelo, derivar es puro ruido.\",\n          \"isCorrect\": true,\n          \"text\": \"Modelar: ganancia vs. precio\"\n        },\n        {\n          \"feedback\": \"No del todo: derivar sin una función bien planteada puede optimizar algo equivocado (p. ej., ingresos en vez de ganancia). Primero modelo.\",\n          \"isCorrect\": false,\n          \"text\": \"Derivar la demanda directo y ya\"\n        },\n        {\n          \"feedback\": \"Eso solo sirve para un chequeo rápido, pero no garantiza óptimo ni incorpora costo. Necesitamos cálculo y modelo.\",\n          \"isCorrect\": false,\n          \"text\": \"Elegir el precio por benchmark\"\n        },\n        {\n          \"feedback\": \"Una simulación puede ayudar después, pero si el modelo está mal, simulas basura. Primero función objetivo y restricciones.\",\n          \"isCorrect\": false,\n          \"text\": \"Simular precios al azar\"\n        }\n      ],\n      \"question\": \"¿Cuál es el primer paso correcto?\"\n    },\n    {\n      \"context\": \"Ok, entonces: demanda estimada q(p)=1200−30p (usuarios/mes), con p en USD. Costo variable c=8 USD por usuario. Sin costos fijos por ahora. ¿Qué función objetivo maximizamos?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: ganancia = (precio − costo unitario)·cantidad. Aquí: π(p)=(p−8)(1200−30p).\",\n          \"isCorrect\": true,\n          \"text\": \"π(p)=(p−8)(1200−30p)\"\n        },\n        {\n          \"feedback\": \"Eso es ingresos, no ganancia. Ignora el costo variable, y el óptimo puede moverse bastante.\",\n          \"isCorrect\": false,\n          \"text\": \"R(p)=p(1200−30p)\"\n        },\n        {\n          \"feedback\": \"Eso minimiza costo total, pero el objetivo del negocio es maximizar ganancia con el precio como decisión.\",\n          \"isCorrect\": false,\n          \"text\": \"C(p)=8(1200−30p)\"\n        },\n        {\n          \"feedback\": \"Eso es ganancia “por usuario”, pero no incorpora cuántos usuarios compras con ese precio. Falta multiplicar por q(p).\",\n          \"isCorrect\": false,\n          \"text\": \"π(p)=p−8\"\n        }\n      ],\n      \"question\": \"¿Qué objetivo representa la ganancia mensual?\"\n    },\n    {\n      \"context\": \"Perfecto. Ahora necesito el precio óptimo. La gente siempre se confunde: punto crítico no significa máximo. ¿Qué hacemos con π(p)?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: hallas puntos críticos resolviendo π'(p)=0 (y revisas si hay derivada). Luego clasificas con segunda derivada o análisis.\",\n          \"isCorrect\": true,\n          \"text\": \"Calcular π'(p)=0 para críticos\"\n        },\n        {\n          \"feedback\": \"Un punto crítico no siempre es máximo; sin prueba puede ser mínimo o punto de inflexión. Falta clasificar.\",\n          \"isCorrect\": false,\n          \"text\": \"Elegir donde π'(p)=0 y listo\"\n        },\n        {\n          \"feedback\": \"Graficar ayuda, pero no es un método confiable/preciso para reportar un óptimo. Mejor cálculo y verificación.\",\n          \"isCorrect\": false,\n          \"text\": \"Graficar π(p) y mirar el pico\"\n        },\n        {\n          \"feedback\": \"Segunda derivada se usa en puntos críticos. Primero necesitas encontrarlos con π'(p)=0.\",\n          \"isCorrect\": false,\n          \"text\": \"Ir directo a π''(p)\"\n        }\n      ],\n      \"question\": \"¿Cuál es el siguiente paso para encontrar el óptimo?\"\n    },\n    {\n      \"context\": \"Ya derivé: π(p)=(p−8)(1200−30p)=−30p^2+1440p−9600. Entonces π'(p)=−60p+1440. Me da p=24. ¿Cómo confirmamos si es máximo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: π''(p)=−60<0, así que en el punto crítico hay máximo local (y aquí será el máximo relevante si el dominio lo permite).\",\n          \"isCorrect\": true,\n          \"text\": \"Usar prueba de 2ª derivada\"\n        },\n        {\n          \"feedback\": \"Que π'=0 solo da candidato. Podría no ser máximo si cambia el dominio o si fuera un punto plano raro en otros casos.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque π'(24)=0 ya es máximo\"\n        },\n        {\n          \"feedback\": \"Comparar con p=0 y p=40 sin justificar dominio es incompleto. Primero define el intervalo factible y luego sí, extremos globales.\",\n          \"isCorrect\": false,\n          \"text\": \"Comparar con valores al azar\"\n        },\n        {\n          \"feedback\": \"Que sea cuadrática no elimina la necesidad de concluir el tipo. Además, el signo de la segunda derivada te da la clasificación formal.\",\n          \"isCorrect\": false,\n          \"text\": \"No hace falta, es una parábola\"\n        }\n      ],\n      \"question\": \"¿Cómo verificas el tipo de extremo en p=24?\"\n    },\n    {\n      \"context\": \"Bien. Pero legal me mete una restricción: “el precio debe estar entre 10 y 30 USD”. Y el director quiere el mejor precio global en ese rango. ¿Qué no podemos olvidar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: en extremos globales en un intervalo cerrado, revisas puntos críticos dentro y también los extremos p=10 y p=30.\",\n          \"isCorrect\": true,\n          \"text\": \"Evaluar en p=10, p=30 y críticos\"\n        },\n        {\n          \"feedback\": \"Si el crítico estuviera fuera del rango, el óptimo puede caer en un borde. Siempre hay que revisar extremos del dominio.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo usar el punto crítico\"\n        },\n        {\n          \"feedback\": \"La segunda derivada clasifica localmente; no compara con los bordes. Para global necesitas evaluar candidatos y extremos.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo mirar el signo de π''\"\n        },\n        {\n          \"feedback\": \"Graficar puede engañar y no reemplaza evaluar candidatos. Además el reporte necesita números concretos.\",\n          \"isCorrect\": false,\n          \"text\": \"Graficar en el rango y listo\"\n        }\n      ],\n      \"question\": \"¿Qué debes hacer para el máximo global en [10,30]?\"\n    },\n    {\n      \"context\": \"Ok, evalúo: π(24)=? y también π(10), π(30). Pero el equipo de marketing dice: “si p<12, se disparan las devoluciones y el costo unitario sube a 11”. O sea, el costo depende del precio. ¿Cómo lo modelamos sin romper todo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: cambió el modelo. Definir π(p) por tramos (c=11 si p<12, c=8 si p≥12) y optimizar en cada tramo con sus dominios.\",\n          \"isCorrect\": true,\n          \"text\": \"Función por tramos y optimizar cada una\"\n        },\n        {\n          \"feedback\": \"Promediar es tentador, pero distorsiona el óptimo porque la ganancia cambia de forma no lineal cerca del umbral.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar costo promedio 9.5 y ya\"\n        },\n        {\n          \"feedback\": \"Ignorar el cambio de costo hace que el “óptimo” sea irrealizable o subóptimo. El modelo debe reflejar la realidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorarlo: es “caso borde”\"\n        },\n        {\n          \"feedback\": \"Cambiar la demanda no arregla el hecho de que el costo cambió. Tienes dos efectos distintos; aquí te dieron explícito el costo por tramos.\",\n          \"isCorrect\": false,\n          \"text\": \"Meter el efecto en q(p) y listo\"\n        }\n      ],\n      \"question\": \"¿Cómo ajustas el modelo con costo dependiente de p?\"\n    },\n    {\n      \"context\": \"Listo, lo hago por tramos. Ahora el COO aparece con otra bomba: “además del precio, podemos elegir gasto en ads a. La demanda sería q(p,a)=1200−30p+20a, pero el gasto cuesta a^2 al mes. Y solo tenemos presupuesto fijo: p·q(p,a)=revenue=20000”. O sea, optimizar ganancia con restricción de ingresos. ¿Qué herramienta toca?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: es optimización con restricción de igualdad en dos variables. Usas multiplicadores de Lagrange: ∇π = λ∇g con g(p,a)=p·q−20000.\",\n          \"isCorrect\": true,\n          \"text\": \"Multiplicadores de Lagrange\"\n        },\n        {\n          \"feedback\": \"Derivar “por separado” ignora la restricción acoplada entre p y a. Necesitas imponerla formalmente (Lagrange o sustitución).\",\n          \"isCorrect\": false,\n          \"text\": \"Derivar en p y en a por separado\"\n        },\n        {\n          \"feedback\": \"Probar combos puede funcionar pero no garantiza óptimo ni es defendible. Aquí hay estructura matemática clara para explotar.\",\n          \"isCorrect\": false,\n          \"text\": \"Hacer búsqueda por grilla\"\n        },\n        {\n          \"feedback\": \"La segunda derivada sirve tras encontrar candidatos; pero primero hay que incorporar la restricción revenue=20000.\",\n          \"isCorrect\": false,\n          \"text\": \"Segunda derivada y ya\"\n        }\n      ],\n      \"question\": \"¿Qué método usas con restricción revenue=20000?\"\n    },\n    {\n      \"context\": \"Ok, armé L(p,a,λ)=π(p,a)+λ(p(1200−30p+20a)−20000), con π=(p−8)q−a^2. Pero mira esto: Finanzas acaba de decir que el “revenue=20000” NO era restricción dura, era una meta. Si pasamos de 20000, ok; si quedamos por debajo, hay penalización 3(20000−revenue). Plot twist total. ¿Qué hacemos ahora?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: ya no es restricción de igualdad; es función objetivo con penalización (piecewise con max(0,20000−revenue)). Se reformula y luego optimizas con derivadas/casos.\",\n          \"isCorrect\": true,\n          \"text\": \"Reformular con penalización y casos\"\n        },\n        {\n          \"feedback\": \"Mantener Lagrange fuerza revenue=20000, pero la meta permite revenue>20000. Eso puede cambiar el óptimo totalmente.\",\n          \"isCorrect\": false,\n          \"text\": \"Seguir con Lagrange igual\"\n        },\n        {\n          \"feedback\": \"Ignorar la penalización te da una solución que puede quedar bajo la meta y salir carísima en el criterio real.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorar la meta y maximizar π\"\n        },\n        {\n          \"feedback\": \"Redondear no resuelve el cambio conceptual: pasaste de restricción a objetivo con penalización. Primero reformula, luego calculas.\",\n          \"isCorrect\": false,\n          \"text\": \"Elegir lo más cercano a 20000\"\n        }\n      ],\n      \"question\": \"Con esa “meta”, ¿cómo se plantea el problema?\"\n    },\n    {\n      \"context\": \"Perfecto, {{NAME}}. Entonces: primero modelamos bien (objetivo real + restricciones reales), luego sacamos candidatos (críticos / casos), y al final validamos globalmente en el dominio. Si lo resumimos para el director en una frase, ¿qué le dirías para que no nos cambie el problema otra vez a mitad?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto: captura la idea central: buen modelado + candidatos con derivadas + verificación (bordes/restricciones) antes de decidir.\",\n          \"isCorrect\": true,\n          \"text\": \"Modelo correcto, luego optimizo y verifico\"\n        },\n        {\n          \"feedback\": \"“Derivar” sin contexto no evita errores de modelo ni revisa bordes/restricciones. El proceso es más que una derivada.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo necesito derivar y ya\"\n        },\n        {\n          \"feedback\": \"La intuición ayuda, pero no reemplaza evaluar críticos, bordes y restricciones. Se necesita un método defendible.\",\n          \"isCorrect\": false,\n          \"text\": \"Decidimos por intuición y validamos\"\n        },\n        {\n          \"feedback\": \"Lagrange solo aplica a restricciones de igualdad; y aun así necesitas modelar y verificar. No es una bala de plata universal.\",\n          \"isCorrect\": false,\n          \"text\": \"Siempre se resuelve con Lagrange\"\n        }\n      ],\n      \"question\": \"¿Cuál es el takeaway clave para cerrar?\"\n    }\n  ]\n}",
      "outputTokens": 2539,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-math-calculus-optimization-1",
      "userPrompt": "LESSON_TITLE: Optimizacion con Calculo\nLESSON_DESCRIPTION: Aplicando tecnicas de calculo para encontrar optimos en problemas de ingenieria y negocios\nCHAPTER_TITLE: Aplicaciones del Calculo\nCOURSE_TITLE: Calculo para Ingenieria\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Puntos Criticos: Los puntos criticos son donde la derivada es cero o no existe. Son CANDIDATOS a extremos — no todos los puntos criticos son maximos o minimos.\n2. Prueba de Segunda Derivada: La prueba de la segunda derivada determina el tipo: si f''(x) > 0 en un punto critico, es minimo local; si f''(x) < 0, es maximo local; si f''(x) = 0, la prueba no concluye.\n3. Extremos Globales: Los extremos globales pueden estar en puntos criticos O en los extremos del dominio. Siempre evalua tambien los bordes del intervalo.\n4. Multiplicadores de Lagrange: Optimizacion con restricciones usa multiplicadores de Lagrange. Maximizar f(x,y) sujeto a g(x,y)=0 requiere que los gradientes sean paralelos.\n5. Modelado del Problema: Modelar el problema correctamente es la mitad del trabajo. Define la funcion objetivo, identifica las restricciones, y expresa todo en terminos de las variables relevantes."
    }
  ],
  "taskId": "activity-story"
}
