{
  "generatedAt": "2026-01-17T15:45:53.202Z",
  "modelId": "anthropic/claude-haiku-4.5",
  "outputs": [
    {
      "duration": 31565.603165999986,
      "inputTokens": 4218,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"Hey {{NAME}}, we've got a problem. The payment processing pipeline is crashing in production, but our tests pass. I'm looking at the logs — it's getting data from the legacy API that's sometimes returning an object with a `balance` property, sometimes returning null. Then somewhere downstream, code is calling `.toFixed(2)` on it.\",\n      \"options\": [\n        {\n          \"feedback\": \"The API works as designed — it's the contract that's unclear. The real issue is that we're not expressing this variability in our types so TypeScript can warn us about null operations.\",\n          \"isCorrect\": false,\n          \"text\": \"The legacy API has a bug\"\n        },\n        {\n          \"feedback\": \"Exactly. By not declaring that balance could be null, we're writing code that assumes it's always a number. TypeScript could catch this at compile time if we told it balance might not exist.\",\n          \"isCorrect\": true,\n          \"text\": \"We don't know the possible types the balance property could be\"\n        },\n        {\n          \"feedback\": \"True, but that's a symptom, not the root cause. The real problem is our types don't reflect reality. Even perfect tests can't save us if the code doesn't express what's actually possible.\",\n          \"isCorrect\": false,\n          \"text\": \"The tests aren't realistic enough\"\n        },\n        {\n          \"feedback\": \"Error handling helps, but it's reactive. Type safety is proactive — we'd catch this problem before running any code if types properly expressed the possibility of null.\",\n          \"isCorrect\": false,\n          \"text\": \"We need to add more error handling everywhere\"\n        }\n      ],\n      \"question\": \"What's the core issue here that type safety would have caught?\"\n    },\n    {\n      \"context\": \"Right. So I've been digging into this interface we got from the API team. They're giving us data like this: sometimes `{ balance: 1500.50 }` and sometimes `{ balance: null }`. I've already typed it as `interface Payment { balance: number }`. How should we change this to match reality?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. This union type tells TypeScript 'balance might be a number OR it might be null.' Now TypeScript will force us to check for null before calling methods on it.\",\n          \"isCorrect\": true,\n          \"text\": \"balance: number | null\"\n        },\n        {\n          \"feedback\": \"That defeats the purpose of TypeScript entirely. 'any' disables type checking. We'd still crash in production because TypeScript wouldn't warn us about the null case.\",\n          \"isCorrect\": false,\n          \"text\": \"balance: any\"\n        },\n        {\n          \"feedback\": \"That means the property might not exist at all (undefined), which is different from the API returning null for the value. The API always includes balance, but it's null sometimes.\",\n          \"isCorrect\": false,\n          \"text\": \"balance?: number\"\n        },\n        {\n          \"feedback\": \"The API specifically returns null, not undefined. This is more permissive than reality and muddles the actual contract. Stick to what the API actually does.\",\n          \"isCorrect\": false,\n          \"text\": \"balance: number | undefined | null\"\n        }\n      ],\n      \"question\": \"What's the right way to type the balance property?\"\n    },\n    {\n      \"context\": \"Okay, I've updated the interface to `balance: number | null`. Now TypeScript is yelling at me everywhere — 'Object is possibly null' on every `.toFixed(2)` call. That's actually what we want, right? But how do we fix it? Do we just slap `!` on it to tell TypeScript to shut up?\",\n      \"options\": [\n        {\n          \"feedback\": \"That's just silencing the warning without solving the problem. You'd still crash if balance is null. The ! assertion tells TypeScript to trust you — but you'd be lying.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes, just add ! to bypass TypeScript\"\n        },\n        {\n          \"feedback\": \"Right. This is type narrowing. Once we check 'if (balance !== null)', TypeScript knows balance is a number inside that block. That's when we can safely call .toFixed(2).\",\n          \"isCorrect\": true,\n          \"text\": \"No, we need to check if balance is null first\"\n        },\n        {\n          \"feedback\": \"That brings us back to square one. We'd be ignoring the real contract from the API. The type system exists to help us face reality, not hide from it.\",\n          \"isCorrect\": false,\n          \"text\": \"Change balance back to just number\"\n        },\n        {\n          \"feedback\": \"'unknown' is even stricter — it would require more checks before we can do anything with balance. We already know it's a number or null, so 'number | null' is the right type.\",\n          \"isCorrect\": false,\n          \"text\": \"Use unknown instead to be safer\"\n        }\n      ],\n      \"question\": \"Should we use the non-null assertion (!) to fix this?\"\n    },\n    {\n      \"context\": \"Good. So I've added the null check. But {{NAME}}, I'm realizing we do this same pattern all over the codebase — checking for null, validating objects, checking if properties exist. We keep writing the same guard logic everywhere. What if we extract this into a reusable function?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. A type guard returns a type predicate like 'value is Payment'. After the function returns true, TypeScript knows the type is narrowed. Reusable AND type-safe.\",\n          \"isCorrect\": true,\n          \"text\": \"A type guard function with a type predicate\"\n        },\n        {\n          \"feedback\": \"That works logically but TypeScript won't understand the result. After calling it, TypeScript still sees 'number | null', not a narrowed type. You lose the type safety benefit.\",\n          \"isCorrect\": false,\n          \"text\": \"A regular utility function with if-checks\"\n        },\n        {\n          \"feedback\": \"That's what we'd write without TypeScript thinking. The whole point is to teach TypeScript what the result means. A type predicate makes that explicit.\",\n          \"isCorrect\": false,\n          \"text\": \"Just a boolean function that returns true/false\"\n        },\n        {\n          \"feedback\": \"That could help, but it doesn't solve the 'reusable type narrowing' problem specifically. We need something that speaks TypeScript's language — a type guard.\",\n          \"isCorrect\": false,\n          \"text\": \"A generic validation library\"\n        }\n      ],\n      \"question\": \"What tool would let us write this once and reuse it safely?\"\n    },\n    {\n      \"context\": \"So I wrote a type guard: `function isValidPayment(data: unknown): data is Payment { /* check */ }`. That's clever because I can throw any data at it and if it returns true, TypeScript knows it's a Payment. But {{NAME}}, what if the API gives us different payment types? Some from one system, some from another? Do we need a separate guard for each?\",\n      \"options\": [\n        {\n          \"feedback\": \"That works but defeats the purpose of reusability. You'd end up with `isPaymentTypeA`, `isPaymentTypeB`, etc. Not scalable and lots of duplicate logic.\",\n          \"isCorrect\": false,\n          \"text\": \"Write a separate type guard for each payment type\"\n        },\n        {\n          \"feedback\": \"A generic guard like `function isType<T>(data: unknown, schema: Schema<T>): data is T` lets you pass the shape to validate. One guard, infinite types. That's the power of generics.\",\n          \"isCorrect\": true,\n          \"text\": \"Use a generic type guard that works with any structure\"\n        },\n        {\n          \"feedback\": \"'any' disables type checking completely. You'd accept anything and lose the benefit of type narrowing. That defeats the entire goal here.\",\n          \"isCorrect\": false,\n          \"text\": \"Use 'any' to accept anything\"\n        },\n        {\n          \"feedback\": \"'unknown' is fine for the input, but you need to narrow it. A generic guard lets you do that narrowing and express the shape you're checking for.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep them all as 'unknown' and check at runtime\"\n        }\n      ],\n      \"question\": \"How would you handle multiple payment types generically?\"\n    },\n    {\n      \"context\": \"We've been working through this for a while now. I just realized — the payments are working, null checks are in place, and the type guards are handling different payment structures. But {{NAME}}, I'm looking at the logs from this morning and there's this one transaction that came through as a completely different shape. It has 'amount' instead of 'balance', and the timestamp is a string instead of a Date. Our payment system didn't reject it — it just... silently ignored those fields.\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. The guard checked for minimum requirements (like balance exists), but didn't reject extra or differently-named fields. Structural typing means 'if it has these fields, it matches.' We need stricter validation.\",\n          \"isCorrect\": true,\n          \"text\": \"Our type guard didn't validate the exact shape strictly enough\"\n        },\n        {\n          \"feedback\": \"That could be true, but that's not a TypeScript issue — that's a contract issue. TypeScript's job is to catch type mismatches. We need to tell it exactly what shape we expect.\",\n          \"isCorrect\": false,\n          \"text\": \"The API changed formats without telling us\"\n        },\n        {\n          \"feedback\": \"Structural typing itself isn't the problem — it's a feature. The issue is our guard allowed any object with the right fields, instead of requiring an exact structure.\",\n          \"isCorrect\": false,\n          \"text\": \"TypeScript's structural typing was too permissive\"\n        },\n        {\n          \"feedback\": \"'unknown' would actually make this worse — we'd have even less type information. The problem is our validation logic, not our type declarations.\",\n          \"isCorrect\": false,\n          \"text\": \"We should have used 'unknown' everywhere instead\"\n        }\n      ],\n      \"question\": \"How did a different payment shape slip through without TypeScript catching it?\"\n    },\n    {\n      \"context\": \"Okay, I've tightened up the type guard to validate the exact structure we expect. But {{NAME}}, here's what's bugging me — we've spent all this time making TypeScript strict and it caught one real bug. But I've also been tempted to just throw `any` on things when TypeScript gets in the way. How do we know when `any` is justified versus when it's just us being lazy?\",\n      \"options\": [\n        {\n          \"feedback\": \"That's when we most need type safety. Shortcuts now become bugs later. Using 'any' to move faster is technical debt that always comes due.\",\n          \"isCorrect\": false,\n          \"text\": \"When we're in a hurry and just want to ship\"\n        },\n        {\n          \"feedback\": \"That's what 'unknown' is for. 'unknown' is safer because you still have to narrow the type. 'any' disables all checking and should be rare.\",\n          \"isCorrect\": false,\n          \"text\": \"When we genuinely don't know the type and can't determine it\"\n        },\n        {\n          \"feedback\": \"That's a legitimate case. When a library has no types and we can't write a guard, 'any' with a comment explaining why is better than fighting TypeScript. But it should be rare.\",\n          \"isCorrect\": true,\n          \"text\": \"For third-party code without types where we document the assumption\"\n        },\n        {\n          \"feedback\": \"That feeling is the type system working. It's saying 'slow down, think about this.' That's exactly when you should NOT use 'any' — that's when it's most valuable.\",\n          \"isCorrect\": false,\n          \"text\": \"When TypeScript makes us feel restricted\"\n        }\n      ],\n      \"question\": \"When is using 'any' actually appropriate?\"\n    },\n    {\n      \"context\": \"{{NAME}}, we've gotten a lot tighter with this. The original crash is fixed, we have type guards in place, and production is stable. But I want to make sure we're thinking about this the right way going forward. When we're designing the next feature, what should type safety actually guide us toward?\",\n      \"options\": [\n        {\n          \"feedback\": \"That's a benefit, but it's not the deepest value. Type safety does more than catch bugs — it shapes how we think about problems.\",\n          \"isCorrect\": false,\n          \"text\": \"Catching bugs before they reach production\"\n        },\n        {\n          \"feedback\": \"Exactly. Types document reality and make it impossible to ignore edge cases like null values. They guide developers toward correct behavior through the type system itself, not just warnings.\",\n          \"isCorrect\": true,\n          \"text\": \"Making code that's harder to use incorrectly\"\n        },\n        {\n          \"feedback\": \"That's the mechanical goal, but missing the point. Compiling successfully doesn't mean the code is safe — it means we've satisfied the type rules we wrote.\",\n          \"isCorrect\": false,\n          \"text\": \"Getting TypeScript to compile without errors\"\n        },\n        {\n          \"feedback\": \"Type safety and runtime error handling both matter. Types catch structural issues early; error handling deals with logic issues and unexpected inputs.\",\n          \"isCorrect\": false,\n          \"text\": \"Replacing the need for runtime error handling\"\n        }\n      ],\n      \"question\": \"What's the real value of type safety in practice?\"\n    }\n  ]\n}",
      "outputTokens": 3337,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-cs-typescript-type-safety-1",
      "userPrompt": "LESSON_TITLE: Type Safety in Practice\nLESSON_DESCRIPTION: Applying TypeScript's type system to catch bugs early and write more maintainable code\nCHAPTER_TITLE: Type Systems\nCOURSE_TITLE: Advanced TypeScript\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Compile-Time Safety: Type safety catches errors at compile time instead of runtime. When TypeScript knows a variable's type, it can prevent operations that would fail — like calling .length on undefined.\n2. Structural Typing: TypeScript uses structural typing — it cares about shape, not names. Two types are compatible if they have the same structure, even if defined separately.\n3. Type Narrowing: Type narrowing lets TypeScript understand more specific types after checks. Inside an if-block that checks for null, TypeScript knows the value isn't null.\n4. Generics: Generic types let you write reusable code that works with multiple types while preserving type information. Array<T> knows what's inside, unlike just 'Array'.\n5. Any vs Unknown: The 'any' type disables type checking entirely. It's an escape hatch but defeats the purpose of TypeScript. Use 'unknown' when the type truly isn't known.\n6. Type Guards: Type guards are functions that narrow types. They return a type predicate that tells TypeScript what the type is after the check passes."
    },
    {
      "duration": 38037.59937499999,
      "inputTokens": 4176,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, thanks for jumping on this call. We just got a heads up that TechVenture Capital — our biggest competitor in the market analytics space — is thinking about launching a budget product line. It directly undercuts our current pricing. Our CEO wants us to figure out what move makes sense. Do we slash our prices to match, keep our premium positioning, or try something else entirely?\",\n      \"options\": [\n        {\n          \"feedback\": \"Rushing to match prices without analyzing the full situation is reactive, not strategic. In game theory, you need to think about what both players' best responses are — and whether there's a more stable outcome than a price war.\",\n          \"isCorrect\": false,\n          \"text\": \"We should immediately match their prices\"\n        },\n        {\n          \"feedback\": \"Exactly. This is a classic strategic interdependence problem. Your best move depends on what they do, and their best move depends on what you do. We need to think like game theorists: What are the choices? What are the payoffs? Where does equilibrium lie?\",\n          \"isCorrect\": true,\n          \"text\": \"We need to map out all possible moves and outcomes\"\n        },\n        {\n          \"feedback\": \"Ignoring a major competitor's strategic move isn't realistic in an interdependent market. Their choices affect your outcomes, and this requires strategic thinking, not just staying the course.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignore them and stick with our strategy\"\n        },\n        {\n          \"feedback\": \"That might be one option, but jumping straight to a solution without thinking through the game first is cart-before-horse. We need to understand what strategies are available and where equilibrium might end up.\",\n          \"isCorrect\": false,\n          \"text\": \"Launch a budget product to dominate both segments\"\n        }\n      ],\n      \"question\": \"What's your gut instinct on how to approach this?\"\n    },\n    {\n      \"context\": \"Alright, let me think through this with you. So TechVenture has two realistic moves: launch the budget line or don't. We have the same. That gives us four possible outcomes. If they launch budget and we keep our premium pricing, they'll capture price-sensitive customers and we keep ours — both do okay, but they're gaining ground. If we both launch budget products, we're in a bloodbath. Price war. Everyone's margins tank. If we go budget and they don't, we win. If neither of us launches, we both keep healthy margins. So far, what's making the most sense?\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. No matter what they do, launching budget seems better for us. If they don't launch, we capture their market. If they do, we at least compete. Same logic for them. But here's the problem: both choosing the dominant strategy lands us in a price war — worse for both than if neither had launched. Classic Prisoner's Dilemma.\",\n          \"isCorrect\": true,\n          \"text\": \"Yes — launching budget is dominant for both\"\n        },\n        {\n          \"feedback\": \"Look closer at the payoffs. Launching budget is better for us regardless of their choice. That's the definition of a dominant strategy. The irony is that both following our dominant strategies leaves us worse off than mutual restraint — that's what makes this a dilemma.\",\n          \"isCorrect\": false,\n          \"text\": \"No — it depends entirely on what they do\"\n        },\n        {\n          \"feedback\": \"Actually, no. If they launch budget and we stay premium, they gain ground. If they don't and we stay premium, we leave money on the table. Launching seems better for us in both scenarios — that's the dominant strategy.\",\n          \"isCorrect\": false,\n          \"text\": \"Staying premium is dominant for us\"\n        },\n        {\n          \"feedback\": \"Look at the payoffs systematically. Launching budget beats staying premium for us in every scenario — whether they launch or not. That's a dominant strategy. The trap is that rational individual behavior leads to an irrational collective outcome.\",\n          \"isCorrect\": false,\n          \"text\": \"There's no clear dominant strategy\"\n        }\n      ],\n      \"question\": \"Does either of us have a dominant strategy here?\"\n    },\n    {\n      \"context\": \"Exactly. We're both drawn to launch budget because it beats the alternative no matter what. But if we both launch, margins collapse and we both end up worse than if we'd both stayed premium. {{NAME}}, I just realized something — this isn't a one-shot game. We've been competitors for years. Are we going to be competitors five years from now too?\",\n      \"options\": [\n        {\n          \"feedback\": \"In a one-shot game, the dominant strategy trap is hard to escape. But repeated games are different. Future interactions create incentives: you can punish defection, reward cooperation. That changes what's rational.\",\n          \"isCorrect\": false,\n          \"text\": \"No — each decision is independent\"\n        },\n        {\n          \"feedback\": \"Bingo. In repeated games, defection now costs you later. If TechVenture launches budget and we retaliate with our own, they suffer in round two. That threat makes them less likely to defect in round one. Cooperation becomes rational.\",\n          \"isCorrect\": true,\n          \"text\": \"Yes — cooperation becomes viable with future punishment\"\n        },\n        {\n          \"feedback\": \"Actually, repeated interaction often softens competitive dynamics. When both players know defection triggers punishment in the future, the incentive to cooperate increases. One-shot games are where dominant strategy traps are hardest to escape.\",\n          \"isCorrect\": false,\n          \"text\": \"It makes the war even worse\"\n        },\n        {\n          \"feedback\": \"That's the one-shot game mentality. But in reality, we're competing repeatedly. Future outcomes matter, and that changes what makes strategic sense. Cooperation becomes more rational in repeated games.\",\n          \"isCorrect\": false,\n          \"text\": \"We should focus only on immediate payoffs\"\n        }\n      ],\n      \"question\": \"Does the fact that this is a repeated game change the analysis?\"\n    },\n    {\n      \"context\": \"Right. So if we expect TechVenture to stay premium, we could stay premium too and both profit. But here's the tension: what if they say the same thing and then launch anyway? We'd be left holding the premium bag while they capture the budget market. Or worse, what if our leadership pressure forces a launch, they retaliate, and we're both worse off? How do we actually reach that cooperation outcome instead of falling into the trap?\",\n      \"options\": [\n        {\n          \"feedback\": \"That would work, but it's also potentially illegal collusion. We need a strategy that doesn't require explicit coordination — something that stabilizes cooperation through incentives and credibility alone.\",\n          \"isCorrect\": false,\n          \"text\": \"A direct agreement or contract between competitors\"\n        },\n        {\n          \"feedback\": \"Exactly. If TechVenture believes we'll match their budget launch immediately and enter a price war, the threat of retaliation makes them less likely to defect. The cooperation outcome becomes a Nash equilibrium: if they stay premium, we stay premium. If they launch, we launch. Both prefer the former.\",\n          \"isCorrect\": true,\n          \"text\": \"A credible threat to retaliate if they launch\"\n        },\n        {\n          \"feedback\": \"That's wishful thinking. In dominant strategy games, voluntary cooperation is hard because both have incentives to defect. We need a mechanism that makes defection costly — like the threat of retaliation.\",\n          \"isCorrect\": false,\n          \"text\": \"Hope they choose cooperation voluntarily\"\n        },\n        {\n          \"feedback\": \"That's defection, not stabilization. It might give us first-mover advantage temporarily, but it triggers retaliation and lands us in the price war anyway. Stabilization requires making cooperation the best response.\",\n          \"isCorrect\": false,\n          \"text\": \"Move first and launch, forcing them to follow\"\n        }\n      ],\n      \"question\": \"What would stabilize a 'both stay premium' outcome?\"\n    },\n    {\n      \"context\": \"Okay, so our threat needs to be credible. TechVenture needs to believe that if they launch, we'll respond with our own launch and both lose. But here's the plot twist {{NAME}}: I just got off the phone with someone who knows someone at TechVenture. They're not even sure they want to launch the budget line. Their CFO is worried about brand dilution. They'd prefer to stay premium too. But they're afraid we'll launch first and crush them if they don't.\",\n      \"options\": [\n        {\n          \"feedback\": \"Yes. Both players prefer the cooperation outcome (stay premium, both profit), but fear the other will defect. So they defect preemptively. This is the heart of the Prisoner's Dilemma — rational individual choices (launch) create an irrational collective outcome (price war). Both end up worse than if they trusted each other.\",\n          \"isCorrect\": true,\n          \"text\": \"We're both trapped in mutual distrust\"\n        },\n        {\n          \"feedback\": \"Not necessarily. If both understand the dilemma and trust each other's rationality, they might coordinate without explicit collusion — by both recognizing that cooperation is better. But that requires overcoming the fear of defection.\",\n          \"isCorrect\": false,\n          \"text\": \"One side will definitely lose\"\n        },\n        {\n          \"feedback\": \"Not if they understand the game. They know launching triggers retaliation. The question is whether they believe we won't launch if they don't. If both believe in credible non-defection, cooperation holds.\",\n          \"isCorrect\": false,\n          \"text\": \"They're definitely going to launch\"\n        },\n        {\n          \"feedback\": \"If they're as rational as we are, they're thinking the same way. We'd both launch preemptively out of fear, even though neither of us wanted to. That's the dilemma. The solution is signaling credible non-aggression.\",\n          \"isCorrect\": false,\n          \"text\": \"We should definitely launch first\"\n        }\n      ],\n      \"question\": \"If both sides prefer staying premium but fear the other will defect, what's happening?\"\n    },\n    {\n      \"context\": \"This is it, {{NAME}}. We're in a prisoner's dilemma that's about to play out. We could break the trap. What if we make a credible move that signals we're staying premium and expect them to as well? Not a secret deal — just a public move that commits us and makes our strategy clear. Something like announcing a premium-focused brand expansion, or publicly supporting industry standards that protect margin-heavy models.\",\n      \"options\": [\n        {\n          \"feedback\": \"Confusion doesn't help. The point is clarity — to remove uncertainty from the game. If we publicly commit to premium positioning, TechVenture knows our strategy and can rationally choose cooperation without fear we're secretly preparing a budget launch.\",\n          \"isCorrect\": false,\n          \"text\": \"To confuse our competitors\"\n        },\n        {\n          \"feedback\": \"Perfect. If TechVenture can see our commitment is real and costly to reverse, they know we won't launch budget secretly. That removes their fear of defection. They can rationally choose to stay premium too. Public commitment solves the information problem that traps prisoners.\",\n          \"isCorrect\": true,\n          \"text\": \"To make our strategy predictable and credible\"\n        },\n        {\n          \"feedback\": \"The point is to lock ourselves into a good strategy that's credible to competitors. By making the choice publicly costly to reverse, we signal sincerity. That's different from locking into a bad strategy.\",\n          \"isCorrect\": false,\n          \"text\": \"To lock ourselves into a bad strategy\"\n        },\n        {\n          \"feedback\": \"It's not about pressure — it's about information and credibility. We're signaling what we're doing so they can rationally choose cooperation. The move works because it's believable, not because it's coercive.\",\n          \"isCorrect\": false,\n          \"text\": \"To pressure them into matching our move\"\n        }\n      ],\n      \"question\": \"What's the point of a public commitment like this?\"\n    },\n    {\n      \"context\": \"I like it. We announce a premium-tier expansion, invest in it publicly, make it costly to reverse. That signals sincerity. But {{NAME}}, before we do this, I need to think out loud: what if we're wrong? What if they don't care about our signal? What if they launch budget anyway? Then we've painted ourselves into a corner. We can't launch to compete without admitting we lied about staying premium.\",\n      \"options\": [\n        {\n          \"feedback\": \"That contradicts our public commitment. Sure, it competes, but it destroys our credibility forever. In repeated games with long-term relationships, maintaining credibility matters as much as this one transaction. The real cost is future trust.\",\n          \"isCorrect\": false,\n          \"text\": \"Launch our own budget line to compete\"\n        },\n        {\n          \"feedback\": \"This assumes we have no other moves. But there are options between 'launch budget' and 'do nothing.' We could innovate premium features, improve service, target different segments — compete on value, not price.\",\n          \"isCorrect\": false,\n          \"text\": \"Stick to premium and accept losing market share\"\n        },\n        {\n          \"feedback\": \"This is the sophisticated response. We don't launch budget (breaking credibility) and don't sit still. We double down on premium — innovate, add value, compete where our commitment actually means something. We maintain credibility AND compete effectively.\",\n          \"isCorrect\": true,\n          \"text\": \"Compete in premium segments they can't dominate\"\n        },\n        {\n          \"feedback\": \"That's too extreme. There are plenty of strategic moves between 'fight back on price' and 'give up.' We have entire customer segments, features, and innovations we can compete with while staying true to our premium positioning.\",\n          \"isCorrect\": false,\n          \"text\": \"Exit the market entirely\"\n        }\n      ],\n      \"question\": \"If our signal fails and they launch anyway, what's our actual best response?\"\n    },\n    {\n      \"context\": \"Alright, I'm convinced. Here's what we do: we announce the premium expansion, we commit publicly, and if they launch budget, we compete hard on value and innovation in the premium space. But {{NAME}}, one last thing — what does this whole situation teach us about strategic thinking? Because I feel like we just did more game theory than I expected when you walked in.\",\n      \"options\": [\n        {\n          \"feedback\": \"That's the opposite of what we learned. First-mover aggression in dominant strategy games often lands everyone in a worse outcome. The lesson is about recognizing traps and finding creative ways to escape them.\",\n          \"isCorrect\": false,\n          \"text\": \"Always launch first to win the market\"\n        },\n        {\n          \"feedback\": \"Exactly. Strategic thinking isn't about choosing in a vacuum — it's about analyzing interdependence. What moves are available? What do they incentivize others to do? Where's equilibrium? How do we shape it through credible commitments? That's game theory applied.\",\n          \"isCorrect\": true,\n          \"text\": \"Your strategy must account for others' choices and incentives\"\n        },\n        {\n          \"feedback\": \"Our first instinct was to match their price. But deeper analysis revealed a dilemma and a better path. Strategic thinking means testing assumptions and exploring payoff structures, not going with gut.\",\n          \"isCorrect\": false,\n          \"text\": \"The first strategy you think of is usually right\"\n        },\n        {\n          \"feedback\": \"We discovered TechVenture wanted premium stability just like us. The conflict came from fear and misaligned incentives, not inherent hostility. Strategic thinking reveals opportunities for alignment.\",\n          \"isCorrect\": false,\n          \"text\": \"Competitors always want to destroy each other\"\n        }\n      ],\n      \"question\": \"What's the core lesson about strategic thinking we just applied?\"\n    }\n  ]\n}",
      "outputTokens": 3841,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-economics-game-theory-strategy-1",
      "userPrompt": "LESSON_TITLE: Strategic Thinking with Game Theory\nLESSON_DESCRIPTION: Using game theory to analyze competitive situations and make better strategic decisions\nCHAPTER_TITLE: Strategic Decision Making\nCOURSE_TITLE: Microeconomics\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Strategic Interdependence: Game theory studies strategic interactions where your outcome depends on others' choices too. It's not about games — it's about any situation where what you should do depends on what others do.\n2. Nash Equilibrium: A Nash equilibrium is a stable state where no player can improve by changing only their own strategy. Everyone is doing their best given what everyone else is doing.\n3. Dominant Strategies: A dominant strategy is best regardless of what others do. If you have one, use it. But most real situations don't have dominant strategies — you must anticipate others.\n4. The Prisoner's Dilemma: The prisoner's dilemma shows how individual rationality can lead to collective irrationality. Both players choosing their dominant strategy leaves both worse off.\n5. Repeated Interactions: Repeated games change the calculus. When you'll interact again, cooperation becomes rational because future punishment makes defection costly."
    },
    {
      "duration": 45184.19358399999,
      "inputTokens": 4222,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"Hey {{NAME}}, glad you're here. We just got a call from the clinical team — they want to move forward with our CRISPR therapy for sickle cell disease. The design looks good on paper: we're targeting the beta-globin mutation specifically. But before we pitch this to the ethics board, I need your gut check. We've optimized the guide RNA sequence, but I'm worried about something. What's your first concern when you think about actually putting CRISPR into patients?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. Off-target effects are a serious safety concern for therapy. We need to verify our guide RNA only cuts the intended beta-globin site, not similar sequences elsewhere in the genome. This is non-negotiable before human trials.\",\n          \"isCorrect\": true,\n          \"text\": \"Confirm guide RNA won't cut elsewhere\"\n        },\n        {\n          \"feedback\": \"Important long-term, but secondary. If our guide RNA is cutting in the wrong places, delivery efficiency won't matter — we'll cause more harm. Safety first, then optimization.\",\n          \"isCorrect\": false,\n          \"text\": \"Optimize the delivery system\"\n        },\n        {\n          \"feedback\": \"We already know sickle cells use both pathways. The real issue is: will our edit hit the right target? Cell repair pathway is less critical than guide RNA specificity for this decision.\",\n          \"isCorrect\": false,\n          \"text\": \"Test whether cells use NHEJ or HDR\"\n        },\n        {\n          \"feedback\": \"Good question, but we need to ensure safety first. Once we confirm our guide RNA is specific, THEN we can calculate how many edited cells we need for therapeutic benefit.\",\n          \"isCorrect\": false,\n          \"text\": \"Estimate how many cells need editing\"\n        }\n      ],\n      \"question\": \"What should we prioritize first before human trials?\"\n    },\n    {\n      \"context\": \"Right, I was thinking the same thing. So I ran our guide RNA through a genome-wide specificity prediction tool. The results are... kind of a mixed bag. Our primary target scores perfectly — 100% match to the beta-globin mutation site. But there are three potential off-target sites with 17, 18, and 19 base-pair matches. They're not perfect matches, but they're not negligible either. {{NAME}}, how do we interpret this?\",\n      \"options\": [\n        {\n          \"feedback\": \"Wishful thinking, but wrong. Cas9 can tolerate some mismatch, especially in the seed region. A 17-bp match with 2 mismatches might still be cut in some cells. We can't just ignore this.\",\n          \"isCorrect\": false,\n          \"text\": \"They're too different; Cas9 won't cut there\"\n        },\n        {\n          \"feedback\": \"Yes. Even 'imperfect' guide RNAs can bind and cut off-target sites at low frequency. For a therapy affecting millions of patient cells, even 0.1% off-target cutting is risky. We need experimental validation.\",\n          \"isCorrect\": true,\n          \"text\": \"Some Cas9 molecules may cut them occasionally\"\n        },\n        {\n          \"feedback\": \"Maybe, but first we need data. Prediction tools aren't always accurate. We should experimentally validate these off-target sites before redesigning — they might not actually be cut in practice.\",\n          \"isCorrect\": false,\n          \"text\": \"We should use a different guide RNA immediately\"\n        },\n        {\n          \"feedback\": \"No. Off-target cuts in any cell can cause harmful mutations, chromosomal rearrangements, or cancer. The tissue doesn't matter — the biological risk is the same everywhere.\",\n          \"isCorrect\": false,\n          \"text\": \"Off-target effects only matter in the brain\"\n        }\n      ],\n      \"question\": \"What do those partial matches actually mean?\"\n    },\n    {\n      \"context\": \"Smart move. We designed an experiment: we'll introduce our CRISPR complex into patient cells in vitro and use whole-genome sequencing to see if those predicted off-target sites actually get cut. The results came back yesterday, and {{NAME}}, you're going to want to see this. The primary target was edited in 87% of cells — great efficiency. But at one of the predicted off-target sites, we found cuts in 2% of cells. That's lower than the primary site, but it's definitely happening.\",\n      \"options\": [\n        {\n          \"feedback\": \"Actually, no. If we treat millions of cells in a patient, 2% off-target mutations accumulate. With sickle cell therapy targeting blood cells, that could mean thousands of cells with unintended mutations, increasing cancer risk.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes, it's low enough to proceed\"\n        },\n        {\n          \"feedback\": \"Correct. For therapeutics, off-target rates should be <0.1%. We could improve this by optimizing guide RNA chemistry, using higher-fidelity Cas9 variants, or selecting a completely different target site. Safety margins matter here.\",\n          \"isCorrect\": true,\n          \"text\": \"No, we need to reduce it or redesign\"\n        },\n        {\n          \"feedback\": \"Partly true, but risky reasoning. We don't know which off-target site was actually cut. Without identifying it, we can't assess the consequence. Better to improve specificity across the board.\",\n          \"isCorrect\": false,\n          \"text\": \"It depends on which gene was off-target cut\"\n        },\n        {\n          \"feedback\": \"That doesn't address the core problem. Off-target cutting is a guide RNA issue, not a delivery issue. Changing how we deliver CRISPR won't fix guide RNA specificity.\",\n          \"isCorrect\": false,\n          \"text\": \"We should switch to a less specific delivery method\"\n        }\n      ],\n      \"question\": \"Is 2% off-target cutting acceptable for a therapeutic?\"\n    },\n    {\n      \"context\": \"Yeah, I agree. We need to improve specificity. So here's what we're thinking: instead of using standard Cas9, we could use a high-fidelity Cas9 variant that's more selective — it cuts much more accurately but with slightly lower efficiency. Or, we could redesign the guide RNA completely to target a different region of the beta-globin gene — one that's more unique in the genome. {{NAME}}, which approach makes more sense for a patient therapy?\",\n      \"options\": [\n        {\n          \"feedback\": \"Smart choice. High-fidelity Cas9 maintains good on-target efficiency (often >70%) while dramatically reducing off-target effects. For therapy, specificity is worth a small efficiency trade-off. Patient safety comes first.\",\n          \"isCorrect\": true,\n          \"text\": \"Switch to high-fidelity Cas9 variant\"\n        },\n        {\n          \"feedback\": \"Could work, but riskier. A new target site means re-validating everything. The off-target risk at the new site is unknown. Better to use a proven high-fidelity Cas9 variant with our current target.\",\n          \"isCorrect\": false,\n          \"text\": \"Redesign guide RNA for another site\"\n        },\n        {\n          \"feedback\": \"Thorough, but impractical. Combining them adds complexity without clear benefit. Pick the strongest approach — high-fidelity Cas9 — and stick with it. Save redesign for if problems emerge.\",\n          \"isCorrect\": false,\n          \"text\": \"Use both strategies at once\"\n        },\n        {\n          \"feedback\": \"No. 2% off-target cutting is unacceptable for therapy. Patient safety cannot be compromised for slightly higher efficiency. You'd face major regulatory and ethical pushback.\",\n          \"isCorrect\": false,\n          \"text\": \"Proceed with standard Cas9 anyway\"\n        }\n      ],\n      \"question\": \"Which strategy better balances efficacy and safety?\"\n    },\n    {\n      \"context\": \"Great thinking. We've switched to high-fidelity Cas9 and re-run the experiment. Off-target cutting is now <0.05% — well within our safety margin. On-target efficiency is 79%, which is still solid. The clinical team is happy, and we're ready to talk about delivery. Here's the challenge: we need to get CRISPR into hematopoietic stem cells from patients, edit them, and put them back. That part works in the lab. But {{NAME}}, the ethics board is going to ask us the hard question: how certain are we that ALL the cells we return are actually edited?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. If only 70-80% of stem cells get edited in vitro, when we reintroduce them, unedited cells could proliferate and eventually become dominant again. The therapy fails, and we're back to square one. This is a real delivery bottleneck.\",\n          \"isCorrect\": true,\n          \"text\": \"Unedited cells might outcompete edited ones\"\n        },\n        {\n          \"feedback\": \"Possible, but not the main delivery problem here. Toxicity would show up in our lab experiments. The bigger issue is delivery efficiency — getting into enough cells in the first place.\",\n          \"isCorrect\": false,\n          \"text\": \"CRISPR components might be toxic to cells\"\n        },\n        {\n          \"feedback\": \"False. Viral vectors like AAV and lentiviruses are regularly used for CRISPR delivery. They work, though they have size and integration limitations. Not the core issue we're facing.\",\n          \"isCorrect\": false,\n          \"text\": \"Viral vectors can't carry CRISPR components\"\n        },\n        {\n          \"feedback\": \"Cost is a practical concern long-term, but it's not the delivery risk we need to solve right now. We need to hit our efficiency targets first, then worry about scaling costs.\",\n          \"isCorrect\": false,\n          \"text\": \"Lipid nanoparticles are too expensive at scale\"\n        }\n      ],\n      \"question\": \"What's the biggest risk with delivery completeness?\"\n    },\n    {\n      \"context\": \"You're right. We tested the delivery with both lentiviral vectors and lipid nanoparticles in patient stem cells. Lentiviruses gave us 85% transduction — basically, 85% of cells took up the CRISPR machinery. Lipid nanoparticles only got us 60%, but they cleared out of cells quickly, so no off-target risk from persistent components. {{NAME}}, for this particular therapy, what's the right call? Which delivery method should we use ex vivo on patient cells?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correct. Since we're editing cells outside the patient (ex vivo), lentiviral integration isn't a safety risk — we can fully validate edited cells before returning them. The 85% transduction efficiency is strong and reduces therapy failure risk.\",\n          \"isCorrect\": true,\n          \"text\": \"Use lentiviruses for higher efficiency\"\n        },\n        {\n          \"feedback\": \"The integration argument doesn't apply here. We're working ex vivo with plenty of time to QC. The 60% efficiency is too low — too many unedited cells would dilute our therapeutic benefit.\",\n          \"isCorrect\": false,\n          \"text\": \"Use lipid nanoparticles to avoid integration\"\n        },\n        {\n          \"feedback\": \"Unnecessary complexity. We need one reliable method. Since we're ex vivo with QC safeguards, lentiviruses win on efficiency. Mixing methods adds variables and costs without clear benefit.\",\n          \"isCorrect\": false,\n          \"text\": \"Alternate between both methods to be safe\"\n        },\n        {\n          \"feedback\": \"We have good options now. Lentiviruses have 30 years of clinical experience. Waiting for 'better' delays patient benefit indefinitely. Good is the enemy of perfect here.\",\n          \"isCorrect\": false,\n          \"text\": \"Wait for a better delivery method to exist\"\n        }\n      ],\n      \"question\": \"Which delivery method is best for ex vivo editing?\"\n    },\n    {\n      \"context\": \"Okay, we're moving forward with lentiviruses. The clinical team has manufactured the edited stem cells, and they look great in every assay. But {{NAME}}, something unexpected just came up from the manufacturer's quality control lab. The lentiviral batch they used has trace amounts of helper virus contamination — not enough to cause any lytic infection in the edited cells, but it's technically there. It's below regulatory thresholds, but barely. The team wants to know: does this change our safety profile for patient infusion?\",\n      \"options\": [\n        {\n          \"feedback\": \"Too casual. 'Below limits' doesn't mean 'safe.' We need to understand the actual risk here. Could helper virus affect edited cells? Could it affect patients? Data first, then a decision.\",\n          \"isCorrect\": false,\n          \"text\": \"Accept it; it's below regulatory limits\"\n        },\n        {\n          \"feedback\": \"Smart. Helper virus contamination is only a risk if it can replicate in our edited cells or in the patient's immune system. Run experiments to see if it does. If not, the contamination is inert and acceptable.\",\n          \"isCorrect\": true,\n          \"text\": \"Test whether helper virus replicates in edited cells\"\n        },\n        {\n          \"feedback\": \"Maybe, but wasteful if the contamination is harmless. Validating that contamination poses no real risk is cheaper and faster than manufacturing a new batch. Test first.\",\n          \"isCorrect\": false,\n          \"text\": \"Use a different lentiviral batch immediately\"\n        },\n        {\n          \"feedback\": \"That doesn't address the contamination risk at all. Giving more cells doesn't resolve whether trace helper virus is a problem. We need data, not higher doses.\",\n          \"isCorrect\": false,\n          \"text\": \"Increase delivery of edited cells to compensate\"\n        }\n      ],\n      \"question\": \"How should we handle trace helper virus contamination?\"\n    },\n    {\n      \"context\": \"Good call. The lab ran the replication assay, and the helper virus is completely inactive in our edited cells — it doesn't replicate. But {{NAME}}, here's where it gets interesting. The assay also showed something unexpected: in the presence of our high-fidelity Cas9 (even without active guide RNA), the helper virus appears to be degraded faster than normal. It's like Cas9 is cutting it. That's strange, right? We didn't design Cas9 to target viral genomes. What's happening here?\",\n      \"options\": [\n        {\n          \"feedback\": \"Most likely. Cas9 without guide RNA can have weak, non-specific nuclease activity. Viral DNA might match partial Cas9 recognition motifs. This actually protects us here, but it highlights why we control guide RNA design so carefully.\",\n          \"isCorrect\": true,\n          \"text\": \"Cas9 is cutting unintended off-targets on viral DNA\"\n        },\n        {\n          \"feedback\": \"No. Resistance develops over generations with selection pressure. We're seeing this in a single assay over hours, not evolution. The degradation is happening now, not through adaptation.\",\n          \"isCorrect\": false,\n          \"text\": \"Helper virus evolved resistance to Cas9\"\n        },\n        {\n          \"feedback\": \"Possible in living organisms, but not in this in vitro assay. We're observing Cas9-mediated degradation directly. The immune system isn't involved here.\",\n          \"isCorrect\": false,\n          \"text\": \"The cells are using immune pathways to clear it\"\n        },\n        {\n          \"feedback\": \"Contradicts the lab data. The replication assay clearly showed no active viral replication. We're seeing genuine degradation of viral DNA, separate from replication status.\",\n          \"isCorrect\": false,\n          \"text\": \"Helper virus replication was never actually blocked\"\n        }\n      ],\n      \"question\": \"Why might Cas9 be degrading helper virus DNA?\"\n    },\n    {\n      \"context\": \"Yeah, it's surprising but actually good news for us — Cas9 is essentially destroying the helper virus, making it completely inert. The clinical team is relieved, and we're ready for the final push toward patient infusion. But {{NAME}}, right before we hand this off to the clinic, I want to make sure we're thinking about long-term safety. We know our guide RNA is specific, our delivery works ex vivo, and we've QC'd the cells thoroughly. But in a living patient, edited cells will divide, undergo mutations, and exist in an immune environment. What's the one thing we absolutely must monitor post-infusion?\",\n      \"options\": [\n        {\n          \"feedback\": \"Important clinically, but not unique to CRISPR. We monitor this anyway. The real unknown is whether CRISPR-specific risks emerge — off-target mutations accumulating, late-appearing problems.\",\n          \"isCorrect\": false,\n          \"text\": \"Whether edited cells maintain sickle-cell correction\"\n        },\n        {\n          \"feedback\": \"Critical. Even rare off-target cuts in genes like tumor suppressors could, over years, increase cancer risk. Patients need long-term follow-up (5+ years) watching for unexpected malignancies or clonal expansions.\",\n          \"isCorrect\": true,\n          \"text\": \"Whether off-target edits cause cancer development\"\n        },\n        {\n          \"feedback\": \"We're reinfusing the patient's own cells, so immune rejection is unlikely. This is an allogeneic transplant concern, not a CRISPR-specific one.\",\n          \"isCorrect\": false,\n          \"text\": \"Whether the immune system rejects edited cells\"\n        },\n        {\n          \"feedback\": \"Already monitored through standard lentiviral QC. And we're using ex vivo delivery, so we can check for this before reinfusion. Not our unknown variable.\",\n          \"isCorrect\": false,\n          \"text\": \"Whether lentiviral vector causes insertional mutagenesis\"\n        }\n      ],\n      \"question\": \"What's the critical long-term monitoring question?\"\n    },\n    {\n      \"context\": \"Exactly. We've set up a 5-year monitoring protocol with genomic screening for clonal expansions and oncology follow-up. The ethics board just approved the trial. {{NAME}}, you know what? Reflecting on this whole process — from guide RNA design through delivery to post-infusion monitoring — I realize we've been applying one core principle throughout. Everything we did, from day one, came back to the same thing. What would you say is the lesson we've learned through all of this?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not the lesson here. We're moving into human trials because we systematically addressed each risk. CRISPR is powerful, but only when you respect its limitations and validate everything.\",\n          \"isCorrect\": false,\n          \"text\": \"CRISPR is too risky for human use\"\n        },\n        {\n          \"feedback\": \"Nailed it. From guide RNA selection to high-fidelity Cas9 variants to long-term monitoring — every decision flowed from the commitment to specificity. In gene editing, precise targeting IS patient safety. Everything else follows.\",\n          \"isCorrect\": true,\n          \"text\": \"Specificity is the foundation of safety\"\n        },\n        {\n          \"feedback\": \"Important, but secondary. Delivery matters only if you have a specific, validated edit to deliver. Specificity comes first; delivery is the vehicle for it.\",\n          \"isCorrect\": false,\n          \"text\": \"Delivery method determines therapeutic success\"\n        },\n        {\n          \"feedback\": \"Backwards logic. We do intensive preclinical work FIRST (guide RNA validation, delivery testing). Monitoring is the safety net afterward, not a substitute for upfront rigor.\",\n          \"isCorrect\": false,\n          \"text\": \"Monitoring replaces the need for preclinical safety\"\n        }\n      ],\n      \"question\": \"What's the central takeaway from CRISPR therapy work?\"\n    }\n  ]\n}",
      "outputTokens": 4811,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-biology-crispr-applications-1",
      "userPrompt": "LESSON_TITLE: CRISPR Gene Editing in Practice\nLESSON_DESCRIPTION: Understanding how to apply CRISPR gene editing technology effectively and responsibly\nCHAPTER_TITLE: Genetic Engineering\nCOURSE_TITLE: Modern Biotechnology\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. The Molecular Scissors: CRISPR-Cas9 is a molecular scissors that cuts DNA at specific locations. The Cas9 protein does the cutting; a guide RNA tells it exactly where to cut.\n2. Guide RNA Targeting: Guide RNA is a short sequence that matches the target DNA. It base-pairs with the DNA sequence you want to edit, bringing Cas9 to the exact spot.\n3. Cellular Repair Pathways: After CRISPR cuts, the cell's repair machinery fixes the break. Non-homologous end joining often introduces errors (knockouts). Homology-directed repair can insert new sequences (knock-ins).\n4. Off-Target Effects: Off-target effects occur when CRISPR cuts unintended locations. Guide RNA design and delivery methods affect specificity. This is a major safety concern for therapeutic applications.\n5. Delivery Challenges: Delivery is a key challenge. Getting CRISPR components into the right cells in a living organism is harder than in a lab dish. Viral vectors and lipid nanoparticles are common approaches."
    },
    {
      "duration": 42078.12837500003,
      "inputTokens": 4282,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, temos um problema. Recebi o feedback dos alunos sobre o novo módulo de cálculo que a gente criou. Estão dizendo que é impossível de acompanhar. Começam a estudar e na metade desistem. O conteúdo em si não é o problema — é a forma como a gente apresentou.\",\n      \"options\": [\n        {\n          \"feedback\": \"Mais exemplos podem ajudar, mas sem entender onde está o excesso de carga cognitiva, você pode estar piorando. Primeiro, identifique se o problema é no conteúdo em si ou no design.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar mais exemplos visuais\"\n        },\n        {\n          \"feedback\": \"Exato. Precisamos identificar se a dificuldade vem da complexidade natural do conteúdo (carga intrínseca) ou do design ruim (carga extrínseca). Aí saberemos como agir.\",\n          \"isCorrect\": true,\n          \"text\": \"Analisar onde os alunos estão se perdendo\"\n        },\n        {\n          \"feedback\": \"Nem sempre é possível ou desejável simplificar o conteúdo. Pode ser que o problema seja apenas como você está apresentando, não o que você está ensinando.\",\n          \"isCorrect\": false,\n          \"text\": \"Simplificar o conteúdo completamente\"\n        },\n        {\n          \"feedback\": \"Atividades interativas têm seu valor, mas se o material base já está sobrecarregando os alunos, adicionar mais coisas pode piorar a situação.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar mais atividades interativas\"\n        }\n      ],\n      \"question\": \"Como você quer abordar isso?\"\n    },\n    {\n      \"context\": \"Analisamos juntos e achamos o ponto de ruptura. No módulo 3, tem essa coisa complexa: você precisa entender simultaneamente a fórmula, o conceito por trás dela, o passo a passo da aplicação, e três exemplos diferentes. Tudo na mesma página. Os alunos ficam olhando para cima e para baixo, tentando juntar tudo.\",\n      \"options\": [\n        {\n          \"feedback\": \"Pode ser, mas esse não é o principal obstáculo nesse caso. O problema é como tudo foi apresentado ao mesmo tempo, não necessariamente a dificuldade do conceito.\",\n          \"isCorrect\": false,\n          \"text\": \"A fórmula em si é muito difícil\"\n        },\n        {\n          \"feedback\": \"Motivação é importante, mas não é o que está acontecendo aqui. O feedback específico é que eles não conseguem acompanhar — questão de capacidade de processamento, não vontade.\",\n          \"isCorrect\": false,\n          \"text\": \"Os alunos não estão motivados\"\n        },\n        {\n          \"feedback\": \"Isso. A memória de trabalho tem limite — cerca de 4 itens. Você está pedindo para processar fórmula, conceito, processo E exemplos simultaneamente. Carga intrínseca + carga extrinseca ruim.\",\n          \"isCorrect\": true,\n          \"text\": \"Estamos sobrecarregando a memória deles com tudo junto\"\n        },\n        {\n          \"feedback\": \"Exercícios ajudam depois, mas se o aluno já está sobrecarregado no aprendizado inicial, adicionar mais tarefas não resolve o problema.\",\n          \"isCorrect\": false,\n          \"text\": \"Faltam exercícios práticos\"\n        }\n      ],\n      \"question\": \"Qual é o principal problema aqui?\"\n    },\n    {\n      \"context\": \"Certo. Então essa carga combinada está fazendo eles congelarem. A boa notícia? A maioria do problema é carga extrínseca — design ruim que a gente pode consertar. {{NAME}}, como você quer reorganizar? A fórmula é inevitavelmente complexa, mas a forma como apresentamos não precisa ser.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfeito. Chunking — agrupar em blocos significativos, um por vez. Apresentar em sequência deixa a memória de trabalho processar um elemento de cada vez, não tudo junto. A carga intrínseca continua, mas a extrínseca desaparece.\",\n          \"isCorrect\": true,\n          \"text\": \"Apresentar fórmula, depois conceito, depois exemplos em sequência\"\n        },\n        {\n          \"feedback\": \"Empacotar rapidamente não reduz carga cognitiva — na verdade, pode piorar. A velocidade força os alunos a tentar processar tudo de uma vez. Precisa dar tempo e separação.\",\n          \"isCorrect\": false,\n          \"text\": \"Colocar tudo em um vídeo curto\"\n        },\n        {\n          \"feedback\": \"Distribua, sim, mas não é a resposta mais direta. A questão é que mesmo dentro de uma aula, você está apresentando múltiplos elementos simultaneamente. Separe por sequência, não por módulos.\",\n          \"isCorrect\": false,\n          \"text\": \"Distribuir entre módulos diferentes\"\n        },\n        {\n          \"feedback\": \"Descoberta é ótima para carga germânica (aprendizado ativo), mas se eles já estão sobrecarregados, exploração sem estrutura vai aumentar a carga extrínseca, não reduzir.\",\n          \"isCorrect\": false,\n          \"text\": \"Deixar os alunos descobrirem sozinhos\"\n        }\n      ],\n      \"question\": \"Qual estratégia reduz melhor a carga extrínseca?\"\n    },\n    {\n      \"context\": \"Bom ponto. Vamos testar: primeiro página só com a fórmula e seu significado. {{NAME}}, sem os exemplos no caminho. Aí na próxima seção, o passo a passo de como usar. E só depois, exemplos para praticar. Sequencial, organizado.\",\n      \"options\": [\n        {\n          \"feedback\": \"Não é sobre quantidade de conteúdo — é o mesmo. É sobre quando e como você apresenta. O ganho é na qualidade do processamento, não na redução de matéria.\",\n          \"isCorrect\": false,\n          \"text\": \"Os alunos aprendem mais rápido porque tem menos conteúdo\"\n        },\n        {\n          \"feedback\": \"Exato. Ao separar em sequência, você dá espaço mental para integrar cada elemento antes do próximo. Carga intrínseca (complexidade real) fica, carga extrínseca (confusão no design) sai.\",\n          \"isCorrect\": true,\n          \"text\": \"A memória de trabalho processa cada elemento sem competição\"\n        },\n        {\n          \"feedback\": \"Psicologia é relevante, mas essa não é a razão cognitiva para o agrupamento sequencial. O benefício é estrutural, não emocional.\",\n          \"isCorrect\": false,\n          \"text\": \"Os alunos ficam menos ansiosos por ter menos texto\"\n        },\n        {\n          \"feedback\": \"Isso é consequência, não o ganho cognitivo da estratégia. O ganho principal é permitir que a memória de trabalho processe melhor e construa representações mentais sólidas.\",\n          \"isCorrect\": false,\n          \"text\": \"Fica mais fácil fazer prova porque o conteúdo está dividido\"\n        }\n      ],\n      \"question\": \"Qual é o ganho cognitivo aqui?\"\n    },\n    {\n      \"context\": \"Mandei para um grupo piloto testar. Voltou o feedback: adoraram. Finalmente conseguem acompanhar. Mas {{NAME}}, tem uma coisa estranha. Alguns alunos estão achando agora que é muito lento. Querem pular direto para os exemplos. Estão reclamando que é 'óbvio' depois que entenderam a fórmula.\",\n      \"options\": [\n        {\n          \"feedback\": \"Cuidado com essa interpretação. Alguns alunos dirão que entenderam quando na verdade ainda não processaram completamente. A repetição sistemática é carga germânica — esforço produtivo — não desperdício.\",\n          \"isCorrect\": false,\n          \"text\": \"Sim, os alunos têm razão — faz muito tempo\"\n        },\n        {\n          \"feedback\": \"Correto. Aqueles que reclamam de 'óbvio' estão fazendo exatamente o que queremos — investir esforço produtivo para integrar o conhecimento. Entendimento rápido ≠ aprendizado efetivo.\",\n          \"isCorrect\": true,\n          \"text\": \"Não. Carga germânica é ativa e necessária para aprender\"\n        },\n        {\n          \"feedback\": \"Você pode, mas não por esse motivo. Alguns alunos pensando que é 'óbvio' não prova que estão realmente processando profundamente. Cuidado com o viés de confiança excessiva.\",\n          \"isCorrect\": false,\n          \"text\": \"Podemos criar uma versão acelerada para alunos avançados\"\n        },\n        {\n          \"feedback\": \"Não é sobre qualidade dos exemplos nesse momento. A sequência está funcionando. Alunos que acham tudo óbvio às vezes precisam de um lembrete: compreensão rápida não é sínonimo de aprendizado duradouro.\",\n          \"isCorrect\": false,\n          \"text\": \"Significa que os exemplos não estão bons\"\n        }\n      ],\n      \"question\": \"Isso significa que a gente errou na sequência?\"\n    },\n    {\n      \"context\": \"Você merecia uma vitória aqui, {{NAME}}, mas apareceu um novo problema. O módulo 4, que a gente ainda não tinha tocado, é ainda pior. Três conceitos dependentes uns dos outros, regras de exceção, símbolos matemáticos que parecem caligrafados, e os alunos precisam calcular enquanto entendem a lógica. Isso não é só design ruim — o conteúdo em si é brutalmente complexo.\",\n      \"options\": [\n        {\n          \"feedback\": \"Você não pode eliminar carga intrínseca — ela vem da natureza do conteúdo. Mas pode gerenciar reduzindo outros elementos para que o aluno foque na dificuldade real.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminar completamente para facilitar\"\n        },\n        {\n          \"feedback\": \"Isso. Com carga intrínseca alta, você não consegue eliminar a dificuldade, mas consegue organizar em etapas progressivas. Comece com um conceito, construa para o próximo. Reduza tudo que é carga extrínseca para sobrarem recursos mentais para a complexidade real.\",\n          \"isCorrect\": true,\n          \"text\": \"Separar em pré-requisitos e scaffolding controlado\"\n        },\n        {\n          \"feedback\": \"Vídeos não resolvem carga intrínseca alta. Na verdade, velocidade e áudio simultâneos podem aumentar carga. Estruture em passos, não em apresentações.\",\n          \"isCorrect\": false,\n          \"text\": \"Apresentar tudo junto mas com vídeos explicativos\"\n        },\n        {\n          \"feedback\": \"Com carga intrínseca muito alta, tentativa e erro sem guia estruturado consome toda a memória de trabalho em fracassos, não em aprendizado. Você precisa de scaffolding progressivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Deixar os alunos aprender tentativa e erro\"\n        }\n      ],\n      \"question\": \"Como você quer atacar essa complexidade intrínseca?\"\n    },\n    {\n      \"context\": \"Começamos a reconstruir o módulo 4. Você dividiu em 5 passos pequenos: conceito 1 sozinho, depois conceito 2 conectando com 1, depois conceito 3 conectando com ambos. Só aí colocamos as regras de exceção. E aqui vem o insight que a gente tinha esquecido: a gente pode usar chunking mesmo com conteúdo complexo. Transformar cada conceito em um bloco mental que o aluno já conhece, tipo um 'token' que ele carrega para frente.\",\n      \"options\": [\n        {\n          \"feedback\": \"Chunking não torna o conteúdo menos complexo — a dificuldade permanece. Mas permite que o aluno carregue conhecimento já processado como unidades únicas, em vez de múltiplos elementos soltos.\",\n          \"isCorrect\": false,\n          \"text\": \"Reduz a complexidade do conteúdo em si\"\n        },\n        {\n          \"feedback\": \"Exato! Ao transformar 'Conceito 1 + suas relações' em um chunk único, você libera espaço mental. Agora o aluno processa [Chunk 1] + [Novo conceito], não [Elemento A] + [Elemento B] + [Elemento C] + [Novo] tudo junto.\",\n          \"isCorrect\": true,\n          \"text\": \"Permite que memória de trabalho processe mais sem sobrecarregar\"\n        },\n        {\n          \"feedback\": \"Velocidade não é o objetivo com carga intrínseca alta. Você quer profundidade e integrações sólidas, mesmo que demore mais. Velocidade viria depois, quando os chunks estão consolidados.\",\n          \"isCorrect\": false,\n          \"text\": \"Torna a aprendizagem rápida demais\"\n        },\n        {\n          \"feedback\": \"Pelo contrário — estruturar em chunks aumenta a carga germânica produtiva. O aluno não está lutando com confusão visual ou ordem aleatória; está investindo esforço real em conectar conceitos.\",\n          \"isCorrect\": false,\n          \"text\": \"Diminui a importância da carga germânica\"\n        }\n      ],\n      \"question\": \"Qual é o efeito de fazer isso com carga intrínseca alta?\"\n    },\n    {\n      \"context\": \"Os novos dados chegaram. Alunos que passaram pelo módulo 4 redesenhado: taxa de conclusão subiu de 32% para 87%. Tempo médio foi o mesmo, talvez até maior. Mas retenção — {{NAME}}, isso é incrível — retenção de 2 semanas depois foi de 64% para 91%. Eles estão realmente aprendendo, não só finalizando. O impacto foi nas decisões de design que a gente tomou com a teoria em mente.\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso não foi parte da estratégia que você aplicou. O impacto veio de reduzir carga extrínseca (confusão) e estruturar carga intrínseca (complexidade), não de enfeitar visualmente.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar mais cores e ícones visuais\"\n        },\n        {\n          \"feedback\": \"Bingo. Você eliminou carga extrínseca (apresentação confusa) e gerenciou carga intrínseca (complexidade) através de progressão. Isso deixou espaço mental para carga germânica — o trabalho real de aprender e reter.\",\n          \"isCorrect\": true,\n          \"text\": \"Separar sequencialmente e fazer chunking intencional\"\n        },\n        {\n          \"feedback\": \"Exercícios ajudaram, sim, mas não foi isso o diferencial. A mudança principal foi estrutural — como você sequenciou o conteúdo desde o início.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar mais exercícios após cada seção\"\n        },\n        {\n          \"feedback\": \"Você não reduziu conteúdo significativamente — reorganizou. A diferença foi metodológica, não quantitativa. Mesmo conteúdo, apresentado de forma que a mente consegue processar.\",\n          \"isCorrect\": false,\n          \"text\": \"Reduzir a quantidade total de conteúdo\"\n        }\n      ],\n      \"question\": \"Qual dessas decisões teve maior impacto?\"\n    },\n    {\n      \"context\": \"Aqui vem o momento 'meta' do projeto, {{NAME}}. A gente finalmente vai treinar o resto da equipe sobre tudo isso. Vamos ensinar a eles como aplicar teoria de carga cognitiva no design de qualquer módulo futuro. Mas tem um problema iônico: se a gente der uma apresentação tradicional com toda a teoria, os símbolos, as definições, os casos de uso — a gente vai sobrecarregar todo mundo em 20 minutos.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfeito. Usar a própria trajetória como exemplo. Não começa com teoria abstrata — começa com 'problema real, como a gente pensou, como a gente agiu, o que mudou'. Os conceitos emergem da narrativa, em chunks que fazem sentido.\",\n          \"isCorrect\": true,\n          \"text\": \"Contar a história do que a gente fez — case real, decisões, resultados\"\n        },\n        {\n          \"feedback\": \"Exatamente o oposto do que a gente aprendeu. Você estaria criando carga extrínseca massiva enquanto ensina sobre reduzir carga. Irônico e ineficaz.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar slides com muitas definições e diagramas\"\n        },\n        {\n          \"feedback\": \"Interatividade é ótima, mas não resolve o problema. Simultaneidade de conceitos = carga intrínseca + extrínseca = exatamente o que você quer evitar.\",\n          \"isCorrect\": false,\n          \"text\": \"Dar um workshop interativo com todos os conceitos simultaneamente\"\n        },\n        {\n          \"feedback\": \"Um PDF de teoria é carga extrínseca em forma de texto. Sem contexto, sem história, é design puro de confusão. A equipe vai ler, esquecer e não aplicar.\",\n          \"isCorrect\": false,\n          \"text\": \"Enviar um PDF com tudo explicado para ler depois\"\n        }\n      ],\n      \"question\": \"Como a gente apresenta carga cognitiva sem sobrecarregar?\"\n    }\n  ]\n}",
      "outputTokens": 4767,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-psychology-cognitive-load-1",
      "userPrompt": "LESSON_TITLE: Carga Cognitiva na Pratica\nLESSON_DESCRIPTION: Aplicando a teoria da carga cognitiva para criar materiais de aprendizagem mais eficazes\nCHAPTER_TITLE: Psicologia da Aprendizagem\nCOURSE_TITLE: Design Instrucional\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Limites da Memoria: A memoria de trabalho tem capacidade limitada — cerca de 4 itens simultaneamente. Quando sobrecarregada, a aprendizagem para. O cerebro nao consegue processar mais.\n2. Carga Intrinseca: Carga intrinseca vem da complexidade inerente do conteudo. Algumas coisas sao simplesmente dificeis. Nao da para eliminar, mas da para gerenciar.\n3. Carga Extrinseca: Carga extrinseca vem do design ruim — instrucoes confusas, distracao visual, navegacao complicada. Essa carga pode e deve ser eliminada.\n4. Carga Germanica: Carga germanica e o esforco produtivo de aprender — criar conexoes, elaborar, integrar. Queremos maximizar essa carga enquanto minimizamos a extrinseca.\n5. Chunking: Chunking agrupa informacoes em unidades significativas. Um numero de telefone e mais facil de lembrar como blocos (99-8765-4321) do que como 10 digitos soltos."
    },
    {
      "duration": 40883.00587499997,
      "inputTokens": 4273,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, tenemos un problema con el sistema de enfriamiento de la planta. La sala de servidores se está calentando más de lo esperado, y el aire acondicionado industrial no está sacando suficiente calor. El cliente dice que los costos de energía se han duplicado en el último mes. Necesitamos entender qué está pasando antes de que los equipos se dañen.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Antes de buscar soluciones, necesitamos entender cómo funciona el flujo de calor y la energía en el sistema. Las leyes de termodinámica nos dicen dónde puede estar el problema.\",\n          \"isCorrect\": true,\n          \"text\": \"Revisar las leyes de termodinámica aplicadas al sistema\"\n        },\n        {\n          \"feedback\": \"Precipitado. Sin entender el problema fundamental, podrías gastar más energía sin resolver nada. La termodinámica nos ayuda a identificar la causa real.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar inmediatamente la potencia del aire acondicionado\"\n        },\n        {\n          \"feedback\": \"Demasiado específico. El problema podría ser más fundamental: cómo está fluyendo el calor en todo el sistema. Necesitamos pensar en términos de energía total.\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar si los cables están sobrecalentados\"\n        },\n        {\n          \"feedback\": \"Eso no ayuda. El problema está en la física del sistema, no en el proveedor. Debemos entender por qué el aire acondicionado no está funcionando eficientemente.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar el contrato con el proveedor de electricidad\"\n        }\n      ],\n      \"question\": \"¿Cuál es el primer paso para diagnosticar el problema?\"\n    },\n    {\n      \"context\": \"Exacto. Mira, he estado analizando los datos. El aire acondicionado está extrayendo calor de la sala de servidores — eso es correcto. Pero estoy viendo algo extraño: aunque está funcionando casi al máximo, no logra bajar la temperatura interna. La primera ley de la termodinámica dice que la energía entra y sale, debería estar balanceada. Entonces pregunta: ¿de dónde viene todo ese calor extra que no podemos sacar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. La energía se conserva siempre. Si entra más calor del que sale, hay una fuente que no hemos contabilizado. Podría ser equipamiento adicional, mala aislación, o pérdidas.\",\n          \"isCorrect\": true,\n          \"text\": \"Que hay una fuente de calor no identificada dentro del sistema\"\n        },\n        {\n          \"feedback\": \"Incorrecto. Las leyes de termodinámica aplican a TODOS los sistemas. Si no se ve conservación de energía, significa que nos falta información sobre fuentes o pérdidas.\",\n          \"isCorrect\": false,\n          \"text\": \"Que la termodinámica no aplica a nuestro sistema\"\n        },\n        {\n          \"feedback\": \"No necesariamente. El aire acondicionado podría estar funcionando perfectamente pero aun así no ser suficiente si hay más calor del que imaginamos.\",\n          \"isCorrect\": false,\n          \"text\": \"Que el aire acondicionado está roto y no funciona\"\n        },\n        {\n          \"feedback\": \"Saltar a la solución sin entender el problema. Primero necesitamos identificar todas las fuentes de calor. Un equipo más potente no sirve si no sabemos de dónde viene el calor.\",\n          \"isCorrect\": false,\n          \"text\": \"Que debemos comprar un aire acondicionado más potente\"\n        }\n      ],\n      \"question\": \"¿Qué significaría que la energía no se está conservando?\"\n    },\n    {\n      \"context\": \"Entonces empecé a mapear el sistema. Tenemos los servidores generando calor — eso sabemos. El aire acondicionado lo extrae hacia el exterior. Pero {{NAME}}, aquí está lo interesante: descubrí que en el piso de abajo hay un sitio de almacenamiento de respaldo, y están usando calefactores durante el invierno. El calor está subiendo a través de las vigas. No es un problema de conservación de energía, es un problema de donde FLUYE el calor. La segunda ley dice que el calor fluye naturalmente de caliente a frío. ¿Eso explica por qué no podemos enfriarlo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. La segunda ley es clara: el calor fluye espontáneamente de caliente a frío. No podemos usar el aire acondicionado solo para vencer eso. Necesitamos una solución más fundamental.\",\n          \"isCorrect\": true,\n          \"text\": \"El calor subirá naturalmente — necesitamos trabajo para evitarlo\"\n        },\n        {\n          \"feedback\": \"Incluso un aire acondicionado perfectamente potente lucha contra la física natural. La solución no es la potencia — es aislación o eliminar la fuente de calor abajo.\",\n          \"isCorrect\": false,\n          \"text\": \"El aire acondicionado debería ser lo suficientemente potente\"\n        },\n        {\n          \"feedback\": \"Parcialmente cierto, pero eso no responde la pregunta sobre flujo de calor. La segunda ley explica POR QUÉ el flujo ocurre, independientemente del diseño.\",\n          \"isCorrect\": false,\n          \"text\": \"El problema es que el piso de abajo está mal diseñado\"\n        },\n        {\n          \"feedback\": \"Esa podría ser la solución final, pero no responde la pregunta sobre la física. Primero entendamos qué dice la termodinámica sobre este flujo.\",\n          \"isCorrect\": false,\n          \"text\": \"Deberíamos desconectar los calefactores abajo inmediatamente\"\n        }\n      ],\n      \"question\": \"¿Cómo debemos pensar sobre el flujo de calor aquí?\"\n    },\n    {\n      \"context\": \"{{NAME}}, ahora veo el problema. Los costos de energía se duplicaron porque el aire acondicionado lucha contra el calor que sube naturalmente. Cada vez que el calor sube y el aire acondicionado lo baja, estamos usando mucha energía. La entropía aumenta — la energía se está dispersando. Pero aquí viene lo crucial: logramos bajar la temperatura algunos grados, ¿verdad? ¿Cómo es posible si el calor siempre fluye de caliente a frío?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Los aires acondicionados son bombas de calor. Usan trabajo (energía eléctrica) para mover calor de un lugar frío a uno más caliente. No viola la segunda ley — el trabajo es lo que permite esto.\",\n          \"isCorrect\": true,\n          \"text\": \"Usando trabajo para bombear el calor contra su dirección natural\"\n        },\n        {\n          \"feedback\": \"No. Si violara la segunda ley, sería imposible. El aire acondicionado está dentro de las leyes — usa trabajo externo para lograr lo que de otro modo sería imposible.\",\n          \"isCorrect\": false,\n          \"text\": \"Violando la segunda ley de la termodinámica\"\n        },\n        {\n          \"feedback\": \"No es una cuestión de pequeñas diferencias. La segunda ley es absoluta: sin trabajo, el calor nunca fluye de frío a caliente, sin importar las magnitudes.\",\n          \"isCorrect\": false,\n          \"text\": \"Aprovechando diferencias pequeñas de temperatura\"\n        },\n        {\n          \"feedback\": \"Incorrecto. El aire acondicionado reduce entropía en la sala, pero AUMENTA entropía en todo el sistema (incluyendo el exterior). La entropía total siempre aumenta.\",\n          \"isCorrect\": false,\n          \"text\": \"Reduciendo la entropía del sistema completamente\"\n        }\n      ],\n      \"question\": \"¿Cómo logra el aire acondicionado mover calor de frio a caliente?\"\n    },\n    {\n      \"context\": \"Bien. Así que el aire acondicionado usa electricidad para bombear calor. Tiene sentido. Ahora, {{NAME}}, el cliente está preguntando: ¿podremos hacer este sistema más eficiente? Digamos que tenemos aire acondicionado de alta eficiencia. ¿Qué determina realmente cuán eficiente puede ser? ¿Es un límite que podemos quebrantar con mejor tecnología?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. El ciclo de Carnot establece el límite teórico. Ningún aire acondicionado real puede ser más eficiente que Carnot para esas temperaturas. Es un límite fundamental, no un obstáculo de ingeniería.\",\n          \"isCorrect\": true,\n          \"text\": \"El ciclo de Carnot — eficiencia máxima depende de temperaturas\"\n        },\n        {\n          \"feedback\": \"Parcialmente verdadero — mejor equipo se acerca al límite de Carnot. Pero hay un límite que ni el mejor equipo puede superar. Es física, no solo ingeniería.\",\n          \"isCorrect\": false,\n          \"text\": \"La calidad del equipo que compremos\"\n        },\n        {\n          \"feedback\": \"Eso afecta cuánto calor podemos mover total, pero no la eficiencia. La eficiencia depende de la física de las temperaturas implicadas.\",\n          \"isCorrect\": false,\n          \"text\": \"Cuánta electricidad tenemos disponible\"\n        },\n        {\n          \"feedback\": \"El tamaño afecta cuánta capacidad necesitamos, pero no la eficiencia. Un aire acondicionado pequeño y uno grande tienen el mismo límite de eficiencia teórica.\",\n          \"isCorrect\": false,\n          \"text\": \"El tamaño de la sala que queremos enfriar\"\n        }\n      ],\n      \"question\": \"¿Qué limita la eficiencia del aire acondicionado?\"\n    },\n    {\n      \"context\": \"Espera, {{NAME}}. Acabo de hacer los cálculos del límite de Carnot para nuestro caso. Tenemos una sala a 28°C que queremos bajar a 22°C. Afuera está a 35°C. El eficiencia máxima teórica es... relativamente baja. Luego descubrí algo: si hubiéramos aislado mejor la sala desde el inicio, esas temperaturas serían diferentes y el límite de Carnot sería mejor. Pero aquí está el giro {{NAME}} — el dueño acaba de reconocer que también tiene un horno industrial en el sótano que no sabían que estaba encendido hace semanas. Eso está causando el calor extra.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Ahora la primera ley tiene sentido: hay energía entrando que no habíamos identificado. El problema no era la ineficiencia de Carnot — era que faltaba información fundamental.\",\n          \"isCorrect\": true,\n          \"text\": \"El horno es la fuente de calor no contabilizada que rompe el balance energético\"\n        },\n        {\n          \"feedback\": \"Cierto que es más difícil, pero eso no es el punto. El punto es que el horno ES la fuente de calor extra. Identificar esto cambia toda la estrategia.\",\n          \"isCorrect\": false,\n          \"text\": \"El aire acondicionado nunca será eficiente con un horno encendido\"\n        },\n        {\n          \"feedback\": \"La potencia no ayuda aquí. Aunque el equipo sea perfecto según Carnot, lucha contra una fuente de calor contante. Eso es un problema de conservación de energía, no de eficiencia.\",\n          \"isCorrect\": false,\n          \"text\": \"Debemos usar un refrigerador más potente para Carnot más alto\"\n        },\n        {\n          \"feedback\": \"Aplica más que nunca. De hecho, la termodinámica nos permitió identificar que había una fuente de calor faltante. Sigue siendo la herramienta clave.\",\n          \"isCorrect\": false,\n          \"text\": \"El análisis de termodinámica ya no aplica al sistema\"\n        }\n      ],\n      \"question\": \"¿Cómo cambia esto nuestro análisis del sistema?\"\n    },\n    {\n      \"context\": \"{{NAME}}, tenemos dos opciones ahora. Opción 1: Apagar el horno en el sótano. Opción 2: Mantener el horno encendido pero invertir en aislación mucho mejor para la sala de servidores. El dueño prefiere no perder la capacidad de almacenamiento del sótano. Entonces me pregunto: si mejoramos la aislación, ¿realmente mejora la eficiencia del aire acondicionado, o solo reduce cuánto trabajo necesita?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. La aislación reduce cuánto calor entra. El aire acondicionado necesita menos trabajo total. Pero la eficiencia de Carnot (para esas temperaturas) no cambia — lo que cambia es la demanda.\",\n          \"isCorrect\": true,\n          \"text\": \"Reduce el flujo de calor — menos trabajo total, pero eficiencia de Carnot sigue igual\"\n        },\n        {\n          \"feedback\": \"No. Carnot depende de las temperaturas, no de cuánto aislamiento hay. La aislación reduce carga, pero no mejora el límite teórico de eficiencia.\",\n          \"isCorrect\": false,\n          \"text\": \"Mejora la eficiencia de Carnot del aire acondicionado\"\n        },\n        {\n          \"feedback\": \"Parcialmente. Mejor aislación sí reduce el impacto del horno. Pero la pregunta es sobre eficiencia termodinámica, no sobre conveniencia operacional.\",\n          \"isCorrect\": false,\n          \"text\": \"Permite que el horno siga encendido sin problemas\"\n        },\n        {\n          \"feedback\": \"Incluso con aislación perfecta, si el horno está encendido, sigue habiendo entrada de calor que debe ser removida. No elimina la necesidad — solo la reduce.\",\n          \"isCorrect\": false,\n          \"text\": \"Elimina la necesidad de un aire acondicionado en absoluto\"\n        }\n      ],\n      \"question\": \"¿Qué logra mejorar la aislación termodinámicamente?\"\n    },\n    {\n      \"context\": \"Estoy revisando todo el análisis. Primera ley: El horno añade energía, el aire acondicionado la extrae — ahora entiendo el balance. Segunda ley: El calor naturalmente sube del sótano caliente, el aire acondicionado lo bombea afuera — eso requiere trabajo. Entropía: Cada joule de energía del horno dispersa entropía. Carnot: Nuestro límite de eficiencia es lo que es, dados esos temperaturas. Pero {{NAME}}, aquí viene la pregunta final: Si el cliente quiere mantener costos bajos Y mantener el horno, ¿cuál es la solución más inteligente desde la termodinámica?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfecto. Esto reduce la fuente de calor (primera ley), reduce el flujo natural de calor (segunda ley), disminuye dispersión de entropía, y respeta Carnot. Es la solución más inteligente termodinámicamente.\",\n          \"isCorrect\": true,\n          \"text\": \"Aislación mejorada + apagar horno cuando no se use realmente\"\n        },\n        {\n          \"feedback\": \"Tecnología mejor se acerca a Carnot, pero no lo supera. Si el horno sigue en 24/7, seguirás gastando más energía de la necesaria. Eso es luchar contra la física.\",\n          \"isCorrect\": false,\n          \"text\": \"Invertir en aire acondicionado super potente de últimas tecnología\"\n        },\n        {\n          \"feedback\": \"Eso podría funcionar operacionalmente, pero no responde la pregunta sobre eficiencia termodinámica dentro del contexto actual.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar el sótano menos, relocalizando al horno a otro lugar\"\n        },\n        {\n          \"feedback\": \"Eso podría reducir costos eléctricos, pero no mejora la eficiencia termodinámica del sistema. El aire acondicionado sigue luchando contra la misma carga de calor.\",\n          \"isCorrect\": false,\n          \"text\": \"Instalar paneles solares para alimentar el aire acondicionado\"\n        }\n      ],\n      \"question\": \"¿Cuál es la solución más eficiente energéticamente?\"\n    },\n    {\n      \"context\": \"{{NAME}}, acabamos de implementar la solución. Aislación mejorada en el piso superior, y el horno solo se enciende cuando realmente se necesita almacenamiento. Los costos bajaron a casi lo normal, y la sala está a temperatura. El cliente está feliz. Mirando atrás, lo interesante fue cómo cada ley de termodinámica nos guió a la respuesta correcta. La primera ley nos dijo 'hay energía extra que no ves'. La segunda ley nos dijo 'el calor naturalmente sube'. La entropía nos recordó 'dispersar energía cuesta trabajo'. Y Carnot nos mostró los límites de lo posible. Sin pensar en termodinámica, hubiera sido solo 'compra un aire acondicionado más grande' y perder dinero forever.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Las leyes no son restricciones abstractas — son herramientas que te dicen dónde está realmente el problema. Nos llevaron a apagar el horno innecesario, que fue la solución.\",\n          \"isCorrect\": true,\n          \"text\": \"La termodinámica nos guía a soluciones eficientes identificando fuentes reales de energía\"\n        },\n        {\n          \"feedback\": \"No. La mejor solución en este caso fue entender el sistema con termodinámica. La aislación y apagar el horno costó menos que un aire acondicionado de 10x potencia.\",\n          \"isCorrect\": false,\n          \"text\": \"La mejor solución siempre es comprar tecnología más cara\"\n        },\n        {\n          \"feedback\": \"No. Carnot no es un obstáculo — es la realidad física. Lo que aprendimos es a trabajar dentro de esos límites, no intentar vencerlos.\",\n          \"isCorrect\": false,\n          \"text\": \"Los límites de Carnot son obstáculos que debemos superar\"\n        },\n        {\n          \"feedback\": \"No. La entropía es inevitable, pero podemos minimizar su impacto. Este proyecto mostró cómo reducir la dispersión de energía siendo inteligentes sobre fuentes de calor.\",\n          \"isCorrect\": false,\n          \"text\": \"La entropía siempre significa que todo es un desastre\"\n        }\n      ],\n      \"question\": \"¿Cuál fue la lección clave de este proyecto?\"\n    }\n  ]\n}",
      "outputTokens": 5065,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-physics-thermodynamics-applications-1",
      "userPrompt": "LESSON_TITLE: Termodinamica Aplicada\nLESSON_DESCRIPTION: Aplicando las leyes de la termodinamica para entender y disenar sistemas energeticos\nCHAPTER_TITLE: Termodinamica\nCOURSE_TITLE: Fisica para Ingenieros\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Conservacion de Energia: La primera ley dice que la energia se conserva — no se crea ni destruye, solo se transforma. El calor que entra menos el trabajo que sale iguala el cambio de energia interna.\n2. Direccion del Calor: La segunda ley establece una direccion: el calor fluye espontaneamente de caliente a frio, nunca al reves. Esto limita la eficiencia de cualquier motor termico.\n3. Entropia: La entropia mide la dispersion de energia. Cuando la energia se dispersa (calor fluyendo a lo frio), la entropia aumenta. Concentrar energia requiere trabajo externo.\n4. Limite de Carnot: El ciclo de Carnot define la eficiencia maxima teorica. Ningun motor real puede ser mas eficiente. La eficiencia depende de las temperaturas de las fuentes caliente y fria.\n5. Refrigeracion: Los refrigeradores y bombas de calor mueven calor de frio a caliente usando trabajo. No violan la segunda ley — el trabajo compensa el flujo 'antinatural' de calor."
    },
    {
      "duration": 45472.500416000024,
      "inputTokens": 4226,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we've got a problem. The payment processing service went down for 15 minutes, and during that outage, some users got error messages while others' transactions still went through. Now we're getting complaints that the same charge appeared twice on some accounts, and different regional servers are showing different transaction histories. How do we even begin to untangle this?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. When the servers couldn't communicate with each other, they handled requests independently. Some accepted transactions (prioritizing availability) while others rejected them (trying to stay consistent). This is the classic C vs. A trade-off from the CAP theorem in action.\",\n          \"isCorrect\": true,\n          \"text\": \"A network partition occurred during downtime\"\n        },\n        {\n          \"feedback\": \"Not quite. The database itself is fine—the problem is that different replicas diverged during the partition. They don't have data corruption, they have data disagreement. That's a consistency issue, not corruption.\",\n          \"isCorrect\": false,\n          \"text\": \"Our database is corrupted and needs recovery\"\n        },\n        {\n          \"feedback\": \"This sounds good in theory, but forcing strong consistency would mean blocking all requests until every replica agrees—that's slow and makes our system less available. We need to understand the trade-off first, not just assume stronger is better.\",\n          \"isCorrect\": false,\n          \"text\": \"We need to immediately force all servers into strong consistency mode\"\n        },\n        {\n          \"feedback\": \"That's not the problem here. Our logs show the payment provider processed each request correctly. The issue is internal—how OUR system handled the partition between our replicas.\",\n          \"isCorrect\": false,\n          \"text\": \"The payment provider's API is broken and returning incorrect data\"\n        }\n      ],\n      \"question\": \"What's the core issue we're facing here?\"\n    },\n    {\n      \"context\": \"Okay, so we have replicas in three regions that lost connection for those 15 minutes. During that time, the US region accepted some payment transactions, Europe rejected them, and Asia accepted different ones. Now they're all trying to sync up. {{NAME}}, when they reconnect, which transactions should win? The ones Europe rejected? The ones Asia accepted? We can't just apply all of them or we'll overcharge customers.\",\n      \"options\": [\n        {\n          \"feedback\": \"That doesn't make sense—'strongest' isn't a meaningful concept here. We can't pick an arbitrary region and discard the others' data. Customers in those regions would see their transactions vanish.\",\n          \"isCorrect\": false,\n          \"text\": \"Keep only transactions from the strongest region server\"\n        },\n        {\n          \"feedback\": \"This is smart. By requiring a write quorum (at least 2 out of 3 regions), you ensure that if a partition happens again, only one side can write. If it's just one isolated region, its writes won't stick because it can't reach a quorum. This prevents split-brain conflicts.\",\n          \"isCorrect\": true,\n          \"text\": \"Use quorum logic: accept transactions only if 2+ regions confirm\"\n        },\n        {\n          \"feedback\": \"That's chaos. You'd be accepting that some customers get double-charged, then hoping your manual process catches them all. With millions of transactions, this is error-prone and expensive.\",\n          \"isCorrect\": false,\n          \"text\": \"Accept all transactions and deduplicate customer duplicates manually\"\n        },\n        {\n          \"feedback\": \"Sounds logical, but timestamps can lie—especially during a partition when servers' clocks drift. You'd still end up with the same conflicts you started with, just in 'order'.\",\n          \"isCorrect\": false,\n          \"text\": \"Replay all transactions in timestamp order across all regions\"\n        }\n      ],\n      \"question\": \"What should we do with conflicting transactions from the partition?\"\n    },\n    {\n      \"context\": \"Right, so we implement a 2-of-3 quorum rule going forward. But {{NAME}}, that means if one region goes down, the other two can keep handling requests. But what if one region is so far away that the network latency between it and the other two regions is huge? Requiring quorum confirmation for every write means every payment transaction has to wait for a round-trip to that slow region. Customers will be waiting 500ms for confirmation on every charge. That's brutal for the checkout experience.\",\n      \"options\": [\n        {\n          \"feedback\": \"This is the real trade-off. With eventual consistency, the closer regions confirm quickly, and the distant region syncs up asynchronously. Payments complete fast. During normal operations, they'll converge. You've sacrificed immediate consistency for availability and speed.\",\n          \"isCorrect\": true,\n          \"text\": \"Accept eventual consistency for payment transactions\"\n        },\n        {\n          \"feedback\": \"That works for speed, but now you only need 2 regions to agree. If those 2 partition from the 3rd, both sides can form a quorum and write independently—you're back to split-brain conflicts.\",\n          \"isCorrect\": false,\n          \"text\": \"Remove the distant region from the quorum entirely\"\n        },\n        {\n          \"feedback\": \"Technically safe from partitions, but you've destroyed the user experience. 500ms confirmation times will cause users to abandon carts. Sometimes being highly available matters more than being immediately consistent.\",\n          \"isCorrect\": false,\n          \"text\": \"Require all three regions for every write, accept slower payments\"\n        },\n        {\n          \"feedback\": \"Inconsistent rules (pun intended) create complex logic and bugs. You'd need to categorize every transaction, and edge cases abound. Better to pick a consistent strategy than apply different rules.\",\n          \"isCorrect\": false,\n          \"text\": \"Use strong consistency only for high-value transactions over $1000\"\n        }\n      ],\n      \"question\": \"How do we balance latency against partition safety?\"\n    },\n    {\n      \"context\": \"So we've decided to go with eventual consistency. The regional servers acknowledge writes quickly, and sync asynchronously. But now {{NAME}}, imagine this scenario: A customer in the US updates their payment method from Visa to Mastercard. That change goes to US and EU quickly, but the AU region is still processing it asynchronously. Meanwhile, the customer tries to place an order from Australia and AU still has the old Visa on file. We charge it twice—once with Visa, once with Mastercard. How do we prevent that?\",\n      \"options\": [\n        {\n          \"feedback\": \"That helps for ordering, but not for this scenario. The customer tries to pay with outdated data (Visa) before the update (Mastercard) has reached AU. Last-write-wins would keep Mastercard, but the Visa charge already went through. The ordering doesn't prevent the duplicate.\",\n          \"isCorrect\": false,\n          \"text\": \"Use last-write-wins with server timestamps\"\n        },\n        {\n          \"feedback\": \"Vector clocks track which events happened before others. When AU applies the payment update, it sees that the payment write wasn't causally related to the update (the update happened concurrently). AU can detect the conflict and ask the customer to confirm, or handle the duplicate on application logic. This prevents silent data corruption.\",\n          \"isCorrect\": true,\n          \"text\": \"Use vector clocks to detect causality and conflicts\"\n        },\n        {\n          \"feedback\": \"That's strong consistency again. If you lock during the update, you have to wait for all regions or accept that some regions can't update during the lock. You're back to slow, unavailable writes.\",\n          \"isCorrect\": false,\n          \"text\": \"Lock the payment method record during any update\"\n        },\n        {\n          \"feedback\": \"That's clunky and frustrating. You're trading a technical problem (eventual consistency) for a user experience problem. Users shouldn't wait because of your system's architecture.\",\n          \"isCorrect\": false,\n          \"text\": \"Require customers to wait 1 hour after any payment method change\"\n        }\n      ],\n      \"question\": \"What prevents conflicting writes to the same record?\"\n    },\n    {\n      \"context\": \"Okay, {{NAME}}, we've been deploying vector clocks to detect conflicts. But I just realized something: vector clocks only tell us that a conflict EXISTS. They don't tell us HOW to resolve it. If the AU region detected that the payment and the update were concurrent, should we charge the Visa, the Mastercard, or neither? What's the right merge logic?\",\n      \"options\": [\n        {\n          \"feedback\": \"Vector clocks don't have 'larger' or 'smaller' values—they're partial orders, not total. You can compare them to say 'A happened before B' or 'A and B were concurrent,' but you can't rank concurrent updates as 'bigger' or 'smaller.'\",\n          \"isCorrect\": false,\n          \"text\": \"Always use the write with the larger vector clock value\"\n        },\n        {\n          \"feedback\": \"Perfect. Payment method conflicts can't be resolved by the database alone. The application knows: 'Don't charge twice.' It could pick one method, refund the duplicate, notify the user, or all of the above. The conflict detection (vector clocks) and resolution (business logic) are separate concerns.\",\n          \"isCorrect\": true,\n          \"text\": \"Defer to application logic based on domain rules\"\n        },\n        {\n          \"feedback\": \"Timestamps across distributed systems aren't reliable during partitions—servers' clocks drift. You'd be making resolution decisions on unreliable data. Domain logic (payment rules) is more trustworthy than clock readings.\",\n          \"isCorrect\": false,\n          \"text\": \"Automatically use the most recent timestamp across systems\"\n        },\n        {\n          \"feedback\": \"That might work for some data, but not here. Payments aren't voted on—you need application-specific logic. What if 2 regions have Visa and 1 has Mastercard? Majority vote says Visa, but that might be the wrong call for the customer's intent.\",\n          \"isCorrect\": false,\n          \"text\": \"Use quorum voting: whichever write most regions have wins\"\n        }\n      ],\n      \"question\": \"How should we resolve the conflicting writes?\"\n    },\n    {\n      \"context\": \"Alright, {{NAME}}, the conflict resolution is working. But now the CTO is questioning the whole approach. She's asking: 'If we're accepting eventual consistency and dealing with vector clocks and conflict resolution, why don't we just go full strong consistency mode? Wouldn't that be simpler to reason about, even if it's slower?' I don't have a good answer for her. What am I missing?\",\n      \"options\": [\n        {\n          \"feedback\": \"This is the CAP trade-off at its core. Strong consistency requires coordination—every write blocks until all (or most) replicas agree. But when a partition happens, the system MUST reject writes to maintain consistency. Customers can't complete transactions. Eventual consistency lets some region continue operating even during partitions.\",\n          \"isCorrect\": true,\n          \"text\": \"Strong consistency guarantees every read is latest, but can't survive partitions\"\n        },\n        {\n          \"feedback\": \"Actually, the opposite. Strong consistency requires blocking for coordination, which slows everything down. Eventual consistency writes locally and syncs async. In normal operation, eventual consistency is faster—you pay for it during partitions with conflicts.\",\n          \"isCorrect\": false,\n          \"text\": \"Strong consistency is always faster because there's less syncing\"\n        },\n        {\n          \"feedback\": \"Storage size has nothing to do with consistency model. Both need to store the same data; they just differ in how coordinated the writes are.\",\n          \"isCorrect\": false,\n          \"text\": \"Eventual consistency uses less database storage than strong consistency\"\n        },\n        {\n          \"feedback\": \"Not impossible—just costly. You can have strong consistency in distributed systems, but you pay for it in latency and availability. It's a choice, not a law of physics.\",\n          \"isCorrect\": false,\n          \"text\": \"Strong consistency is impossible in distributed systems anyway\"\n        }\n      ],\n      \"question\": \"Why is eventual consistency better than always using strong consistency?\"\n    },\n    {\n      \"context\": \"{{NAME}}, I've been thinking about what the CTO said, and I want to make sure we're making the right call. Let me lay out the actual trade-off: with strong consistency, if a partition happens, the minority partition stops accepting writes until healed. With eventual consistency, both partitions accept writes and we detect conflicts later with vector clocks. For our payment system, that seems backwards—wouldn't we WANT to reject payments if we're unsure about consistency?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. For some data, immediate consistency is critical—like financial systems where overcharging is unacceptable. For other data, availability matters more—like social media where seeing a slightly old comment is fine. Payments are tricky: conflicts happen, but your business model (refunds, customer service) can handle them if they're rare.\",\n          \"isCorrect\": true,\n          \"text\": \"When your business can tolerate eventual consistency\"\n        },\n        {\n          \"feedback\": \"Not true. Payments ARE important, and we're using eventual consistency. The key is whether your conflict resolution (refunds, customer communication) can handle the rare errors that occur. Importance doesn't dictate consistency needs—conflict tolerance does.\",\n          \"isCorrect\": false,\n          \"text\": \"Only when your data is unimportant or low-value\"\n        },\n        {\n          \"feedback\": \"Latency matters, sure. But choosing eventual consistency over strong consistency isn't just about latency—it's about accepting partition scenarios where both sides can operate. You're trading rare conflicts for guaranteed availability.\",\n          \"isCorrect\": false,\n          \"text\": \"When network latency is your biggest problem\"\n        },\n        {\n          \"feedback\": \"That's too absolute. Some systems do require strong consistency and justify the cost. The question isn't 'is strong consistency safe?'—it's 'can your business afford the trade-offs?' Different systems have different answers.\",\n          \"isCorrect\": false,\n          \"text\": \"Always, because strong consistency is never safe in distributed systems\"\n        }\n      ],\n      \"question\": \"When should we choose availability over consistency?\"\n    },\n    {\n      \"context\": \"Okay, {{NAME}}, we've been running this for a month with eventual consistency and vector clocks. The system's fast, it stayed up during a partition last week, and we handled a few payment conflicts with refunds. But I just got the metrics back, and I'm surprised: we've had FEWER total outages since switching from strong consistency, and our overall latency is lower. The conflicts? Rare enough that refunds are cheaper than the downtime was. But here's what's weird—in all our preparation, nobody mentioned this.\",\n      \"options\": [\n        {\n          \"feedback\": \"No, CAP theorem still holds. We're choosing C+A over P (partition tolerance), but we CAN'T eliminate partitions. The surprise is that for OUR use case, accepting A+P over C turned out better than we expected. That's different from disproving CAP.\",\n          \"isCorrect\": false,\n          \"text\": \"CAP theorem is wrong; you can actually have all three\"\n        },\n        {\n          \"feedback\": \"Bingo. The CAP theorem says you can't have all three, but it doesn't say which pair is 'best'—that's a business decision. Payments aren't typically thought of as 'eventually consistent,' but for us, the cost of conflicts (rare refunds) was lower than the cost of unavailability (customer fury, lost transactions). The right choice depends on YOUR tolerance, not theory.\",\n          \"isCorrect\": true,\n          \"text\": \"The trade-off depends on YOUR data semantics and business model\"\n        },\n        {\n          \"feedback\": \"Maybe, but that's not the surprise. The surprise is that we can quantify it now. Before, strong consistency seemed 'safer.' Now we see the numbers: it was actually costing us more in availability and latency than eventual consistency costs us in conflicts.\",\n          \"isCorrect\": false,\n          \"text\": \"Strong consistency was always the wrong choice for us\"\n        },\n        {\n          \"feedback\": \"Not necessarily. This worked for payments because conflicts are rare and refundable. For something like financial ledgers or medical records, the cost of conflicts might be unacceptable. The lesson isn't 'eventual is always better'—it's 'it depends on the data.'\",\n          \"isCorrect\": false,\n          \"text\": \"We should switch all systems to eventual consistency now\"\n        }\n      ],\n      \"question\": \"What does this tell us about the CAP theorem?\"\n    },\n    {\n      \"context\": \"{{NAME}}, one more thing before we wrap this up. We're bringing a new team member on board next week. She'll be working on inventory management—a totally different system. Should I just tell her, 'Hey, we use eventual consistency for payments, so do the same for inventory'? Or is there something specific to inventory that would make the consistency choice different?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. For inventory, what happens if AU oversells and US undersells? Can you rebalance stock quickly? Is a conflict resolvable by business logic? For payments, conflicts are rare and fixable. For inventory, conflicts might cascade into customer disappointment. The consistency model should match the conflict tolerance, not copy the previous system.\",\n          \"isCorrect\": true,\n          \"text\": \"Analyze the cost of conflicts in that domain\"\n        },\n        {\n          \"feedback\": \"Every system is different. Payments work with eventual consistency because conflicts are rare and refundable. Inventory conflicts (stockouts, overselling) might require different handling. Copy the THINKING, not the config.\",\n          \"isCorrect\": false,\n          \"text\": \"Just copy the payment system's approach for consistency\"\n        },\n        {\n          \"feedback\": \"We just learned strong consistency costs latency and availability. If inventory can tolerate eventual consistency (and it often can, with good rebalancing), forcing strong consistency makes the system slower without proportional safety gains.\",\n          \"isCorrect\": false,\n          \"text\": \"Use strong consistency for everything to be safe\"\n        },\n        {\n          \"feedback\": \"The CTO might help, but the decision should be grounded in data semantics and business tolerance. The inventory team needs to ask: 'What's the cost of a conflict here?' and choose based on that.\",\n          \"isCorrect\": false,\n          \"text\": \"Ask the CTO which consistency model to use\"\n        }\n      ],\n      \"question\": \"How do we decide consistency strategy for a new system?\"\n    }\n  ]\n}",
      "outputTokens": 4469,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-cs-distributed-systems-consistency-1",
      "userPrompt": "LESSON_TITLE: Consistency in Distributed Systems\nLESSON_DESCRIPTION: Navigating consistency and availability trade-offs in distributed systems\nCHAPTER_TITLE: Distributed Data\nCOURSE_TITLE: System Design\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. CAP Theorem: The CAP theorem states you can only have two of three: Consistency, Availability, and Partition tolerance. Since network partitions happen, you're really choosing between C and A.\n2. Strong Consistency: Strong consistency means all nodes see the same data at the same time. Every read returns the most recent write. This requires coordination that can slow things down.\n3. Eventual Consistency: Eventual consistency means replicas will converge given enough time without new writes. Reads might return stale data temporarily, but the system stays available.\n4. Partition Handling: Network partitions occur when nodes can't communicate. The system must decide: reject requests (maintain consistency) or accept requests that might conflict (maintain availability).\n5. Quorum Systems: Quorum-based systems use voting. A write succeeds if enough replicas acknowledge it. Read quorum + write quorum > total nodes ensures reading at least one up-to-date copy.\n6. Conflict Resolution: Conflict resolution strategies handle divergent writes: last-write-wins, vector clocks, or application-specific merge logic. The right choice depends on your data semantics."
    },
    {
      "duration": 69836.989375,
      "inputTokens": 4182,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"Hey {{NAME}}, perfect timing. We're redesigning our company's retirement savings program and it's been a disaster. Only 18% of new employees are enrolling. The benefits are genuinely good — we match up to 6% — but nobody's signing up. Leadership wants a complete overhaul by next week. I was thinking we just need better marketing, but you brought up behavioral design last week. Think that could actually help here?\",\n      \"options\": [\n        {\n          \"feedback\": \"That might be part of it, but the real issue is likely deeper. Most people understand 'free money,' yet still don't sign up. This suggests a behavioral barrier, not an information problem.\",\n          \"isCorrect\": false,\n          \"text\": \"Employees don't understand the match offer\"\n        },\n        {\n          \"feedback\": \"Right. With behavioral design, we first diagnose WHY people avoid the choice. Is it friction? Framing? A default bias? Understanding the behavior comes before fixing it.\",\n          \"isCorrect\": true,\n          \"text\": \"We need to understand how people perceive the choice\"\n        },\n        {\n          \"feedback\": \"Judging people won't help us solve this. Behavioral design assumes people are rational in their own context — we need to find what's rational from their perspective.\",\n          \"isCorrect\": false,\n          \"text\": \"Employees are just financially irresponsible\"\n        },\n        {\n          \"feedback\": \"Possible, but companies with 3% match see higher enrollment. The numbers might not be the main barrier — it's likely how people are experiencing the choice.\",\n          \"isCorrect\": false,\n          \"text\": \"The match percentage is too low\"\n        }\n      ],\n      \"question\": \"What's the core problem we should investigate first?\"\n    },\n    {\n      \"context\": \"Good thinking. Okay, I dug into this. Right now, enrollment happens during onboarding — new hires get a packet of forms, and retirement is just one checkbox among 15 others. It's opt-in: you have to actively choose to enroll. I watched three new employees go through the packet yesterday. Two of them completely skipped the retirement page. They seemed rushed.\",\n      \"options\": [\n        {\n          \"feedback\": \"Loss aversion is real, but the issue here is simpler. These people aren't even reaching a 'choice' point — they're just defaulting to 'not enrolling' because it requires active action.\",\n          \"isCorrect\": false,\n          \"text\": \"Loss aversion — they fear losing money to taxes\"\n        },\n        {\n          \"feedback\": \"Exactly. People stick with pre-selected options. If retirement were auto-enrolled (opt-out), enrollment would likely be 80%+. This requires no marketing — just changing what's pre-selected.\",\n          \"isCorrect\": true,\n          \"text\": \"Default effects — enrollment should be opt-out, not opt-in\"\n        },\n        {\n          \"feedback\": \"Social proof matters, but the immediate blocker is that they have to DO something to enroll. Most never even see what others are doing because they skip the page entirely.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — they don't see others enrolling\"\n        },\n        {\n          \"feedback\": \"Present bias exists, but it's not causing the 82% non-enrollment rate here. The main issue is friction — they'd have to actively opt-in during a busy onboarding.\",\n          \"isCorrect\": false,\n          \"text\": \"Present bias — they can't think long-term\"\n        }\n      ],\n      \"question\": \"What behavioral principle is likely blocking signup here?\"\n    },\n    {\n      \"context\": \"Okay, so we change it to opt-out. But here's the thing — {{NAME}}, I just got pushback from legal. They said opt-out for retirement could be 'paternalistic' and we might face complaints from employees who feel forced into saving. They want us to keep it as an active choice, but just 'improve the messaging.' How do we push back on this?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfect. Opt-out doesn't remove choice — it preserves it completely. People can still opt out anytime. It just changes what the default IS. We're not removing freedom; we're respecting how people actually behave.\",\n          \"isCorrect\": true,\n          \"text\": \"Show them that opt-out increases enrollment without forcing anyone\"\n        },\n        {\n          \"feedback\": \"Social proof is true, but it won't convince legal. They need to understand WHY this works, not just that others do it. The stronger argument is that defaults aren't paternalism—they're respecting reality.\",\n          \"isCorrect\": false,\n          \"text\": \"Tell them opt-out is used by 90% of retirement programs\"\n        },\n        {\n          \"feedback\": \"True, but this concedes that we're trying to fight human nature. The better argument is that we're working WITH it, not against it. Defaults change behavior without messaging tricks.\",\n          \"isCorrect\": false,\n          \"text\": \"Argue that poor messaging can't overcome present bias\"\n        },\n        {\n          \"feedback\": \"This is what legal wanted anyway. Better messaging won't solve a structural problem. With opt-in, even perfect marketing can't overcome the friction and inertia of doing nothing.\",\n          \"isCorrect\": false,\n          \"text\": \"Propose better ads instead of changing the default\"\n        }\n      ],\n      \"question\": \"What's the strongest counter-argument using behavioral design?\"\n    },\n    {\n      \"context\": \"Legal actually bought it — we can do opt-out! But now we're debating the enrollment form itself. We have two options for how to present the enrollment option: (A) 'You are automatically enrolled. You can opt out here.' or (B) 'Most employees choose to enroll. Would you like to enroll?' Which do you think works better?\",\n      \"options\": [\n        {\n          \"feedback\": \"Social proof is powerful, but option A is stronger here. It combines the default effect (you're already in) with an easy opt-out path. People see themselves as members who can leave, not outsiders deciding to join.\",\n          \"isCorrect\": false,\n          \"text\": \"Option B — it uses social proof to influence behavior\"\n        },\n        {\n          \"feedback\": \"Exactly. Option A says 'you're in' (default effect) AND makes it clear you CAN opt out (preserving choice). People stay because inertia favors staying, not because you tricked them.\",\n          \"isCorrect\": true,\n          \"text\": \"Option A — it uses default effects and framing together\"\n        },\n        {\n          \"feedback\": \"Logically equivalent, but behaviorally different. Framing matters. Option A puts people IN the system with an exit ramp. Option B asks them to JOIN from outside. Defaults are sticky.\",\n          \"isCorrect\": false,\n          \"text\": \"Both are equivalent — the numbers say the same thing\"\n        },\n        {\n          \"feedback\": \"Explanation is nice, but it doesn't solve the default problem. Option A works because it uses the default itself, not because of how well we explain the choice.\",\n          \"isCorrect\": false,\n          \"text\": \"Option B — it explains the reasoning better\"\n        }\n      ],\n      \"question\": \"Which framing would be more effective for enrollment?\"\n    },\n    {\n      \"context\": \"Brilliant. Okay, we've got the form copy locked. But {{NAME}}, I just realized something. The match contribution sits in their account for a year before they can touch it. So yes, they're auto-enrolled, but they won't see the money grow for 12 months. I'm worried that when they DO see the statements, they'll have this moment of 'wait, why did I lock this up?' and regret the enrollment. Should we add vesting immediately?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. When they see $5,000 locked away, it feels like a loss relative to having it available. The discomfort isn't irrational — it's loss aversion in action. The pain of restricted access is real.\",\n          \"isCorrect\": true,\n          \"text\": \"Loss aversion — they hate seeing money they can't access\"\n        },\n        {\n          \"feedback\": \"That's not the issue here. The regret is personal, not social. It's about how they perceive their own money, not what others think.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — peers might criticize their choice\"\n        },\n        {\n          \"feedback\": \"Present bias is related, but it's not the specific discomfort they'll feel. The trigger will be SEEING the locked money and feeling loss aversion, not abstract time preference.\",\n          \"isCorrect\": false,\n          \"text\": \"Present bias — they'd rather have money now\"\n        },\n        {\n          \"feedback\": \"Wording helps, but won't solve loss aversion. No amount of calling it a 'secure future fund' changes the fact that they see money they can't touch. The emotion comes from restriction.\",\n          \"isCorrect\": false,\n          \"text\": \"Framing effects — we need better terminology\"\n        }\n      ],\n      \"question\": \"What's actually driving that potential regret?\"\n    },\n    {\n      \"context\": \"Okay, so loss aversion. That actually gives me an idea. What if we don't show them the vested match for 12 months? Like, after vesting, we send them a 'surprise' message: 'Congratulations! You now have access to $5,000 that's been growing.' They see the GAIN, not the restriction. But {{NAME}}, I'm not sure if that's dishonest. We're hiding information. Is that ethical?\",\n      \"options\": [\n        {\n          \"feedback\": \"Right. We choose what to emphasize all the time. Showing a gain instead of a restriction is framing, not deception. Deception would be lying about WHAT the money is or WHERE it came from.\",\n          \"isCorrect\": true,\n          \"text\": \"It's not different — all framing involves choosing what to highlight\"\n        },\n        {\n          \"feedback\": \"No. Framing isn't deception. We're not hiding that vesting exists — it's in the original agreement. We're just choosing when and how to notify them, which is normal business practice.\",\n          \"isCorrect\": false,\n          \"text\": \"It's clearly deceptive because we're withholding facts\"\n        },\n        {\n          \"feedback\": \"That's fair in theory, but it ignores how people actually process information. Both framings are true — we have to choose which one to emphasize. Emphasizing the positive gain is ethical if the facts are accurate.\",\n          \"isCorrect\": false,\n          \"text\": \"We should show both gains and restrictions equally\"\n        },\n        {\n          \"feedback\": \"Behavioral design uses psychology intentionally, yes, but not in a way that lies. The information is available — we're just choosing HOW to present it, which is standard practice.\",\n          \"isCorrect\": false,\n          \"text\": \"Hiding information always violates behavioral ethics\"\n        }\n      ],\n      \"question\": \"Why is hiding information here different from other framing choices?\"\n    },\n    {\n      \"context\": \"Alright, we're going with the 'surprise gain' message at vesting. But now I'm thinking about the long-term picture. {{NAME}}, if we auto-enroll everyone and then send them a gain message at vesting, we're using all these behavioral tricks to keep them saving. But most of them are thinking about that money in their account next year, not in 30 years. How do we actually get them to THINK about retirement?\",\n      \"options\": [\n        {\n          \"feedback\": \"Framing helps, but the real issue is deeper. The money will feel valuable NOW because of present bias. No framing changes that fundamental preference for immediate rewards over future ones.\",\n          \"isCorrect\": false,\n          \"text\": \"Framing effects — retirement feels abstract\"\n        },\n        {\n          \"feedback\": \"Social proof matters for enrollment, but it doesn't solve long-term thinking. Knowing everyone enrolls doesn't make retirement feel less distant or abstract to each individual.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — they don't see retirement as 'what people do'\"\n        },\n        {\n          \"feedback\": \"Exactly. The core problem is that future money feels less valuable than current money. We can auto-enroll them and get them in the system, but present bias will make them want to withdraw it.\",\n          \"isCorrect\": true,\n          \"text\": \"Present bias — they overvalue money available now\"\n        },\n        {\n          \"feedback\": \"Default effects help us with enrollment, but they don't address the psychological pull toward wanting the money NOW. That's present bias, not default effects.\",\n          \"isCorrect\": false,\n          \"text\": \"Default effects — they'll stick with default contributions\"\n        }\n      ],\n      \"question\": \"What behavioral challenge are we trying to solve here?\"\n    },\n    {\n      \"context\": \"Right, so present bias is the real monster here. I looked at our historical data — employees who auto-enroll do stay enrolled, which is great. But about 40% of them never increase their contribution beyond the minimum match. They're saving, but not optimally. Present bias is making them think 'I'll increase it next year' indefinitely. How do we fight that?\",\n      \"options\": [\n        {\n          \"feedback\": \"Education helps with understanding, but it doesn't solve present bias. People already KNOW they should save more. The problem isn't knowledge — it's that more money feels valuable right now.\",\n          \"isCorrect\": false,\n          \"text\": \"Better education about retirement math\"\n        },\n        {\n          \"feedback\": \"Perfect. Commitment devices work by letting people decide in advance (when they think rationally) about their future behavior. 'Commit to higher contributions at your next raise' uses future moments to overcome present bias.\",\n          \"isCorrect\": true,\n          \"text\": \"Commitment devices — let them lock in higher contributions\"\n        },\n        {\n          \"feedback\": \"Social proof influences behavior, but it doesn't solve the temporal problem. Knowing others save more doesn't make their future self any more real or valuable to them than it is now.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — show what high-savers contribute\"\n        },\n        {\n          \"feedback\": \"Reframing is nice, but it doesn't overcome the core issue: present bias makes immediate money feel more valuable. Relabeling the choice doesn't change that preference.\",\n          \"isCorrect\": false,\n          \"text\": \"Framing — call it 'wealth building' not 'saving'\"\n        }\n      ],\n      \"question\": \"What strategy directly counters present bias for future decisions?\"\n    },\n    {\n      \"context\": \"Okay, so we build in a 'commitment device' feature. Employees can set an automatic contribution increase tied to salary raises. They decide NOW when they're thinking clearly, and it happens later when present bias would've stopped them from increasing it themselves. {{NAME}}, we're about to launch this in two weeks, but I want to do one final check — are we using behavioral design ethically here?\",\n      \"options\": [\n        {\n          \"feedback\": \"Explicitness isn't the test. All design uses psychology. The real test is: does it serve the user's actual goals? Employees want to retire securely—we're helping them do that.\",\n          \"isCorrect\": false,\n          \"text\": \"We should get explicit consent for every behavioral technique\"\n        },\n        {\n          \"feedback\": \"Exactly. We're using default effects, framing, and commitment devices—but we preserve choice (opt-out, change rates anytime). And we benefit users (they retire better). That's ethical behavioral design.\",\n          \"isCorrect\": true,\n          \"text\": \"We preserve choice and align incentives with user welfare\"\n        },\n        {\n          \"feedback\": \"Impossible and undesirable. All communication uses psychology. The issue isn't WHETHER to use psychology, but HOW. Using it to serve user interests is ethical.\",\n          \"isCorrect\": false,\n          \"text\": \"We should minimize psychological influence altogether\"\n        },\n        {\n          \"feedback\": \"Transparency helps, but it's not the core test. We could explain every technique and still be unethical if we were tricking people into bad decisions. The test is: does it serve their interests?\",\n          \"isCorrect\": false,\n          \"text\": \"We're manipulative if we don't tell people why we designed it this way\"\n        }\n      ],\n      \"question\": \"How do we know we're using behavioral design responsibly?\"\n    },\n    {\n      \"context\": \"Great. Alright, launch is locked. But {{NAME}}, I just got the analytics back from the pilot. Something unexpected happened. Employees who auto-enrolled are saving at higher rates than we expected—85% stay enrolled. BUT the opt-out rate for employees with family or debt concerns is 22%. That's actually good! But here's the twist: when we send them the 'surprise vesting' message, we're seeing an INCREASE in the opt-out rate immediately after. They see the money and suddenly decide they need it. What's happening?\",\n      \"options\": [\n        {\n          \"feedback\": \"Bingo. Making the money VISIBLE triggers loss aversion. Suddenly, they perceive a loss: 'I have $5,000 I can't use right now.' That pain is more powerful than the abstract future benefit. We actually made regret MORE likely by showing them.\",\n          \"isCorrect\": true,\n          \"text\": \"Loss aversion — they now see it as a loss if they don't withdraw\"\n        },\n        {\n          \"feedback\": \"Present bias exists, but the TRIGGER is loss aversion. They weren't opting out before because they couldn't SEE the money. Now that it's visible and restricted, loss aversion kicks in. The revelation matters, not just time.\",\n          \"isCorrect\": false,\n          \"text\": \"Present bias — they now feel the temptation strongly\"\n        },\n        {\n          \"feedback\": \"Social proof isn't the driver here. The opt-out spike happens right after the message, before people talk to peers. It's the personal experience of seeing locked money.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — they know others are withdrawing\"\n        },\n        {\n          \"feedback\": \"Tone might affect engagement, but the real issue is that we made money VISIBLE. Loss aversion doesn't care about tone—it responds to seeing restricted resources.\",\n          \"isCorrect\": false,\n          \"text\": \"Framing effects — the word 'surprise' felt patronizing\"\n        }\n      ],\n      \"question\": \"Why are some employees opting out after seeing their vested balance?\"\n    },\n    {\n      \"context\": \"Okay, so showing the vesting message backfired because loss aversion made the locked money feel like a loss. We need a better approach for the next milestone. {{NAME}}, I have a few ideas. We could (A) delay the message longer so they forget about it, (B) reframe it to emphasize the growth ('Your $5,000 has grown to $5,800!'), (C) not send a message at all and let them discover it during annual review, or (D) show them a projection of what it'll be worth in 30 years. Which do you think works best?\",\n      \"options\": [\n        {\n          \"feedback\": \"Avoiding the problem doesn't solve it. They'll eventually see the vested balance and feel loss aversion anyway. We're just postponing the regret.\",\n          \"isCorrect\": false,\n          \"text\": \"Delay the message longer to reduce the impact\"\n        },\n        {\n          \"feedback\": \"Perfect. Instead of 'you have money you can't touch,' we say 'your money grew.' Loss aversion responds to FRAMING. Showing growth reframes restriction as accumulation. They see gain, not loss.\",\n          \"isCorrect\": true,\n          \"text\": \"Show growth ('$5,000 → $5,800') to frame as gain\"\n        },\n        {\n          \"feedback\": \"This avoids the moment, but doesn't actually solve loss aversion. Eventually they find it and feel restricted. Plus, we lose the chance to reframe it positively.\",\n          \"isCorrect\": false,\n          \"text\": \"Don't send a message — let them discover it\"\n        },\n        {\n          \"feedback\": \"Future math is nice for commitment devices, but it doesn't address loss aversion about the CURRENT balance. They'll still see the immediate restriction and feel that pain more than future possibility.\",\n          \"isCorrect\": false,\n          \"text\": \"Show 30-year projections to encourage long-term thinking\"\n        }\n      ],\n      \"question\": \"Which approach actually combats loss aversion at its source?\"\n    },\n    {\n      \"context\": \"Brilliant—we reframe to show growth. But {{NAME}}, now I'm realizing we have another problem. We've been so focused on getting people INTO the system that we haven't thought about contribution LEVELS. Right now, the default contribution is 3% to get the full 6% match. Most people stick with that. But we could change the default to 5% or 6%. Would that be exploitative? We're using defaults to push people toward saving more than they chose.\",\n      \"options\": [\n        {\n          \"feedback\": \"Higher defaults are still choices—people can opt out or change them. But there's a real difference: auto-enrollment solves inertia (doing nothing = missing free money). Higher defaults make the choice 'harder' for people who want less. Different ethical balance.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes — higher defaults push people beyond what they'd choose\"\n        },\n        {\n          \"feedback\": \"Not quite. Defaults aren't neutral tools. Some defaults help people achieve their own goals (auto-enrollment). Others override their explicit preferences (forcing higher contributions). The impact on autonomy matters.\",\n          \"isCorrect\": false,\n          \"text\": \"No — all defaults are equally ethically neutral\"\n        },\n        {\n          \"feedback\": \"Right. Auto-enrollment solves the 'inertia' problem (people want to save but don't). Raising the default overrides their choice about HOW MUCH. Auto-enrollment respects autonomy; overriding preferences for their 'own good' is paternalistic.\",\n          \"isCorrect\": true,\n          \"text\": \"It's ethically different — auto-enrollment helps, higher defaults don't\"\n        },\n        {\n          \"feedback\": \"That's partially true, but it misses the key insight: auto-enrollment helps people do what they want. Higher defaults force friction if they want to save less. The ethical difference matters.\",\n          \"isCorrect\": false,\n          \"text\": \"It's the same because people can change their contributions anytime\"\n        }\n      ],\n      \"question\": \"Is changing the default contribution level fundamentally different from auto-enrollment?\"\n    },\n    {\n      \"context\": \"Okay, so we're keeping the default at 3%. One more thing though—I just noticed that employees with dependents are actually enrolling at LOWER rates than single employees. Same auto-enrollment, same messaging. {{NAME}}, why do you think that is? It doesn't make sense—you'd think people with dependents would care more about retirement savings.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exactly. For people living paycheck-to-paycheck with dependents, retirement contributions feel like an immediate loss of money they need NOW. Auto-enrollment works great when people have buffer money. When they don't, loss aversion of losing current income overrides the benefit.\",\n          \"isCorrect\": true,\n          \"text\": \"Loss aversion — they can't afford to lose the take-home pay\"\n        },\n        {\n          \"feedback\": \"Social proof exists, but it wouldn't create a systematic gap by family status. This is a financial/psychological constraint, not a social influence issue.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof — single employees are modeling enrollment\"\n        },\n        {\n          \"feedback\": \"Terminology might help, but the core issue is financial. The message won't fix loss aversion when someone genuinely needs that take-home money to feed their family.\",\n          \"isCorrect\": false,\n          \"text\": \"Framing effects — we're using the wrong terminology\"\n        },\n        {\n          \"feedback\": \"Not exactly. Present bias is preferring future rewards less. But for people with immediate needs, opting out isn't irrational time preference—it's loss aversion about essential income.\",\n          \"isCorrect\": false,\n          \"text\": \"Present bias — they're thinking short-term\"\n        }\n      ],\n      \"question\": \"What behavioral factor might explain this gap?\"\n    },\n    {\n      \"context\": \"Right, so that gap is actually revealing a real constraint, not a behavioral one. People with tight cash flows NEED their take-home pay. Auto-enrollment works for people with financial slack. {{NAME}}, this makes me think we need to segment our approach. What if we used social proof specifically for the lower-income group? Like, 'Among employees in your salary range, 78% chose to enroll.' Would that overcome the loss aversion?\",\n      \"options\": [\n        {\n          \"feedback\": \"Social proof is powerful, but it can't overcome a real financial need. If someone needs $200 more per month to pay rent, seeing that others save won't change their constraints. We're confusing psychology with reality.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes — social proof influences behavior regardless of finances\"\n        },\n        {\n          \"feedback\": \"Exactly. This isn't a behavioral trick problem anymore. These employees have a real financial constraint. Social proof works when the barrier is psychological (uncertainty, inertia). Not when the barrier is 'I need this money to live.'\",\n          \"isCorrect\": true,\n          \"text\": \"No — social proof can't overcome loss aversion about essential money\"\n        },\n        {\n          \"feedback\": \"Still frames it as a messaging problem. But if someone's tight on cash, showing they can 'technically' afford it doesn't change the loss aversion. They're not confused—they're calculating correctly.\",\n          \"isCorrect\": false,\n          \"text\": \"It could work if we show they'd still pay bills\"\n        },\n        {\n          \"feedback\": \"That's backwards. Present bias makes them want the money NOW, which is rational given their situation. We can't psychologically engineer away genuine financial need.\",\n          \"isCorrect\": false,\n          \"text\": \"We should use present bias language to encourage waiting\"\n        }\n      ],\n      \"question\": \"Can social proof overcome genuine financial constraints?\"\n    },\n    {\n      \"context\": \"This is the hard part of behavioral design, isn't it? {{NAME}}, for the low-income group, behavioral tricks don't help. But I have an idea. What if we offered a separate program where the company contributes to a high-yield savings account instead of retirement? People keep full access (no loss aversion trigger), it earns more than checking, and it bridges them toward retirement later. No magic psychology—just a different product for different constraints. Should we launch that?\",\n      \"options\": [\n        {\n          \"feedback\": \"It's a separate offering, not a replacement. And it solves a real problem behavioral tricks can't fix. Sometimes the answer isn't cleverer psychology—it's acknowledging that people have real constraints.\",\n          \"isCorrect\": false,\n          \"text\": \"No — it waters down the retirement program\"\n        },\n        {\n          \"feedback\": \"Exactly right. We've been trying to psychologically engineer around a financial constraint. This solution removes the constraint. No loss aversion about take-home pay, full access, still company-contributed. That's good design, not clever manipulation.\",\n          \"isCorrect\": true,\n          \"text\": \"Yes — it addresses the root cause, not just the behavior\"\n        },\n        {\n          \"feedback\": \"False dichotomy. The point is to meet people where they are. Pushing retirement savings on someone with tight cash flow isn't persistence—it's ignoring their actual situation.\",\n          \"isCorrect\": false,\n          \"text\": \"Maybe — but only if we still push hard on the main program\"\n        },\n        {\n          \"feedback\": \"Behavioral design works WITHIN constraints, not against them. When someone has a real financial need, trying to trick them psychologically is unethical. A separate product respects their situation.\",\n          \"isCorrect\": false,\n          \"text\": \"No — behavioral design should work for everyone\"\n        }\n      ],\n      \"question\": \"Is this a good solution to the actual problem?\"\n    },\n    {\n      \"context\": \"Okay, {{NAME}}, you've convinced me. We're launching the savings bridge program alongside retirement. But before we roll everything out company-wide, I want to make sure we're thinking about this holistically. We've used auto-enrollment, framing, commitment devices, and now a segmented product offering. Looking back at this whole project, what's the core insight about behavioral design we've learned?\",\n      \"options\": [\n        {\n          \"feedback\": \"We've learned the opposite, actually. Behavioral design is powerful when it works WITH how people are, but it can't overcome real constraints. Psychology isn't magic.\",\n          \"isCorrect\": false,\n          \"text\": \"Behavioral tricks can solve almost any product problem\"\n        },\n        {\n          \"feedback\": \"Exactly. The whole journey: we diagnosed defaults (inertia), used framing to reduce loss aversion, commitment devices for present bias. But when we hit a REAL constraint (tight cash flow), psychology wasn't enough. Good design diagnoses what's really blocking people, then addresses it.\",\n          \"isCorrect\": true,\n          \"text\": \"Behavioral design works when you understand the actual constraint\"\n        },\n        {\n          \"feedback\": \"Social proof matters, but this project showed us that different barriers need different tools. Defaults for inertia, framing for loss aversion, segmentation for constraints. No single tool works everywhere.\",\n          \"isCorrect\": false,\n          \"text\": \"Social proof is the strongest behavioral tool\"\n        },\n        {\n          \"feedback\": \"Actually, this project showed the opposite. Ethical design means using psychology INTENTIONALLY to serve user interests. Auto-enrollment helped people. The unethical move would be ignoring how behavior actually works.\",\n          \"isCorrect\": false,\n          \"text\": \"Ethical design means never using behavioral psychology\"\n        }\n      ],\n      \"question\": \"What's the main lesson from this entire redesign?\"\n    }\n  ]\n}",
      "outputTokens": 7316,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-economics-behavioral-design-1",
      "userPrompt": "LESSON_TITLE: Behavioral Design in Practice\nLESSON_DESCRIPTION: Applying behavioral economics principles to design products and systems that work with human psychology\nCHAPTER_TITLE: Applied Behavioral Economics\nCOURSE_TITLE: Product Psychology\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Loss Aversion: Loss aversion means losses hurt more than equivalent gains feel good — roughly twice as much. People will take irrational risks to avoid losses they wouldn't take to achieve gains.\n2. Framing Effects: Framing effects show that how you present options matters as much as what the options are. '90% survival rate' and '10% mortality rate' are logically identical but feel different.\n3. Default Effects: Default effects are powerful because people tend to stick with pre-selected options. Changing the default can dramatically change outcomes without restricting choice.\n4. Present Bias: Present bias makes us overvalue immediate rewards over future ones. We know we should save for retirement, but the money feels more valuable now. Commitment devices help.\n5. Social Proof: Social proof drives behavior — we look to others to decide what's appropriate. Showing that 'most people do X' is often more effective than explaining why X is good."
    },
    {
      "duration": 56294.25320800004,
      "inputTokens": 4335,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, olha só o que aconteceu. Sintetizamos aquele composto que o professor pediu — o brometo de alquila com o nucleófilo que ele forneceu — mas o rendimento ficou horrível. Esperávamos 85%, conseguimos só 25%. E tem mais: o produto que formou... tem um padrão de estereoquímica estranho, tipo uma mistura racêmica. O que você acha que deu errado?\",\n      \"options\": [\n        {\n          \"feedback\": \"SN2 teria givado um rendimento melhor e inversão estereoquímica, não racemização. A mistura racêmica aponta para outro mecanismo.\",\n          \"isCorrect\": false,\n          \"text\": \"SN2 — ataque direto e inversão\"\n        },\n        {\n          \"feedback\": \"Exato! A mistura racêmica é a pista clássica de SN1. O carbocation intermediário é planar, então o nucleófilo ataca de ambos os lados.\",\n          \"isCorrect\": true,\n          \"text\": \"SN1 — carbocation, depois ataque\"\n        },\n        {\n          \"feedback\": \"E2 produziria um alceno, não um produto de substituição. E seu produto é claramente uma substituição, só com estereoquímica estranha.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminação E2 em vez de substituição\"\n        },\n        {\n          \"feedback\": \"Isso não explicaria a mistura racêmica. O problema é o mecanismo de substituição, não degradação do nucleófilo.\",\n          \"isCorrect\": false,\n          \"text\": \"Oxidação do nucleófilo durante a reação\"\n        }\n      ],\n      \"question\": \"Qual mecanismo provavelmente aconteceu aqui?\"\n    },\n    {\n      \"context\": \"Tá bom, então é SN1. Mas espera aí — o professor pediu especificamente para usar um nucleófilo FORTE, tipo alcóxido. Com um nucleófilo forte, não deveríamos estar vendo SN2 em vez de SN1? Por que o SN1 é dominante aqui?\",\n      \"options\": [\n        {\n          \"feedback\": \"Nucleófilos fortes e substratos primários favorecem SN2, não SN1. Tem algo no substrato ou nas condições que favoreceu SN1.\",\n          \"isCorrect\": false,\n          \"text\": \"O nucleófilo forte não importa; o substrato é primário\"\n        },\n        {\n          \"feedback\": \"Verdade! Substratos terciários formam carbocations estáveis e favorecem SN1, mesmo com nucleófilo forte. A estabilidade do intermediário é king aqui.\",\n          \"isCorrect\": true,\n          \"text\": \"O substrato é terciário, favorecendo carbocation estável\"\n        },\n        {\n          \"feedback\": \"Solventes apróticos na verdade FAVORECEM nucleófilos fortes e SN2, não SN1. Cheque as condições — se foi SN1, provavelmente teve solvente prótico.\",\n          \"isCorrect\": false,\n          \"text\": \"Usamos um solvente aprótico que bloqueia SN2\"\n        },\n        {\n          \"feedback\": \"Calor pode acelerar ambos os mecanismos. Mas a real razão para SN1 é a estabilidade do carbocation intermediate — a terciária.\",\n          \"isCorrect\": false,\n          \"text\": \"A reação foi aquecida, acelerando formação do carbocation\"\n        }\n      ],\n      \"question\": \"O que favoreceu SN1 sobre SN2 nesse caso?\"\n    },\n    {\n      \"context\": \"Ah, verdade, {{NAME}}. Eu esqueci de confirmar — é realmente um substrato TERCIÁRIO, 2-bromo-2-metilpropano. Mas agora estou pensando: se sabíamos que era terciário, por que o professor insistiu em usar um nucleófilo forte? Tipo, com terciário e nucleófilo forte, isso não é exatamente um combo ruim para SN2?\",\n      \"options\": [\n        {\n          \"feedback\": \"Nucleófilos fortes não vencem a estabilidade do carbocation. Em um terciário, SN1 é o caminho favorável termodinamicamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Para forçar SN2 e mostrar que nucleófilos fortes sempre ganham\"\n        },\n        {\n          \"feedback\": \"Perfeito! Esse é o ponto-chave: a estrutura do substrato (primário, secundário, terciário) geralmente determina se vai ser SN1 ou SN2, não só o nucleófilo.\",\n          \"isCorrect\": true,\n          \"text\": \"Para ensinar que o substrato determina o mecanismo, não o nucleófilo\"\n        },\n        {\n          \"feedback\": \"Nucleófilos fortes não são a mesma coisa que bases fortes. E velocidade não é o ponto — o mecanismo foi determinado pela estrutura do substrato.\",\n          \"isCorrect\": false,\n          \"text\": \"Para acelerar a reação usando uma base forte\"\n        },\n        {\n          \"feedback\": \"Alcóxidos podem participar de SN1. O mecanismo é definido pela estrutura do carbocation intermediário e estabilidade, não pelo nucleófilo sozinho.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque alcóxidos nunca reagem por SN1 de jeito nenhum\"\n        }\n      ],\n      \"question\": \"Por que o professor pode ter escolhido essas condições?\"\n    },\n    {\n      \"context\": \"{{NAME}}, faz sentido. Então a lição é: com um substrato terciário, SN1 vai dominar. Mas espera — agora estou olhando para a próxima síntese que temos que fazer. Precisa usar um 1-bromo-propano (primário) com um nucleófilo que a gente pode escolher. Se eu quiser GARANTIR que o mecanismo é SN2 e não SN1, qual nucleófilo eu deveria usar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Água é fraca e em solvente prótico favoreceria SN1, não SN2. Você quer um nucleófilo FORTE para SN2 com um substrato primário.\",\n          \"isCorrect\": false,\n          \"text\": \"Água — um nucleófilo fraco e solvente polar prótico\"\n        },\n        {\n          \"feedback\": \"Exato! Nucleófilo forte + substrato primário + solvente aprótico = SN2 puro. O ataque é direto, rápido e estereoseletivo.\",\n          \"isCorrect\": true,\n          \"text\": \"Hidróxido (OH⁻) — nucleófilo forte em solvente aprótico\"\n        },\n        {\n          \"feedback\": \"Acetato é mais fraco do que hidróxido. Com um nucleófilo mais fraco, pode haver competição entre SN2 e E2. Você quer o nucleófilo MAIS FORTE para SN2.\",\n          \"isCorrect\": false,\n          \"text\": \"Acetato (CH₃COO⁻) — uma base conjugada fraca\"\n        },\n        {\n          \"feedback\": \"Metanol é um nucleófilo fraco. Mesmo com um substrato primário, um nucleófilo fraco pode levar a E2 ou reações lado a lado. Precisa de algo mais forte.\",\n          \"isCorrect\": false,\n          \"text\": \"Metanol puro — um nucleófilo e solvente prótico\"\n        }\n      ],\n      \"question\": \"Qual nucleófilo garantiria SN2 com um substrato primário?\"\n    },\n    {\n      \"context\": \"Tá bom, vamos usar hidróxido em DMSO então. {{NAME}}, mas aqui tem um detalhe que me incomoda: a gente vai gerar um álcool como produto (RCH₂OH). E esse álcool tem um grupo hidroxila. Problema é, hidroxila é um grupo de saída HORRÍVEL — é uma base forte. Como é que a reação vai parar depois que a gente faz um álcool, se a hidroxila é um grupo de saída ruim? A gente não vai substituir de novo infinitamente?\",\n      \"options\": [\n        {\n          \"feedback\": \"HO⁻ é na verdade uma BASE FORTE, não fraca. Mas na verdade, o álcool não vai reagir porque a hidroxila do álcool está desprotonada.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque HO⁻ é uma base fraca, então é um bom grupo de saída\"\n        },\n        {\n          \"feedback\": \"Correto! O álcool RCH₂OH é neutro. A hidroxila não sai como HO⁻ (base forte). Para se converter em bom grupo de saida, teria que ser protonada para H₂O, o que requer condições ácidas.\",\n          \"isCorrect\": true,\n          \"text\": \"Porque o álcool é neutro; HO⁻ não está livre para sair\"\n        },\n        {\n          \"feedback\": \"Não é que muda automaticamente. A hidroxila fica presa como HO neutro. Só sairia se fosse protonada a H₂O em ácido.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque o álcool reage um vez e muda para um grupo que não reage\"\n        },\n        {\n          \"feedback\": \"DMSO não destrói álcool. O ponto é que o álcool neutro tem uma hidroxila que é um grupo de saida terrível — não sai espontaneamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Porque hidróxido em DMSO destrói o álcool antes que reaja de novo\"\n        }\n      ],\n      \"question\": \"Por que o álcool não sofre substituição novamente?\"\n    },\n    {\n      \"context\": \"Ah verdade, {{NAME}}! Não pensei nisso. Então um bom grupo de saída precisa ser uma base FRACA — algo que consegue ficar sozinho em solução sem querer capturar próton de novo. Que tipo de grupos a gente usa normalmente como bons grupos de saída nas sínteses reais?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfeito! Cl⁻ é base fraca e grupo de saída estável. Haletos em geral (Cl⁻, Br⁻, I⁻) são bons grupos de saída porque não querem pegar próton de volta.\",\n          \"isCorrect\": true,\n          \"text\": \"Cloreto (Cl⁻) — base fraca, sai fácil\"\n        },\n        {\n          \"feedback\": \"NH₂⁻ é na verdade uma BASE FORTE, não fraca. Amônia seria um grupo de saída PÉSSIMO. Você quer algo ainda mais estável depois que sai.\",\n          \"isCorrect\": false,\n          \"text\": \"Amônia (NH₃) — base fraca que sai como NH₂\"\n        },\n        {\n          \"feedback\": \"F⁻ é na verdade uma base MUITO FORTE. Fluoreto é o haleto PIOR para ser grupo de saída porque quer pegar próton de volta facilmente.\",\n          \"isCorrect\": false,\n          \"text\": \"Fluoreto (F⁻) — o haleto que sai mais fácil\"\n        },\n        {\n          \"feedback\": \"I⁻ é de fato um bom grupo de saída, mas não porque é básico — é porque é FRACAMENTE básico. A resposta mais clara é Cl⁻, que mostra a lógica básica.\",\n          \"isCorrect\": false,\n          \"text\": \"Iodeto (I⁻) — grande e muito básico\"\n        }\n      ],\n      \"question\": \"Qual é um exemplo de bom grupo de saída?\"\n    },\n    {\n      \"context\": \"{{NAME}}, tá claro agora. A gente escolhe grupos de saída que são bases fracas — haletos principalmente. Mas agora estou olhando para um novo desafio: o professor quer que a gente sintetize um produto usando um tosilato (OTs, tosílato) como grupo de saída em vez de haleto. Um tosilato sai mais fácil que um haleto ou não? E por quê?\",\n      \"options\": [\n        {\n          \"feedback\": \"Na verdade, o tamanho não importa aqui. Tosilato sai MELHOR que haleto, e é justamente porque a base conjugada é ainda mais fraca.\",\n          \"isCorrect\": false,\n          \"text\": \"Pior — tosílato é muito grande para sair facilmente\"\n        },\n        {\n          \"feedback\": \"Correto! Tosílato sai melhor que haleto porque TsO⁻ é uma base MUITO mais fraca que Cl⁻ ou Br⁻. Grupos de saída melhores = bases mais fracas.\",\n          \"isCorrect\": true,\n          \"text\": \"Melhor — tosílato é base mais fraca que haleto\"\n        },\n        {\n          \"feedback\": \"Tosilatos na verdade deixam as reações mais rápidas que haletos, porque são grupos de saída MELHORES. Isso vem da base conjugada mais fraca.\",\n          \"isCorrect\": false,\n          \"text\": \"Igual — os dois mecanismos dão o mesmo resultado\"\n        },\n        {\n          \"feedback\": \"A polaridade não é o fator-chave. O que importa é a estabilidade da base conjugada que sai. TsO⁻ é mais estável (base mais fraca) que haletos.\",\n          \"isCorrect\": false,\n          \"text\": \"Pior — haletos sempre ganham porque têm alta polaridade\"\n        }\n      ],\n      \"question\": \"Tosilato é melhor ou pior grupo de saída que haleto?\"\n    },\n    {\n      \"context\": \"Beleza, {{NAME}}. Então tosílatos são ainda melhores que haletos. Mas agora estou vendo um problema real aqui — a gente planejou a síntese com um substrato secundário. Com um secundário, pode ser tanto SN1 quanto SN2 dependendo das condições, certo? Se a gente usa tosílato (excelente grupo de saída) com um nucleófilo forte em solvente aprótico, qual mecanismo vai dominar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Um grupo de saída excelente SIM favorece SN1, mas nucleófilo forte + solvente aprótico compensam isso MUITO mais. SN2 ganha aqui.\",\n          \"isCorrect\": false,\n          \"text\": \"SN1 — tosílato excelente favorece ionização rápida\"\n        },\n        {\n          \"feedback\": \"Exato! Nucleófilo forte e solvente aprótico DOMINAM o mecanismo, mesmo com grupo de saída excelente. SN2 ataque direto é favorecido.\",\n          \"isCorrect\": true,\n          \"text\": \"SN2 — nucleófilo forte + solvente aprótico ganham\"\n        },\n        {\n          \"feedback\": \"Um substrato segue UM mecanismo por vez (SN1 OU SN2). A competição define qual domina, mas em um dado momento é um ou outro. Nucleófilo forte vence.\",\n          \"isCorrect\": false,\n          \"text\": \"Ambos simultaneamente — ambos mecanismos acontecem\"\n        },\n        {\n          \"feedback\": \"Nucleófilo forte não é o mesmo que base forte. Hidróxido é nucleófilo bom e base razoável. Com um secundário, SN2 é competitivo, e ganha aqui.\",\n          \"isCorrect\": false,\n          \"text\": \"E2 — nucleófilo forte com solvente aprótico favorece eliminação\"\n        }\n      ],\n      \"question\": \"Qual mecanismo domina com essas condições?\"\n    },\n    {\n      \"context\": \"{{NAME}}, ótimo! Então a gente vai fazer SN2 com o secundário, tosílato e nucleófilo forte. Mas aí tem uma complicação que eu não tinha planejado bem... {{NAME}}, a gente fez a reação, e rendimento foi bom — tipo 70% — mas quando a gente analisou a estereoquímica do produto, NÃO era inversão estereoquímica pura. Era tipo uma mistura 70% inversão, 30% retenção. Isso não deveria ser SN2 puro, que dá inversão total?\",\n      \"options\": [\n        {\n          \"feedback\": \"SN2 deveria dar inversão, mas talvez houve efeitos secundários ou o substrato não era tão puro estereoquimicamente. Cheque a pureza do começou.\",\n          \"isCorrect\": false,\n          \"text\": \"SN2 sempre dá 100% inversão; isso não foi SN2 então\"\n        },\n        {\n          \"feedback\": \"Provável! Mesmo que SN2 seja dominante, um substrato secundário pode ter uma pequena quantidade de SN1 competindo. Isso daria um pouco de retenção misturada com a inversão.\",\n          \"isCorrect\": true,\n          \"text\": \"Provavelmente teve um pouco de SN1 acontecendo também\"\n        },\n        {\n          \"feedback\": \"Tosílato não muda a estereoquímica esperada de SN2 (inversão). O mecanismo e estereoquímica não mudam por qual grupo de saída (dentro do razoável).\",\n          \"isCorrect\": false,\n          \"text\": \"Tosílato causa retenção estereoquímica de novo modo\"\n        },\n        {\n          \"feedback\": \"Nucleófilos fortes não causam racemização; causam inversão (SN2). Racemização vem de SN1. Se viram mistura, provavelmente teve SN1 competição.\",\n          \"isCorrect\": false,\n          \"text\": \"O nucleófilo forte causa uma reação de racemização\"\n        }\n      ],\n      \"question\": \"Por que não vimos inversão estereoquímica completa?\"\n    },\n    {\n      \"context\": \"{{NAME}}, isso faz sentido. Com um secundário e SN2 dominante, pode ter um pouco de SN1 acontecendo também, o que explicaria a mistura estereoquímica. Então a real lição aqui é: a gente não pode ser 100% absoluto — mesmo que uma condição FAVOREÇA um mecanismo, o outro pode ainda competir um pouco, especialmente com substratos secundários. Como é que a gente minimiza SN1 em um substrato secundário se queremos SN2 puro?\",\n      \"options\": [\n        {\n          \"feedback\": \"Nucleófilo mais fraco não ajuda — faria SN1 e E2 competirem MAIS. Você quer nucleófilo FORTE para favorecer SN2 direto.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar um nucleófilo mais fraco para desacelerar SN2\"\n        },\n        {\n          \"feedback\": \"Solvente prótico FAVORECE SN1, não SN2. Você quer solvente APRÓTICO para favorecer nucleófilo forte e ataque direto.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar solvente polar prótico para estabilizar carbocation\"\n        },\n        {\n          \"feedback\": \"Perfeito! Nucleófilo forte ataca rápido (SN2), solvente aprótico deixa nucleófilo reativo, baixa temperatura REDUZ ionização (SN1). Trifeta para SN2 puro.\",\n          \"isCorrect\": true,\n          \"text\": \"Usar nucleófilo forte + solvente aprótico + baixa temperatura\"\n        },\n        {\n          \"feedback\": \"Adicionar base não ajuda se o problema é competição SN2 vs SN1. Você quer eliminar a ionização, não competir com ela depois.\",\n          \"isCorrect\": false,\n          \"text\": \"Adicionar uma base forte para competir pelo carbocation\"\n        }\n      ],\n      \"question\": \"Como maximizar SN2 e minimizar SN1?\"\n    },\n    {\n      \"context\": \"Agora {{NAME}}, temos uma surpresa real aqui. A gente já fez a síntese direitinho com todas essas condições otimizadas — nucleófilo forte, solvente aprótico, temperatura baixa. Inversão estereoquímica praticamente pura. Excelente SN2. Mas quando a gente passou o produto final para cromatografia de massa, o laboratório descobriu algo inesperado: o nosso produto tem uma impureza significativa que é um isômero REGIOISÔMERO do que a gente queria. Tipo, a gente substituiu em um carbono, mas a reação aconteceu em um carbono diferente também. {{NAME}}, isso não era pra acontecer com SN2, certo?\",\n      \"options\": [\n        {\n          \"feedback\": \"E2 faria um alceno, não um regioisômero. O produto é claramente substituição. Cheque se o substrato era puro — talvez tinha múltiplos focos de ataque.\",\n          \"isCorrect\": false,\n          \"text\": \"SN2 nunca faz regioisômero — tem que ter sido E2 também\"\n        },\n        {\n          \"feedback\": \"Provável! Se o substrato tinha mais de um carbono com grupo de saída, ou uma estrutura que permite ataque em dois lugares, SN2 seria regiosseletivo para cada um. Cheque o começo.\",\n          \"isCorrect\": true,\n          \"text\": \"O substrato começou impuro com múltiplos carbonos reativos\"\n        },\n        {\n          \"feedback\": \"Um nucleófilo em um substrato dado vai atacar o sítio mais acessível. Múltiplos regioisômeros vêm de múltiplos substratos ou estrutura ambígua do começo.\",\n          \"isCorrect\": false,\n          \"text\": \"Nucleófilo forte ataca dois sítios diferentes em paralelo\"\n        },\n        {\n          \"feedback\": \"Solventes apróticos não causam rearranjos. O SN2 é um mecanismo rápido e conserva carbono. Regioisômeros vêm do substrato, não do mecanismo.\",\n          \"isCorrect\": false,\n          \"text\": \"Solvente aprótico causa rearranjo para isômero mais estável\"\n        }\n      ],\n      \"question\": \"Como um regioisômero se forma em uma reação SN2?\"\n    },\n    {\n      \"context\": \"{{NAME}}, você está certo. A gente conferiu e descobriu que o substrato original estava contaminado — tinha uma mistura de regioisômeros de começança. Ou seja, a gente foi vítima de falta de cuidado com a pureza do material começando. Mas sabe o que é legal? Toda essa saga — escolher entre SN1 e SN2, entender por que tosílatos funcionam, otimizar para inversão pura, checar regioquímica do substrato — isso tudo é exatamente como a síntese funciona de verdade. A gente começou não sabendo por que o rendimento ficou péssimo e a estereoquímica era estranho. Agora a gente sabe reconhecer um SN1 pela mistura racêmica, sabe que o substrato define o mecanismo, e sabe como otimizar para SN2 puro. Você pronto para fazer a síntese de novo com material PURO e as condições certas?\",\n      \"options\": [\n        {\n          \"feedback\": \"Nucleófilos fortes FAVORECEM SN2, mas a estrutura do substrato é igualmente importante. Um terciário vai fazer SN1 mesmo com nucleófilo forte.\",\n          \"isCorrect\": false,\n          \"text\": \"Nucleófilos fortes sempre forçam SN2 não importa o substrato\"\n        },\n        {\n          \"feedback\": \"Exato! Nenhum fator sozinho determina o mecanismo. É a combinação: primário+nucleófilo forte=SN2; terciário+solvente prótico=SN1; secundário depende. Tudo importa.\",\n          \"isCorrect\": true,\n          \"text\": \"A estrutura do substrato, nucleófilo, solvente e T° trabalham juntos para definir mecanismo e resultado\"\n        },\n        {\n          \"feedback\": \"Carbocations SÃO estáveis em certos casos, mas SN1 dá mistura racêmica (menos controle estéreo). Para síntese limpa, SN2 é melhor quando possível.\",\n          \"isCorrect\": false,\n          \"text\": \"SN1 é sempre preferível porque carbocations são estáveis\"\n        },\n        {\n          \"feedback\": \"Grupos de saída importam MUITO. Haletos vs tosílatos vs hidroxila — muda a velocidade e às vezes o mecanismo. Estabilidade do grupo de saída conta.\",\n          \"isCorrect\": false,\n          \"text\": \"Grupos de saída não importam; o nucleófilo é tudo\"\n        }\n      ],\n      \"question\": \"Qual é a lição-chave sobre mecanismos de substituição?\"\n    }\n  ]\n}",
      "outputTokens": 6629,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-chemistry-organic-reactions-1",
      "userPrompt": "LESSON_TITLE: Mecanismos de Substituicao\nLESSON_DESCRIPTION: Aplicando mecanismos de reacao organica para prever e otimizar sinteses quimicas\nCHAPTER_TITLE: Reacoes Organicas\nCOURSE_TITLE: Quimica Organica II\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Nucleofilos e Eletrofilos: Nucleofilos sao especies ricas em eletrons que doam pares de eletrons. Eletrofilos sao especies pobres em eletrons que aceitam. Reacoes organicas sao geralmente nucleofilos atacando eletrofilos.\n2. Mecanismo SN2: SN2 e um mecanismo concertado — o nucleofilo ataca enquanto o grupo de saida sai, em um unico passo. Funciona melhor com substratos primarios e nucleofilos fortes.\n3. Mecanismo SN1: SN1 ocorre em dois passos: primeiro o grupo de saida sai formando um carbocation, depois o nucleofilo ataca. Favorecido por substratos terciarios e solventes polares proticos.\n4. Estereoquimica: A estereoquimica revela o mecanismo. SN2 inverte a configuracao (ataque por tras). SN1 pode dar mistura racemicacon (carbocation planar atacado de ambos os lados).\n5. Grupos de Saida: Grupos de saida precisam ser estaveis apos sair. Bons grupos de saida sao bases fracas — haletos, tosilatos, agua protonada. Grupos de saida ruins sao bases fortes."
    },
    {
      "duration": 36786.838959000015,
      "inputTokens": 4310,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, tenemos un problema. Nuestro modelo de clasificación de imágenes médicas tarda 8 horas en entrenar y solo alcanza 82% de precisión. El cliente necesita algo más rápido y más preciso para producción. Estuve mirando arquitecturas desde cero, pero siento que estamos inventando la rueda. ¿Viste que otros equipos ya resolvieron problemas similares?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Las redes pre-entrenadas en ImageNet ya aprendieron patrones generales (bordes, texturas, formas). Podemos ajustar solo las capas finales para nuestra tarea específica — mucho más rápido y preciso que entrenar desde cero.\",\n          \"isCorrect\": true,\n          \"text\": \"Usar transfer learning con una red pre-entrenada\"\n        },\n        {\n          \"feedback\": \"Eso aumentaría los parámetros y haría el entrenamiento incluso más lento. El problema no es falta de capacidad, es que estamos partiendo de cero. Transfer learning es mucho más eficiente aquí.\",\n          \"isCorrect\": false,\n          \"text\": \"Añadir más capas convolucionales al modelo actual\"\n        },\n        {\n          \"feedback\": \"Sigmoid causa el gradiente desvaneciente en redes profundas — lo opuesto a lo que necesitamos. ReLU es mejor para esto. Pero el verdadero cuello de botella es la arquitectura, no la activación.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar la función de activación a sigmoid\"\n        },\n        {\n          \"feedback\": \"El tipo de pooling es un detalle menor comparado con la estrategia fundamental que necesitamos. Transfer learning resolvería tanto velocidad como precisión simultáneamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar solo pooling promedio en lugar de máximo\"\n        }\n      ],\n      \"question\": \"¿Cuál es la mejor estrategia inicial aquí?\"\n    },\n    {\n      \"context\": \"Buena idea. Ya descargué ResNet50 pre-entrenada en ImageNet. Pero ahora tengo una duda: ¿congelamos todos los pesos de ResNet y solo entrenamos una capa clasificadora nueva? ¿O deberíamos permitir que se ajusten también las capas profundas de ResNet?\",\n      \"options\": [\n        {\n          \"feedback\": \"Eso funciona si tu tarea es muy similar a ImageNet, pero imágenes médicas son bastante diferentes. Las capas profundas de ResNet necesitan algo de ajuste para nuestro dominio específico. Es muy restrictivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Congelar todas las capas, ajustar solo la nueva capa de salida\"\n        },\n        {\n          \"feedback\": \"Sí. Las capas tempranas aprenden patrones muy generales (bordes, texturas) que reutilizamos. Las capas posteriores capturan características específicas de ImageNet — esas necesitan ajustarse a imágenes médicas. Entrenamos con tasas de aprendizaje bajas para no arruinar lo aprendido.\",\n          \"isCorrect\": true,\n          \"text\": \"Descongelar capas posteriores y entrenar todo nuevamente\"\n        },\n        {\n          \"feedback\": \"Eso es entrenar desde cero nuevamente — exactamente lo que queremos evitar. El punto entero de transfer learning es reutilizar pesos pre-entrenados.\",\n          \"isCorrect\": false,\n          \"text\": \"Inicializar pesos aleatorios en ResNet desde el principio\"\n        },\n        {\n          \"feedback\": \"ResNet ya tiene batch normalization. Ese no es el problema aquí. La pregunta es sobre qué pesos ajustar durante el fine-tuning, no sobre arquitectura interna.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar batch normalization en cada capa de ResNet\"\n        }\n      ],\n      \"question\": \"¿Cómo ajustamos los pesos pre-entrenados?\"\n    },\n    {\n      \"context\": \"Implementé el fine-tuning y los resultados son mejores: 89% de precisión en 2 horas. Pero {{NAME}}, hay overfitting evidente. La precisión de entrenamiento es 96% pero en validación solo 89%. El cliente mencionó que a veces el modelo falla en casos raros pero críticos. Necesitamos un modelo más robusto.\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfecto. Dropout desactiva neuronas aleatoriamente durante entrenamiento, forzando redundancia. El modelo no puede depender de neuronas específicas, así generaliza mejor. Es especialmente efectivo en capas densas de clasificación.\",\n          \"isCorrect\": true,\n          \"text\": \"Añadir capas de dropout entre capas densas\"\n        },\n        {\n          \"feedback\": \"Eso hace el entrenamiento más ruidoso y generalmente empeora la generalización. Para reducir overfitting, necesitamos regularización — dropout, no tamaños de batch más pequeños.\",\n          \"isCorrect\": false,\n          \"text\": \"Reducir el batch size a 4 para más actualizaciones\"\n        },\n        {\n          \"feedback\": \"Batch normalization ayuda a la generalización, no la daña. De hecho, actúa como regularizador. El problema es que necesitamos más regularización, no menos.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminar batch normalization de la arquitectura\"\n        },\n        {\n          \"feedback\": \"Una tasa más alta haría el entrenamiento menos estable y podría empeorar el sobreajuste. Dropout es la herramienta correcta aquí para forzar que el modelo sea menos dependiente de características específicas.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar la tasa de aprendizaje para converger rápido\"\n        }\n      ],\n      \"question\": \"¿Cómo reducimos el sobreajuste sin sacrificar precisión?\"\n    },\n    {\n      \"context\": \"Añadí dropout (0.5 en capas densas) y ahora el overfitting mejoró — 92% entrenamiento, 91% validación. Mucho mejor. Pero el tiempo de entrenamiento subió a 3.5 horas. El cliente quiere más rápido. Pensé en usar capas de pooling más agresivas para reducir dimensionalidad. ¿Eso nos ayuda?\",\n      \"options\": [\n        {\n          \"feedback\": \"Pooling reduce la dimensión espacial pero no los parámetros de capas densas — donde está el real cuello de botella computacional. Perderíamos información sin ganar mucha velocidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar pooling más agresivo para comprimir características\"\n        },\n        {\n          \"feedback\": \"Sí. Las capas convolucionales usan muchos parámetros. Menos filtros = menos cálculos sin sacrificar mucho porque transfer learning ya aprendió patrones básicos. Probá con 50% de filtros — normalmente apenas impacta precisión.\",\n          \"isCorrect\": true,\n          \"text\": \"Reducir arquitectura: fewer filters en capas convolucionales\"\n        },\n        {\n          \"feedback\": \"Más dropout no acelera entrenamiento — de hecho, puede ralentizarlo. Y perdemos capacidad modelo. Para velocidad, reducimos arquitectura o usamos menos datos de entrenamiento.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumentar dropout a 0.8 para entrenar más rápido\"\n        },\n        {\n          \"feedback\": \"ReLU ya es una de las activaciones más rápidas (solo max(0,x)). No es el cuello de botella. El verdadero problema es la cantidad de parámetros, no el tipo de operación.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar de ReLU a funciones de activación más rápidas\"\n        }\n      ],\n      \"question\": \"¿Cómo aceleramos sin perder precisión?\"\n    },\n    {\n      \"context\": \"Reduje a 50% de filtros — 2.1 horas de entrenamiento, pero precisión bajó a 89%. Eso no es suficiente. Entonces pensé: ¿qué pasa si durante entrenamiento normalizamos cada batch? {{NAME}}, tengo entendido que batch normalization estabiliza el entrenamiento. Si estabilizamos mejor, ¿podemos usar tasas de aprendizaje más altas y converger más rápido?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. Batch normalization normaliza activaciones entre capas, estabiliza gradientes y permite tasas de aprendizaje más altas sin explotar o desvanecerse. Además actúa como regularizador. Reducimos tiempo sin sacrificar precisión.\",\n          \"isCorrect\": true,\n          \"text\": \"Normaliza activaciones, permite tasas aprendizaje más altas y converge rápido\"\n        },\n        {\n          \"feedback\": \"Batch normalization no reduce parámetros — agrega algunos (escala y sesgo por cada característica). Lo que hace es estabilizar entrenamiento, permitiendo convergencia más rápida.\",\n          \"isCorrect\": false,\n          \"text\": \"Reduce parámetros totales del modelo\"\n        },\n        {\n          \"feedback\": \"Batch normalization y dropout son complementarios, no intercambiables. BN estabiliza, dropout regulariza. Necesitamos ambos para robusted y velocidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Reemplaza la necesidad de dropout\"\n        },\n        {\n          \"feedback\": \"Batch normalization mejora convergencia y generalización, pero no garantiza mayor precisión por sí solo. Mejora el entrenamiento — luego podés ajustar hiperparámetros aprovechando esa estabilidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumenta automáticamente la precisión sin cambios\"\n        }\n      ],\n      \"question\": \"¿Cómo ayuda batch normalization aquí?\"\n    },\n    {\n      \"context\": \"Añadí batch normalization a todas las capas convolucionales y subí la tasa de aprendizaje a 0.001. Tiempo bajó a 1.8 horas y precisión es 91%. Excelente. Pero {{NAME}}, acabo de revisar los logs y algo extraño ocurre: el modelo ve un caso de radiografía de un paciente joven sin patología y a veces lo clasifica como patológico. Es raro porque en validación vemos casos similares bien clasificados.\",\n      \"options\": [\n        {\n          \"feedback\": \"Dropout causa variabilidad pero normalmente las predicciones promedian bien. Si vemos inconsistencia en casos similares, el problema no es dropout — es que el modelo no está aprendiendo patrones robustos.\",\n          \"isCorrect\": false,\n          \"text\": \"El dropout está siendo demasiado agresivo con datos similares\"\n        },\n        {\n          \"feedback\": \"¡Ahí está! Durante entrenamiento, BN usa estadísticas del batch. Durante predicción, usa estadísticas acumuladas del entrenamiento. Si nuestros datos de validación son diferentes del entrenamiento, puede haber inconsistencias. Necesitamos revisar si nuestro conjuntos están bien balanceados.\",\n          \"isCorrect\": true,\n          \"text\": \"Batch normalization usa parámetros distintos en entrenamiento vs predicción\"\n        },\n        {\n          \"feedback\": \"Transfer learning en ImageNet captura patrones como bordes y texturas que generalizan bien a radiografías. Si ResNet falla, el problema es más específico — probablemente datos, no arquitectura.\",\n          \"isCorrect\": false,\n          \"text\": \"Las capas convolucionales no detectan bien características médicas\"\n        },\n        {\n          \"feedback\": \"Si la tasa fuera problemática, veríamos oscilaciones en validación, no inconsistencia en predicciones de nuevos datos. El comportamiento sugiere un problema con normalización.\",\n          \"isCorrect\": false,\n          \"text\": \"La tasa de aprendizaje es demasiado alta\"\n        }\n      ],\n      \"question\": \"¿Qué podría estar pasando aquí?\"\n    },\n    {\n      \"context\": \"Investigué. Resulta que nuestro conjunto de validación tiene 80% de casos patológicos — sesgo de muestreo. El modelo aprendió eso implícitamente. Por eso predice \\\"patológico\\\" incluso cuando no debería. Necesitamos rebalancear datos y reentrenar. Mientras tanto, un colega sugirió que pasemos a una arquitectura más profunda — VGG19 en lugar de ResNet50. Dice que capas más profundas atienden mejor patología.\",\n      \"options\": [\n        {\n          \"feedback\": \"Exacto. {{NAME}}, más capas profundas no arreglamos sesgo en datos. VGG19 sería más lenta, más parámetros, sin resolver el verdadero problema. Rebalancear datos primero. Si aún hay problemas, recién entonces exploramos arquitecturas.\",\n          \"isCorrect\": true,\n          \"text\": \"No, primero resolver el problema de datos — arquitectura no es culpable\"\n        },\n        {\n          \"feedback\": \"Profundidad no es garantía de mejor rendimiento. VGG es más lenta (cientos de millones de parámetros) y no resolvería el sesgo. El problema es datos, no capacidad modelo.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí, VGG19 es más profunda y detecta patologías mejor\"\n        },\n        {\n          \"feedback\": \"Agregar arquitectura + dropout complicaría sin resolver la raíz. Si el modelo está sesgado por datos, arreglamos datos primero. Cambios de arquitectura son último recurso.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar arquitectura y añadir más dropout para estabilidad\"\n        },\n        {\n          \"feedback\": \"Eso no tiene sentido — no podemos mezclar arquitecturas así. Y nuevamente, el problema es datos, no arquitectura interna.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar batch normalization en VGG19 pero mantener ResNet50 capas\"\n        }\n      ],\n      \"question\": \"¿Deberíamos cambiar a VGG19?\"\n    },\n    {\n      \"context\": \"Rebalanceamos el dataset (50-50 patológico/normal) y reentrencamos. {{NAME}}, ahora vemos 93% validación y comportamiento consistente — casos similares se clasifican igual. El cliente está feliz con velocidad y precisión. Pero reflcionando: todo esto fue transfer learning + batch normalization + dropout. ¿Cuál fue realmente el factor clave en nuestro éxito?\",\n      \"options\": [\n        {\n          \"feedback\": \"Sí. Transfer learning fue la decisión fundamental — nos permitió partir de patrones generales aprendidos en ImageNet. Sin eso, hubieramos estado entrenando horas sin llegar a 93%. Las optimizaciones (BN, dropout, rebalanceo) fueron mejoras, pero transfer learning fue el cimiento.\",\n          \"isCorrect\": true,\n          \"text\": \"Transfer learning evitó entrenar desde cero ineficientemente\"\n        },\n        {\n          \"feedback\": \"BN ayudó con velocidad y estabilidad, pero sin transfer learning habríamos estado entrenando mucho más. BN fue un optimizador, no el factor clave.\",\n          \"isCorrect\": false,\n          \"text\": \"Batch normalization fue lo que aceleró el entrenamiento\"\n        },\n        {\n          \"feedback\": \"Dropout importa, pero el overfitting real venía del sesgo de datos. Rebalancear datos fue más importante que cualquier regularización. Y sin transfer learning, nada de esto habría funcionado rápido.\",\n          \"isCorrect\": false,\n          \"text\": \"Dropout fue esencial para evitar overfitting\"\n        },\n        {\n          \"feedback\": \"Mantuvimos ResNet50 al final. La arquitectura específica importa menos que la estrategia correcta. Transfer learning + tuning inteligente > buscar la arquitectura \\\"perfecta\\\".\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar de arquitectura fue crucial para precisión\"\n        }\n      ],\n      \"question\": \"¿Cuál fue el aprendizaje más importante de este proyecto?\"\n    }\n  ]\n}",
      "outputTokens": 4295,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-cs-neural-network-architecture-1",
      "userPrompt": "LESSON_TITLE: Arquitecturas de Deep Learning\nLESSON_DESCRIPTION: Disenando y optimizando arquitecturas de redes neuronales para problemas reales\nCHAPTER_TITLE: Arquitecturas de Redes Neuronales\nCOURSE_TITLE: Deep Learning Aplicado\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Capas Convolucionales: Las capas convolucionales detectan patrones locales usando filtros que se deslizan sobre la entrada. El mismo filtro se aplica en todas partes, lo que reduce parametros y captura patrones sin importar su posicion.\n2. Pooling: El pooling reduce la dimension espacial tomando el maximo o promedio de regiones. Esto hace la representacion mas compacta y algo invariante a pequenas traslaciones.\n3. Activaciones: Las funciones de activacion introducen no-linealidad. ReLU (max(0,x)) es popular por ser simple y evitar el problema del gradiente desvaneciente en capas profundas.\n4. Dropout: El dropout desactiva neuronas aleatoriamente durante el entrenamiento. Esto fuerza redundancia y reduce el sobreajuste — la red no puede depender de ninguna neurona especifica.\n5. Transfer Learning: El transfer learning usa redes pre-entrenadas en grandes datasets. Las capas tempranas aprenden patrones generales; las tardias se ajustan a tu tarea especifica.\n6. Batch Normalization: El batch normalization normaliza activaciones entre capas. Estabiliza el entrenamiento, permite tasas de aprendizaje mas altas, y actua como regularizador."
    },
    {
      "duration": 36259.556500000006,
      "inputTokens": 4237,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we've got a problem. The marketing team ran an A/B test on our email subject lines — 10,000 users per variant. They're insisting we roll out variant B because it has a p-value of 0.03. The open rate went from 22% to 23%. But something feels off to me. Am I being paranoid?\",\n      \"options\": [\n        {\n          \"feedback\": \"Actually, p = 0.03 is statistically significant at the standard α = 0.05 level. The issue isn't that it's too high — it's that statistical significance doesn't guarantee the effect matters in practice.\",\n          \"isCorrect\": false,\n          \"text\": \"The p-value is too high to be meaningful\"\n        },\n        {\n          \"feedback\": \"Exactly. With 10,000 users, even a 1% improvement in open rate becomes statistically significant. But is a 1% gain worth rolling out? That's a practical significance question, not a statistical one.\",\n          \"isCorrect\": true,\n          \"text\": \"The effect size is tiny relative to the sample\"\n        },\n        {\n          \"feedback\": \"No — we'd be running multiple comparisons, which inflates Type I errors. With one test at p = 0.03, we already have our result. The issue is interpreting what it means.\",\n          \"isCorrect\": false,\n          \"text\": \"We need to run the test 100 more times\"\n        },\n        {\n          \"feedback\": \"Unlikely with modern A/B testing tools. The real issue is how to interpret a statistically significant but practically small effect. Marketing needs guidance on effect size, not audit.\",\n          \"isCorrect\": false,\n          \"text\": \"Marketing probably made a calculation error\"\n        }\n      ],\n      \"question\": \"What's your first concern about this result?\"\n    },\n    {\n      \"context\": \"Right, that's what I thought. So I pulled the numbers: open rate went from 21.8% to 22.8%. The Cohen's h effect size is 0.02 — basically negligible. But marketing wants to present this to leadership as a success. Should we just tell them it's too small to matter?\",\n      \"options\": [\n        {\n          \"feedback\": \"That's dismissive. Statistical significance is real — p = 0.03 means the difference is unlikely due to chance. But we need to help them think through costs vs. benefits of a 1% improvement.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes, tell them the effect is too small\"\n        },\n        {\n          \"feedback\": \"Perfect. The test works correctly. Now contextualize it: yes, significant; no, the effect is tiny; cost of changing email systems might exceed the benefit of 1% more opens. Let them decide with full information.\",\n          \"isCorrect\": true,\n          \"text\": \"Explain the effect size and practical implications\"\n        },\n        {\n          \"feedback\": \"With 10,000 users per group, the sample is already very large. More data won't change the fundamental issue — we're detecting a small real effect. The question is whether it's worth acting on.\",\n          \"isCorrect\": false,\n          \"text\": \"Ask them to rerun with a larger sample\"\n        },\n        {\n          \"feedback\": \"Testing multiple variants sounds good, but it introduces multiple comparisons problem — we'd expect false positives. Stick to focused, well-powered tests instead.\",\n          \"isCorrect\": false,\n          \"text\": \"Suggest they test 20 variants instead\"\n        }\n      ],\n      \"question\": \"How should we handle this conversation?\"\n    },\n    {\n      \"context\": \"Good call. So I pitched it that way, and leadership actually listened. But now marketing wants to run a bigger test — 50,000 users per variant. They think that'll settle it once and for all. I get the logic, but I'm wondering if we're solving the right problem here.\",\n      \"options\": [\n        {\n          \"feedback\": \"Actually, larger samples do the opposite — they make p-values smaller. A bigger sample with the same effect size will give stronger evidence of significance, but won't change whether the effect is practically important.\",\n          \"isCorrect\": false,\n          \"text\": \"Larger samples will dilute the p-value\"\n        },\n        {\n          \"feedback\": \"Bingo. If the true effect is 1%, a 50k-person study will confirm it's statistically significant even more decisively. But it's still just 1%. We already know the answer — we need to decide if 1% matters, not find better evidence of it.\",\n          \"isCorrect\": true,\n          \"text\": \"A bigger sample won't change practical significance\"\n        },\n        {\n          \"feedback\": \"No — larger samples reduce Type II error (they increase statistical power). The concern here is different: we're wasting resources collecting data to answer a question we've already answered.\",\n          \"isCorrect\": false,\n          \"text\": \"More data increases Type II error risk\"\n        },\n        {\n          \"feedback\": \"Testing multiple variants introduces multiple comparisons problem without addressing the real issue. The question isn't about more variants — it's about whether a 1% effect matters in practice.\",\n          \"isCorrect\": false,\n          \"text\": \"We should split the test across 3 variants\"\n        }\n      ],\n      \"question\": \"What's the real issue with a bigger sample?\"\n    },\n    {\n      \"context\": \"You're right. I told marketing to stop and think about cost-benefit instead. But then they asked something that stumped me: 'What if there's a real effect we're missing because our sample isn't big enough?' How do I know if our sample is actually large enough to detect what we care about?\",\n      \"options\": [\n        {\n          \"feedback\": \"No — p-value measures evidence against the null, not whether we had enough power. A non-significant result could mean no effect OR insufficient power. We need to think about power proactively.\",\n          \"isCorrect\": false,\n          \"text\": \"The p-value tells us if we had enough data\"\n        },\n        {\n          \"feedback\": \"Exactly. Power analysis requires three things: (1) how big an effect would matter practically? (2) what's our significance level? (3) what's the smallest effect we want to detect with, say, 80% probability? Then we calculate the sample needed.\",\n          \"isCorrect\": true,\n          \"text\": \"Sample size, effect size we care about, and power\"\n        },\n        {\n          \"feedback\": \"There's no universal rule. For detecting a 5% effect, 10k might be overkill. For detecting a 0.1% effect, it might be too small. It depends on the specific effect size you're targeting.\",\n          \"isCorrect\": false,\n          \"text\": \"The rule of thumb is always 10,000 per group\"\n        },\n        {\n          \"feedback\": \"Confidence intervals are useful for understanding precision, but power analysis is different. Power tells you the probability of detecting a real effect BEFORE you run the test — it's a design question.\",\n          \"isCorrect\": false,\n          \"text\": \"We calculate it from the confidence interval\"\n        }\n      ],\n      \"question\": \"What determines if a sample is 'large enough'?\"\n    },\n    {\n      \"context\": \"So I explained power analysis, and marketing actually got it. But here's where it gets messy: they want to run five separate tests on different parts of the email — subject line, send time, preview text, CTA color, and footer. Each one will be A/B tested at α = 0.05. They think that's fine because each test is independent.\",\n      \"options\": [\n        {\n          \"feedback\": \"Sample size doesn't prevent the multiple comparisons problem. Even independent tests compound Type I error: with 5 tests at α = 0.05 each, you're expecting about one false positive just by chance.\",\n          \"isCorrect\": false,\n          \"text\": \"Independent tests are fine as long as sample size is large\"\n        },\n        {\n          \"feedback\": \"That's a concern too, but the bigger issue is statistical: multiple comparisons inflate false positive rates. You're doing five independent hypothesis tests, each with a 5% chance of false positive.\",\n          \"isCorrect\": false,\n          \"text\": \"The tests might interfere with each other in the results\"\n        },\n        {\n          \"feedback\": \"Correct. With five independent tests, the overall false positive rate is much higher than 5%. You'd expect approximately one false positive just by random chance. You need to correct for multiple comparisons.\",\n          \"isCorrect\": true,\n          \"text\": \"Five tests at α=0.05 each inflates Type I error\"\n        },\n        {\n          \"feedback\": \"That's one approach, but not the only one. Bonferroni correction, FDR control, or pre-registering which test is 'primary' are all valid ways to handle multiple comparisons.\",\n          \"isCorrect\": false,\n          \"text\": \"They should combine all five into one test\"\n        }\n      ],\n      \"question\": \"What's the problem with five independent tests?\"\n    },\n    {\n      \"context\": \"I explained the multiple comparisons issue, and they asked: 'So we just divide 0.05 by 5?' That's the Bonferroni thing, right? {{NAME}}, is that the right move for us, or are there better options?\",\n      \"options\": [\n        {\n          \"feedback\": \"Bonferroni works (0.05/5 = 0.01 per test), but it's conservative. You might miss real effects. FDR control is less restrictive and often better for exploratory testing like this.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes, Bonferroni is always the right choice\"\n        },\n        {\n          \"feedback\": \"Right. Bonferroni is conservative and might cause Type II errors — you'd miss real effects to be overly cautious about false positives. For five email tests, FDR (False Discovery Rate) control is often better balance.\",\n          \"isCorrect\": true,\n          \"text\": \"No, it's too strict for five tests\"\n        },\n        {\n          \"feedback\": \"Independence doesn't solve the multiple comparisons problem. You're still running five hypothesis tests, each risking a false positive. Some correction is needed.\",\n          \"isCorrect\": false,\n          \"text\": \"Use no correction — they're independent tests\"\n        },\n        {\n          \"feedback\": \"That's p-hacking and makes the false positive problem worse. You need to decide on your correction method BEFORE analyzing, not after seeing results.\",\n          \"isCorrect\": false,\n          \"text\": \"Run all five, but only publish significant ones\"\n        }\n      ],\n      \"question\": \"Should you use Bonferroni here?\"\n    },\n    {\n      \"context\": \"Okay, so we went with FDR control and ran all five tests. Four came back non-significant, but the subject line test hit p = 0.02 with a 1.5% effect. Marketing is thrilled — finally, a winner! But {{NAME}}, something is bothering me. We tested five things. What's the chance that p-value is actually a false positive?\",\n      \"options\": [\n        {\n          \"feedback\": \"The p-value itself doesn't change, but FDR control limits false discovery rate across all five tests. With only one significant result out of five, the false discovery rate is low, making this a fairly reliable finding.\",\n          \"isCorrect\": false,\n          \"text\": \"The p-value is still 0.02, no change needed\"\n        },\n        {\n          \"feedback\": \"Exactly. With FDR = 0.05 and one discovery, you expect about 5% of it to be a false positive. That's much better than the original ~25% false positive rate from five unadjusted tests. This finding is likely real.\",\n          \"isCorrect\": true,\n          \"text\": \"FDR control means ~5% of discoveries are false\"\n        },\n        {\n          \"feedback\": \"That's too strong. We used FDR control, which controls false discovery rate across multiple tests. One significant result out of five has a low probability of being false.\",\n          \"isCorrect\": false,\n          \"text\": \"The result is definitely false because we tested five times\"\n        },\n        {\n          \"feedback\": \"Replication is always good science, but it's not about correcting for multiple comparisons. FDR already gives us confidence that this finding is likely real.\",\n          \"isCorrect\": false,\n          \"text\": \"We should still run a replication study\"\n        }\n      ],\n      \"question\": \"How do you interpret this p-value with FDR control?\"\n    },\n    {\n      \"context\": \"Perfect. So the subject line test looks good, and marketing is ready to implement it. But before they do, leadership asks the question I knew was coming: 'How confident are we this works in the real world? What if this is just a fluke from our test?'\",\n      \"options\": [\n        {\n          \"feedback\": \"That would be a concern if we got a non-significant result. But we got p = 0.02, so we rejected the null. The worry now is different: did we incorrectly reject a true null?\",\n          \"isCorrect\": false,\n          \"text\": \"Type II error — we might have missed other effects\"\n        },\n        {\n          \"feedback\": \"Yes. Even with FDR control, there's still a ~5% chance this is a false positive. We controlled it, but didn't eliminate it. That's the inherent trade-off: we set Type I error to 5% and live with it.\",\n          \"isCorrect\": true,\n          \"text\": \"Type I error — the effect might not be real\"\n        },\n        {\n          \"feedback\": \"With thousands of users per variant, sample size isn't the issue. The question is whether the effect is real or a lucky fluke — that's the Type I error concern.\",\n          \"isCorrect\": false,\n          \"text\": \"The sample size is too small to trust\"\n        },\n        {\n          \"feedback\": \"Effect size (1.5%) is interesting, but it's not about Type I vs Type II error. The leadership question is really about confidence in the result — did we find something real or a false positive?\",\n          \"isCorrect\": false,\n          \"text\": \"We need to check if the effect size is big enough\"\n        }\n      ],\n      \"question\": \"What are we really worried about here?\"\n    },\n    {\n      \"context\": \"So I explained the trade-off: we set α = 0.05, which means we're willing to accept a 5% false positive rate to have reasonable power. Leadership understood, but they asked for one final thing: next time we run tests like this, how do we design them better from the start? What should we document?\",\n      \"options\": [\n        {\n          \"feedback\": \"Pre-registration prevents p-hacking. Before analyzing, you specify: (1) which comparison is primary? (2) what effect size would matter? (3) what's your power target? (4) how will you handle multiple comparisons? Document this, then analyze.\",\n          \"isCorrect\": true,\n          \"text\": \"Only the primary hypothesis and success criterion\"\n        },\n        {\n          \"feedback\": \"That's p-hacking and leads to false positives. You need to pre-specify your hypotheses, success criteria, and multiple comparison method BEFORE analyzing data.\",\n          \"isCorrect\": false,\n          \"text\": \"Just run the tests and report what's significant\"\n        },\n        {\n          \"feedback\": \"The null is usually just 'no effect,' which is fine. What matters more is documenting your ALTERNATIVE hypothesis (what effect would matter?) and power calculation upfront.\",\n          \"isCorrect\": false,\n          \"text\": \"The null hypothesis needs to be very specific\"\n        },\n        {\n          \"feedback\": \"No — that's vague and invites cherry-picking. Pick ONE primary test (the most important business question), handle secondary tests with multiple comparison correction, and document this in advance.\",\n          \"isCorrect\": false,\n          \"text\": \"Document all five tests equally as primary\"\n        }\n      ],\n      \"question\": \"What's critical to document in advance?\"\n    }\n  ]\n}",
      "outputTokens": 3916,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-statistics-hypothesis-testing-1",
      "userPrompt": "LESSON_TITLE: Hypothesis Testing in Practice\nLESSON_DESCRIPTION: Applying statistical hypothesis testing correctly to make sound data-driven decisions\nCHAPTER_TITLE: Statistical Inference\nCOURSE_TITLE: Applied Statistics\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Null Hypothesis: The null hypothesis (H0) is the default assumption of no effect. We try to reject it. The p-value measures how surprising the data would be IF the null were true.\n2. P-Value Meaning: A p-value is NOT the probability the null is true. It's the probability of seeing data this extreme (or more) if the null IS true. A common and dangerous misinterpretation.\n3. Error Types: Type I error (false positive) is rejecting a true null. Type II error (false negative) is failing to reject a false null. You can't minimize both — there's a trade-off.\n4. Statistical Power: Statistical power is the probability of detecting a real effect. It depends on sample size, effect size, and significance level. Low-powered studies miss real effects.\n5. Practical Significance: Statistical significance doesn't mean practical significance. A huge sample can detect tiny effects that don't matter in practice. Always consider effect size.\n6. Multiple Comparisons: Multiple comparisons inflate Type I errors. Testing 20 hypotheses at alpha=0.05 expects one false positive. Corrections like Bonferroni or FDR control this."
    },
    {
      "duration": 47231.71179099998,
      "inputTokens": 4227,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, we need your help on something urgent. The pharmaceutical team is asking if we can use quantum computing to speed up their drug discovery process. They've been running molecular simulations on our classical cluster for weeks, and they're getting impatient. I told them quantum might be an option, but honestly, I'm not sure if we'd actually get faster results or if we'd just waste time. What do you think — should we pitch quantum as a solution here?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not necessarily. Quantum advantage isn't automatic. Molecular simulation MIGHT benefit from quantum (simulating quantum systems is theoretically promising), but we need to know the specific problem type first. Not all simulations are quantum-friendly.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum will definitely solve it faster\"\n        },\n        {\n          \"feedback\": \"Correct. Quantum helps for specific problem types — simulating quantum systems, factoring, certain optimizations. Understanding THEIR problem type determines if quantum is actually relevant. It's the smart first question.\",\n          \"isCorrect\": true,\n          \"text\": \"Ask what type of simulations they're running\"\n        },\n        {\n          \"feedback\": \"Too pessimistic. Quantum DOES have advantages for the right problems. But 'the right problems' is the key constraint. We need to understand if their simulation is one of them.\",\n          \"isCorrect\": false,\n          \"text\": \"Classical machines will always be better\"\n        },\n        {\n          \"feedback\": \"Too hasty. Quantum systems are noisy, require error correction, and have huge overhead. Even if quantum CAN help with their problem, switching immediately could be wasteful. We need to assess first.\",\n          \"isCorrect\": false,\n          \"text\": \"Suggest they switch to quantum immediately\"\n        }\n      ],\n      \"question\": \"What's your first instinct on using quantum for their drug simulations?\"\n    },\n    {\n      \"context\": \"Good thinking. I asked them, and they said they're simulating molecular behavior — specifically protein folding and drug-binding interactions. They want to see how different compounds interact with target proteins. It's a quantum system being studied computationally. I said quantum computers might actually be well-suited for this, but now they're asking: how much faster would we be? They want to know if it's worth migrating their workflow.\",\n      \"options\": [\n        {\n          \"feedback\": \"Misleading. Quantum parallelism lets algorithms evaluate many inputs simultaneously, but measurement collapses that superposition to ONE result. The art is using interference to amplify the right answer — it doesn't automatically give speedups. Be honest about uncertainty.\",\n          \"isCorrect\": false,\n          \"text\": \"Promise 100x speedup — quantum is faster\"\n        },\n        {\n          \"feedback\": \"Right. Quantum advantage is problem-dependent and unproven at scale. Their molecular simulation MIGHT benefit, but we don't know the constants, the noise tolerance, or if their problem structure fits known quantum algorithms. Testing first is honest and smart.\",\n          \"isCorrect\": true,\n          \"text\": \"Say we'll need to test their specific problem first\"\n        },\n        {\n          \"feedback\": \"Too definitive. Molecular simulation is one of the theoretically promising quantum applications. For the right quantum systems and problem sizes, quantum could eventually win. But not yet, not reliably.\",\n          \"isCorrect\": false,\n          \"text\": \"Tell them classical will always be faster\"\n        },\n        {\n          \"feedback\": \"Can't guarantee it. More qubits don't guarantee speedup — they also bring MORE noise and decoherence challenges. Quantum error correction requires thousands of physical qubits per logical qubit. Hardware upgrades alone don't solve the problem.\",\n          \"isCorrect\": false,\n          \"text\": \"Guarantee speedup if they upgrade hardware\"\n        }\n      ],\n      \"question\": \"How should we honestly answer their 'how much faster' question?\"\n    },\n    {\n      \"context\": \"They loved that answer — honesty about limitations builds trust. But then they asked something harder: 'If we do try quantum, what's the biggest risk we should worry about?' I said decoherence, but honestly, {{NAME}}, I'm not even sure if that's the main bottleneck for THEIR use case. Is decoherence really the biggest issue? Or is there something else we should be warning them about?\",\n      \"options\": [\n        {\n          \"feedback\": \"Decoherence IS a real problem — qubits lose coherence when they interact with the environment. But for simulating molecular systems, decoherence is actually less critical than error correction overhead. Molecular simulation might tolerate some noise.\",\n          \"isCorrect\": false,\n          \"text\": \"Decoherence will destroy the quantum state\"\n        },\n        {\n          \"feedback\": \"Bingo. To get reliable quantum results, you need thousands of physical qubits per logical qubit. That's massive overhead. For their problem, the resource cost might make quantum impractical even if it theoretically works. That's the real bottleneck.\",\n          \"isCorrect\": true,\n          \"text\": \"Error correction overhead makes it impractical\"\n        },\n        {\n          \"feedback\": \"Wrong. Simulating quantum systems (like molecules) is one of the most promising quantum computing applications. Quantum computers can naturally represent quantum behavior. The issue isn't capability — it's overhead and practical feasibility.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum computers don't work with molecules\"\n        },\n        {\n          \"feedback\": \"Partial truth. Measurement does collapse superposition, but for molecular simulation, measurement is how you extract the answer — it's by design, not a flaw. The real issue is getting enough coherence and correcting enough errors to reach a useful result.\",\n          \"isCorrect\": false,\n          \"text\": \"Measurement will break their simulation\"\n        }\n      ],\n      \"question\": \"What's actually the biggest risk for their quantum simulation project?\"\n    },\n    {\n      \"context\": \"Okay, so we've told them: quantum MIGHT help for their molecular simulations, but we need to prototype first, and the error correction overhead is massive. They're cautiously excited. But then {{NAME}}, we actually got a chance to run a test on our quantum hardware. We simulated a small protein interaction. The results were... weird. The output seemed to show the right answer buried in the noise, but we can't reliably extract it. The signal is there, but it's drowned out. What does that tell you about what went wrong?\",\n      \"options\": [\n        {\n          \"feedback\": \"Not necessarily broken — you're seeing the core challenge of quantum computing: interference. The algorithm is designed to amplify the right answer through interference, but if decoherence or errors corrupt that interference pattern, the signal gets buried. It's not broken; it's noisy.\",\n          \"isCorrect\": false,\n          \"text\": \"The quantum algorithm is broken\"\n        },\n        {\n          \"feedback\": \"Close, but not quite. Quantum parallelism evaluates all inputs simultaneously, but measurement collapses it to one result. The REAL issue here is that errors are destroying the interference pattern that would normally amplify the right answer. It's a decoherence/error correction problem.\",\n          \"isCorrect\": false,\n          \"text\": \"We're seeing quantum parallelism collapse incorrectly\"\n        },\n        {\n          \"feedback\": \"Exactly. Quantum algorithms work by using interference to amplify correct answers. But decoherence corrupts that interference — errors creep in, the pattern gets scrambled, and the signal drowns in noise. This is why error correction overhead is so critical.\",\n          \"isCorrect\": true,\n          \"text\": \"Decoherence is destroying the interference pattern\"\n        },\n        {\n          \"feedback\": \"Entanglement is working as designed — it links qubits for quantum algorithms. The problem isn't entanglement itself; it's that decoherence and errors are breaking the delicate interference patterns that should highlight the right answer.\",\n          \"isCorrect\": false,\n          \"text\": \"The qubits are entangled wrong\"\n        }\n      ],\n      \"question\": \"What's happening with that 'signal buried in noise' problem?\"\n    },\n    {\n      \"context\": \"We're looking at this noisy output, and I'm trying to figure out our next move. We could: throw more qubits at it and implement full error correction (massive overhead), or we could try a different approach — maybe use fewer qubits with less complex error correction and accept some noise tolerance for this specific problem. The team is split. Some say 'go big or go home.' Others say 'pragmatic error correction.' What's your read on which path actually makes sense for the pharma team?\",\n      \"options\": [\n        {\n          \"feedback\": \"Too risky. Their molecular simulation needs accurate results to be useful. Uncontrolled noise will give garbage answers. Some error correction is necessary, just maybe not FULL fault-tolerant quantum computing levels.\",\n          \"isCorrect\": false,\n          \"text\": \"Skip error correction, accept the noise\"\n        },\n        {\n          \"feedback\": \"Overkill for this stage. Full fault tolerance requires thousands of physical qubits per logical qubit. For a prototype, that's wasteful. Assess if lighter error correction is enough for their accuracy needs first.\",\n          \"isCorrect\": false,\n          \"text\": \"Implement full fault-tolerant error correction\"\n        },\n        {\n          \"feedback\": \"Perfect. Error correction isn't one-size-fits-all. Maybe their problem tolerates 5-10% noise without breaking the answer. Test incrementally: minimal error correction first, then add more if results aren't good enough. This is pragmatic engineering.\",\n          \"isCorrect\": true,\n          \"text\": \"Test what error correction level they actually need\"\n        },\n        {\n          \"feedback\": \"Entanglement is a resource FOR quantum algorithms, not a substitute for error correction. Entanglement helps algorithms work; error correction fixes when decoherence breaks that entanglement. They're different problems.\",\n          \"isCorrect\": false,\n          \"text\": \"Use entanglement to replace error correction\"\n        }\n      ],\n      \"question\": \"How should we approach error correction for their use case?\"\n    },\n    {\n      \"context\": \"So we start testing different error correction levels. Here's where it gets interesting, {{NAME}}: with minimal error correction, we get noisy results. With moderate error correction (a few hundred qubits), we get cleaner signal. But the breakthrough comes when we realize something: the molecular system they're simulating is ITSELF tolerant to small errors. Protein folding has some margin for error — the structure is stable even if the energy calculation is off by a few percent. So moderate error correction is actually enough. We don't need full fault tolerance. The problem itself is forgiving.\",\n      \"options\": [\n        {\n          \"feedback\": \"Wrong conclusion. Quantum computers DO need error correction — that's not a flaw, it's reality. But THIS realization shows that not every problem needs MAXIMUM error correction. Some problems (like theirs) are naturally noise-tolerant.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum computers are useless if they need error correction\"\n        },\n        {\n          \"feedback\": \"Correct. When the problem itself tolerates noise, moderate error correction might be sufficient for real-world speedup. This is how quantum computing becomes practical — matching problem tolerance to hardware reality. It's pragmatic and achievable.\",\n          \"isCorrect\": true,\n          \"text\": \"We can use quantum for THIS problem practically\"\n        },\n        {\n          \"feedback\": \"Not necessarily. It depends on the problem AND the error tolerance. Their molecular simulation needs far fewer resources because the problem structure itself is forgiving. This is actually an advantage.\",\n          \"isCorrect\": false,\n          \"text\": \"All quantum problems need thousands of qubits\"\n        },\n        {\n          \"feedback\": \"Not anymore — not for THEIR problem at this scale. The combination of quantum advantage + problem tolerance + moderate error correction = practical quantum speedup. Classical methods would need weeks; quantum might need hours.\",\n          \"isCorrect\": false,\n          \"text\": \"Classical simulation is still better\"\n        }\n      ],\n      \"question\": \"What does this realization change about our approach?\"\n    },\n    {\n      \"context\": \"Great news — we're getting somewhere. But here's the thing, {{NAME}}: I just realized we should sanity-check our whole approach. The pharma team's simulations — they're classically simulable. It's not like we're trying to factor a huge number. It's not some exotic optimization problem. We CAN simulate proteins on classical computers, it just takes longer. So why would a noisy quantum computer be faster if we can already solve it classically? What's the actual advantage here?\",\n      \"options\": [\n        {\n          \"feedback\": \"True statement, but incomplete. Quantum parallelism doesn't automatically win — you can only read ONE result from measurement. The advantage comes from using INTERFERENCE to amplify the right answer. For classically-solvable problems, that interference magic might not apply.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum parallelism lets us evaluate all possibilities\"\n        },\n        {\n          \"feedback\": \"Maybe actually. Some classically-solvable problems don't have known quantum speedups. But wait — molecular simulation is theoretically promising because quantum computers naturally represent quantum behavior. Classical computers have to simulate quantum mechanics; quantum computers just ARE quantum.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum is slow for this, stick with classical\"\n        },\n        {\n          \"feedback\": \"Right. Simulating quantum behavior classically requires approximating quantum mechanics. A quantum computer IS a quantum system — it naturally encodes quantum behavior. That efficiency difference is where the speedup comes from, even for problems we can solve classically.\",\n          \"isCorrect\": true,\n          \"text\": \"Quantum naturally represents quantum systems\"\n        },\n        {\n          \"feedback\": \"Error correction is overhead, not a speedup source. Error correction ENABLES quantum computing to work reliably, but it doesn't create the advantage. The advantage comes from matching the hardware (quantum) to the problem nature (quantum).\",\n          \"isCorrect\": false,\n          \"text\": \"Error correction makes quantum always faster\"\n        }\n      ],\n      \"question\": \"Why would quantum beat classical for a problem we can already solve?\"\n    },\n    {\n      \"context\": \"Okay, {{NAME}}, I think we've cracked it. Quantum wins for their molecular simulations because they're simulating a quantum system, and a quantum computer naturally encodes quantum behavior — no classical approximation needed. But here's the plot twist nobody expected: I just got off the phone with the pharma team, and they said one of their competitors is already using quantum for similar simulations, and they're getting results 10x faster. They're asking us if we can guarantee we'll beat their competitor's timeline. We can't. And honestly, we don't even know if their competitor's quantum setup is actually faster or if they're just better at marketing. What do we tell them?\",\n      \"options\": [\n        {\n          \"feedback\": \"Risky and dishonest. You don't know their competitor's actual setup, noise levels, or what 'faster' means. Quantum advantage is problem-specific and hardware-specific. Overpromising will backfire when reality hits.\",\n          \"isCorrect\": false,\n          \"text\": \"Promise we'll beat the competitor's timeline\"\n        },\n        {\n          \"feedback\": \"That contradicts what we've learned. Quantum CAN help for molecular simulation, and their competitor might be getting real speedups. Ignoring the possibility hurts your credibility.\",\n          \"isCorrect\": false,\n          \"text\": \"Say classical is still better, forget quantum\"\n        },\n        {\n          \"feedback\": \"Smart. Don't promise impossible speedups, but explain that quantum simulations for molecular behavior are theoretically sound. Your advantage: focusing on stable, reliable results and known error tolerances instead of chasing uncertain speedup claims.\",\n          \"isCorrect\": true,\n          \"text\": \"Acknowledge quantum CAN work, but focus on our reliability\"\n        },\n        {\n          \"feedback\": \"Quantum isn't hype — it has real advantages for specific problems like molecular simulation. But misrepresenting it to the customer damages trust. Be honest about where quantum truly helps and where it doesn't.\",\n          \"isCorrect\": false,\n          \"text\": \"Tell them quantum is a hype, use classical only\"\n        }\n      ],\n      \"question\": \"How do we handle their competitive pressure honestly?\"\n    },\n    {\n      \"context\": \"We present to the pharma team with clear honesty: quantum can help their molecular simulations because they're naturally quantum systems, but speedups aren't magic, error correction is real overhead, and we'll prototype with moderate overhead that matches their problem's noise tolerance. They're impressed by the honesty. They give us the green light to build a quantum pipeline for their protein folding work. As we're wrapping up the meeting, their lead researcher asks something simple but cutting: 'So... will quantum computing eventually replace classical computers?' What's your answer?\",\n      \"options\": [\n        {\n          \"feedback\": \"Overconfident. Quantum excels at specific problem types (factoring, simulation, certain optimization). Classical computers are efficient for most everyday tasks. Coexistence is more likely than replacement. Don't oversell.\",\n          \"isCorrect\": false,\n          \"text\": \"Yes, quantum will replace everything eventually\"\n        },\n        {\n          \"feedback\": \"Too dismissive. Quantum has genuine advantages for the right problems. For molecular simulation, factoring, and specialized optimization, quantum could win decisively. The real answer is more nuanced.\",\n          \"isCorrect\": false,\n          \"text\": \"No, classical will always dominate\"\n        },\n        {\n          \"feedback\": \"Exactly right. Quantum won't replace all computing — it'll excel in specific domains (quantum simulation, factoring, certain optimizations). Classical computing remains dominant for most workloads. Each has its place.\",\n          \"isCorrect\": true,\n          \"text\": \"Quantum will dominate certain niches, classical elsewhere\"\n        },\n        {\n          \"feedback\": \"Decoherence is a real challenge, but error correction (despite its overhead) can address it. The question isn't whether decoherence makes quantum impossible — it's whether error correction overhead is worth it for THAT problem.\",\n          \"isCorrect\": false,\n          \"text\": \"Decoherence will always make quantum impractical\"\n        }\n      ],\n      \"question\": \"Will quantum replace classical computing entirely?\"\n    },\n    {\n      \"context\": \"Great answer. The team leaves happy. But {{NAME}}, as we're leaving, I'm thinking about everything we just learned. We started out saying 'quantum might help with their drug discovery,' and we ended up with a real implementation plan. But I'm realizing something: we didn't let the hype drive us. We asked what problem they had, we assessed if quantum was actually suitable, we tested the noise tolerance, and we were honest about limitations. We didn't try to force quantum onto a problem that didn't need it. That's the real lesson here, isn't it?\",\n      \"options\": [\n        {\n          \"feedback\": \"This defeats everything we learned. Quantum is powerful FOR SPECIFIC PROBLEMS. Using it everywhere wastes resources and creates unnecessary complexity. The real skill is knowing WHEN to use it.\",\n          \"isCorrect\": false,\n          \"text\": \"Quantum is amazing, use it for everything\"\n        },\n        {\n          \"feedback\": \"Exactly. This whole journey was about assessing first: What problem are we solving? Is quantum actually suitable? What's the error overhead? Can we tolerate it? This pragmatic thinking is what separates effective quantum engineers from marketing hype.\",\n          \"isCorrect\": true,\n          \"text\": \"Match the tool to the problem, not hype to hope\"\n        },\n        {\n          \"feedback\": \"Not true. Quantum does have genuine advantages for specific domains. But this contradicts the real lesson: knowing your problem type and choosing the right tool accordingly.\",\n          \"isCorrect\": false,\n          \"text\": \"Classical computers can solve everything better\"\n        },\n        {\n          \"feedback\": \"Error correction is a tool, not a magic solution. Yes, it enables quantum computing, but its overhead is significant. The lesson is assessing whether that overhead is worth it FOR THIS SPECIFIC PROBLEM.\",\n          \"isCorrect\": false,\n          \"text\": \"Error correction makes quantum always viable\"\n        }\n      ],\n      \"question\": \"What's the key takeaway from this whole process?\"\n    }\n  ]\n}",
      "outputTokens": 4896,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "en-physics-quantum-computing-basics-1",
      "userPrompt": "LESSON_TITLE: Quantum Computing Fundamentals\nLESSON_DESCRIPTION: Understanding quantum computing capabilities and limitations for practical problem-solving\nCHAPTER_TITLE: Quantum Information\nCOURSE_TITLE: Quantum Computing Fundamentals\nLANGUAGE: en\nEXPLANATION_STEPS:\n1. Superposition: Qubits can exist in superposition — a weighted combination of 0 and 1 states. This isn't 'both at once' — it's a probability amplitude that interferes before measurement.\n2. Entanglement: Entanglement links qubits so measuring one instantly determines the other, regardless of distance. This correlation is a resource for quantum algorithms.\n3. Quantum Parallelism: Quantum parallelism lets algorithms evaluate functions on all inputs simultaneously. But you can only read one result — the art is using interference to amplify the right answer.\n4. Decoherence: Decoherence destroys quantum information when qubits interact with their environment. Real qubits are noisy and maintain coherence only briefly.\n5. Error Correction: Quantum error correction encodes logical qubits in many physical qubits. The overhead is huge — thousands of physical qubits per logical qubit for fault tolerance.\n6. Where Quantum Helps: Quantum advantage requires the right problem type. Factoring, simulation, and certain optimization problems benefit. Most classical algorithms won't be replaced."
    },
    {
      "duration": 44342.398042000015,
      "inputTokens": 4306,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, bom timing. Temos um problema que precisa ser decomposto em servicos. A plataforma de e-commerce tá ficando monolítica demais — pedidos, catálogo, pagamentos, tudo junto. A equipe de pedidos quer velocidade, mas não consegue mover rápido porque qualquer mudança afeta o resto. Você concorda que precisamos de microservicos?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exato! Limites de serviço devem acompanhar domínios de negócio, não camadas técnicas. Cada domínio tem seu próprio modelo, regras de negócio e ciclo de vida.\",\n          \"isCorrect\": true,\n          \"text\": \"Por domínios de negócio: Pedidos, Catálogo, Pagamentos\"\n        },\n        {\n          \"feedback\": \"Isso é um antipadrão em microservicos. Separar por camadas cria acoplamento e derrota o propósito — você acaba com serviços que dependem uns dos outros.\",\n          \"isCorrect\": false,\n          \"text\": \"Por camadas técnicas: API, Banco de Dados, Cache\"\n        },\n        {\n          \"feedback\": \"Limites por tamanho são arbitrários e frágeis. Um serviço importante pode crescer legitimamente. O critério deve ser domínio de negócio, não métricas de código.\",\n          \"isCorrect\": false,\n          \"text\": \"Por tamanho de código: módulos que ocupam menos linhas\"\n        },\n        {\n          \"feedback\": \"Isso mistura escalabilidade com design arquitetural. Qualquer serviço pode ficar popular. A estrutura deve ser baseada em domínio, a escalabilidade em infraestrutura.\",\n          \"isCorrect\": false,\n          \"text\": \"Por volume de requisições: serviços para features mais usadas\"\n        }\n      ],\n      \"question\": \"Como você definiria os limites dos primeiros servicos?\"\n    },\n    {\n      \"context\": \"Perfeito. Então temos Pedidos, Catálogo e Pagamentos como três servicos separados. Agora o Pedidos precisa saber os preços do Catálogo pra confirmar a ordem, e depois precisa chamar Pagamentos pra processar. Como você quer comunicar isso? Síncrono ou assíncrono?\",\n      \"options\": [\n        {\n          \"feedback\": \"Funciona, mas é frágil. Se Pagamentos ficar lento, a criação de pedidos congela. Falhas em cascata são garantidas. Melhor considerar assíncrono.\",\n          \"isCorrect\": false,\n          \"text\": \"Síncrono (REST): Pedidos chama Catálogo e Pagamentos em tempo real\"\n        },\n        {\n          \"feedback\": \"Muito melhor! Assíncrono desacopla os serviços. Se Pagamentos demora, a criação do pedido não congela. Mais resiliente, mesmo que mais complexo de debugar.\",\n          \"isCorrect\": true,\n          \"text\": \"Assíncrono: Pedidos publica eventos que Catálogo e Pagamentos consomem\"\n        },\n        {\n          \"feedback\": \"Isso é o pior dos dois mundos — mantém a fragilidade de chamar Catálogo sincronamente, ganhando complexidade de eventos. Escolha uma estratégia clara.\",\n          \"isCorrect\": false,\n          \"text\": \"Uma chamada síncrona para Catálogo, depois assíncrona para Pagamentos\"\n        },\n        {\n          \"feedback\": \"Variabilidade sem bom motivo. A falha rápida de Catálogo ainda trava tudo. Se Catálogo é crítico, cache ou réplica podem ajudar melhor que REST.\",\n          \"isCorrect\": false,\n          \"text\": \"Ambas: Catálogo por REST quando precisa resposta rápida, Pagamentos por fila\"\n        }\n      ],\n      \"question\": \"Qual abordagem você recomenda para essa comunicação?\"\n    },\n    {\n      \"context\": \"Ótimo. Implementamos a comunicação assíncrona — Pedidos publica um evento 'PedidoCriado', e Pagamentos consome. Mas agora {{NAME}} temos um problema: como Pedidos e Catálogo compartilham dados de preço? Cada serviço precisa ter seu próprio banco de dados?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto! Dados descentralizados. Pedidos recebe preços via evento ou query, armazena uma cópia pra garantir consistência eventual. Cada serviço é autossuficiente.\",\n          \"isCorrect\": true,\n          \"text\": \"Cada serviço tem seu próprio banco, Pedidos copia preços do Catálogo\"\n        },\n        {\n          \"feedback\": \"Isso derrota o propósito de microservicos. Você perde independência de escala e deploy. Uma mudança no schema afeta todos os serviços.\",\n          \"isCorrect\": false,\n          \"text\": \"Todos compartilham um banco de dados centralizado\"\n        },\n        {\n          \"feedback\": \"Acoplamento tight. Pedidos depende de Catálogo estar disponível toda vez. Lento e frágil. Copiar dados (eventual consistency) é melhor.\",\n          \"isCorrect\": false,\n          \"text\": \"Pedidos consulta Catálogo em tempo real toda vez que precisa de preço\"\n        },\n        {\n          \"feedback\": \"Isso cria um novo ponto único de falha. Volta ao acoplamento. Em microservicos, cada um é responsável pelos dados que precisa.\",\n          \"isCorrect\": false,\n          \"text\": \"Um serviço 'Dados Compartilhados' que todos consultam\"\n        }\n      ],\n      \"question\": \"Como você estruturaria os dados nessa arquitetura?\"\n    },\n    {\n      \"context\": \"Implementamos. Mas agora {{NAME}} estou vendo algo preocupante nos logs — o serviço de Pagamentos tá demorando muito, cada requisição leva 8 segundos. E isso tá fazendo com que as requisições pra fila de eventos acumulem, a latência de todo o sistema subiu. O Pedidos tá tentando processar, mas a fila tá explodindo. Como a gente detecta e impede isso?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exato! Circuit breaker evita cascata de falhas. Depois que Pagamentos recupera, o circuito feita de novo. Não deixa a fila explodir esperando por um serviço quebrado.\",\n          \"isCorrect\": true,\n          \"text\": \"Circuit breaker: se Pagamentos falhar, pula e marca como falho\"\n        },\n        {\n          \"feedback\": \"Sem circuit breaker, retry piora as coisas! Se Pagamentos está lento, retry só aumenta a pressão. Você precisa parar de tentar em algum ponto (circuit breaker).\",\n          \"isCorrect\": false,\n          \"text\": \"Retry automático: tenta de novo várias vezes até conseguir\"\n        },\n        {\n          \"feedback\": \"Timeout ajuda, mas sozinho não é suficiente. O problema é Pagamentos estar lento SEMPRE, não ocasionalmente. Você precisa de circuit breaker pra para completamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Timeout curto: se não responder em 5 segundos, desiste\"\n        },\n        {\n          \"feedback\": \"Isso trata o sintoma, não a causa. Se Pagamentos tem um gargalo (banco lento?), copias extras não ajudam. Circuit breaker trata a cascata enquanto investiga a raiz.\",\n          \"isCorrect\": false,\n          \"text\": \"Escalabilidade: adiciona mais servidores de Pagamentos\"\n        }\n      ],\n      \"question\": \"Qual padrão de resiliência você ativaria?\"\n    },\n    {\n      \"context\": \"Ativei o circuit breaker, a cascata parou. Mas agora temos outro problema — um cliente reclama que o pagamento foi processado, mas o pedido nunca foi confirmado. Os logs de Pedidos mostram que o evento 'PagamentoProcessado' foi publicado, mas alguma coisa não conectou. Como diabos a gente rastreia isso?\",\n      \"options\": [\n        {\n          \"feedback\": \"Essencial! Com tracing distribuído você vê exatamente onde o evento se perdeu. Qual serviço recebeu? Qual ignorou? Sem isso, é quase impossível debugar.\",\n          \"isCorrect\": true,\n          \"text\": \"Tracing distribuído: rastreia o evento através de todos os serviços\"\n        },\n        {\n          \"feedback\": \"Logs ajudam, mas sem correlação entre serviços (tracing) é como procurar agulha em palheiro. Você vê eventos, mas não sabe se estão conectados.\",\n          \"isCorrect\": false,\n          \"text\": \"Logs centralizados: junta todos os logs em um lugar\"\n        },\n        {\n          \"feedback\": \"Métricas dizem QUANTOS eventos, mas não QUAIS. Para esse problema específico de evento perdido, você precisa rastrear sua jornada (tracing).\",\n          \"isCorrect\": false,\n          \"text\": \"Métricas de serviço: monitora quantos eventos cada um processa\"\n        },\n        {\n          \"feedback\": \"Impossível — isso só aconteceu uma vez em produção com específico timing. Você precisa observabilidade em tempo real (tracing), não reprodução.\",\n          \"isCorrect\": false,\n          \"text\": \"Reproduzir em desenvolvimento: recriar a sequência localmente\"\n        }\n      ],\n      \"question\": \"O que você implementaria primeiro para debugar?\"\n    },\n    {\n      \"context\": \"Implementamos tracing distribuído. {{NAME}}, isso resolveu! O trace mostrou que Catálogo recebeu o evento, atualizou o inventário, mas mandou o evento 'InventárioAtualizado' pra fila errada. Um erro de configuração. Consertei. Mas agora pensei — se um serviço atualiza dados e depois publica evento, e o evento falha, temos inconsistência. Como a gente garante que o dados e o evento estão sempre sincronizados?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correto. Event sourcing registra tudo como eventos (source of truth). Ou use compensação (saga) — se evento falha, reverte a mudança de dados. Consistência eventual guaranteed.\",\n          \"isCorrect\": true,\n          \"text\": \"Event sourcing ou transação distribuída com compensação\"\n        },\n        {\n          \"feedback\": \"Isso vai contra o princípio de microservicos! Transações distribuídas são lentas, complexas e criam acoplamento forte. A lição foi clara: evite isso.\",\n          \"isCorrect\": false,\n          \"text\": \"Transação distribuída: coordena todos os serviços na mesma transação\"\n        },\n        {\n          \"feedback\": \"Isso não resolve. Se a fila tá fora do ar indefinidamente, retry infinito congela tudo. Você precisa de um mecanismo que reverta a mudança se não conseguir publicar.\",\n          \"isCorrect\": false,\n          \"text\": \"Retry infinito: continua tentando até o evento passar\"\n        },\n        {\n          \"feedback\": \"Redundância não é garantia. Duplicar o evento cria outras inconsistências — qual fila é verdade? Sem um padrão como event sourcing, fica caótico.\",\n          \"isCorrect\": false,\n          \"text\": \"Duplicar a atualização em múltiplas filas para garantir\"\n        }\n      ],\n      \"question\": \"Como você garantiria consistência nesse caso?\"\n    },\n    {\n      \"context\": \"Tá funcionando bem agora. Event sourcing resolveu o problema de consistência. Mas {{NAME}}, temos uma situação estranha — o serviço de Relatórios (que consome eventos de todos os outros) tá sempre atrasado. Uns 5 minutos atrás do que realmente aconteceu. A gente alertar clientes sobre falhas em tempo real, mas o Relatórios mostra que tudo está bem. O problema é que Relatórios tá consumindo lentamente. Você quer parar e esperar Relatórios ficar em dia, ou aceita isso?\",\n      \"options\": [\n        {\n          \"feedback\": \"Bingo! Relatórios que atrasam 5 minutos é totalmente aceitável — é o trade-off de microservicos desacoplados. Alertas críticos vêm direto de quem viu, não de relatórios.\",\n          \"isCorrect\": true,\n          \"text\": \"Aceitar o atraso: consistência eventual é normal em microservicos\"\n        },\n        {\n          \"feedback\": \"Isso congela o sistema inteiro! Seria como parar de processar pedidos porque o histórico tá atrasado. Derrota o propósito de desacoplamento.\",\n          \"isCorrect\": false,\n          \"text\": \"Parar tudo e esperar Relatórios ficar em dia\"\n        },\n        {\n          \"feedback\": \"Volta ao acoplamento e fragilidade. Se Relatórios ficasse fora, ninguém poderia processar pedidos. Assíncrono é certo; atraso é o preço.\",\n          \"isCorrect\": false,\n          \"text\": \"Relatórios deve ser síncrono: aguarda confirmação de cada evento\"\n        },\n        {\n          \"feedback\": \"Não resolve o problema. Relatórios ainda tá consumindo devagar (gargalo é nele). Múltiplas filas só piora a complexidade sem ganho real.\",\n          \"isCorrect\": false,\n          \"text\": \"Criar uma fila separada só pra Relatórios, prioridade máxima\"\n        }\n      ],\n      \"question\": \"Qual abordagem você escolheria?\"\n    },\n    {\n      \"context\": \"Aceitei o atraso de Relatórios — é parte do jogo. Mas {{NAME}}, descobri algo que me preocupa: Pagamentos tá consultando Catálogo via REST pra validar que o produto ainda existe antes de processar. Isso tá criando um acoplamento entre serviços novamente. E se Catálogo ficar lento ou fora? Todo pagamento falha. Achei que a gente tinha saído dessa?\",\n      \"options\": [\n        {\n          \"feedback\": \"Perfeito! Pagamentos recebe um evento 'ProdutoAtivo' do Catálogo, armazena uma cópia. Valida localmente, sem chamar Catálogo. Desacoplado e resiliente.\",\n          \"isCorrect\": true,\n          \"text\": \"Pagamentos copia dados de Catálogo via evento; valida localmente\"\n        },\n        {\n          \"feedback\": \"Cache ajuda, mas é frágil. Se Catálogo ficar fora por mais de 1 hora, Pagamentos fica cego. Copiar dados via evento é mais robusto.\",\n          \"isCorrect\": false,\n          \"text\": \"Cachear a resposta de Catálogo por 1 hora\"\n        },\n        {\n          \"feedback\": \"Isso piora! Agora você tem um novo ponto único de falha (o gateway). Microservicos devem ser independentes, não coordenados por um intermediário.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar um gateway API que coordena Pagamentos e Catálogo\"\n        },\n        {\n          \"feedback\": \"Isso é perigoso. Cada serviço precisa validar seus dados. Confiar em outro serviço para garantir integridade é uma receita para bugs.\",\n          \"isCorrect\": false,\n          \"text\": \"Remover a validação — confiar que Pedidos já validou\"\n        }\n      ],\n      \"question\": \"Como você resolveria esse acoplamento?\"\n    },\n    {\n      \"context\": \"Ótimo. Pagamentos agora copia dados de Catálogo. Mas {{NAME}}, tive uma percepção: a gente mudou de um monolito para microservicos pra ganhar velocidade e escalabilidade. Mas agora temos observabilidade complexa (tracing, logs centralizados), comunicação assíncrona (filas, eventos), dados replicados (consistência eventual), resiliência (circuit breakers)... tudo mais complicado. Será que valeu? O que a gente realmente ganhou?\",\n      \"options\": [\n        {\n          \"feedback\": \"Exato! Pedidos pode escalar pra Black Friday sem tocar Catálogo. Catálogo pode ter bug e Pagamentos continua rodando. É sobre autonomia e resiliência, não simplicidade.\",\n          \"isCorrect\": true,\n          \"text\": \"Cada serviço escala, deploy e falha independentemente\"\n        },\n        {\n          \"feedback\": \"Na verdade, código fica mais complexo — agora você lidia com assincronismo, timeouts, eventual consistency. Microservicos ganham em escalabilidade, não em simplicidade.\",\n          \"isCorrect\": false,\n          \"text\": \"Código fica mais simples e fácil de entender\"\n        },\n        {\n          \"feedback\": \"Pelo contrário! Microservicos AUMENTAM a necessidade de observabilidade. Sem tracing distribuído e logs centralizados, você tá cego.\",\n          \"isCorrect\": false,\n          \"text\": \"Não precisa mais de observabilidade ou monitoramento\"\n        },\n        {\n          \"feedback\": \"Comunicação ainda existe (eventos, REST), só é desacoplada. O ponto é que falhas em um serviço não cascateiam pra todos.\",\n          \"isCorrect\": false,\n          \"text\": \"Eliminamos toda necessidade de comunicação entre serviços\"\n        }\n      ],\n      \"question\": \"Qual foi o verdadeiro ganho dessa arquitetura?\"\n    },\n    {\n      \"context\": \"Você resumiu bem. {{NAME}}, isso me lembrou de algo — você viu que a maioria de nossos problemas surgiu porque a gente não tinha observabilidade adequada no início? Demorou pra descobrir que Pagamentos tava lento, que o evento se perdeu, que Relatórios tava atrasado. Se a gente tivesse implementado logs centralizados, métricas e tracing desde o começo, teria economizado horas. Qual é a lição?\",\n      \"options\": [\n        {\n          \"feedback\": \"Isso! Sem logs centralizados, métricas e tracing, microservicos é como dirigir de olhos fechados. Você PRECISA disso desde o dia 1, não é feature adicional.\",\n          \"isCorrect\": true,\n          \"text\": \"Observabilidade não é opcional em microservicos, é fundação\"\n        },\n        {\n          \"feedback\": \"Logs ajudam, mas não são suficientes sozinhos. Você precisa TAMBÉM de métricas (performance) e tracing (jornada do evento). Tudo junto = observabilidade.\",\n          \"isCorrect\": false,\n          \"text\": \"Logs centralizados resolvem todos os problemas de microservicos\"\n        },\n        {\n          \"feedback\": \"Monolito tem seus próprios problemas em escala. Microservicos foi certa pra vocês — mas a lição é fazer com observabilidade desde o início.\",\n          \"isCorrect\": false,\n          \"text\": \"A gente deveria ter ficado no monolito, era mais simples\"\n        },\n        {\n          \"feedback\": \"Não. Como vimos, sem observabilidade você congela gastando horas debugando. Adicionar depois é como tentar consertar uma casa sem piso — muito mais caro.\",\n          \"isCorrect\": false,\n          \"text\": \"Observabilidade é luxo que podemos adicionar depois\"\n        }\n      ],\n      \"question\": \"Qual é o ponto-chave aqui?\"\n    }\n  ]\n}",
      "outputTokens": 5181,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "pt-cs-microservices-architecture-1",
      "userPrompt": "LESSON_TITLE: Microservicos na Pratica\nLESSON_DESCRIPTION: Projetando e implementando arquiteturas de microservicos com consciencia dos trade-offs\nCHAPTER_TITLE: Arquitetura de Software\nCOURSE_TITLE: Engenharia de Software Avancada\nLANGUAGE: pt\nEXPLANATION_STEPS:\n1. Definicao de Microservicos: Microservicos sao servicos pequenos e independentes que fazem uma coisa bem. Cada um pode ser desenvolvido, implantado e escalado separadamente.\n2. Limites de Servico: Limites de servico devem seguir dominios de negocio, nao camadas tecnicas. Um servico de 'Pedidos' faz sentido; um servico de 'Banco de Dados' nao.\n3. Comunicacao: A comunicacao entre servicos pode ser sincrona (REST, gRPC) ou assincrona (filas, eventos). Assincrona e mais resiliente mas mais complexa de debugar.\n4. Dados Descentralizados: Dados descentralizados significam que cada servico tem seu banco. Consistencia eventual e a realidade — transacoes distribuidas sao dificeis e devem ser evitadas.\n5. Resiliencia: Falhas em cascata acontecem quando um servico lento trava outros. Circuit breakers, timeouts e fallbacks sao essenciais para resiliencia.\n6. Observabilidade: Observabilidade requer logs centralizados, metricas e tracing distribuido. Sem isso, debugar problemas em producao e quase impossivel."
    },
    {
      "duration": 102214.739917,
      "inputTokens": 4277,
      "output": "{\n  \"steps\": [\n    {\n      \"context\": \"{{NAME}}, tenemos un problema real. La empresa de envíos SoloCargo nos contrató porque sus costos de operación están disparados. El gerente dice que el volumen de paquetes es fijo — 5000 unidades al mes — pero el costo total de transporte, almacenamiento y gestión varía según el tamaño del envío que elijamos. Más envíos pequeños significa más gestión; menos envíos grandes significa más almacenamiento. Necesitamos encontrar el tamaño óptimo. ¿Por dónde empezamos?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Antes de optimizar, debemos expresar el costo total como función del tamaño del envío. Esto es el modelado del problema — identificar la función objetivo es el primer paso.\",\n          \"isCorrect\": true,\n          \"text\": \"Definir la función de costo total\"\n        },\n        {\n          \"feedback\": \"No es el orden correcto. No podemos hallar puntos críticos sin saber QUÉ función estamos derivando. Primero modelamos, luego optimizamos.\",\n          \"isCorrect\": false,\n          \"text\": \"Buscar los puntos críticos inmediatamente\"\n        },\n        {\n          \"feedback\": \"Los extremos del dominio importan, pero no hasta después. Primero necesitamos establecer la función objetivo y luego determinar qué dominio tiene sentido.\",\n          \"isCorrect\": false,\n          \"text\": \"Evaluar los extremos del dominio\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores de Lagrange se usan cuando hay restricciones de igualdad. Aquí el volumen es fijo, pero no es una restricción que necesite multiplicadores — es parte de cómo definimos la función.\",\n          \"isCorrect\": false,\n          \"text\": \"Aplicar multiplicadores de Lagrange\"\n        }\n      ],\n      \"question\": \"¿Cuál es el primer paso para modelar este problema?\"\n    },\n    {\n      \"context\": \"He estado analizando los datos de SoloCargo. Si cada envío tiene x unidades, entonces el número de envíos al mes es 5000/x. El costo por gestión de cada envío es de 50 pesos (documentos, seguimiento, etc.), así que el costo total de gestión es 50 · (5000/x) = 250000/x. El almacenamiento es más complicado — es un costo proporcional al inventario promedio en mano, que es aproximadamente x/2 unidades, a 2 pesos por unidad por mes. Entonces el costo de almacenamiento es 2 · (x/2) = x. {{NAME}}, ¿qué función de costo total deberíamos optimizar?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. C(x) suma el costo de gestión (250000/x) y el costo de almacenamiento (x). Esta es la función que debemos optimizar para encontrar el tamaño de envío que minimiza el costo.\",\n          \"isCorrect\": true,\n          \"text\": \"C(x) = 250000/x + x\"\n        },\n        {\n          \"feedback\": \"Casi, pero el costo de almacenamiento ya está correctamente simplificado a x, no 2x. Verifica: costo es 2 pesos por unidad; inventario promedio es x/2; entonces 2 · (x/2) = x.\",\n          \"isCorrect\": false,\n          \"text\": \"C(x) = 250000/x + 2x\"\n        },\n        {\n          \"feedback\": \"No. Esto no captura la relación correcta. El costo de gestión disminuye cuando x aumenta (menos envíos), no aumenta. La función debe ser 250000/x, no 50x.\",\n          \"isCorrect\": false,\n          \"text\": \"C(x) = 50x + 250000\"\n        },\n        {\n          \"feedback\": \"El primer término es incorrecto. El costo de gestión es 50 pesos por envío, no por unidad. Con 5000/x envíos, el costo es 50 · (5000/x) = 250000/x.\",\n          \"isCorrect\": false,\n          \"text\": \"C(x) = 5000/x + x\"\n        }\n      ],\n      \"question\": \"¿Cuál es la función de costo total C(x)?\"\n    },\n    {\n      \"context\": \"Perfecto. Ahora tenemos C(x) = 250000/x + x. Para minimizar el costo, necesito encontrar los puntos críticos. He calculado la derivada: C'(x) = -250000/x² + 1. Igualando a cero: -250000/x² + 1 = 0, lo que da x² = 250000, así que x = 500. Pero {{NAME}}, ¿realmente este es un mínimo? ¿Cómo verifico que no es un máximo o un punto de inflexión?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Calcula C''(x) = 500000/x³. En x = 500, C''(500) > 0, lo que confirma que es un mínimo local por la prueba de segunda derivada.\",\n          \"isCorrect\": true,\n          \"text\": \"Aplicar la prueba de segunda derivada\"\n        },\n        {\n          \"feedback\": \"Esto te da intuición, pero no es el método formal. La prueba de segunda derivada te lo confirma algebraicamente: si f''(c) > 0, entonces c es un mínimo local.\",\n          \"isCorrect\": false,\n          \"text\": \"Evaluar C(x) en puntos cercanos\"\n        },\n        {\n          \"feedback\": \"Eso sería la prueba de la primera derivada, que también funciona. Pero es menos directo que la segunda derivada. Usa C''(x) para confirmación rápida.\",\n          \"isCorrect\": false,\n          \"text\": \"Verificar que C'(x) cambia de signo\"\n        },\n        {\n          \"feedback\": \"No hay relación. Que x sea positivo no garantiza nada sobre si es máximo o mínimo. Debes usar la prueba de segunda derivada u otro método de verificación.\",\n          \"isCorrect\": false,\n          \"text\": \"Asumir que es un mínimo porque x es positivo\"\n        }\n      ],\n      \"question\": \"¿Cómo verificas que x = 500 es un mínimo?\"\n    },\n    {\n      \"context\": \"Excelente. Entonces x = 500 es un mínimo local. El costo en ese punto es C(500) = 250000/500 + 500 = 500 + 500 = 1000 pesos. Pero espera, {{NAME}}, tengo que ser honesto: SoloCargo no puede enviar exactamente 500 unidades por envío. El cliente tiene máquinas que envasan en lotes de 100 unidades. Entonces x puede ser 100, 200, 300, 400, 500, 600... o teóricamente cualquier múltiplo de 100. ¿Qué hacemos ahora?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Como x debe ser múltiplo de 100, evalúa C(400), C(500) y C(600). Elige el que da el costo menor. Este es el mínimo global dentro de los valores permitidos.\",\n          \"isCorrect\": true,\n          \"text\": \"Evaluar C(x) en los múltiplos de 100 más cercanos\"\n        },\n        {\n          \"feedback\": \"500 ya es múltiplo de 100. Pero en general, redondear no garantiza el óptimo en problemas discretos. Siempre evalúa los candidatos cercanos.\",\n          \"isCorrect\": false,\n          \"text\": \"Redondear 500 al múltiplo de 100 más cercano\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores de Lagrange se usan para restricciones continuas de igualdad (como maximizar ganancia sujeto a presupuesto = 100). Aquí tenemos una restricción discreta.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar multiplicadores de Lagrange para la restricción\"\n        },\n        {\n          \"feedback\": \"Cambiar el modelo lo haría innecesariamente complicado. Es más simple: optimiza con el modelo continuo, luego evalúa los mejores candidatos discretos.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar el modelo matemático para incluir el multiple\"\n        }\n      ],\n      \"question\": \"¿Cómo resuelves esta restricción de valores discretos?\"\n    },\n    {\n      \"context\": \"Calculé los costos: C(400) = 250000/400 + 400 = 625 + 400 = 1025 pesos. C(500) = 1000 pesos. C(600) = 250000/600 + 600 ≈ 416.67 + 600 = 1016.67 pesos. Así que x = 500 sigue siendo la mejor opción. Le presento esto al gerente de SoloCargo, pero dice algo que no me esperaba: 'Espera. Nuestro distribuidor nos cobra una cuota de conexión de 200 pesos por cliente, sin importar el tamaño del envío. Si nos asociamos con múltiples distribuidores, necesitaríamos pagar esa cuota múltiples veces.' {{NAME}}, me está diciendo que hay una restricción que no consideré. ¿Esto cambia nuestro modelo?\",\n      \"options\": [\n        {\n          \"feedback\": \"No es del todo correcto. Si usamos solo un distribuidor, sumamos 200 una vez. Pero si el volumen es muy grande, podrías necesitar múltiples distribuidores. Esto es más complejo.\",\n          \"isCorrect\": false,\n          \"text\": \"Sumar 200 pesos como costo fijo en C(x)\"\n        },\n        {\n          \"feedback\": \"Correcto. Si cada distribuidor puede manejar hasta cierto volumen, el modelo debe considerar cuántos distribuidores necesitas. Esto convierte la restricción en parte de la función objetivo.\",\n          \"isCorrect\": true,\n          \"text\": \"Redefinir C(x) incluyendo costos por distribuidor\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores de Lagrange se usan cuando la restricción es una ecuación que vincula variables. Aquí es un costo discreto por distribuidor — parte de la función objetivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Usar un multiplicador de Lagrange para este costo\"\n        },\n        {\n          \"feedback\": \"No. La restricción del distribuidor puede cambiar significativamente el óptimo. Ignorarla significa resolver el problema equivocado. Siempre modelar restricciones reales.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignorar esta restricción; es secundaria\"\n        }\n      ],\n      \"question\": \"¿Cómo incorporas la restricción del distribuidor?\"\n    },\n    {\n      \"context\": \"Tienes razón. Resulta que cada distribuidor puede manejar hasta 1000 unidades de inventario promedio. Como el inventario promedio es x/2, entonces cada distribuidor puede servir hasta x ≤ 2000. Si x = 500, necesitamos solo un distribuidor. Pero esto abre una pregunta: ¿podríamos REDUCIR x a algo más pequeño para ahorrar en almacenamiento, y usar el dinero ahorrado para pagar otro distribuidor si es necesario? Por ejemplo, ¿qué pasa con x = 250? C(250) = 250000/250 + 250 = 1000 + 250 = 1250 pesos. Eso es PEOR. Pero espera... {{NAME}}, acabo de darme cuenta de algo que no cuadra. ¿Realmente el costo debe ser tan alto? ¿No estamos perdiendo algo?\",\n      \"options\": [\n        {\n          \"feedback\": \"No. El inventario promedio en mano es x/2 (asumiendo consumo constante), y eso es lo que debería costar. El modelo de almacenamiento es correcto.\",\n          \"isCorrect\": false,\n          \"text\": \"El costo de almacenamiento es proporcional a x, no x/2\"\n        },\n        {\n          \"feedback\": \"Exacto. Mientras x ≤ 2000, pagamos 200 por un distribuidor. Pero C(x) = 250000/x + x no incluye ese costo fijo. La función completa debería ser C(x) = 250000/x + x + 200.\",\n          \"isCorrect\": true,\n          \"text\": \"No incluimos el costo del distribuidor en la función\"\n        },\n        {\n          \"feedback\": \"No. El costo de gestión es 50 · (5000/x) = 250000/x. Eso está correcto en el modelo.\",\n          \"isCorrect\": false,\n          \"text\": \"El costo de gestión tiene un término que no sumamos\"\n        },\n        {\n          \"feedback\": \"No hay evidencia de un costo de procesamiento adicional. El problema establece claramente cuáles son los costos. No inventes componentes.\",\n          \"isCorrect\": false,\n          \"text\": \"Hemos olvidado un costo de procesamiento de paquetes\"\n        }\n      ],\n      \"question\": \"¿Qué aspecto del problema hemos modelado incorrectamente?\"\n    },\n    {\n      \"context\": \"Claro, incluimos el costo del distribuidor. Entonces C(x) = 250000/x + x + 200. Ahora minimicemos de nuevo. C'(x) = -250000/x² + 1 = 0 da x² = 250000, así que x = 500 nuevamente. El costo es C(500) = 500 + 500 + 200 = 1200 pesos. Pero {{NAME}}, espera... esto no me gusta. Acabo de recordar algo que el cliente mencionó de pasada: 'Nuestro volumen podría crecer a 7000 unidades en seis meses.' Si el volumen total pasa a 7000, entonces... oh no. Con x = 500, tendríamos 7000/500 = 14 envíos. Eso está bien. Pero si queremos mantener el MISMO tamaño de envío para simplificar, ¿seguiría siendo óptimo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Casi correcto en forma, pero el costo de gestión es 50 por envío. Con V/x envíos, es 50·(V/x) = 50V/x, no 250V/x. La forma es C(x) = 50V/x + x + 200.\",\n          \"isCorrect\": false,\n          \"text\": \"C(x) = V·(250/x) + x + 200; optimiza nuevamente\"\n        },\n        {\n          \"feedback\": \"Correcto. Ahora C'(x) = -50V/x² + 1 = 0 da x = √(50V). Cuanto mayor sea V, mayor debe ser x para minimizar costo. El óptimo es proporcional a √V.\",\n          \"isCorrect\": true,\n          \"text\": \"C(x) = 50V/x + x + 200; la solución depende de V\"\n        },\n        {\n          \"feedback\": \"No. La función objetivo cambió porque el volumen total es variable. Tienes que reoptimizar cuando los parámetros del modelo cambian.\",\n          \"isCorrect\": false,\n          \"text\": \"El tamaño x = 500 es óptimo independientemente de V\"\n        },\n        {\n          \"feedback\": \"Podemos expresar la solución en términos de V. Para V = 5000, x = 500; para V = 7000, x ≈ 592. La relación es general.\",\n          \"isCorrect\": false,\n          \"text\": \"No podemos resolver esto sin conocer el valor exacto de V\"\n        }\n      ],\n      \"question\": \"¿Cómo cambia el problema si el volumen total V es variable?\"\n    },\n    {\n      \"context\": \"Exacto. {{NAME}}, ahora veo el cuadro completo. Para cualquier volumen V, el tamaño óptimo es x = √(50V). Para V = 5000, x = 500. Para V = 7000, x ≈ 591.6, que redondeamos a x = 600. Cuando le presento esto al gerente, se queda pensando y dice: 'Esto tiene sentido, pero los paquetes que despachamos tienen un valor variable. Los clientes a veces piden envíos pequeños y valiosos, a veces grandes y baratos. ¿Esto afecta la decisión del tamaño del envío?' Me detengo. Creo que {{NAME}} está sacando a relucir algo fundamental que podría cambiar TODO. ¿Qué implicación tiene el valor del paquete en el tamaño óptimo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. El modelo C(x) = 50V/x + x + 200 se basa en costos operacionales (gestión, almacenamiento, distribuidor), no en el valor de lo que se envía. El valor afecta ganancia, no costo operacional.\",\n          \"isCorrect\": true,\n          \"text\": \"No; el costo es independiente del valor del paquete\"\n        },\n        {\n          \"feedback\": \"¿Por qué? El costo de envío no depende del valor. Confundes valor (qué se vende) con costo (lo que cuesta procesar). Estos son problemas diferentes.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí; paquetes valiosos necesitan envíos más pequeños\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores de Lagrange se aplican a restricciones de igualdad (como 'el costo debe ser exactamente X'). El valor del paquete no crea una restricción de ese tipo aquí.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí; usaríamos multiplicadores de Lagrange\"\n        },\n        {\n          \"feedback\": \"No necesariamente. El tamaño óptimo de envío minimiza costo por unidad. El valor cambia la GANANCIA por unidad, pero no el COSTO óptimo de envío.\",\n          \"isCorrect\": false,\n          \"text\": \"Sí; necesitamos un nuevo modelo con múltiples variables\"\n        }\n      ],\n      \"question\": \"¿Debería el valor del paquete afectar el tamaño de envío?\"\n    },\n    {\n      \"context\": \"Perfecto. Le explico al gerente que el valor del paquete no afecta el tamaño óptimo de envío — eso está determinado por los costos operacionales. Sin embargo, el valor SÍ importa para una pregunta diferente: ¿cuánto riesgo estamos dispuestos a aceptar si un envío se pierde o daña? Pero eso es otra optimización. Por ahora, le recomiendo: para V = 5000, usa x = 500. Para V = 7000, usa x = 600. Implementamos la solución. Dos semanas después, el gerente llama: 'Funciona. Los costos bajaron un 8%. Pero {{NAME}}, ahora tenemos un nuevo problema: resulta que usar exactamente 500 unidades por envío requiere reconfigurar las máquinas, y eso toma 30 minutos. Hacerlo 10 veces al mes es 5 horas. ¿Vale la pena?' ¿Cómo incorporo ESTE costo en la decisión?\",\n      \"options\": [\n        {\n          \"feedback\": \"Eso sería un costo fijo único. Pero el problema es dinámico: si cambias x, cambia el número de envíos, y por tanto el número de reconfiguraciones. Debe estar vinculado a x.\",\n          \"isCorrect\": false,\n          \"text\": \"Suma el costo total de 5 horas a C(x) como constante\"\n        },\n        {\n          \"feedback\": \"Correcto. Si hay k reconfiguración por mes y cada una cuesta (tiempo · tarifa), entonces añade k·(costo de reconfiguration) al modelo. Esto depende de cuántos envíos hagas, que depende de x.\",\n          \"isCorrect\": true,\n          \"text\": \"Define costo de reconfiguración como función de envíos\"\n        },\n        {\n          \"feedback\": \"No puedes ignorar costos reales. Aunque 5 horas al mes parece pequeño, podría ser significativo. Cuantifica e incluye en el modelo.\",\n          \"isCorrect\": false,\n          \"text\": \"Ignora este costo; es demasiado pequeño (8% de mejora)\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores se usan cuando tienes una restricción de igualdad independiente (como 'el presupuesto es exactamente 10000'). Aquí el costo de reconfiguración es PARTE de la función objetivo.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa multiplicadores de Lagrange con la restricción de tiempo\"\n        }\n      ],\n      \"question\": \"¿Cómo integras el costo de reconfiguración de máquinas?\"\n    },\n    {\n      \"context\": \"Digamos que cada reconfiguración cuesta el equivalente a 100 pesos (en tiempo y mano de obra). Si hacemos 5000/x envíos al mes, necesitamos 5000/x reconfiguración. Entonces el costo total es C(x) = 50·(5000/x) + x + 200 + 100·(5000/x). Simplificando: C(x) = (250000 + 500000)/x + x + 200 = 750000/x + x + 200. {{NAME}}, cuando optimizo esto, C'(x) = -750000/x² + 1 = 0, así que x² = 750000 y x ≈ 866. Pero esto es rarísimo. Con x = 866, cada envío está fuera de los múltiplos de 100 que la máquina puede hacer. ¿Qué hago?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Cuando la solución óptima continua no es implementable, evalúa los candidatos implementables más cercanos. C(800) vs C(900) — elige el que minimiza costo real.\",\n          \"isCorrect\": true,\n          \"text\": \"Evalúa el costo en x = 800 y x = 900, elige el menor\"\n        },\n        {\n          \"feedback\": \"Redondear es una heurística, pero no garantiza el óptimo. En problemas discretos, siempre evalúa los candidatos cercanos, no solo el redondeado.\",\n          \"isCorrect\": false,\n          \"text\": \"Redondea 866 al múltiplo de 100 más cercano: 900\"\n        },\n        {\n          \"feedback\": \"Eso haría el modelo muy complicado. Es mejor resolver el continuo y luego evaluar los discretos cerca del óptimo.\",\n          \"isCorrect\": false,\n          \"text\": \"Reformula el modelo para usar solo múltiplos de 100\"\n        },\n        {\n          \"feedback\": \"El modelo ESTÁ correcto — refleja la realidad: costo de gestión + almacenamiento + distribuidor + reconfiguración. El problema no es el modelo, es que la solución óptima continua no es viable.\",\n          \"isCorrect\": false,\n          \"text\": \"Cuestiona si el modelo está correcto\"\n        }\n      ],\n      \"question\": \"¿Cómo tratas una solución óptima que no es implementable?\"\n    },\n    {\n      \"context\": \"Calculé: C(800) = 750000/800 + 800 + 200 = 937.5 + 1000 = 1937.5. C(900) = 750000/900 + 900 + 200 = 833.33 + 1100 = 1933.33. Así que x = 900 es ligeramente mejor. Le digo esto al gerente, pero hace una observación: 'Espera. Si enviamos 5000 unidades en lotes de 900, eso es 5000/900 ≈ 5.56 envíos. No puedes hacer envío parcial. El último debe ajustarse.' {{NAME}}, acabo de darme cuenta de que el problema es aún MÁS discreto de lo que pensé. ¿Cómo manejo ESTO?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Si n es el número de envíos y V es el volumen total, entonces x = V/n (aproximadamente). Optimiza sobre valores enteros de n, no sobre x continuo.\",\n          \"isCorrect\": true,\n          \"text\": \"Usa un modelo discreto explícito; sea n = número de envíos\"\n        },\n        {\n          \"feedback\": \"Con 5.56 vs 5 envíos, la diferencia es ~11%. Eso no es negligible. Para problemas pequeños, no puedes asumir continuidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Asume que los envíos parciales son negligibles\"\n        },\n        {\n          \"feedback\": \"Eso es un enfoque, pero es ad hoc. Mejor: modela explícitamente n como entero y optimiza directamente sobre n, no sobre x.\",\n          \"isCorrect\": false,\n          \"text\": \"Redondea 5.56 a 6 envíos y calcula x = 5000/6\"\n        },\n        {\n          \"feedback\": \"No es realista. Los clientes no harán eso solo para simplificar tu modelo. Debes acomodar la realidad, no reescribirla.\",\n          \"isCorrect\": false,\n          \"text\": \"Requiere al cliente que siempre envíe en múltiplos exactos\"\n        }\n      ],\n      \"question\": \"¿Cómo abordas el problema de no poder hacer envíos parciales?\"\n    },\n    {\n      \"context\": \"Tienes razón. Reformulo el problema: Sea n = número de envíos al mes. Entonces tamaño por envío = 5000/n. Costo de gestión = 50n. Costo de almacenamiento = (5000/n)/2 · 2 = 5000/n. Costo de distribuidor = 200. Costo de reconfiguración = 100n. Total: C(n) = 50n + 5000/n + 200 + 100n = 150n + 5000/n + 200. Ahora C'(n) = 150 - 5000/n² = 0 da n² = 5000/150 ≈ 33.33, así que n ≈ 5.77. Como n DEBE ser entero, evalúo n = 5 y n = 6. C(5) = 150(5) + 5000/5 + 200 = 750 + 1000 + 200 = 1950. C(6) = 150(6) + 5000/6 + 200 = 900 + 833.33 + 200 = 1933.33. {{NAME}}, ¿y si el volumen sigue creciendo a 7000? ¿Cambiaría n óptimo?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Cuando V cambia, la función de costo cambia. Ahora C'(n) = 150 - 7000/n² = 0 da n ≈ 6.83, así que evalúas n = 6 y n = 7. La decisión depende del volumen.\",\n          \"isCorrect\": true,\n          \"text\": \"Recalcula: C(n) = 150n + 7000/n + 200; optimiza\"\n        },\n        {\n          \"feedback\": \"No. n óptimo escala con √V, no linealmente. De 5000 a 7000 es 1.4×, así que n debería crecer a ~6.83, no quedar en 6.\",\n          \"isCorrect\": false,\n          \"text\": \"n = 6 sigue siendo óptimo; n escala linealmente\"\n        },\n        {\n          \"feedback\": \"No. Si los parámetros del modelo (V) cambian, debes reoptimizar. Usar la solución antigua cuando el problema cambió es ignorar la información nueva.\",\n          \"isCorrect\": false,\n          \"text\": \"Solo suma el 7000 al modelo anterior sin reoptimizar\"\n        },\n        {\n          \"feedback\": \"V no es una restricción de igualdad a la que optimizar sujeto a ella — V es un parámetro del problema. Simplemente reoptimiza la función con el nuevo valor de V.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa multiplicadores de Lagrange para incorporar V\"\n        }\n      ],\n      \"question\": \"¿Cómo cambia n óptimo si V pasa de 5000 a 7000?\"\n    },\n    {\n      \"context\": \"Perfecto. Así que cuando V = 7000, n óptimo es aproximadamente 6.83, redondeando a n = 7. Evalúo: C(7) = 150(7) + 7000/7 + 200 = 1050 + 1000 + 200 = 2250. Espera. ¿2250? Eso es MÁS que los 1950 de cuando V = 5000. {{NAME}}, acaba de ocurrirmse algo: el costo TOTAL sube cuando el volumen sube. Pero ¿qué pasa con el COSTO POR UNIDAD? ¿Es eso lo que realmente debería optimizar?\",\n      \"options\": [\n        {\n          \"feedback\": \"El cliente sí paga el total, pero cuando el volumen es variable, el costo total subirá naturalmente. Lo relevante es qué tan eficientemente procesas cada unidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Costo total; ese es lo que el cliente paga\"\n        },\n        {\n          \"feedback\": \"Correcto. Costo por unidad = C(n)/V = (150n + V/n + 200)/V. Optimizar esto te muestra cómo escala la eficiencia con volumen. Para SoloCargo, 2250/7000 ≈ 0.321 pesos/unidad es mejor que 1950/5000 = 0.39.\",\n          \"isCorrect\": true,\n          \"text\": \"Costo por unidad; es la métrica de eficiencia real\"\n        },\n        {\n          \"feedback\": \"No son equivalentes. Minimizar C(n) y minimizar C(n)/V pueden dar resultados diferentes. Para decisiones operacionales con volumen variable, usa costo por unidad.\",\n          \"isCorrect\": false,\n          \"text\": \"Ambos; son equivalentes para optimización\"\n        },\n        {\n          \"feedback\": \"Ganancia incluye precio de venta, que es diferente problema. Aquí optimizamos solo COSTO. Primero resuelve esto; luego considera ganancia.\",\n          \"isCorrect\": false,\n          \"text\": \"Ninguno; usa ganancia total menos costo total\"\n        }\n      ],\n      \"question\": \"¿Deberías optimizar costo total o costo por unidad?\"\n    },\n    {\n      \"context\": \"Claro. Costo por unidad es la métrica correcta de eficiencia. Le presento esto al gerente: 'A 5000 unidades, costo es 0.39 pesos/unidad. A 7000 unidades, cuesta 0.321 pesos/unidad. El volumen MAYOR es más eficiente.' El gerente asiente, pero luego pregunta: 'Pero {{NAME}}, aquí hay un límite operacional que no hemos considerado. Nuestro almacén puede manejar máximo un inventario promedio de 2000 unidades. Con n envíos, el inventario promedio es 5000/(2n). ¿Cómo incorporamos esta restricción?' Ah. Ahora sí tenemos una RESTRICCIÓN REAL. ¿Debería usar multiplicadores de Lagrange aquí?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. La restricción es g(n) = 5000/(2n) ≤ 2000, o 5000/(2n) = 2000 en el límite. Usa multiplicadores de Lagrange para maximizar/minimizar C sujeto a g(n) = 2000.\",\n          \"isCorrect\": true,\n          \"text\": \"Sí; usa multiplicadores de Lagrange: ∇C = λ∇g\"\n        },\n        {\n          \"feedback\": \"Encontrar n máximo te dice el límite operacional, pero no te da el n óptimo. Los multiplicadores conectan la función objetivo con la restricción formalmente.\",\n          \"isCorrect\": false,\n          \"text\": \"No; solo encuentra el máximo n permitido\"\n        },\n        {\n          \"feedback\": \"No. Si reemplazas la restricción, tienes un solo valor de n posible, no una optimización. Los multiplicadores te permiten balancear ambos.\",\n          \"isCorrect\": false,\n          \"text\": \"Reemplaza la restricción directamente en C(n)\"\n        },\n        {\n          \"feedback\": \"No sabes si es vinculante hasta verificar. Si tu n óptimo requiere más de 2000 unidades promedio, la restricción SÍ es vinculante y cambias el óptimo.\",\n          \"isCorrect\": false,\n          \"text\": \"La restricción no es vinculante; ignórala\"\n        }\n      ],\n      \"question\": \"¿Cómo manejas la restricción de almacén?\"\n    },\n    {\n      \"context\": \"Bien. Verifica: ¿es vinculante? Con n = 7, inventario promedio = 5000/(2·7) ≈ 357 unidades. Está bien dentro de 2000. Así que la restricción del almacén no es vinculante ahora. Pero es bueno saber que si SoloCargo decidiera reducir dramáticamente el tamaño de n (hacer muchos envíos pequeños), la restricción del almacén se activaría. Le digo al gerente: 'Entonces tu restricción real es implícita — limita cuán bajo puede bajar n.' Pausa. El gerente dice: 'Pero, {{NAME}}, acá hay algo más. Nuestro distribuidor ofrece un descuento: si hacemos al menos 8 envíos por mes, nos rebaja 50 pesos por envío en gestión, bajando de 50 a 0 pesos por envío. ¿Cómo eso afecta la decisión?'\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Para n < 8: C₁(n) = 150n + V/n + 200. Para n ≥ 8: C₂(n) = 100n + V/n + 200 (descuento reduce 50n del costo). Optimiza ambas, compara en los límites.\",\n          \"isCorrect\": true,\n          \"text\": \"Crea dos funciones C(n): una para n < 8, otra para n ≥ 8\"\n        },\n        {\n          \"feedback\": \"No fácilmente. El descuento es 'discreto' — se activa en n = 8, no gradualmente. Dos funciones por tramos es la forma correcta.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa una sola función C(n) que incluya el descuento\"\n        },\n        {\n          \"feedback\": \"No puedes asumir eso. El óptimo puede estar en n < 8. Debes evaluar ambos regímenes y ver cuál es realmente mejor.\",\n          \"isCorrect\": false,\n          \"text\": \"Asume que siempre n ≥ 8 y aplica descuento\"\n        },\n        {\n          \"feedback\": \"El descuento no es una restricción de igualdad; es un cambio en la estructura de costos. Modela como funciones por tramos, no con multiplicadores.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa multiplicadores de Lagrange para el descuento\"\n        }\n      ],\n      \"question\": \"¿Cómo modelar un costo que cambia según el volumen (descuento por cantidad)?\"\n    },\n    {\n      \"context\": \"Perfecto. Para V = 5000: Si n < 8: C₁(n) = 150n + 5000/n + 200. Optimizando, n ≈ 5.77, redondeamos a n = 5 o 6. Ya sabemos C(5) = 1950, C(6) = 1933.33. Si n ≥ 8: C₂(n) = 100n + 5000/n + 200. Optimizando, 100 - 5000/n² = 0, así que n ≈ 7.07. Pero eso es < 8, así que el óptimo en el régimen n ≥ 8 está en el límite n = 8. C(8) = 100(8) + 5000/8 + 200 = 800 + 625 + 200 = 1625. {{NAME}}, mira eso: 1625 es MUCHO mejor que 1933.33. Hacer solo 1 envío más (pasar de 6 a 8) ahorra 300 pesos. ¿Esto siempre pasa con descuentos?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Calcula el óptimo en cada régimen, luego compara directamente: C(n=6, sin descuento)=1933 vs C(n=8, con descuento)=1625. El descuento es rentable porque 1625 < 1933.\",\n          \"isCorrect\": true,\n          \"text\": \"Compara costo en el óptimo sin descuento vs con descuento\"\n        },\n        {\n          \"feedback\": \"No. Un descuento reduce el costo unitario, pero requiere hacer más envíos. El costo total podría subir. Siempre compara la solución óptima en cada régimen.\",\n          \"isCorrect\": false,\n          \"text\": \"Siempre acepta el descuento; reduce costos por definición\"\n        },\n        {\n          \"feedback\": \"¿Por qué? Si cambiar aumenta ganancias (reduce costo total), es buena decisión. Rechazar un cambio beneficioso solo porque 'cambia el plan' es irracional.\",\n          \"isCorrect\": false,\n          \"text\": \"Rechaza si el descuento requiere cambiar el óptimo original\"\n        },\n        {\n          \"feedback\": \"Promediar no tiene sentido. Tienes que elegir un régimen u otro. La decisión es discreta, así que compara los candidatos finales directamente.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa el costo unitario promedio de ambos regímenes\"\n        }\n      ],\n      \"question\": \"¿Cómo decides si un descuento por cantidad vale la pena?\"\n    },\n    {\n      \"context\": \"Exacto. Le recomiendo al gerente: 'Usa 8 envíos por mes. El costo baja de 1933 a 1625 pesos — una reducción del 16%. Implementamos la solución. Dos semanas después, el gerente llama nuevamente, esta vez con sorpresa en la voz: '{{NAME}}, algo raro acaba de pasar. Empezamos a hacer 8 envíos regularmente, pero resulta que hacer 8 envíos exactos al mes no siempre es posible porque algunos meses tienen anomalías. En octubre, tuvimos una gran campaña publicitaria y el volumen subió a 12000 unidades. Con 8 envíos, cada uno sería de 1500 unidades. Pero nuestro almacén no aguanta un inventario promedio de 750 unidades — ya estamos al límite de 2000. ¿Debemos aumentar a 10 envíos?' ¡Ah! La restricción del almacén se ACTIVÓ. {{NAME}}, ¿cómo resolvemos esto formalmente?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Ahora la restricción g(n) = 12000/(2n) - 2000 = 0 (igualdad en el límite) es vinculante. Resuelve L = C(n) - λ·g(n), encuentra n y λ que satisfacen ∇L = 0 y g(n) = 0.\",\n          \"isCorrect\": true,\n          \"text\": \"Usa multiplicadores de Lagrange: ∇C = λ∇g\"\n        },\n        {\n          \"feedback\": \"Eso te da el límite operacional, pero no optimiza costo. Si solo buscas inventario = 2000, hay un único n posible (n=3). Pero quizá haya un trade-off mejor.\",\n          \"isCorrect\": false,\n          \"text\": \"Encuentra n que satisface inventario = 2000 exactamente\"\n        },\n        {\n          \"feedback\": \"Aumentar a 10 por la restricción de almacén es correcto, pero la forma FORMAL de decidir es multiplicadores de Lagrange. Verifica que 10 es óptimo sujeto a la restricción.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumenta a 10 envíos porque la restricción lo requiere\"\n        },\n        {\n          \"feedback\": \"No. Las restricciones complicadas son exactamente para qué sirven multiplicadores de Lagrange. Reformular el modelo evitaría el problema real.\",\n          \"isCorrect\": false,\n          \"text\": \"Cambiar el modelo; la restricción es demasiado complicada\"\n        }\n      ],\n      \"question\": \"¿Cómo optimizas con restricción activa en la función de costo?\"\n    },\n    {\n      \"context\": \"Bien. Verifiquemos: con V = 12000 y restricción de almacén = 2000, tenemos 12000/(2n) ≤ 2000, así que n ≥ 3. Con 8 envíos, inventario = 12000/16 = 750. Está bien. Así que en realidad, la restricción NO está activada en n = 8. {{NAME}}, espera. El gerente dijo que sí está activada. Déjame preguntarle... Resulta que malinterpretamos: el LÍMITE DEL ALMACÉN es 750 unidades — no 2000. Es una restricción mucho más ajustada. Con V = 12000 y límite = 750, necesitamos n ≥ 12000/(2·750) = 8. Así que n = 8 es EXACTAMENTE el mínimo. Pero con el descuento activo, ¿debería optimizar hacia n > 8?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. C'(n)=100-12000/n²=0 da n≈10.95. Como n≥8 y el óptimo continuo es 10.95, evalúa n=10 y n=11. Elige el menor costo. La restricción no es activa en la solución.\",\n          \"isCorrect\": true,\n          \"text\": \"Minimiza C(n)=100n+12000/n+200 con n≥8\"\n        },\n        {\n          \"feedback\": \"n=8 es el mínimo requerido, pero el óptimo está en n≈11. Fijar en el límite solo es correcto si el óptimo irrestricto está fuera del rango permitido.\",\n          \"isCorrect\": false,\n          \"text\": \"Fija n = 8 porque es el mínimo permitido\"\n        },\n        {\n          \"feedback\": \"Los multiplicadores se usan cuando la restricción es activa en la solución. Aquí n≥8 es la restricción, pero el óptimo está en n>8, así que no es activa en la solución.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa multiplicadores de Lagrange con igualdad n=8\"\n        },\n        {\n          \"feedback\": \"No. Más envíos reduce inventario, pero cada envío cuesta 100 pesos (con descuento). Hay un trade-off. Optimiza formalmente en lugar de asumir dirección.\",\n          \"isCorrect\": false,\n          \"text\": \"Aumenta indefinidamente; más envíos = menos inventario\"\n        }\n      ],\n      \"question\": \"¿Cuál es el n óptimo con descuento y restricción activa?\"\n    },\n    {\n      \"context\": \"Exacto. C(10) = 100(10) + 12000/10 + 200 = 1000 + 1200 + 200 = 2400. C(11) = 100(11) + 12000/11 + 200 = 1100 + 1090.91 + 200 = 2390.91. C(12) = 100(12) + 12000/12 + 200 = 1200 + 1000 + 200 = 2400. Así que n = 11 es óptimo. Le digo al gerente: 'En octubre, con 12000 unidades, haz 11 envíos.' Pausa larga. Luego pregunta: '{{NAME}}, ¿me das exactamente la regla para cualquier volumen V? Quiero automatizar esto.' Ah. ESTA es la pregunta final. Después de toda esta aventura de modelado, optimización, restricciones, descuentos — ¿puedo resumir todo en una regla general que el gerente pueda usar sin volver a llamarme?\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto (aproximadamente). De C₂(n)=100n+V/n+200, C'(n)=100-V/n²=0 da n≈√(V/100). Luego verifica: inventario=V/(2n)≤750. Si no, fija n=V/1500 (mínimo para almacén).\",\n          \"isCorrect\": true,\n          \"text\": \"Regla: n=√(V/100) para V; verifica restricción almacén\"\n        },\n        {\n          \"feedback\": \"Puedes, pero es ineficiente. Derivar la regla general es EXACTAMENTE lo que cálculo de optimización te permite hacer. Eso es reutilización de matemáticas.\",\n          \"isCorrect\": false,\n          \"text\": \"No hay regla general; optimiza cada mes por separado\"\n        },\n        {\n          \"feedback\": \"n=8 es óptimo SOLO cuando V es cierto rango. Para V=12000, n=11 es mejor. La regla debe adaptarse a V.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa siempre n=8 porque el descuento es óptimo\"\n        },\n        {\n          \"feedback\": \"Tecnicamente posible, pero innecesario. Primero derivar la regla analíticamente, luego programar. No necesitas resolver multiplicadores cada vez si tienes la fórmula cerrada.\",\n          \"isCorrect\": false,\n          \"text\": \"Implementa multiplicadores de Lagrange en software\"\n        }\n      ],\n      \"question\": \"¿Cómo sintetizas toda la optimización en una regla general?\"\n    },\n    {\n      \"context\": \"Perfecto. Le doy al gerente la regla: 'Para cualquier volumen mensual V, calcula n ≈ √(V/100). Redondea al entero más cercano. Verifica que el inventario promedio V/(2n) no exceda 750. Si excede, usa n = V/1500. Eso es.' El gerente respira aliviado. Una semana después, me llama: 'Funcionó durante octubre y noviembre. Costos bajaron 22% respecto al año pasado. Pero {{NAME}}, ahora quiero exicir más. ¿Podemos TAMBIÉN optimizar el precio de venta? Tengo demanda variable según precio. Quiero maximizar ganancia total, no solo minimizar costo.' Me quedo en silencio. Porque {{NAME}}, realiza que acabamos de resolver un problema completo de optimización — y ahora el cliente quiere un SEGUNDO problema completamente diferente.\",\n      \"options\": [\n        {\n          \"feedback\": \"Correcto. Ahora tienes costo optimizado. El siguiente problema: maximizar ganancia total = (precio · volumen) - costo(volumen). Esto requiere conocer cómo la demanda cambia con precio.\",\n          \"isCorrect\": true,\n          \"text\": \"Optimiza ganancia=ingresos-costos totales\"\n        },\n        {\n          \"feedback\": \"No. Minimizar costo es UNA parte de maximizar ganancia. Pero el precio de venta, la demanda, los ingresos — son variables independientes que afectan ganancia total.\",\n          \"isCorrect\": false,\n          \"text\": \"Ya está hecho; el costo mínimo es ganancia máxima\"\n        },\n        {\n          \"feedback\": \"Minimizar costo es valioso, pero no es el objetivo final del negocio. Maximizar ganancia es. La optimización de costo fue una herramienta hacia ese fin, no el fin mismo.\",\n          \"isCorrect\": false,\n          \"text\": \"Rechaza; ya optimizaste costos, eso es suficiente\"\n        },\n        {\n          \"feedback\": \"No. Costos responden a logística (gestión, almacenamiento, envíos). Ingresos responden a demanda y precio. Son dinámicas completamente diferentes.\",\n          \"isCorrect\": false,\n          \"text\": \"Usa el mismo modelo de costo para ingresos\"\n        }\n      ],\n      \"question\": \"¿Cuál es el siguiente paso después de optimizar costos?\"\n    }\n  ]\n}",
      "outputTokens": 13105,
      "systemPrompt": "# Role\n\nYou are an expert interactive story designer creating a **Story** activity for a learning app. Your mission is to place learners in a first-person dialogue scenario where they work alongside a colleague to solve a real-world problem using the lesson's concepts.\n\nYou specialize in crafting immersive, dialogue-driven experiences that make learners feel like they're actually solving problems in their field — not just answering quiz questions.\n\n# The Art of Dialogue-Driven Learning\n\nA great Story activity doesn't lecture or test recall — it puts learners IN the situation. Think of it like an interactive movie where the learner IS the main character, making real decisions that matter.\n\n## Why Dialogue Scenarios Work\n\n1. **Authentic Context**: When learners apply concepts to solve realistic problems with a colleague, they see WHY the knowledge matters to them personally.\n\n2. **Active Reasoning**: Making decisions in context requires thinking through principles, not just recognizing memorized facts.\n\n3. **Emotional Investment**: Dialogue creates stakes. The learner cares about the outcome because they're part of the story.\n\n## The Collaborative Problem-Solving Principle\n\nEvery great Story activity creates a sense of partnership:\n\n- **Shared Goal**: You and your colleague are tackling something together\n- **Natural Dialogue**: Conversations feel like real workplace exchanges\n- **Meaningful Choices**: Each decision requires applying what you've learned\n- **Satisfying Resolution**: The problem gets solved and the takeaway sticks\n\n## Why Pure Dialogue Works\n\nEach scene should feel like you're eavesdropping on a real conversation — no narrator, no stage directions, just two people working through a problem. Pure dialogue:\n\n- Immerses learners completely in the scenario\n- Makes abstract concepts feel like lived experience\n- Creates natural pacing through back-and-forth exchange\n- Lets context emerge organically from what people say\n\n# Inputs\n\n- `LESSON_TITLE`: The topic to create a story around\n- `LESSON_DESCRIPTION`: Additional context about what this lesson covers\n- `CHAPTER_TITLE`: The chapter context (for understanding scope)\n- `COURSE_TITLE`: The course context (for understanding audience level)\n- `LANGUAGE`: Output language\n- `EXPLANATION_STEPS`: Array of {title, text} from all explanation activities (Background, Explanation, Mechanics, Examples) the learner completed before this one\n\n## Language Guidelines\n\n- `en`: Use US English unless the content is region-specific\n- `pt`: Use Brazilian Portuguese unless the content is region-specific\n- `es`: Use Latin American Spanish unless the content is region-specific\n\n# Requirements\n\n## Scene Structure\n\nEach scene must have:\n\n- **context**: Maximum 500 characters. Pure dialogue only — no narrator, no character name prefixes (like \"Sarah:\"), no descriptions. This is what your colleague says to you, setting up the decision point.\n- **question**: Maximum 100 characters. A short, clear question about what to do next.\n- **options**: Exactly 4 choices, each with:\n  - **text**: The answer choice (max 50 characters)\n  - **isCorrect**: Boolean indicating if this is the correct answer (exactly 1 must be true)\n  - **feedback**: Why this choice is right (with insight) or wrong (and what would be correct) — max 300 characters\n\n## Story Arc\n\nYour story must follow this structure:\n\n1. **Opening Scene**: Begin \"in the middle of the action\" — the learner and colleague are already working on something. No preamble or setup exposition.\n2. **Rising Complexity**: Each scene builds naturally from the previous dialogue. Decisions compound.\n3. **Plot Twist**: The second-to-last scene introduces an unexpected complication, surprise, or revelation.\n4. **Resolution**: The final scene resolves the problem AND reinforces the main learning takeaway.\n\n## Scene Count\n\n- Minimum: 7 scenes\n- Maximum: 20 scenes\n- Let the problem's complexity dictate the length. A simple concept might need 7-10 scenes; a complex one might need 15-20.\n\n## Tone & Style\n\n- **Pure dialogue**: NO narrator, NO character name prefixes, NO descriptions of actions or settings\n- **Natural conversation**: Write how colleagues actually talk on Slack when solving a problem together — casual, collaborative, sometimes humorous\n- **Professional but warm**: Light, smart humor when appropriate. Never forced or cheesy.\n- **Second-person immersion**: The colleague speaks TO the learner. Context emerges from what's said.\n- **Continuous flow**: Each scene's dialogue should naturally lead into the next\n\n## The {{NAME}} Placeholder\n\nUse `{{NAME}}` wherever the learner's name should appear in dialogue. For example:\n\n- \"{{NAME}}, I think we might have a problem here.\"\n- \"Good catch, {{NAME}}. That's exactly what I was thinking.\"\n\nThis personalizes the experience without requiring actual name input at content creation time.\n\n## Decision Design\n\nEvery decision must:\n\n- **Require reasoning**: Learners must apply principles from the lesson, not recall specific phrases\n- **Feel realistic**: These are choices someone might actually face in this situation\n- **Have plausible distractors**: Wrong options should be tempting but flawed for specific reasons\n- **Avoid \"obvious\" correct answers**: The right choice should require thought, not be the only non-silly option\n\n## What to Avoid\n\n- Narrator text (\"Meanwhile...\" or \"You walk into the office...\")\n- Character name prefixes (\"Sarah:\" or \"Your colleague says:\")\n- Description of actions or settings (except through dialogue itself)\n- Questions that test memorization of facts from earlier activities\n- Obvious \"correct\" answers that don't require applying the concept\n- Silly or clearly wrong distractors that no reasonable person would choose\n- Breaking the fourth wall or meta-commentary\n- Starting with \"In this activity...\" or setup exposition\n\n## Scope\n\n- **Stay focused**: The problem should specifically require THIS lesson's concept to solve\n- **Don't expand**: Other lessons cover related topics — this story tests this lesson\n- **Don't narrow**: If the lesson is broad, the problem should engage multiple aspects of it\n\n## Relationship to Previous Activities\n\nThe learner has already completed:\n\n- **Background**: WHY this exists (origin story, problems solved, historical context)\n- **Explanation**: WHAT it is (core concepts, components, definitions)\n- **Mechanics**: HOW it works (processes in action, cause-effect chains)\n- **Examples**: WHERE it appears (real-world contexts, applications)\n\nYour Story activity answers WHEN DO I USE THIS? (applying concepts to solve realistic problems). These complement each other:\n\n- Background: \"WHY did we need this?\"\n- Explanation: \"WHAT exactly is it?\"\n- Mechanics: \"HOW does it actually work?\"\n- Examples: \"WHERE will I encounter this?\"\n- Story: \"WHEN do I apply this to solve real problems?\"\n\nThe learner knows what the concept IS, how it WORKS, and where they'll SEE it. Now they practice USING it in a realistic scenario.\n\n# Structure Guide\n\nWhile every story is unique, most follow this arc (adapt as needed):\n\n1. **The Hook**: Jump straight into the situation. Something needs to be figured out or decided.\n2. **Initial Assessment**: What's the situation? What do we know? First decisions.\n3. **Deepening Complexity**: The problem has layers. Apply the concept more deeply.\n4. **Complications**: Things aren't as simple as they seemed. Adapt your approach.\n5. **The Twist**: A surprise, revelation, or unexpected turn that requires rethinking.\n6. **The Resolution**: Solve the problem AND crystallize the key insight from the lesson.\n\nNote: Sometimes the final twist can have a humorous or unexpected resolution that still reinforces the learning. Something that makes the learner smile and think \"I didn't see that coming!\"\n\n# Dialogue Tone Examples\n\nThe following examples show the **tone and style** to aim for — not complete scenes, just the kind of dialogue that makes stories feel alive. Adapt freely to your topic.\n\n## Opening Hooks (Jump Into the Action)\n\n> \"{{NAME}}, I've been staring at this bug for an hour. The shopping cart total keeps showing yesterday's prices. The database is fine. Something's wrong with how we're storing them.\"\n\n> \"Okay, {{NAME}}, the client just called. Their entire inventory system crashed right before Black Friday. They're panicking. We need to figure this out fast.\"\n\n> \"{{NAME}}, you're not going to believe this. Remember that algorithm we deployed last week? It's been recommending the exact opposite of what users want. Sales are tanking.\"\n\n## Building Tension (Problems Get Deeper)\n\n> \"Wait. If this pattern is everywhere in the codebase... inventory counts, user roles, discount percentages... we might have a much bigger problem than I thought.\"\n\n> \"Hold on. The logs show someone accessed the admin panel at 3 AM last night. But nobody on the team was working then. {{NAME}}, who else has those credentials?\"\n\n> \"The numbers don't add up. We're showing 500 successful transactions, but the bank only received 487. Where did the other 13 go?\"\n\n## Plot Twists (The Unexpected Turn)\n\n> \"{{NAME}}... I just ran the analysis twice. The bug isn't in our code. It's been in the library we've trusted for three years. Every project using it has this vulnerability.\"\n\n> \"I found the source of the data leak. {{NAME}}, it's not a hacker. It's our own caching system. We've been accidentally exposing user data to anyone who knew where to look.\"\n\n> \"Plot twist: the 'broken' feature? It's working exactly as designed. The original spec was just... completely wrong. We've been solving the wrong problem this whole time.\"\n\n## Humorous Moments (Light Relief)\n\n> \"Well, {{NAME}}, the good news is we found the bug. The bad news? It's been there since 2019. The worse news? I wrote it. The even worse news? So did you. We pair-programmed this disaster together.\"\n\n> \"Congratulations, {{NAME}}. We just spent four hours debugging what turned out to be a typo. 'userID' vs 'userId'. Camel case strikes again.\"\n\n> \"{{NAME}}, remember when I said 'this should be a quick fix'? That was three coffees and one existential crisis ago.\"\n\n## Satisfying Resolutions (Problem Solved + Insight Crystallized)\n\n> \"There it is. The fix works. {{NAME}}, I don't think I'll ever forget this — always check if your data source can change while you're holding onto a copy of it.\"\n\n> \"We did it. The system's stable. You know what the real lesson here was? Sometimes the simplest explanation IS the right one. We kept looking for complex bugs when the answer was right in front of us.\"\n\n> \"That's it — problem solved, client happy, crisis averted. {{NAME}}, I think we just learned more about distributed systems in the last hour than in any textbook.\"\n\n## Unexpected/Funny Endings\n\n> \"So after all that debugging... it was a timezone issue. Every single time. I'm starting to think all bugs are secretly timezone issues in disguise.\"\n\n> \"{{NAME}}, the CEO just called to thank us. Apparently fixing that 'minor bug' saved them $2 million. I think we need to renegotiate our rates.\"\n\n> \"The system's fixed. Also, I may have accidentally discovered that our competitor's product has the exact same bug. Should we... tell them? Actually, don't answer that.\"\n\nRemember: These are just **tone examples**. Your story should be original, fit the lesson topic, and create its own memorable journey. Mix problem-solving tension with moments of humor or surprise. The best stories make learners think \"I didn't see that coming!\" while still teaching the concept.\n\n# Quality Checks\n\nBefore finalizing, verify:\n\n- [ ] Is the dialogue pure conversation with NO narrator, NO character prefixes, NO descriptions?\n- [ ] Does every scene flow naturally from the previous one (continuous story)?\n- [ ] Do all decisions require applying lesson concepts, not just recalling facts?\n- [ ] Is there a genuine plot twist in the second-to-last scene?\n- [ ] Does the resolution both solve the problem AND reinforce the main learning?\n- [ ] Is `{{NAME}}` used appropriately to personalize the dialogue?\n- [ ] Are all distractors plausible (not obviously silly)?\n- [ ] Does the story feel like a real workplace conversation, not a quiz in disguise?\n- [ ] Is the scope exactly the lesson topic — not broader or narrower?\n- [ ] Are all constraints met (context ≤500 chars, question ≤100 chars, options ≤50 chars each, feedback ≤300 chars each)?\n- [ ] Is the scene count between 7 and 20?\n\n# Output Format\n\nReturn an array of scenes, each with:\n\n- **context**: Pure dialogue from colleague (max 500 chars)\n- **question**: Decision prompt (max 100 chars)\n- **options**: Array of exactly 4 objects, each with:\n  - **text**: The answer choice (max 50 chars)\n  - **isCorrect**: Boolean (exactly 1 must be true, 3 must be false)\n  - **feedback**: Why right or wrong (max 300 chars)\n\nUse 7-20 scenes to tell a complete, engaging story. Let the problem's complexity dictate the length.\n",
      "testCaseId": "es-math-calculus-optimization-1",
      "userPrompt": "LESSON_TITLE: Optimizacion con Calculo\nLESSON_DESCRIPTION: Aplicando tecnicas de calculo para encontrar optimos en problemas de ingenieria y negocios\nCHAPTER_TITLE: Aplicaciones del Calculo\nCOURSE_TITLE: Calculo para Ingenieria\nLANGUAGE: es\nEXPLANATION_STEPS:\n1. Puntos Criticos: Los puntos criticos son donde la derivada es cero o no existe. Son CANDIDATOS a extremos — no todos los puntos criticos son maximos o minimos.\n2. Prueba de Segunda Derivada: La prueba de la segunda derivada determina el tipo: si f''(x) > 0 en un punto critico, es minimo local; si f''(x) < 0, es maximo local; si f''(x) = 0, la prueba no concluye.\n3. Extremos Globales: Los extremos globales pueden estar en puntos criticos O en los extremos del dominio. Siempre evalua tambien los bordes del intervalo.\n4. Multiplicadores de Lagrange: Optimizacion con restricciones usa multiplicadores de Lagrange. Maximizar f(x,y) sujeto a g(x,y)=0 requiere que los gradientes sean paralelos.\n5. Modelado del Problema: Modelar el problema correctamente es la mitad del trabajo. Define la funcion objetivo, identifica las restricciones, y expresa todo en terminos de las variables relevantes."
    }
  ],
  "taskId": "activity-story"
}
