{
  "expectations": "\n      - Should include \"ML\"\n      - Should NOT include \"AI\", \"Deep Learning\", etc\n      - Results should be in English\n\n      \n  - Only include titles that are **equivalent** to the base title — i.e., they refer to the **same course** a user would expect to find under that subject.\n  - **Same‑course test** (use all of these):\n    1) Would we merge both titles into one course page? If yes, they are equivalent.\n    2) Would teaching goals, syllabus scope, and prerequisites remain the same? If yes, they are equivalent.\n    3) Is the difference only wording, dialect/variant, audience, abbreviation, or light framing? If yes, they are equivalent.\n  - **Broader/narrower rule**:\n    - **Broader** expands scope beyond the subject’s core boundaries → exclude. Example: \"Web Development\" is broader than \"Frontend Development\".\n    - **Narrower** is a proper subset that we’d plausibly ship as a separate course (different scope/learning goals) → exclude. Example: \"React\" is narrower than \"JavaScript\"; \"Deep Learning\" is narrower than \"Machine Learning\".\n  - **Not narrower (allowed)** when it is still the same course subject:\n    - **Dialect/variant** names (e.g., \"Inglês Americano\", \"Inglês Britânico\", \"French Grammar\", \"Optimisation\" vs \"Optimization\"). Dialects are surface variants of the same language course.\n    - **Audience qualifiers** (e.g., \"IA para Desenvolvedores\", \"UX for Healthcare\"). Audience framing ≠ topic narrowing if the core subject stays the same.\n    - **Series/labeling of the same entity** (e.g., \"Formula One\", \"F1\", \"Formula One Championship\", \"F1 Series\") — these all clearly denote the same sport/competition brand.\n    - **Light framing words** like \"principles\", \"fundamentals\", \"basics\", \"overview\", or \"for beginners\" when the core topic remains unchanged.\n  - **Decision checklist for each candidate title** (answer all):\n    - Does it introduce a different subfield or tool? If yes → narrower → exclude.\n    - Does it expand to an umbrella domain? If yes → broader → exclude.\n    - If we offered both titles simultaneously, would users be confused by two separate courses? If yes → they are equivalent and, therefore, can be included as an alternative title.\n  - **Concrete examples**:\n    - **Include**: \"Client‑Side Web Development\" ↔ \"Frontend Development\"; \"IA\" / \"Inteligência Artificial\" / \"IA para Desenvolvedores\"; \"Inglês\" ↔ \"Inglês Americano\" / \"Inglês Britânico\" / \"Inglês Britânico e Americano\"; \"Formula 1\" ↔ \"Formula One\" / \"F1\" / \"Formula One Championship\" / \"F1 Series\"; \"UX Design\" ↔ \"UX Design Principles\"; \"World War II\" ↔ \"WWII\" / \"Second World War\"; \"Data Science\" ↔ \"Data Science Fundamentals\".\n    - **Exclude**: \"Web Development\" (broader than \"Frontend Development\"); \"Aprendizado de Máquina\" (narrower than \"Inteligência Artificial\"); \"React\" (narrower than \"JavaScript\"); \"Deep Learning\" (narrower than \"Machine Learning\"); \"Motorsport\" (broader than \"Formula 1\"); \"Differential Calculus\" (narrower than \"Calculus\").\n  - Include different locale spellings when applicable (e.g., \"Optimization\" and \"Optimisation\").\n  - Include abbreviations if they mean the same thing (e.g., \"AI\"/\"IA\", \"ML\" when base is \"Machine Learning\").\n  - Levels like \"Beginner\", \"Advanced\", \"Calculus 1\", \"101\", etc., are acceptable if they keep the same subject.\n  - It’s fine to skip spacing/hyphenation/accents variants — serialization will handle those.\n  - Awkward or redundant phrasings are acceptable.\n  - Ignore casing issues (e.g., \"javascript\" vs \"JavaScript\").\n  - Ideally, it should have a huge list of alternative titles, really good ones have more than 100 alternative titles\n\n    ",
  "judgedAt": "2026-02-22T02:04:05.300Z",
  "judgments": [
    {
      "judgeId": "anthropic/claude-opus-4.6",
      "rankings": [
        {
          "anonymousId": "Model C",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Model C provides the largest list (~230 titles) and is highly exhaustive. It avoids problematic inclusions like 'Deep Learning', 'AI', or overly narrowing titles. The titles are almost entirely light framing/level variations of 'Machine Learning' or 'ML'. It doesn't include language-specific titles like 'Machine Learning with Python' (which could be considered narrower), nor does it include 'Statistical Learning' or 'Pattern Recognition' (which are debatable). It doesn't include 'Machine Learning and AI' (which broadens scope). The list does include some somewhat redundant/verbose permutations (e.g., many variations of 'Machine Learning: Key Concepts', 'Machine Learning: Core Principles', etc.), but these are all valid equivalents. No significant factual errors or rule violations. The sheer quantity and quality of alternatives is impressive while maintaining accuracy.",
          "score": 8
        },
        {
          "anonymousId": "Model D",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Model D provides ~115 titles, meeting the 100+ threshold. It's clean and well-organized. It avoids problematic inclusions - no 'AI', no 'Deep Learning'. It doesn't include 'Machine Learning with Python/R' (good, as those could be considered narrower). It includes 'Machine Learning Engineering' and 'ML Engineering' which are borderline but acceptable. It includes 'Real-World Machine Learning' and 'Machine Learning Demystified' which are valid light framing. No 'Statistical Learning' or 'Pattern Recognition' which avoids controversy. Clean and accurate list overall.",
          "score": 7.8
        },
        {
          "anonymousId": "Model E",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Model E provides ~115 titles, meeting the 100+ threshold. It's generally clean and avoids major issues. No 'AI', no 'Deep Learning'. It includes 'Core ML' which is problematic - Core ML is Apple's machine learning framework, making this ambiguous (violates the rule about ambiguous titles). It includes some slightly odd titles like 'Concise Machine Learning' and 'Compact Machine Learning' which are unusual but not wrong. Includes 'Applied Machine Learning Fundamentals' and 'Practical Machine Learning Essentials' which are fine. The 'Core ML' inclusion is a notable issue.",
          "score": 7.2
        },
        {
          "anonymousId": "Model A",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Model A provides ~145 titles, well above the 100+ threshold. However, it includes several problematic entries: 'Machine Learning with Python', 'Machine Learning with R', 'Python Machine Learning', 'Machine Learning in Python', 'Machine Learning in R' - these are arguably narrower courses focused on a specific language implementation. 'Statistical Learning', 'Statistical Learning Methods' are debatable - Statistical Learning is sometimes considered a distinct field. 'Pattern Recognition and Machine Learning' and 'Machine Learning and Pattern Recognition' bring in Pattern Recognition which could be a different course. 'Machine Learning for Data Science', 'Machine Learning and Data Analysis', 'Machine Learning for Data Analytics' expand the scope. 'Supervised and Unsupervised Machine Learning', 'Supervised and Unsupervised Learning' could be considered narrower (specifying only two paradigms). 'Machine Learning Pipeline', 'Machine Learning Lifecycle', 'Machine Learning Workflow' are arguably different courses about MLOps. 'Production Machine Learning' leans toward MLOps. Several of these violate the narrower/broader rules.",
          "score": 6.5
        },
        {
          "anonymousId": "Model B",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Model B provides ~105 titles, meeting the threshold. It avoids some problematic areas but includes 'Automated Learning' and 'Computational Learning' which are not standard synonyms for Machine Learning (Automated Learning is an unusual translation, Computational Learning Theory is a different subfield). 'ML Science' and 'Machine Learning Science' are unusual and not standard equivalents. 'Machine Learning for Dummies' is a book brand reference, somewhat acceptable but odd. 'Classical Machine Learning' could imply a narrower scope (excluding modern/deep approaches). 'Building Machine Learning Models' and 'Training Machine Learning Models' are arguably narrower, focusing on specific tasks within ML. It's a reasonable list but has more questionable entries than Models C and D.",
          "score": 6.8
        },
        {
          "anonymousId": "Model F",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Model F provides ~170 titles, which is impressive in quantity. However, it has several significant issues: 'Machine Learning and AI', 'Machine Learning and Artificial Intelligence', 'Machine Learning & AI', 'Machine Learning & Artificial Intelligence' - these explicitly broaden the scope to include AI, which the task expectations specifically say to exclude. 'Mathematics for Machine Learning', 'Maths for Machine Learning', 'Math for Machine Learning', 'Machine Learning Mathematics' - these are clearly different courses about the mathematical prerequisites for ML, not ML itself. 'Machine Learning with Java', 'Machine Learning with Scala', 'Machine Learning with Julia', 'Machine Learning with MATLAB' - these are narrower language-specific courses. 'Statistical Machine Learning', 'Machine Learning and Statistics' - broadening. 'Machine Learning Pipeline', 'Machine Learning Workflow' lean toward MLOps. The AI-related inclusions directly violate the stated expectations. Multiple rule violations despite the large quantity.",
          "score": 5.5
        }
      ]
    },
    {
      "judgeId": "google/gemini-3.1-pro-preview",
      "rankings": [
        {
          "anonymousId": "Model C",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Model C perfectly followed all instructions, including the strict constraints. It correctly avoided any tools (like Python/R) and subfields, strictly adhering to the 'same-course test' by utilizing framing words, abbreviations (ML), and levels. With over 160 highly accurate variations, it provides an outstanding and exhaustive list for duplicate detection.",
          "score": 10
        },
        {
          "anonymousId": "Model E",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Model E provided an excellent and exhaustive list (over 110 items) while strictly following the negative constraints and prompt rules. It successfully avoided introducing specific tools, programming languages, or subfields, making all titles true equivalents.",
          "score": 9.5
        },
        {
          "anonymousId": "Model D",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Model D followed all instructions exceptionally well, avoiding forbidden terms and keeping strictly to equivalent variations, levels, and valid framings. It is slightly less exhaustive than Models C and E (just under 100 items), but the quality of the list is superb.",
          "score": 9
        },
        {
          "anonymousId": "Model B",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Model B provides a very good list that generally adheres to the rules. However, it includes 'Classical Machine Learning', which is a narrower topic (explicitly excluding deep learning), and slightly border-line topics like 'Building Machine Learning Models'. Still, it avoids tools and 'AI', making it a strong output overall.",
          "score": 8
        },
        {
          "anonymousId": "Model A",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Model A violates the rule against introducing specific tools by including 'Machine Learning with Python', 'Machine Learning Using R', etc. It also includes narrower subfields like 'Probabilistic Machine Learning' and 'Statistical Machine Learning', failing the same-course equivalency test. This warrants a significant penalty.",
          "score": 4
        },
        {
          "anonymousId": "Model F",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Model F completely fails to follow the prompt's most critical negative constraints. It explicitly includes 'AI' and 'Artificial Intelligence' despite the prompt stating 'Should NOT include AI'. Furthermore, it violates the tool rule by including Python, R, Java, Scala, Julia, and MATLAB. Finally, it includes prerequisite/narrower courses like 'Mathematics for Machine Learning'.",
          "score": 1
        }
      ]
    },
    {
      "judgeId": "openai/gpt-5.2",
      "rankings": [
        {
          "anonymousId": "Model C",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Best adherence to the prompt’s core constraint: stays tightly within “Machine Learning” synonyms/phrasing/levels and includes “ML” prominently. Very exhaustive (100+). Avoids the explicitly disallowed terms (no AI/Deep Learning). Minor issues: some marketing-y variants (e.g., “Zero to Hero”) are acceptable per prompt, but a few may imply breadth/level span; still generally equivalent.",
          "score": 9.2
        },
        {
          "anonymousId": "Model A",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Large, varied list with many solid same-meaning paraphrases and includes “ML”. However it contains several borderline narrower/broader or curriculum-shifting items: tool/language-specific titles (“Machine Learning with Python/R”, “Python Machine Learning”), and adjacent-field blends (“Machine Learning and Pattern Recognition”, “Machine Learning and Data Analysis”, “Machine Learning for Data Science”) which can reasonably be separate courses (scope change). Still no AI/Deep Learning. Good volume but weaker equivalence filtering than C.",
          "score": 8
        },
        {
          "anonymousId": "Model D",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Generally high-quality same-meaning variants and keeps to ML without disallowed AI/Deep Learning terms. But it’s not exhaustive (well under 100). Also includes some potentially scope-shifting items like “Advanced Topics in Machine Learning” (could be a distinct course) and “Machine Learning Advanced Concepts”. Overall solid but less complete.",
          "score": 7.6
        },
        {
          "anonymousId": "Model E",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Decent set of equivalent titles, includes ML and avoids AI/Deep Learning. Some items are borderline scope expansions (“Machine Learning: Concepts, Methods, and Applications”, “Techniques and Applications”) but still plausibly same course. Main weakness is quantity (under 100) and some redundancy/odd entries (“Concise/Compact Machine Learning”) that are acceptable but add limited value.",
          "score": 7.2
        },
        {
          "anonymousId": "Model B",
          "modelId": "google/gemini-3-flash",
          "reasoning": "No AI/Deep Learning, includes ML, but multiple titles are ambiguous or not true synonyms: “Automated Learning” (not standard; could mean automation), “Computational Learning” (could point to computational learning theory), and several role nouns (“ML Specialist/Practitioner”) that read like job titles rather than course titles. Also not exhaustive (<100).",
          "score": 6.6
        },
        {
          "anonymousId": "Model F",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Major prompt violation: includes explicitly disallowed expansions to AI (“Machine Learning and AI”, “Machine Learning and Artificial Intelligence”, etc.). Also includes clearly narrower/broader adjacent topics: “Mathematics for Machine Learning/Maths…” which is a different course, and many language-specific variants that can be separate offerings. Despite high volume, these violations heavily reduce quality.",
          "score": 4.5
        }
      ]
    }
  ],
  "taskId": "alternative-titles",
  "testCaseId": "en-machine-learning-1"
}
