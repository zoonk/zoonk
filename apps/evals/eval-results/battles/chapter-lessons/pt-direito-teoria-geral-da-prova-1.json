{
  "expectations": "\n      - MUST be in Brazilian Portuguese\n      - Should cover each type of evidence individually\n      - Should separate burden of proof from standards of proof\n      - Should break down presumptions as individual concepts\n      - Should NOT create dedicated lessons teaching forensic/technical evidence or perícias (neighboring chapter \"Perícias e prova técnica\" covers that) — brief contextual references are fine\n      - Should NOT create dedicated lessons teaching legal risk management (neighboring chapter \"Risk management jurídico\" covers that) — brief contextual references are fine\n      - Should NOT create dedicated lessons teaching precedent analysis or jurisprudence (neighboring chapter \"Análise de precedentes\" covers that) — brief contextual references are fine\n      - Should NOT create dedicated lessons teaching strategic litigation or amici curiae (neighboring chapter \"Litigância estratégica e impacto\" covers that) — brief contextual references are fine\n\n      \n  - Each lesson should cover a SINGLE, SPECIFIC concept that can be explained within 10 short tweets\n  - Break down topics into the smallest, most manageable units possible, so that each lesson can be learned in 2-3 minutes\n  - If a topic is too broad, split it into multiple lessons\n  - Each lesson should be extremely focused on a SINGLE concept\n  - If a lesson is too broad, split it into multiple lessons\n  - If you find yourself using \"AND\", \"OR\", or \"VS\" in a title, you should split it into separate lessons\n  - Lesson titles should be short and specific to the exact concept covered\n  - Build a logical progression from basic to advanced concepts\n  - Ensure lessons build on knowledge from previous lessons\n  - Focus lessons for this specific chapter, not the entire course\n  - Don't include summary or review lessons. For example, do NOT create a lesson title \"Summary of Key Concepts\" or \"Review of Chapter\"\n  - Don't include assessment or quiz lessons\n  - Don't include final project or capstone lessons\n  - Should follow the language specified by language parameter\n  - Should follow title and description guidelines: no fluff, be concise, straight to the point\n  - Descriptions should be concise and straight to the point, no fluff/filler words (avoid \"learn\", \"understand\", \"explore\", \"introduction to\", etc.)\n  - You don't need to evaluate the output format here, just focus on the lesson content quality\n  - Include an extensive list of lessons to cover all the concepts needed to learn the chapter. Complex topics will usually requiere more than 100 lessons\n\n  Things to check:\n  - Is each lesson too broad? If so, it should be broken down further\n  - Can each concept be explained in 10 short tweets or less? If not, it should be broken down\n  - Does each lesson focus on a single specific concept? If not, it should be split\n  - Does it have lessons that don't belong in this chapter? If so, they should be removed\n\n    ",
  "judgedAt": "2026-02-22T03:09:46.479Z",
  "judgments": [
    {
      "judgeId": "anthropic/claude-opus-4.6",
      "rankings": [
        {
          "anonymousId": "Model B",
          "modelId": "openai/gpt-5.2:high",
          "reasoning": "Model B provides the most extensive and granular lesson list (97 lessons), covering all aspects of the chapter description thoroughly. It excels in several areas: (1) Single-concept focus — nearly every lesson covers exactly one concept; (2) Logical progression — it builds from foundational concepts (proof function, controverted facts) through standards, burden, presumptions, and statistical proof in a well-structured sequence; (3) Proper separation of burden vs. standards as required; (4) Presumptions are broken down individually (legal absolute, legal relative, judicial, revelia, administrative legitimacy); (5) Statistical proof is covered extensively with appropriate granularity (conditional probability, likelihood ratio, Bayes theorem, base rate, prosecutor's fallacy, sample size, confidence intervals, etc.); (6) Descriptions are concise and to the point without fluff words like 'learn' or 'explore'; (7) It respects neighboring chapter boundaries — no dedicated lessons on perícias or technical evidence; (8) Titles are generally short and specific. Minor issues: a few descriptions are slightly longer than ideal, and some topics in the statistical section (meta-analysis, outliers, regression to mean) could be seen as slightly beyond core scope, but they are defensible as part of 'prova estatística'. The coverage of dynamic distribution is excellent with separate lessons for asymmetry, greater ease of proof, justification, timing, and contradictory. Very well done overall.",
          "score": 8.5
        },
        {
          "anonymousId": "Model G",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Model G provides an extremely extensive list (115+ lessons) with very fine granularity. It covers all required topics and goes deep into statistical proof concepts. Strengths: (1) Very granular breakdown — each lesson is genuinely focused on a single concept; (2) Excellent coverage of statistical proof including p-value, error types, confidence intervals, sensitivity/specificity, odds ratio, regression models, etc.; (3) Good separation of burden and standards; (4) Presumptions are well broken down (legal, judicial, relative, absolute, fact-base, presumed fact, fiction). However, there are significant issues: (1) Several duplicate/near-duplicate titles — there are two lessons both titled 'Dúvida razoável', two titled 'Presunção', and multiple others with identical or near-identical titles, which is confusing and poor design; (2) Some lessons go excessively deep into statistics methodology (regressão linear, regressão logística, variável dependente/independente, overfitting, validação cruzada, modelo caixa-preta, explicabilidade local, imputação, dados faltantes) — these feel more like a statistics course than a law chapter on proof theory, potentially exceeding chapter scope; (3) Some titles are too vague or short without being descriptive (e.g., 'Ônus', 'Inversão', 'Presunção' used multiple times); (4) The lesson on NNT/NNH seems clearly out of scope for a legal theory of proof chapter. Despite excellent granularity in many areas, the scope creep into deep statistics/ML territory and the duplicate titles are notable weaknesses.",
          "score": 7
        },
        {
          "anonymousId": "Model F",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Model F provides 49 lessons with good topical coverage. Strengths: (1) Well-organized logical progression; (2) Good coverage of standards, burden, presumptions, and statistical proof; (3) Includes useful topics like prova emprestada, prova atípica, prova diabólica, comunhão da prova; (4) Respects neighboring chapter boundaries; (5) Standards are properly covered in Brazilian context. Issues: (1) Several titles use 'e' (and) which violates the splitting rule — 'Meios, fontes e elementos de prova', 'Falácia do promotor e falácia da defesa', 'Verdade formal e verdade real'; (2) Some lessons combine multiple concepts — 'Fatos que independem de prova' combines notórios, incontroversos, and presunções absolutas; (3) 'Presunções legais e presunções judiciais' should be split; (4) Some descriptions use phrases like 'O que significa' repeatedly; (5) The lesson count (49) is moderate — not as extensive as requested but covers the material adequately; (6) Statistical proof section could be more granular. The 'and' violations are a notable problem given the explicit prompt rules.",
          "score": 6.8
        },
        {
          "anonymousId": "Model C",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Model C provides 41 lessons. Strengths: (1) Good logical flow; (2) Covers all main topics; (3) Includes useful additions like Blue Bus paradox, frutos da árvore envenenada, non liquet; (4) Brazilian context is addressed. Issues: (1) Several titles explicitly violate the 'AND' rule — 'Prova direta e prova indireta', 'Fonte de prova e meio de prova', 'Relevância e admissibilidade da prova', 'Ônus da prova como regra de conduta e de julgamento', 'Inversão legal versus inversão judicial do ônus'; (2) Some descriptions use forbidden language — 'Limitações à exclusão da prova derivada ilícita' combines three theories in one lesson; (3) The lesson count (41) is on the lower end for a chapter this complex — the prompt asks for extensive coverage and suggests 100+ for complex topics; (4) Statistical proof section is relatively thin (only about 7 lessons); (5) Presumptions could be broken down further; (6) Some descriptions are slightly longer than ideal. The multiple 'and'/'versus' violations are a significant problem.",
          "score": 6
        },
        {
          "anonymousId": "Model A",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Model A provides 41 lessons with reasonable coverage. Strengths: (1) Covers all main areas; (2) Generally single-concept focused; (3) Good coverage of statistical concepts including prosecutor's fallacy, base rate fallacy, conditional probability; (4) Clean descriptions. Issues: (1) Title 'Fatos relevantes versus fatos controvertidos' uses 'versus' which should be split; (2) Only 41 lessons — not extensive enough for the chapter's complexity; (3) Presumptions section is relatively thin; (4) No coverage of dynamic distribution of burden of proof — a major omission since the chapter description includes burden distribution; (5) No lesson on prova diabólica or non liquet; (6) Some areas could be more granular — e.g., the burden of proof section has only about 6-7 lessons; (7) Missing coverage of conventions on burden of proof; (8) The lesson 'Prova documental eletrônica — autenticidade' feels somewhat out of scope given neighboring chapter on perícias. Overall adequate but lacks the extensiveness and completeness required.",
          "score": 5.8
        },
        {
          "anonymousId": "Model E",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Model E provides only 30 lessons, which is the least extensive of all models. Strengths: (1) Clean, focused titles; (2) Good logical progression; (3) Single-concept focus is generally maintained; (4) Covers all major areas at a high level. Issues: (1) Far too few lessons — 30 is inadequate for a complex chapter, especially when the prompt explicitly asks for extensive coverage and suggests 100+; (2) Statistical proof has only 4 lessons — grossly insufficient for a topic explicitly in the chapter description; (3) Presumptions have only 5 lessons — could be more granular; (4) Missing many important sub-topics: no prova diabólica, no dynamic distribution details, no conventions on burden, no Blue Bus paradox, no Bayes theorem, no base rate fallacy (only prosecutor's fallacy); (5) No lesson on prova ilícita or related concepts; (6) Descriptions use 'A' at the beginning of many descriptions which is slightly formulaic; (7) Overall lacks depth and breadth required by the prompt.",
          "score": 5
        },
        {
          "anonymousId": "Model D",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Model D provides only 25 lessons, which is the shortest list by far. Strengths: (1) Titles are clean and focused; (2) Covers the main topics at a surface level; (3) No 'and'/'or'/'vs' violations. Issues: (1) Extremely insufficient number of lessons — 25 is far below what's needed for comprehensive coverage, especially when the prompt asks for 100+ for complex topics; (2) Many critical sub-topics are missing: no coverage of prova ilícita, prova direta/indireta, prova emprestada, relevância/admissibilidade details, prova diabólica, non liquet, dynamic distribution details, conventions on burden, base rate fallacy, conditional probability, likelihood ratio, confidence intervals, or many other standard topics; (3) Standards section has only 5 lessons; (4) Burden section has about 10 lessons but lacks granularity on dynamic distribution; (5) Presumptions have only 4 lessons; (6) Statistical proof has only 5 lessons — very thin; (7) 'Inversão do Ônus no Direito do Consumidor' combines hipossuficiência and verossimilhança which should be separate; (8) Overall fails to meet the extensiveness requirement significantly.",
          "score": 4
        }
      ]
    },
    {
      "judgeId": "google/gemini-3.1-pro-preview",
      "rankings": [
        {
          "anonymousId": "Model B",
          "modelId": "openai/gpt-5.2:high",
          "reasoning": "Model B provides an exceptional and highly extensive list (100 lessons) that perfectly captures the required granularity. It strictly follows all negative constraints: there are no 'e', 'ou', 'vs', or 'versus' in any of the titles, and it avoids all fluff words in the descriptions. The progression is highly logical and breaks down complex statistical and evidential concepts into precise, single-concept micro-lessons.",
          "score": 10
        },
        {
          "anonymousId": "Model E",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Model E successfully follows the negative constraints, avoiding forbidden words in titles and descriptions while ensuring lessons are focused on single concepts. However, with only 30 lessons, it is significantly less extensive than requested, especially for a chapter containing such complex legal and statistical topics.",
          "score": 7.5
        },
        {
          "anonymousId": "Model D",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Model D also follows the formatting rules and negative constraints beautifully. Like Model E, its main weakness is the lack of depth and extensiveness (only 25 lessons), which falls short of the prompt's instruction to provide an extensive list.",
          "score": 7.5
        },
        {
          "anonymousId": "Model G",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Model G provides a very extensive list (104 lessons). However, it violates a negative constraint by including 'e' in a title ('Boa-fé e ônus dinâmico'). Furthermore, it fails to provide uniquely descriptive titles for several lessons, repeating generic titles like 'Presunção' (5 times) and 'Dúvida razoável' (2 times) for completely different concepts.",
          "score": 6
        },
        {
          "anonymousId": "Model A",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Model A failed to follow the critical negative constraint regarding titles. It includes several titles with 'e' and 'versus' (e.g., 'Fatos relevantes versus fatos controvertidos', 'Significância estatística e margem de erro'), showing an inability to properly split those concepts as instructed.",
          "score": 4
        },
        {
          "anonymousId": "Model C",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Model C repeatedly failed the critical negative constraint for titles, using 'e' and 'versus' across multiple lessons (e.g., 'Prova direta e prova indireta', 'Fonte de prova e meio de prova', 'Inversão legal versus inversão judicial do ônus').",
          "score": 4
        },
        {
          "anonymousId": "Model F",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Model F also ignored the critical constraint against using conjunctions in titles, grouping multiple concepts together with 'e' (e.g., 'Meios, fontes e elementos de prova', 'Ônus subjetivo e ônus objetivo', 'Presunções legais e presunções judiciais').",
          "score": 4
        }
      ]
    },
    {
      "judgeId": "openai/gpt-5.2",
      "rankings": [
        {
          "anonymousId": "Model B",
          "modelId": "openai/gpt-5.2:high",
          "reasoning": "Mais aderente ao escopo e às regras: lista extensa e bem granular, separa claramente standards de prova de ônus (com subdivisões úteis como regra de julgamento/conduta), detalha inversão/dinamização (inclusive contraditório e momento), quebra presunções em conceitos individuais (legal/judicial, relativas/absolutas, prova em contrário, máximas de experiência) e cobre prova estatística com muitos microconceitos (taxa-base, p-valor, erros tipo I/II etc.) sem virar um capítulo de perícias. Também evita títulos com “e”/“versus” em geral. Pequenas derrapagens: entra em temas de tutela de urgência (fumus boni iuris/probabilidade do direito) que podem ser limítrofes ao capítulo e não cobre “cada tipo de prova” de forma tão explícita (testemunhal/documental/confissão) quanto o esperado, mas ainda é o melhor conjunto.",
          "score": 9.2
        },
        {
          "anonymousId": "Model A",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Boa cobertura do núcleo do capítulo (standards, ônus, inversão, presunções, prova estatística) e inclui alguns tipos de prova (testemunhal, documental, confissão, direta/indiciária). Granularidade razoável em estatística (razão de verossimilhança, falácias, significância). Porém viola regras de títulos (“versus” em título; uso de “—” ok, mas “versus” é explicitamente gatilho para split) e não é “extenso” (bem menos do que o esperado de >100 lições). Também inclui “Prova documental eletrônica — autenticidade”, que tende a expandir para prova digital (não descrita no escopo) e pode invadir outros conteúdos. Presunções estão ok, mas poderiam ser mais atomizadas.",
          "score": 7.6
        },
        {
          "anonymousId": "Model G",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Extremamente extenso e bastante granular, especialmente em prova estatística (muitos microconceitos). Parte de standards/ônus/presunções também é detalhada. Problemas relevantes: muitos títulos repetidos (“Presunção”, “Dúvida razoável”) e alguns desalinhamentos título-descrição (ex.: primeira lição tem descrição de conceito de prova, mas título “Fato controvertido”). Há várias lições com escopo excessivamente técnico/estatístico (regressões, overfitting, validação cruzada, explicabilidade) que parecem extrapolar “teoria geral da prova” e se aproximam de ciência de dados/perícia, contrariando o foco e a vizinhança de “Perícias e prova técnica”. Também não trata tipos de prova clássicos (testemunhal, documental etc.).",
          "score": 7.1
        },
        {
          "anonymousId": "Model F",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Cobre standards, ônus, inversão, presunções e prova estatística, com alguns complementos (comunhão/aquisição processual, poderes instrutórios). Contudo, várias lições são amplas demais e frequentemente combinam múltiplos conceitos em um título com “e” (“Meios, fontes e elementos de prova”; “Verdade formal e verdade real”; “Fatos notórios, fatos incontroversos e…”) contrariando a regra de single-concept e o gatilho de split por “AND/OR/VS”. Inclui “Prova de DNA e probabilidades”, que vira tema de prova técnica/pericial (capítulo vizinho). Também não é tão extenso quanto o esperado.",
          "score": 6.4
        },
        {
          "anonymousId": "Model C",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Cobertura razoável dos tópicos centrais (standards, ônus, inversão, presunções, estatística) e inclui aspectos como prova emprestada e frutos da árvore envenenada. Porém é pouco granular: várias lições agregam múltiplos conceitos (\"Prova direta e prova indireta\"; \"Ônus da prova como regra de conduta e de julgamento\"; \"Relevância e admissibilidade da prova\"). Usa “versus” em título e algumas formulações mais “aula ampla”. Também é curta para o requisito de ser “extensiva” e não atende “cada tipo de prova individualmente”.",
          "score": 6
        },
        {
          "anonymousId": "Model E",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Organiza o básico (conceito/finalidade/objeto, ônus, standards, presunções, prova estatística) e mantém linguagem PT-BR. Mas é pouco extenso e pouco granular; vários itens ficam genéricos e alguns deslizam para linguagem menos precisa (“convencimento psicológico”). Não cobre tipos de prova individualmente e a parte de prova estatística é superficial. No geral, insuficiente para “extensive list” e para decomposição em microlições.",
          "score": 5.6
        },
        {
          "anonymousId": "Model D",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Muito curto e incompleto: foca quase só em standards/ônus/presunções/estatística de modo alto nível, sem granularidade e sem cobertura ampla do capítulo. Não atende a exigência de lista extensa, não cobre tipos de prova individualmente, e várias descrições ficam genéricas. Embora não invada capítulos vizinhos, falha fortemente em completude e microsegmentação.",
          "score": 4.3
        }
      ]
    }
  ],
  "taskId": "chapter-lessons",
  "testCaseId": "pt-direito-teoria-geral-da-prova-1"
}
