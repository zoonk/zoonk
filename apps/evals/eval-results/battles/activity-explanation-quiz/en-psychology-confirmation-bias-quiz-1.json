{
  "expectations": "\nSPECIAL CONSIDERATION: This is an edge case - an abstract psychological concept where understanding means recognizing the bias in everyday situations.\n\nTOPIC-SPECIFIC GUIDANCE:\n\n1. APPLICATION CHECK:\n   - GOOD PATTERN: Everyday scenarios where learners must recognize confirmation bias operating in someone's reasoning\n   - GOOD PATTERN: Situations requiring understanding of WHY the bias is unconscious and hard to overcome\n   - BAD PATTERN: Asking to define confirmation bias or list its characteristics without application context\n   - BAD PATTERN: Questions about the sports fan or political supporter examples from the explanation\n\n2. ACCURACY PITFALLS - Penalize if any of these are stated or implied:\n   - Confirmation bias being intentional deception (it's usually unconscious)\n   - Only unintelligent people having confirmation bias (everyone is susceptible, including experts)\n   - Confirmation bias being easy to overcome once you know about it (awareness helps but doesn't eliminate it)\n   - Confirmation bias only affecting beliefs about facts (it affects emotional and value-based beliefs too)\n\n3. FORMAT FIT: Multiple choice excels here - present scenarios and ask which demonstrates the bias. Match columns could connect cognitive biases to example scenarios. AVOID sort_order as the concept isn't sequential.\n\n\nEVALUATION CRITERIA:\n\n1. UNDERSTANDING OVER MEMORIZATION: Questions must test conceptual understanding, not recall. A learner who understood the concept but never read this specific explanation should be able to answer correctly. Penalize questions that:\n   - Use phrases like \"according to the text,\" \"as described,\" or \"the explanation said\"\n   - Reference specific metaphors, analogies, or examples from the explanation steps\n   - Ask \"what is X?\" instead of \"what would happen if...\" or \"which scenario shows...\"\n\n2. APPLICATION TO NOVEL SCENARIOS: Questions should present concepts in new contexts the learner hasn't seen. The scenario in the question should be different from any examples in the explanation steps. Penalize questions that:\n   - Reuse scenarios from the explanation\n   - Ask about facts that could only be known by reading this specific text\n   - Test vocabulary definitions rather than concept application\n\n3. FORMAT APPROPRIATENESS: Evaluate whether the chosen format genuinely tests understanding.\n\n   ANTI-PATTERN - \"Forced variety\": Using different formats just for variety is a serious flaw. Multiple well-crafted questions of the same format are better than poorly-suited formats used for variety's sake. Do NOT penalize for using multiple choice repeatedly if it tests the concepts well.\n\n   Format guidance:\n   - Multiple choice: Often the BEST choice, not just a \"default.\" It excels at testing whether learners can apply concepts to novel scenarios. Use it freely.\n   - Match columns: Best when the concept involves connecting observations to principles (symptoms to causes, effects to mechanisms).\n   - Sort order: ONLY when the concept IS about sequence — when order matters conceptually (biological processes, compilation phases).\n   - Fill blank: Best for completing relationships or processes where the blank tests conceptual understanding.\n   - Select image: ONLY when visual recognition genuinely tests understanding.\n\n   PENALIZE when:\n   - Formats are used for variety rather than fit\n   - A different format would clearly test the concept better\n\n   Do NOT penalize when:\n   - Multiple choice is used repeatedly across several questions\n   - Some available formats are not used at all\n   - The quiz sticks to one or two well-suited formats\n\n4. FEEDBACK QUALITY: Feedback must explain reasoning, not just state correct/incorrect. Good feedback:\n   - For correct answers: Explains WHY it's right plus an additional insight\n   - For incorrect answers: Explains WHY it's wrong AND why the correct answer is right\n   Penalize feedback that only says \"Correct!\" or \"That's wrong.\"\n\n5. FACTUAL ACCURACY: All questions and answers must be scientifically/technically correct. Penalize:\n   - Incorrect facts presented as correct answers\n   - Correct facts marked as incorrect\n   - Misleading simplifications that create misconceptions\n\n6. QUESTION CLARITY: Questions must be unambiguous with a conversational tone. Penalize:\n   - Academic or formal phrasing\n   - Ambiguous scenarios where multiple answers could be valid\n   - Trick questions designed to confuse rather than test understanding\n\n7. APPROPRIATE DIFFICULTY: Questions should challenge understanding without being unfair. Penalize:\n   - Trivially easy questions anyone could guess\n   - Questions requiring knowledge beyond the lesson scope\n   - Trick questions that test careful reading rather than comprehension\n\nANTI-CHECKLIST GUIDANCE (CRITICAL):\n- Do NOT penalize for missing specific question formats you might expect\n- Do NOT require a specific number of questions - quality matters more than quantity\n- Do NOT check against an imagined \"complete\" quiz you think should exist\n- Do NOT penalize for covering some concepts more than others if coverage is reasonable\n- Do NOT expect questions to follow any particular order or progression\n- ONLY penalize for: memorization-based questions, factual errors, poor feedback quality, unclear wording, or inappropriate format choices\n- Different valid quiz designs exist - assess the quality of what IS provided\n\n    ",
  "judgedAt": "2026-02-21T23:46:26.011Z",
  "judgments": [
    {
      "judgeId": "anthropic/claude-opus-4.6",
      "rankings": [
        {
          "anonymousId": "Model C",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Excellent quiz overall. 7 questions with strong variety of well-suited formats. All multiple choice questions present novel, richly detailed scenarios (Maria/neighborhood safety, basketball fans, pharma blinding, Devon/tech luck, friend's willpower approach). The scenarios are vivid and conversational, with detailed context that makes the bias recognizable. Feedback is consistently excellent — every option gets a thorough explanation of WHY it's right or wrong, often with additional insight (e.g., 'It's like trying to willpower your way out of an optical illusion'). The match columns format is perfectly suited, connecting diverse scenarios to specific aspects of confirmation bias. The fill-blank question tests conceptual understanding of the mechanism (unconsciously, discomfort, external) rather than vocabulary recall. Key accuracy points are all correct: bias is unconscious, affects everyone including experts, awareness alone doesn't eliminate it. The 'willpower' question directly tests a common misconception. The only minor weakness is that the basketball scenario somewhat mirrors a common textbook example (sports fans watching a game), but the specific framing with Jake and Lisa is sufficiently novel. No sort_order used, which is good given the guidance that the concept isn't inherently sequential. Conversational tone throughout.",
          "score": 9.2
        },
        {
          "anonymousId": "Model B",
          "modelId": "anthropic/claude-sonnet-4.5",
          "reasoning": "Very strong quiz with 8 well-crafted questions. Excellent novel scenarios: Maya/organic food, James/investment, pharma blinding, political debate, detective Lisa. All test application of confirmation bias in diverse contexts. Feedback quality is outstanding — detailed, explains the 'why' thoroughly, and adds insight. The detective question brilliantly tests that even experts are susceptible. The fill-blank tests key conceptual elements (discomfort, consistency, selective, automatically) — all accurate and meaningful. The sort_order question is used, which the guidelines say to avoid for non-sequential concepts, but the sequence described (belief → encounter info → discomfort → filtering → reinforcement) is a reasonable cognitive process that has a logical order, so this is a minor issue rather than a major one. The match columns format is well-suited with diverse scenarios. One concern: the political debate scenario (two people watching the same event and coming away with opposite impressions) is a fairly standard textbook example of confirmation bias, though it uses novel characters. Also, the sports fan scenario in the match columns ('A loyal sports fan notices more fouls by the opposing team') echoes common explanation examples, which the guidelines say to avoid. Minor deduction for that.",
          "score": 8.9
        },
        {
          "anonymousId": "Model G",
          "modelId": "openai/gpt-5.2:high",
          "reasoning": "Strong quiz with 6 questions (5 MC + 1 match columns). Novel scenarios are well-crafted: supplement/sleep, unsafe neighborhood walk, soccer match fans, supervisor/remote workers, clinic pain medication. Each scenario is detailed enough to clearly illustrate the bias. Feedback is good — explains why correct and incorrect, though slightly less detailed than Models B and C. The match columns format is well-used with excellent pairs. The neighborhood scenario is creative and tests selective attention nicely. The supervisor question about uneven recall is a particularly good novel scenario. No sort_order used (appropriate). One minor issue: the soccer match scenario is very similar to the sports fan example that is commonly used in explanations of confirmation bias, though it's presented with enough novelty. All accuracy points are correct: unconscious nature emphasized, experts susceptible, not deliberate. Feedback could be slightly more expansive in places (e.g., 'Wrong. Random chance doesn't explain...' is adequate but could add more insight).",
          "score": 8.5
        },
        {
          "anonymousId": "Model K",
          "modelId": "anthropic/claude-opus-4.5",
          "reasoning": "Strong quiz with 7 questions covering diverse scenarios. Maya/electric cars, basketball fans (Tom/Sarah), pharma blinding, hiring manager, and Jamie's willpower approach are all good novel scenarios. The Jamie question about whether awareness alone can overcome bias is excellent and tests a key misconception. Feedback is thorough and well-constructed. The fill-blank tests conceptual understanding well (discomfort, selective, filtering, automatically). Match columns are well-suited with diverse pairs. However, the basketball fan scenario (Lakers vs. Celtics) is somewhat close to a standard sports fan example that might appear in explanations. The hiring manager question appears twice in slightly different forms (questions 4 and 5 both involve hiring managers with biased beliefs), which reduces variety. The sort_order format is not used (appropriate). Overall very solid but slightly less varied in scenarios than the top models.",
          "score": 8.4
        },
        {
          "anonymousId": "Model D",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Good quiz with 6 questions. Novel scenarios include: Maya/unreliable coworker, Jordan/standing desk, soccer fans, lab pain therapy, plus match columns. The standing desk scenario is creative and tests how discomfort drives dismissal of evidence. Feedback is good but somewhat more concise than the top models — still explains why each option is right/wrong but with less additional insight. The sort_order question is used with only 4 items and represents a reasonable cognitive sequence, which is acceptable. The soccer match scenario is a common example type. Match columns are well-constructed. One concern: the coworker scenario options include 'cognitive dissonance' as a distractor, which is closely related to confirmation bias, making the distinction potentially confusing for learners. Overall solid but slightly less polished in feedback depth and scenario creativity compared to Models B, C, and G.",
          "score": 8
        },
        {
          "anonymousId": "Model E",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Good but smaller quiz with only 4 questions. The scenarios are well-crafted: Maya/Carlos reading same article, doctor with rare condition hunch, researcher with tutoring program, and a sort_order sequence. The doctor scenario is excellent — tests that experts are susceptible and the unconscious nature. Feedback quality is strong with good explanations. The sort_order has 5 well-ordered steps and reasonable justification. However, only 4 questions feels thin for covering confirmation bias comprehensively — there's no match columns or fill-blank, and only MC + sort_order are used. While the guidelines say not to penalize for quantity, the limited coverage means some important aspects (like the difficulty of overcoming bias through awareness alone) aren't tested. All accuracy points in the existing questions are correct.",
          "score": 7.6
        },
        {
          "anonymousId": "Model H",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Decent quiz with 5 questions across 4 formats. The movie critic scenario is creative and novel — reframing flaws as strengths based on existing beliefs. The hiring manager/Ivy League scenario is good. The fill-blank (automatically/deliberately) is simple but tests a key concept. The sort_order with Brand A coffee is well-structured. Match columns are adequate. However, the sports fan example in match columns ('A sports fan only remembers the times the referee made a bad call against their favorite team') directly uses a scenario type the guidelines say to avoid (from the explanation). The fill-blank has only two blanks, making it quite simple. Feedback is adequate but could be more detailed in places — some explanations are brief. The match columns use abstract labels ('Selective Attention,' 'Safeguards,' etc.) rather than descriptive phrases, which tests vocabulary more than understanding. Overall decent but has more weaknesses than the top models.",
          "score": 7.2
        },
        {
          "anonymousId": "Model A",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Mixed quality quiz with 6 questions. Some good elements: the brand loyalty/reviews scenario is novel, the double-blind trial question is solid. However, several issues: (1) The first question essentially asks to identify which bias is being demonstrated from a list — this is more identification/recall than application. (2) The second question asks 'Which is NOT confirmation bias?' without a scenario context, making it more definitional. (3) The match columns include a sports fan scenario ('A loyal sports fan notices more fouls by the opposing team') which the guidelines specifically say to avoid as it likely mirrors explanation examples. (4) The sort_order is used despite guidelines warning against it for non-sequential concepts. (5) The fill-blank about 'blind procedures' and 'peer review' tests specific safeguard vocabulary rather than conceptual understanding. (6) Some feedback is good but the overall design leans more toward identification and recall than deep application to novel scenarios.",
          "score": 6.5
        },
        {
          "anonymousId": "Model L",
          "modelId": "openai/gpt-5.1-instant",
          "reasoning": "Adequate but notably weak quiz with only 4 questions. Major issues: (1) Scenarios are very thin and lack detail — they feel like brief descriptions rather than rich, engaging scenarios. (2) Feedback is minimal — often just one sentence that states why something is right/wrong without deeper insight (e.g., 'Critical thinking would involve checking the source, which they did not do.'). (3) The basketball fan scenario uses the sports fan example type warned against. (4) Distractors in some questions are weak and easily eliminated (FOMO, anchoring for a bias question feels like a vocabulary test). (5) The questions are quite surface-level — they test recognition of confirmation bias more than deep understanding of its mechanisms. (6) No variety in format beyond multiple choice, though this alone wouldn't be penalized if the MC questions were stronger. The correct answers sometimes just name the bias ('They're relying on confirmation bias') rather than describing the mechanism.",
          "score": 5
        },
        {
          "anonymousId": "Model J",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Only 1 question, which severely limits coverage. The single question is decent — Maya's water/skin belief with a well-constructed scenario and good feedback. It correctly emphasizes the unconscious nature and mental discomfort. But a single question cannot adequately assess understanding of confirmation bias. No coverage of selective attention, safeguards, expert susceptibility, or difficulty of overcoming bias.",
          "score": 3.5
        },
        {
          "anonymousId": "Model I",
          "modelId": "xai/grok-4.1-fast-reasoning",
          "reasoning": "Only 1 question, limiting coverage significantly. The coffee/heart health scenario is reasonable and the feedback correctly identifies the unconscious nature. However, the feedback mentions 'cognitive dissonance' which, while related, introduces a different concept without adequate explanation. The distractor options are somewhat weak ('You're too busy to read the full study'). Like Model J, a single question cannot cover the concept adequately.",
          "score": 3.3
        },
        {
          "anonymousId": "Model F",
          "modelId": "google/gemini-3-pro-preview",
          "reasoning": "Only 1 question, and it has a critical formatting/technical error: the question text contains what appears to be corrupted/garbled text ('} দাঁড়িয়েPhul:default_api:fillBlank{answers:[\"') suggesting a generation failure. The scenario itself (TechBrand X phone crashes) is reasonable but the corruption is a serious quality issue. The feedback is adequate but brief. The corrupted output alone warrants a significant penalty.",
          "score": 1.5
        }
      ]
    },
    {
      "judgeId": "google/gemini-3.1-pro-preview",
      "rankings": [
        {
          "anonymousId": "Model C",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Model C provides an outstanding set of questions. The feedback is exceptionally conversational, engaging, and deeply explains both why the correct answers are right and why the distractors are wrong. It perfectly captures the requirement to test why the bias is unconscious and hard to overcome (especially in the 'willpower' question). It loses a fraction of a point only for including one sports fan example, which was explicitly listed as a bad pattern.",
          "score": 9
        },
        {
          "anonymousId": "Model J",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Model J provides only a single question, but it is flawlessly executed. It completely avoids the forbidden sports/politics examples, substituting a novel scenario about skincare and water consumption. The options are well-crafted to test the psychological discomfort of contradictory evidence, and the feedback adds excellent insight.",
          "score": 8.8
        },
        {
          "anonymousId": "Model K",
          "modelId": "anthropic/claude-opus-4.5",
          "reasoning": "Model K is very similar to Model C in structure and quality. It successfully avoids the 'sort_order' trap, correctly targets the unconscious nature of the bias, and provides detailed feedback for all options. Like Model C, it receives a minor penalty for including a sports fan example.",
          "score": 8.5
        },
        {
          "anonymousId": "Model I",
          "modelId": "xai/grok-4.1-fast-reasoning",
          "reasoning": "Model I provides a single question. The scenario is novel and completely avoids the negative constraints. However, the feedback relies on the repetitive 'Correct!' / 'Wrong.' structure, which is less engaging and explicitly discouraged in the guidelines.",
          "score": 7.5
        },
        {
          "anonymousId": "Model G",
          "modelId": "openai/gpt-5.2:high",
          "reasoning": "Model G correctly avoids the inappropriate 'sort_order' format. It provides solid scenarios but includes the forbidden sports fan example. The feedback, while accurate, is somewhat formulaic and less insightful than the top models.",
          "score": 6.8
        },
        {
          "anonymousId": "Model L",
          "modelId": "openai/gpt-5.1-instant",
          "reasoning": "Model L avoids the 'sort_order' format but relies on the sports fan example. Its primary weakness is the feedback, which is extremely brief and fails to provide the additional insights requested in the prompt.",
          "score": 6
        },
        {
          "anonymousId": "Model A",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Model A is penalized for explicitly violating two negative constraints: it uses the 'sort_order' format (which the prompt specifically warned against because the concept isn't sequential) and it includes the sports fan example.",
          "score": 5
        },
        {
          "anonymousId": "Model D",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Like Model A, Model D is penalized for ignoring format appropriateness by using 'sort_order' to force variety, and for relying on the sports fan example.",
          "score": 5
        },
        {
          "anonymousId": "Model B",
          "modelId": "anthropic/claude-sonnet-4.5",
          "reasoning": "Model B violated multiple explicit constraints. It used the forbidden 'sort_order' format, and it included BOTH the sports referee and political debate examples that were strictly designated as bad patterns.",
          "score": 4.5
        },
        {
          "anonymousId": "Model E",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Model E violated negative constraints by using the 'sort_order' format and relying on the political supporter example. It also provided fewer questions than similar models.",
          "score": 4.5
        },
        {
          "anonymousId": "Model H",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Model H is heavily penalized for using the 'sort_order' format and the sports fan example. Additionally, its feedback is quite brief compared to the prompt's standards.",
          "score": 4.5
        },
        {
          "anonymousId": "Model F",
          "modelId": "google/gemini-3-pro-preview",
          "reasoning": "Model F completely fails the task. The output contains a major generation artifact and garbage text mixed into the JSON values (e.g., '} দাঁড়িয়েPhul:default_api:fillBlank{answers:['). This makes it unacceptable.",
          "score": 1
        }
      ]
    },
    {
      "judgeId": "openai/gpt-5.2",
      "rankings": [
        {
          "anonymousId": "Model B",
          "modelId": "anthropic/claude-sonnet-4.5",
          "reasoning": "Consistently application-focused with novel everyday/professional scenarios (food, investing, pharma trial, debate, detective). Explicitly treats the bias as unconscious, universal (not about intelligence), and hard to overcome; includes good external-safeguard examples. Feedback is strong for both correct and incorrect options, explaining why. Formats used (mostly MC, plus match/fill/sort) generally fit and aren’t just definitional.",
          "score": 9.6
        },
        {
          "anonymousId": "Model K",
          "modelId": "anthropic/claude-opus-4.5",
          "reasoning": "High-quality set with varied, relevant scenarios (EVs, sports, pharma trial, hiring, willpower-overcoming). Avoids major accuracy pitfalls and directly addresses unconscious nature and limits of willpower. Feedback is generally explanatory. Minor issues: one option frames source-dismissal as “logical decision” a bit awkwardly; overall somewhat longer than needed but still clear and accurate. Good use of match/fill in support of application.",
          "score": 9.2
        },
        {
          "anonymousId": "Model G",
          "modelId": "openai/gpt-5.2:high",
          "reasoning": "Strong applied multiple-choice set with clear, novel scenarios and good emphasis on automaticity, sincerity (not lying), and external checks (blinding/independent review, devil’s advocate). Feedback is solid and contrasts against debiasing behaviors. Slight repetitiveness and some options read more like labels than actions (e.g., an option that is essentially a definition), but overall tests recognition well.",
          "score": 8.9
        },
        {
          "anonymousId": "Model C",
          "modelId": "anthropic/claude-opus-4.6",
          "reasoning": "Good everyday contexts and generally excellent feedback that highlights unconscious filtering and why willpower alone fails. Includes both everyday and research safeguards; matchColumns is well-constructed. Weakness: uses a sports-fan example (explicitly discouraged by the prompt guidance) and one item risks sounding like “refereeing is subjective” could make multiple interpretations feel plausible, though the keyed answer remains best.",
          "score": 8.5
        },
        {
          "anonymousId": "Model D",
          "modelId": "openai/gpt-5.2",
          "reasoning": "Clear, application-based questions with decent feedback and good coverage of selective attention/memory and safeguards. Avoids major misconceptions (explicitly not deliberate deception). Main drawbacks: feedback is briefer/less insightful than top models, and the standing-desk scenario brushes close to sunk-cost/choice-justification (though it correctly keys confirmation-bias mechanism). SortOrder included; sequence is plausible but not essential for this concept.",
          "score": 8.1
        },
        {
          "anonymousId": "Model A",
          "modelId": "openai/gpt-5-mini",
          "reasoning": "Several strong items (brand reviews, NOT-an-example item, safeguards MC). Feedback is mostly good. However: includes sortOrder (discouraged for this concept) and the matchColumns includes a sports-fan example (explicitly flagged as “BAD PATTERN”). FillBlank answer set (“blind”, “peer review”) is a bit imprecise (typically “blinding/double-blind” and “peer review”), and distractors make it somewhat guessy.",
          "score": 7.6
        },
        {
          "anonymousId": "Model E",
          "modelId": "anthropic/claude-sonnet-4.6",
          "reasoning": "Accurate and clear with decent feedback and scenarios, but too short/narrow (only 4 items) and includes a sortOrder despite guidance to avoid it here. Less explicit emphasis on universality/unconsciousness and on why it’s hard to overcome compared with stronger sets.",
          "score": 7.4
        },
        {
          "anonymousId": "Model H",
          "modelId": "google/gemini-3-flash",
          "reasoning": "Mostly application-based with decent feedback, and it addresses non-deliberateness. Weaknesses: several items drift toward generic labeling rather than forcing discrimination among close alternatives; matchColumns uses vague category labels (e.g., “Selective Attention”) without requiring much reasoning. FillBlank contrasts “automatically” vs “deliberately” is fine but a bit simplistic. Some scenarios (hiring manager) blend stereotyping/halo effects with confirmation bias without clarifying enough.",
          "score": 7
        },
        {
          "anonymousId": "Model L",
          "modelId": "openai/gpt-5.1-instant",
          "reasoning": "Generally accurate, but items are shallow and sometimes borderline definitional (e.g., option text explicitly says “relying on confirmation bias”). Feedback is minimal and often just restates correctness. Scenarios are less novel/specific, making questions easier/guessable and less diagnostic of understanding.",
          "score": 6.2
        },
        {
          "anonymousId": "Model J",
          "modelId": "google/gemini-3.1-pro-preview",
          "reasoning": "Single-question output. While the scenario is fine and feedback addresses discomfort and non-deliberate nature, it provides very limited assessment coverage and no opportunity to test recognition across contexts. Too little to meet the spirit of the task.",
          "score": 5.8
        },
        {
          "anonymousId": "Model I",
          "modelId": "xai/grok-4.1-fast-reasoning",
          "reasoning": "Only one question; although it’s broadly accurate, the correct option explanation leans heavily on “cognitive dissonance” framing and doesn’t strongly test recognition among close behavioral alternatives. Insufficient breadth and depth for assessing understanding.",
          "score": 5.4
        },
        {
          "anonymousId": "Model F",
          "modelId": "google/gemini-3-pro-preview",
          "reasoning": "Corrupted/incomplete question text (includes stray characters and what looks like formatting leakage), making it unusable. Only one item and the prompt is malformed, which is a major quality failure for a learning app despite the underlying idea being reasonable.",
          "score": 1.5
        }
      ]
    }
  ],
  "taskId": "activity-explanation-quiz",
  "testCaseId": "en-psychology-confirmation-bias-quiz-1"
}
